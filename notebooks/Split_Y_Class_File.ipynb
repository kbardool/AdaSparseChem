{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4d685f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T18:23:08.519624Z",
     "start_time": "2022-04-05T18:23:08.490402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cace61eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T18:23:08.545223Z",
     "start_time": "2022-04-05T18:23:08.525186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if ('..' not in sys.path):\n",
    "    sys.path.append('..')\n",
    "\n",
    "print(len(sys.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cd2d1de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T18:23:08.891926Z",
     "start_time": "2022-04-05T18:23:08.550092Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "# import sparsechem as sc\n",
    "import numpy as np\n",
    "import string\n",
    "import glob\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "import argparse\n",
    "# from urllib.request import urlretrieve\n",
    "# import torch \n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch.optim.lr_scheduler import MultiStepLR\n",
    "# from torchinfo import summary\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import pprint\n",
    "import time\n",
    "# from sparsechem.utils import training_arguments, load_task_weights\n",
    "# from GPUtil import showUtilization as gpu_usage\n",
    "from datetime import datetime\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "994fc053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T20:08:55.817498Z",
     "start_time": "2022-04-05T20:08:55.787058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_class shape          : (18388, 15)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# cmd = (\n",
    "#         f\" --x           /home/kbardool/WSL-projs/MLDatasets/chembl23_mini/chembl_23mini_x.npy\" +\n",
    "#         f\" --y_class     /home/kbardool/WSL-projs/MLDatasets/chembl23_mini/chembl_23mini_y.npy\" +\n",
    "#         f\" --folding     /home/kbardool/WSL-projs/MLDatasets/chembl23_mini/chembl_23mini_folds.npy\" +\n",
    "#         f\" --fold_inputs 32000\" +\n",
    "#         f\" --output_dir  /home/kbardool/WSL-projs/MLDatasets/chembl23_mini_5tasks\" +\n",
    "#         f\" --hidden_sizes 1000 1000 1000 5\" )\n",
    "\n",
    "# cmd = (\n",
    "#         f\" --y_class     /home/kbardool/WSL-projs/MLDatasets/chembl23_synthetic/chembl_23mini_adashare_y_all_bin_sparse\")\n",
    "# parser = training_arguments()        \n",
    "# args = parser.parse_args(cmd.split())\n",
    "\n",
    "y_class_path = \"/home/kbardool/WSL-projs/MLDatasets/chembl23_synthetic/chembl_23mini_adashare_y_all_bin_sparse.npy\"\n",
    "output_path  = \"/home/kbardool/WSL-projs/MLDatasets/chembl23_synthetic/\"\n",
    "\n",
    "# ecfp     = sc.load_sparse(args.x)\n",
    "y_class  = load_sparse(y_class_path)\n",
    "# y_regr   = sc.load_sparse(args.y_regr)\n",
    "# y_censor = sc.load_sparse(args.y_censor)\n",
    "print() \n",
    "# vprint(f\"ecfp shape             : {ecfp.shape}\")\n",
    "print(f\"y_class shape          : {y_class.shape}\")\n",
    "print(type(y_class))\n",
    "# vprint(f\"x shape                : {ecfp.shape}\")\n",
    "# vprint(f\"y_class shape          : {y_class.shape}\")\n",
    "# vprint(f\"y_regr shape           : {y_regr.shape}\")\n",
    "\n",
    "# vprint(f\"y_censor shape         : {y_censor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "66983fc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T19:00:37.778351Z",
     "start_time": "2022-04-05T19:00:37.754883Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "a = copy.copy(y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197073ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T18:23:32.413422Z",
     "start_time": "2022-04-05T18:23:32.396946Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80cfd20e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T19:00:39.549198Z",
     "start_time": "2022-04-05T19:00:39.525987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(18388, 15)\n",
      "{'_shape': (18388, 15), 'maxprint': 50, 'data': array([ 1,  1, -1, ...,  1, -1, -1]), 'indices': array([ 0,  1,  2, ..., 12, 13, 14], dtype=int32), 'indptr': array([     0,     15,     30, ..., 275790, 275805, 275820], dtype=int32)}\n",
      "(275820,)\n",
      " indices / cols :  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14  0  1  2  3  4  5  6  7  8\n",
      "  9 10 11 12 13 14  0  1]\n",
      "(18389,)\n",
      " indptr  :  [  0  15  30  45  60  75  90 105 120 135 150 165 180 195 210 225 240 255\n",
      " 270 285 300 315 330 345 360 375 390 405 420 435 450 465]\n",
      "(275820,)\n",
      "   data  :  [ 1  1 -1 -1 -1 -1  1 -1  1  1 -1  1  1 -1  1  1 -1  1 -1  1  1  1 -1 -1\n",
      " -1 -1  1 -1 -1 -1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "print(type(a) )\n",
    "\n",
    "print(a.shape )\n",
    "print(a.__dict__)\n",
    "print(a.indices.shape)\n",
    "print(' indices / cols : ',a.indices[:32])\n",
    "print(a.indptr.shape)\n",
    "print(' indptr  : ',a.indptr[:32])\n",
    "print(a.data.shape)\n",
    "print('   data  : ',a.data[:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d03eff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T18:45:00.078421Z",
     "start_time": "2022-04-05T18:45:00.059587Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/scipy/sparse/_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "a[2] = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126113ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1_sparse = scipy.sparse.csr_matrix(Y1_labels)\n",
    "Y2_sparse = scipy.sparse.csr_matrix(Y2_labels)\n",
    "Y3_sparse = scipy.sparse.csr_matrix(Y3_labels)\n",
    "print(type(Y1_sparse))\n",
    "print(type(Y2_sparse))\n",
    "print(type(Y3_sparse))\n",
    "\n",
    "np.save('./output/chembl_23mini_adashare_y1.npy', Y1_np)\n",
    "np.save('./output/chembl_23mini_adashare_y2.npy', Y2_np)\n",
    "np.save('./output/chembl_23mini_adashare_y3.npy', Y3_np)\n",
    "np.save('./output/chembl_23mini_adashare_y1_bin.npy', Y1_labels)\n",
    "np.save('./output/chembl_23mini_adashare_y2_bin.npy', Y2_labels)\n",
    "np.save('./output/chembl_23mini_adashare_y3_bin.npy', Y3_labels)\n",
    "np.save('./output/chembl_23mini_adashare_y1_bin_sparse.npy', Y1_sparse)\n",
    "np.save('./output/chembl_23mini_adashare_y2_bin_sparse.npy', Y2_sparse)\n",
    "np.save('./output/chembl_23mini_adashare_y3_bin_sparse.npy', Y3_sparse)\n",
    "\n",
    "tmp = np.load('./output/chembl_23mini_adashare_y1_bin_sparse.npy', allow_pickle=True).item().tocsr()\n",
    "print(type(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "99d37c09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T20:22:12.588498Z",
     "start_time": "2022-04-05T20:22:12.566804Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_csr_matrix_by_cols(mat, indices, pfx = ''):\n",
    "    start_ind = 0\n",
    "    sum = 0\n",
    "    for files, i in enumerate(col_split,1):\n",
    "        sum += i\n",
    "        if sum >= a.shape[1]:\n",
    "            break\n",
    "     \n",
    "    print(f\" column-wise splitting matrix of shape {mat.shape} into {files} files\")\n",
    "    for idx, end_ind in enumerate(indices,1):\n",
    "        stop_ind = min(start_ind+end_ind, mat.shape[1])\n",
    "        print(f\" place {stop_ind - start_ind} columns [{start_ind} : {stop_ind}] into file {idx}\")\n",
    "        tmp = mat[:, start_ind:stop_ind]\n",
    "        print(' tmp shape: ', tmp.shape)\n",
    "        fn = os.path.join(output_path, f\"chembl_23mini_adashare_y_[{start_ind}:{stop_ind}].npy\")\n",
    "        np.save(fn, tmp )\n",
    "        print(' written to : ', fn)\n",
    "        start_ind = stop_ind\n",
    "    if start_ind < mat.shape[1]:\n",
    "        idx+=1\n",
    "        print(f\" place columns [{start_ind} : {mat.shape[1]}] into file {idx}\")\n",
    "#         fn = os.path.join(output_path, f\"chembl_23mini_adashare_y{idx}_{stop_ind - start_ind}cols.npy\")        \n",
    "        fn = os.path.join(output_path, f\"chembl_23mini_adashare_y_[{start_ind}:{stop_ind}].npy\")\n",
    "        np.save(fn, tmp )                \n",
    "        print(' written to : ', fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "020d0a2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T20:55:50.235226Z",
     "start_time": "2022-04-05T20:55:50.180568Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " column-wise splitting matrix of shape (18388, 15) into 8 files\n",
      " place 2 columns [0 : 2] into file 1\n",
      " tmp shape:  (18388, 2)\n",
      " written to :  /home/kbardool/WSL-projs/MLDatasets/chembl23_synthetic/chembl_23mini_adashare_y_[0:2].npy\n",
      " place 2 columns [2 : 4] into file 2\n",
      " tmp shape:  (18388, 2)\n",
      " written to :  /home/kbardool/WSL-projs/MLDatasets/chembl23_synthetic/chembl_23mini_adashare_y_[2:4].npy\n",
      " place 2 columns [4 : 6] into file 3\n",
      " tmp shape:  (18388, 2)\n",
      " written to :  /home/kbardool/WSL-projs/MLDatasets/chembl23_synthetic/chembl_23mini_adashare_y_[4:6].npy\n",
      " place 2 columns [6 : 8] into file 4\n",
      " tmp shape:  (18388, 2)\n",
      " written to :  /home/kbardool/WSL-projs/MLDatasets/chembl23_synthetic/chembl_23mini_adashare_y_[6:8].npy\n",
      " place 2 columns [8 : 10] into file 5\n",
      " tmp shape:  (18388, 2)\n",
      " written to :  /home/kbardool/WSL-projs/MLDatasets/chembl23_synthetic/chembl_23mini_adashare_y_[8:10].npy\n",
      " place 2 columns [10 : 12] into file 6\n",
      " tmp shape:  (18388, 2)\n",
      " written to :  /home/kbardool/WSL-projs/MLDatasets/chembl23_synthetic/chembl_23mini_adashare_y_[10:12].npy\n",
      " place 2 columns [12 : 14] into file 7\n",
      " tmp shape:  (18388, 2)\n",
      " written to :  /home/kbardool/WSL-projs/MLDatasets/chembl23_synthetic/chembl_23mini_adashare_y_[12:14].npy\n",
      " place 1 columns [14 : 15] into file 8\n",
      " tmp shape:  (18388, 1)\n",
      " written to :  /home/kbardool/WSL-projs/MLDatasets/chembl23_synthetic/chembl_23mini_adashare_y_[14:15].npy\n"
     ]
    }
   ],
   "source": [
    "col_split =  [2, 2, 2, 2, 2, 2, 2, 1]\n",
    "# col_split =  [2,  2,11]\n",
    "# col_split =  [2, 13]\n",
    "split_csr_matrix_by_cols(a, col_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c98e7b61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T19:59:46.198453Z",
     "start_time": "2022-04-05T19:59:46.182249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 15\n"
     ]
    }
   ],
   "source": [
    "from itertools import accumulate\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "56769dab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T19:00:49.368102Z",
     "start_time": "2022-04-05T19:00:49.345590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1, -1, -1, -1, -1,  1, -1,  1,  1, -1,  1,  1, -1,  1],\n",
       "       [ 1, -1,  1, -1,  1,  1,  1, -1, -1, -1, -1,  1, -1, -1, -1],\n",
       "       [-1,  1, -1, -1,  1, -1, -1, -1,  1,  1, -1, -1, -1, -1,  1],\n",
       "       [ 1,  1, -1,  1,  1,  1,  1, -1, -1,  1, -1,  1,  1, -1, -1],\n",
       "       [ 1, -1, -1,  1, -1, -1,  1, -1,  1,  1,  1,  1, -1,  1, -1],\n",
       "       [ 1, -1, -1,  1,  1, -1,  1, -1,  1, -1,  1,  1,  1, -1, -1],\n",
       "       [-1, -1, -1,  1,  1, -1, -1,  1, -1, -1,  1,  1,  1, -1, -1],\n",
       "       [ 1,  1, -1,  1,  1,  1, -1,  1,  1,  1, -1, -1, -1,  1, -1],\n",
       "       [ 1,  1, -1, -1, -1, -1,  1, -1, -1,  1, -1, -1, -1,  1, -1],\n",
       "       [ 1, -1,  1,  1, -1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_array = a.toarray()\n",
    "\n",
    "a_array.shape\n",
    "\n",
    "a_array[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b458e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6a4862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3674e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe3021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7883044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T18:22:50.419638Z",
     "start_time": "2022-04-05T18:22:50.396260Z"
    }
   },
   "outputs": [],
   "source": [
    "def training_arguments():\n",
    "    parser = argparse.ArgumentParser(description=\"Training a multi-task model.\")\n",
    "    parser.add_argument(\"--x\"                 , help=\"Descriptor file (matrix market, .npy or .npz)\", type=str, default=None)\n",
    "    parser.add_argument(\"--y_class\", \"--y\", \"--y_classification\" \n",
    "                                              , help=\"Activity file (matrix market, .npy or .npz)\", type=str, default=None)\n",
    "    parser.add_argument(\"--y_regr\" , \"--y_regression\"\n",
    "                                              , help=\"Activity file (matrix market, .npy or .npz)\", type=str, default=None)\n",
    "    parser.add_argument(\"--y_censor\"          , help=\"Censor mask for regression (matrix market, .npy or .npz)\", type=str, default=None)\n",
    "    parser.add_argument(\"--batch_ratio\"       , help=\"Batch ratio\", type=float, default=0.02)\n",
    "    parser.add_argument(\"--censored_loss\"     , help=\"Whether censored loss is used for training (default 1)\", type=int, default=1)\n",
    "    parser.add_argument(\"--dev\"               , help=\"Device to use\", type=str, default=\"cuda:0\")\n",
    "    parser.add_argument(\"--epochs\"            , help=\"Number of epochs\", type=int, default=20)\n",
    "    parser.add_argument(\"--eval_train\"        , help=\"Set this to 1 to calculate AUCs for train data\", type=int, default=0)\n",
    "    parser.add_argument(\"--eval_frequency\"    , help=\"The gap between AUC eval (in epochs), -1 means to do an eval at the end.\", type=int, default=1)\n",
    "    parser.add_argument(\"--folding\"           , help=\"Folding file (npy)\", type=str, required=True)\n",
    "    parser.add_argument(\"--fold_inputs\"       , help=\"Fold input to a fixed set (default no folding)\", type=int, default=None)\n",
    "    parser.add_argument(\"--fold_va\"           , help=\"Validation fold number\", type=int, default=0)\n",
    "    parser.add_argument(\"--fold_te\"           , help=\"Test fold number (removed from dataset)\", type=int, default=None)\n",
    "    parser.add_argument(\"--hidden_sizes\"      , nargs=\"+\", help=\"Hidden sizes\", default=[], type=int, required=True)\n",
    "    parser.add_argument(\"--input_transform\"   , help=\"Transformation to apply to inputs\", type=str, default=\"none\", choices=[\"binarize\", \"none\", \"tanh\", \"log1p\"])\n",
    "    # parser.add_argument(\"--input_size\"      , help=\"Input size\", type=int, default=None)\n",
    "    # parser.add_argument(\"--tail_hidden_size\"  , help=\"Tail Hidden size\", default=0, type=int)\n",
    "    parser.add_argument(\"--input_size_freq\"   , help=\"Number of high importance features\", type=int, default=None)\n",
    "    parser.add_argument(\"--internal_batch_max\", help=\"Maximum size of the internal batch\", type=int, default=None)\n",
    "    parser.add_argument(\"--last_dropout\"      , help=\"Last dropout\", type=float, default=0.2)\n",
    "    parser.add_argument(\"--last_non_linearity\", help=\"Last layer non-linearity\", type=str, default=\"relu\", choices=[\"relu\", \"tanh\"])\n",
    "    parser.add_argument(\"--lr\"                , help=\"Learning rate\", type=float, default=1e-3)\n",
    "    parser.add_argument(\"--lr_alpha\"          , help=\"Learning rate decay multiplier\", type=float, default=0.3)\n",
    "    parser.add_argument(\"--lr_steps\"          , nargs=\"+\", help=\"Learning rate decay steps\", type=int, default=[10])\n",
    "    parser.add_argument(\"--middle_dropout\"    , help=\"Dropout for layers before the last\", type=float, default=0.0)\n",
    "    parser.add_argument(\"--middle_non_linearity\", \"--non_linearity\", help=\"Before last layer non-linearity\", type=str, default=\"relu\", choices=[\"relu\", \"tanh\"])\n",
    "    parser.add_argument(\"--min_samples_class\", help=\"Minimum number samples in each class and in each fold for AUC calculation (only used if aggregation_weight is not provided in --weights_class)\", type=int, default=5)\n",
    "    parser.add_argument(\"--min_samples_auc\"  , help=\"Obsolete: use 'min_samples_class'\", type=int, default=None)\n",
    "    parser.add_argument(\"--min_samples_regr\" , help=\"Minimum number of uncensored samples in each fold for regression metric calculation (only used if aggregation_weight is not provided in --weights_regr)\", type=int, default=10)\n",
    "    parser.add_argument(\"--normalize_loss\"   , help=\"Normalization constant to divide the loss (default uses batch size)\", type=float, default=None)\n",
    "    parser.add_argument(\"--output_dir\"       , help=\"Output directory, including boards (default 'models')\", type=str, default=\"models\")\n",
    "    parser.add_argument(\"--prefix\"           , help=\"Prefix for run name (default 'run')\", type=str, default='run')\n",
    "    parser.add_argument(\"--run_name\"         , help=\"Run name for results\", type=str, default=None)\n",
    "    parser.add_argument(\"--save_model\"       , help=\"Set this to 0 if the model should not be saved\", type=int, default=1)\n",
    "    parser.add_argument(\"--save_board\"       , help=\"Set this to 0 if the TensorBoard should not be saved\", type=int, default=1)\n",
    "    parser.add_argument(\"--verbose\"          , help=\"Verbosity level: 2 = full; 1 = no progress; 0 = no output\", type=int, default=2, choices=[0, 1, 2])\n",
    "    parser.add_argument(\"--weight_decay\"     , help=\"Weight decay\", type=float, default=0.0)\n",
    "    parser.add_argument(\"--weights_class\"    , \"--task_weights\", \"--weights_classification\"\n",
    "                                             , help=\"CSV file with columns task_id, training_weight, aggregation_weight, task_type (for classification tasks)\", type=str, default=None)\n",
    "    parser.add_argument(\"--weights_regr\"     , \"--weights_regression\"\n",
    "                                             , help=\"CSV file with columns task_id, training_weight, censored_weight, aggregation_weight, aggregation_weight, task_type (for regression tasks)\", type=str, default=None)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093edb8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T18:22:52.275326Z",
     "start_time": "2022-04-05T18:22:52.269033Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_sparse(filename):\n",
    "    \"\"\"Loads sparse from Matrix market or Numpy .npy file.\"\"\"\n",
    "    if filename is None:\n",
    "        return None\n",
    "    if filename.endswith('.mtx'):\n",
    "        return scipy.io.mmread(filename).tocsr()\n",
    "    elif filename.endswith('.npy'):\n",
    "        return np.load(filename, allow_pickle=True).item().tocsr()\n",
    "    elif filename.endswith('.npz'):\n",
    "        return scipy.sparse.load_npz(filename).tocsr()\n",
    "    raise ValueError(f\"Loading '{filename}' failed. It must have a suffix '.mtx', '.npy', '.npz'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76e0f984",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T18:23:01.721481Z",
     "start_time": "2022-04-05T18:23:01.714538Z"
    }
   },
   "outputs": [],
   "source": [
    "def sparse_split2(tensor, split_size, dim=0):\n",
    "    \"\"\"\n",
    "    Splits tensor into two parts.\n",
    "    Args:\n",
    "        split_size   index where to split\n",
    "        dim          dimension which to split\n",
    "    \"\"\"\n",
    "    assert tensor.layout == torch.sparse_coo\n",
    "    indices = tensor._indices()\n",
    "    values  = tensor._values()\n",
    "\n",
    "    shape  = tensor.shape\n",
    "    shape0 = shape[:dim] + (split_size,) + shape[dim+1:]\n",
    "    shape1 = shape[:dim] + (shape[dim] - split_size,) + shape[dim+1:]\n",
    "\n",
    "    mask0 = indices[dim] < split_size\n",
    "    X0 = torch.sparse_coo_tensor(\n",
    "            indices = indices[:, mask0],\n",
    "            values  = values[mask0],\n",
    "            size    = shape0)\n",
    "\n",
    "    indices1       = indices[:, ~mask0]\n",
    "    indices1[dim] -= split_size\n",
    "    X1 = torch.sparse_coo_tensor(\n",
    "            indices = indices1,\n",
    "            values  = values[~mask0],\n",
    "            size    = shape1)\n",
    "    return X0, X1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eb1c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
