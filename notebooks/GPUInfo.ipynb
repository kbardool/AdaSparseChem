{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c45f991",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:31:09.518094Z",
     "start_time": "2022-06-24T12:31:09.510622Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52d0513b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:31:14.826520Z",
     "start_time": "2022-06-24T12:31:14.816756Z"
    }
   },
   "outputs": [],
   "source": [
    "class GpuInfo(object):\n",
    "    def __init__(self, index, memory_total, memory_used, gpu_load):\n",
    "        \"\"\"\n",
    "        :param index: GPU index\n",
    "        :param memory_total: total GPU memory, Mb\n",
    "        :param memory_used: GPU memory already in use, Mb\n",
    "        :param gpu_load: gpu utilization load, percents\n",
    "        \"\"\"\n",
    "        self.index = int(index)\n",
    "        self.memory_total = int(memory_total)\n",
    "        self.memory_used = int(memory_used)\n",
    "        try:\n",
    "            self.gpu_load = int(gpu_load) / 100.\n",
    "        except ValueError:\n",
    "            # gpu utilization load is not supported in current driver\n",
    "            self.gpu_load = 0.\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"GPU #{}: memory total={} Mb, used={} Mb ({:.1f} %), gpu.load={}\".format(\n",
    "            self.index, self.memory_total, self.memory_used, 100. * self.memory_used / self.memory_total, self.gpu_load)\n",
    "\n",
    "    def get_available_memory_portion(self):\n",
    "        return (self.memory_total - self.memory_used) / self.memory_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "238bfb40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:31:20.894374Z",
     "start_time": "2022-06-24T12:31:20.883114Z"
    }
   },
   "outputs": [],
   "source": [
    "class NvidiaSmi(object):\n",
    "    def __init__(self):\n",
    "        command = \"nvidia-smi --query-gpu=index,memory.total,memory.used,utilization.gpu --format=csv,noheader,nounits\".split()\n",
    "        self.gpus = []\n",
    "        try:\n",
    "            process = subprocess.Popen(command,\n",
    "                                       universal_newlines=True,\n",
    "                                       stdout=subprocess.PIPE)\n",
    "            stdout, stderr_ignored = process.communicate()\n",
    "            for line in stdout.splitlines():\n",
    "                index, memory_total, memory_used, gpu_load = line.split(', ')\n",
    "                gpu = GpuInfo(index, memory_total, memory_used, gpu_load)\n",
    "                self.gpus.append(gpu)\n",
    "        except FileNotFoundError:\n",
    "            # No GPU is detected. Try running `nvidia-smi` in a terminal.\"\n",
    "            pass\n",
    "\n",
    "    def get_gpus(self, min_free_memory=0., max_load=1.):\n",
    "        \"\"\"\n",
    "        :param min_free_memory: filter GPUs with free memory no less than specified, between 0 and 1\n",
    "        :param max_load: max gpu utilization load, between 0 and 1\n",
    "        :return: list of available GpuInfo's\n",
    "        \"\"\"\n",
    "        gpus = [gpu for gpu in self.gpus if gpu.get_available_memory_portion() >= min_free_memory and\n",
    "                gpu.gpu_load <= max_load]\n",
    "        return gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b7e5f60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:33:24.750323Z",
     "start_time": "2022-06-24T12:33:24.741178Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_cuda_visible_devices(limit_devices=int(1e9), min_free_memory=0.4, max_load=0.6) -> list:\n",
    "    \"\"\"\n",
    "    Automatically sets CUDA_VISIBLE_DEVICES env to first `limit_devices` available GPUs with least used memory.\n",
    "    :param limit_devices: limit available GPU devices to use\n",
    "    :param min_free_memory: filter GPUs with free memory no less than specified, between 0 and 1\n",
    "    :param max_load: max gpu utilization load, between 0 and 1\n",
    "    \"\"\"\n",
    "    gpus = NvidiaSmi().get_gpus(min_free_memory, max_load)\n",
    "    print(f\"gpus: {gpus}\")\n",
    "    gpus.sort(key=lambda gpu: gpu.get_available_memory_portion(), reverse=True)\n",
    "    limit_devices = min(limit_devices, len(gpus))\n",
    "    gpus = gpus[:limit_devices]\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(str(gpu.index) for gpu in gpus)\n",
    "    print(\"'CUDA_VISIBLE_DEVICES' is set to '{}'\".format(os.environ[\"CUDA_VISIBLE_DEVICES\"]))\n",
    "    return gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcefd4f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:33:25.305466Z",
     "start_time": "2022-06-24T12:33:25.259393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpus: [GPU #0: memory total=12196 Mb, used=8 Mb (0.1 %), gpu.load=0.0, GPU #1: memory total=32508 Mb, used=31085 Mb (95.6 %), gpu.load=0.88, GPU #2: memory total=32508 Mb, used=8 Mb (0.0 %), gpu.load=0.0]\n",
      "'CUDA_VISIBLE_DEVICES' is set to '2,0,1'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[GPU #2: memory total=32508 Mb, used=8 Mb (0.0 %), gpu.load=0.0,\n",
       " GPU #0: memory total=12196 Mb, used=8 Mb (0.1 %), gpu.load=0.0,\n",
       " GPU #1: memory total=32508 Mb, used=31085 Mb (95.6 %), gpu.load=0.88]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_cuda_visible_devices(min_free_memory=0.0, max_load=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d5770cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:33:57.936721Z",
     "start_time": "2022-06-24T12:33:57.931530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(os.environ[\"CUDA_VISIBLE_DEVICES\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e45c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
