{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d21d42",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55604c43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:24.999556Z",
     "start_time": "2022-09-06T21:34:24.967267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container  width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container  width:90% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d574cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:26.990443Z",
     "start_time": "2022-09-06T21:34:25.001495Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:08.233990Z",
     "iopub.status.busy": "2022-01-07T22:44:08.233053Z",
     "iopub.status.idle": "2022-01-07T22:44:08.273284Z",
     "shell.execute_reply": "2022-01-07T22:44:08.271908Z",
     "shell.execute_reply.started": "2022-01-07T22:44:08.233943Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import time\n",
    "import argparse\n",
    "import yaml\n",
    "import types, copy, pprint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from utils import (initialize, init_dataloaders, init_environment, init_wandb, training_initializations, model_initializations, \n",
    "                   check_for_resume_training, disp_dataloader_info, disp_info_1, warmup_phase, weight_policy_training, \n",
    "                   display_gpu_info, init_dataloaders_by_fold_id, print_separator, print_heading, print_underline,  \n",
    "                   timestring, print_loss, get_command_line_args, load_from_pickle) \n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "pd.options.display.width = 132\n",
    "# torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Train_Resume.ipynb\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33ac6e",
   "metadata": {},
   "source": [
    "## Create Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a638f8",
   "metadata": {},
   "source": [
    "### Parse Input Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe0d9d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:27.016970Z",
     "start_time": "2022-09-06T21:34:26.992297Z"
    }
   },
   "outputs": [],
   "source": [
    "# synthetic_5task_config = \"../yamls/chembl_synt_train_5task.yaml\"\n",
    "# synthetic_config_file  = \"../yamls/chembl_synt_train.yaml\"\n",
    "# config_file      = \"../yamls/chembl_mini_train.yaml\"\n",
    "# config_file      = \"../yamls/chembl_cb29_train_1task.yaml\"\n",
    "config_file      = \"../yamls/chembl_cb29_train_10task.yaml\"\n",
    "batch_size=4098\n",
    "exp_name  = \"0906_1312\"\n",
    "# batch_size=2048\n",
    "# RESUME_MODEL_CKPT = 'model_train_ep_25_seed_0088'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef25586d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:27.084571Z",
     "start_time": "2022-09-06T21:34:27.019436Z"
    }
   },
   "outputs": [],
   "source": [
    "restart_input_args = f\" --config  {config_file} \" \\\n",
    "             f\" --batch_size       {batch_size} \"  \\\n",
    "             \" --exp_desc            10-task with policy training \" \\\n",
    "             \" --hidden_size         4000 4000 4000 4000 4000 4000 \"  \\\n",
    "             \" --tail_hidden_size    4000 \"  \\\n",
    "             \" --warmup_epochs              20 \"  \\\n",
    "             \" --first_dropout            0.80 \"  \\\n",
    "             \" --middle_dropout           0.80 \"  \\\n",
    "             \" --last_dropout             0.80 \"  \\\n",
    "             \" --seed_idx                    0 \"  \\\n",
    "             \" --task_lr                 0.001 \"  \\\n",
    "             \" --backbone_lr             0.001 \"  \\\n",
    "             \" --decay_lr_rate             0.5 \"  \\\n",
    "             \" --decay_lr_freq              20 \"  \\\n",
    "             \" --decay_lr_cooldown           5 \"  \\\n",
    "             \" --policy_lr                0.01 \"  \\\n",
    "             \" --policy_decay_lr_rate      0.5 \"  \\\n",
    "             \" --policy_decay_lr_freq       20 \"  \\\n",
    "             \" --policy_decay_lr_cooldown    5 \"  \\\n",
    "             \" --lambda_tasks              1.0 \"  \\\n",
    "             \" --lambda_sparsity         0.001 \"  \\\n",
    "             \" --lambda_sharing           0.05 \"  \\\n",
    "             \" --pytorch_threads             7 \"  \\\n",
    "             \" --cuda_devices                2 \"  \\\n",
    "             \" --gpu_ids                     0 \"  \\\n",
    "             \" --resume \"                         \\\n",
    "            f\" --resume_path             ../../experiments/AdaSparseChem-cb29-10task/4000x6_{exp_name}_lr0.001_do0.8\" \\\n",
    "             \" --resume_ckpt             model_warmup_final_ep_78\" \\\n",
    "             \" --resume_metrics          metrics_warmup_final_ep_78\" \\\n",
    "            f\" --exp_name                {exp_name} \" \\\n",
    "             \" --folder_sfx              RETRAIN_1 \"\n",
    "\n",
    "#              \" --exp_id                  154b30qo\" \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6758112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:27.202327Z",
     "start_time": "2022-09-06T21:34:27.086221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " command line parms : \n",
      "------------------------\n",
      " config...................  ../yamls/chembl_cb29_train_10task.yaml\n",
      " project_name.............  None\n",
      " exp_id...................  1fgdsfry\n",
      " exp_name.................  0906_1312\n",
      " folder_sfx...............  RETRAIN_1\n",
      " exp_desc.................  10-task with policy training\n",
      " hidden_sizes.............  [4000, 4000, 4000, 4000, 4000, 4000]\n",
      " tail_hidden_size.........  [4000]\n",
      " warmup_epochs............  20\n",
      " training_epochs..........  None\n",
      " seed_idx.................  0\n",
      " batch_size...............  4098\n",
      " first_dropout............  0.8\n",
      " middle_dropout...........  0.8\n",
      " last_dropout.............  0.8\n",
      " backbone_lr..............  0.001\n",
      " task_lr..................  0.001\n",
      " policy_lr................  0.01\n",
      " decay_lr_rate............  0.5\n",
      " decay_lr_freq............  20\n",
      " decay_lr_cooldown........  5\n",
      " policy_decay_lr_rate.....  0.5\n",
      " policy_decay_lr_freq.....  20\n",
      " policy_decay_lr_cooldown.  5\n",
      " lambda_tasks.............  1.0\n",
      " lambda_sparsity..........  0.001\n",
      " lambda_sharing...........  0.05\n",
      " cuda_devices.............  2\n",
      " gpu_ids..................  [0]\n",
      " pytorch_threads..........  7\n",
      " skip_residual............  False\n",
      " skip_hidden..............  False\n",
      " resume...................  True\n",
      " resume_path..............  ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8\n",
      " resume_ckpt..............  model_warmup_final_ep_78\n",
      " resume_metrics...........  metrics_warmup_final_ep_78\n",
      " cpu......................  False\n",
      " min_samples_class........  None\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ns = types.SimpleNamespace()\n",
    "# input_args = input_args.split() if input_args is not None else input_args\n",
    "input_args = restart_input_args.split() \n",
    "ns.args = get_command_line_args(input_args, display = True)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=ns.args.cuda_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97604425",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:27.275361Z",
     "start_time": "2022-09-06T21:34:27.204117Z"
    }
   },
   "outputs": [],
   "source": [
    "# display_gpu_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfecb2b3",
   "metadata": {},
   "source": [
    "### Read Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a77e34ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:32.217404Z",
     "start_time": "2022-09-06T21:34:27.277136Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "################### READ YAML ####################\n",
      "##################################################\n",
      " Pytorch thread count: 20\n",
      " Set Pytorch thread count to : 7\n",
      " Pytorch thread count set to : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkbardool\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kevin/WSL-projs/AdaSparseChem/notebooks/wandb/run-20220906_233427-1fgdsfry</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task/runs/1fgdsfry\" target=\"_blank\">0906_1312_RETRAIN_1</a></strong> to <a href=\"https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WandB Initialization -----------------------------------------------------------\n",
      " PROJECT NAME: AdaSparseChem-cb29-10Task\n",
      " RUN ID      : 1fgdsfry \n",
      " RUN NAME    : 0906_1312_RETRAIN_1\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " log_dir              folder exists:  ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8_RETRAIN_1\n",
      " result_dir           folder exists:  ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8_RETRAIN_1\n",
      " checkpoint_dir       folder exists:  ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8_RETRAIN_1\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " experiment name       : 0906_1312_RETRAIN_1 \n",
      " experiment id         : 1fgdsfry \n",
      " folder_name           : 4000x6_0906_1312_lr0.001_do0.8_RETRAIN_1 \n",
      " experiment description: 10-task with policy training\n",
      " Random seeds          : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      " Random  seed used     : 88 \n",
      " log folder            : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8_RETRAIN_1\n",
      " checkpoint folder     : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8_RETRAIN_1\n",
      " Gpu ids               : [0]\n",
      " Seed index            : 0\n",
      " policy_iter           : best\n",
      " Data Split ratios     : [0.725, 0.225, 0.05]\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "        project_name : AdaSparseChem-cb29-10Task\n",
      "              exp_id : 1fgdsfry\n",
      "        exp_name_pfx : 0906_1312\n",
      "            exp_name : 0906_1312_RETRAIN_1\n",
      "          exp_folder : 4000x6_0906_1312_lr0.001_do0.8_RETRAIN_1\n",
      "     exp_description : 10-task with policy training\n",
      "          folder_sfx : RETRAIN_1\n",
      "         random_seed : 88\n",
      "           seed_list : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      "              config : ../yamls/chembl_cb29_train_10task.yaml\n",
      "                 cpu : None\n",
      "             gpu_ids : [0]\n",
      "            backbone : SparseChem\n",
      "               tasks : ['class', 'class', 'class', 'class', 'class', 'class', 'class', 'class', 'class', 'class']\n",
      "     tasks_num_class : [472, 624, 688, 192, 620, 184, 224, 148, 344, 72]\n",
      "             lambdas : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "             verbose : False\n",
      "     input_size_freq : None\n",
      "          input_size : 32000\n",
      "        hidden_sizes : [4000, 4000, 4000, 4000, 4000, 4000]\n",
      "    tail_hidden_size : [4000]\n",
      " first_non_linearity : relu\n",
      "middle_non_linearity : relu\n",
      "  last_non_linearity : relu\n",
      "       first_dropout : 0.8\n",
      "      middle_dropout : 0.8\n",
      "        last_dropout : 0.8\n",
      "   class_output_size : None\n",
      "    regr_output_size : None\n",
      "              policy : True\n",
      "        policy_model : task-specific\n",
      "       skip_residual : False\n",
      "         skip_hidden : False\n",
      "           is_sparse : True\n",
      "diff_sparsity_weights : False\n",
      "          is_sharing : True\n",
      "diff_sharing_weights : False\n",
      "          skip_layer : 0\n",
      "       is_curriculum : False\n",
      "    curriculum_speed : 3\n",
      "              fix_BN : False\n",
      "     retrain_from_pl : False\n",
      "\n",
      "train\n",
      "-----\n",
      "       warmup_epochs : 20\n",
      "     training_epochs : 250\n",
      "         total_iters : 25000\n",
      "       warm_up_iters : None\n",
      "             task_lr : 0.001\n",
      "         backbone_lr : 0.001\n",
      "    weight_optimizer : adam\n",
      "    policy_optimizer : adam\n",
      "       decay_lr_rate : 0.5\n",
      "       decay_lr_freq : 20\n",
      "   decay_lr_cooldown : 5\n",
      "           policy_lr : 0.01\n",
      "policy_decay_lr_rate : 0.5\n",
      "policy_decay_lr_freq : 20\n",
      "policy_decay_lr_cooldown : 5\n",
      "     lambda_sparsity : 0.001\n",
      "      lambda_sharing : 0.05\n",
      "        lambda_tasks : 1.0\n",
      "         init_method : random\n",
      "           init_temp : 2.5\n",
      "          decay_temp : 0.75\n",
      "     decay_temp_freq : 3\n",
      "     init_neg_logits : None\n",
      "       hard_sampling : False\n",
      "            val_freq : 500\n",
      "          print_freq : -1\n",
      "warmup_iter_alternate : -1\n",
      "weight_iter_alternate : -1\n",
      "alpha_iter_alternate : -1\n",
      "           val_iters : -1\n",
      "              resume : True\n",
      "      retrain_resume : False\n",
      "         policy_iter : best\n",
      "          which_iter : warmup\n",
      "\n",
      "paths\n",
      "-----\n",
      "             log_dir : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8_RETRAIN_1\n",
      "          result_dir : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8_RETRAIN_1\n",
      "      checkpoint_dir : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8_RETRAIN_1\n",
      "\n",
      "dataload\n",
      "--------\n",
      "             dataset : Chembl29\n",
      "            dataroot : ../../MLDatasets/chembl29_10task\n",
      "                   x : chembl_29_X.npy\n",
      "      x_split_ratios : [0.725, 0.225, 0.05]\n",
      "             folding : chembl_29_folding.npy\n",
      "             y_tasks : ['chembl_29_Y_tg_0_cols_472.npy', 'chembl_29_Y_tg_1_cols_624.npy', 'chembl_29_Y_tg_6_cols_688.npy', 'chembl_29_Y_tg_10_cols_192.npy', 'chembl_29_Y_tg_11_cols_620.npy', 'chembl_29_Y_tg_643_cols_184.npy', 'chembl_29_Y_tg_836_cols_224.npy', 'chembl_29_Y_tg_1005_cols_148.npy', 'chembl_29_Y_tg_1028_cols_344.npy', 'chembl_29_Y_tg_1031_cols_72.npy']\n",
      "            y_censor : None\n",
      "         fold_inputs : 32000\n",
      "     input_transform : None\n",
      "       weights_class : None\n",
      "   min_samples_class : 1\n",
      "           fold_test : [0]\n",
      "             fold_va : [1]\n",
      "         fold_warmup : [2, 3, 4]\n",
      "        fold_weights : [2, 3]\n",
      "         fold_policy : [4]\n",
      "\n",
      "SC\n",
      "--\n",
      "      normalize_loss : None\n",
      "\n",
      "test\n",
      "----\n",
      "          test_iters : -1\n",
      "     pytorch_threads : 7\n",
      "            seed_idx : 0\n",
      "          batch_size : 4098\n",
      "         resume_path : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8\n",
      "         resume_ckpt : model_warmup_final_ep_78\n",
      "      resume_metrics : metrics_warmup_final_ep_78\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt = initialize(ns, build_folders = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb717387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:32.268717Z",
     "start_time": "2022-09-06T21:34:32.221208Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.wandb_run.finish()\n",
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bfa8d",
   "metadata": {},
   "source": [
    "### Setup Dataloader and Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0785b692",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:39.432279Z",
     "start_time": "2022-09-06T21:34:32.270721Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Warmup folds    : [2, 3, 4]\n",
      " Weights folds   : [2, 3]\n",
      " Policy folds    : [4]\n",
      " Validation folds: [1]\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      " Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      " Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 472  Y rows with populated labels: 21581  non zero cols: 53309\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      " Task 2 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      " Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 624  Y rows with populated labels: 22820  non zero cols: 55015\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      " Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      " Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 688  Y rows with populated labels: 53858  non zero cols: 186792\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      " Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n",
      "\n",
      " Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 192  Y rows with populated labels: 12262  non zero cols: 27798\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n",
      "\n",
      " Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n",
      "\n",
      " Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 620  Y rows with populated labels: 30988  non zero cols: 86678\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      " Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n",
      "\n",
      " Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 184  Y rows with populated labels: 9818  non zero cols: 27152\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n",
      "\n",
      " Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n",
      "\n",
      " Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 224  Y rows with populated labels: 7090  non zero cols: 22638\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      " Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 148  Y rows with populated labels: 13262  non zero cols: 28925\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n",
      "\n",
      " Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      " Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 344  Y rows with populated labels: 20684  non zero cols: 63517\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      " Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n",
      "\n",
      " Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 72  Y rows with populated labels: 4475  non zero cols: 10677\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      " Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      " Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 472  Y rows with populated labels: 15323  non zero cols: 38126\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      " Task 2 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      " Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 624  Y rows with populated labels: 15572  non zero cols: 38310\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      " Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      " Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 688  Y rows with populated labels: 34821  non zero cols: 121231\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      " Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n",
      "\n",
      " Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 192  Y rows with populated labels: 7752  non zero cols: 17657\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n",
      "\n",
      " Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n",
      "\n",
      " Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 620  Y rows with populated labels: 20914  non zero cols: 58596\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      " Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 184  Y rows with populated labels: 7179  non zero cols: 19397\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n",
      "\n",
      " Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n",
      "\n",
      " Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 224  Y rows with populated labels: 4476  non zero cols: 14840\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      " Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n",
      "\n",
      " Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 148  Y rows with populated labels: 8900  non zero cols: 19704\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n",
      "\n",
      " Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      " Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 344  Y rows with populated labels: 12593  non zero cols: 39248\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      " Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n",
      "\n",
      " Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 72  Y rows with populated labels: 2897  non zero cols: 6734\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      " Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      " Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 472  Y rows with populated labels: 6258  non zero cols: 15183\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      " Task 2 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      " Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 624  Y rows with populated labels: 7248  non zero cols: 16705\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      " Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      " Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 688  Y rows with populated labels: 19037  non zero cols: 65561\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      " Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 192  Y rows with populated labels: 4510  non zero cols: 10141\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n",
      "\n",
      " Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n",
      "\n",
      " Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 620  Y rows with populated labels: 10074  non zero cols: 28082\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      " Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n",
      "\n",
      " Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 184  Y rows with populated labels: 2639  non zero cols: 7755\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n",
      "\n",
      " Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n",
      "\n",
      " Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 224  Y rows with populated labels: 2614  non zero cols: 7798\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      " Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n",
      "\n",
      " Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 148  Y rows with populated labels: 4362  non zero cols: 9221\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n",
      "\n",
      " Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      " Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 344  Y rows with populated labels: 8091  non zero cols: 24269\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      " Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n",
      "\n",
      " Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 72  Y rows with populated labels: 1578  non zero cols: 3943\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      " Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      " Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 472  Y rows with populated labels: 5643  non zero cols: 14167\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      " Task 2 files pre-filtering : \n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      " Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 624  Y rows with populated labels: 8661  non zero cols: 20196\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      " Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      " Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 688  Y rows with populated labels: 17973  non zero cols: 61209\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      " Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n",
      "\n",
      " Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 192  Y rows with populated labels: 3776  non zero cols: 8372\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n",
      "\n",
      " Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n",
      "\n",
      " Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 620  Y rows with populated labels: 10004  non zero cols: 27223\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      " Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n",
      "\n",
      " Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 184  Y rows with populated labels: 2519  non zero cols: 6085\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n",
      "\n",
      " Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n",
      "\n",
      " Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 224  Y rows with populated labels: 2379  non zero cols: 7992\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      " Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n",
      "\n",
      " Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 148  Y rows with populated labels: 4764  non zero cols: 9313\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n",
      "\n",
      " Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      " Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 344  Y rows with populated labels: 7460  non zero cols: 21553\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      " Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 72  Y rows with populated labels: 1916  non zero cols: 4391\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      " dataloader preparation - set number of batches per warmup training epoch to: 63\n",
      " dataloader preparation - set number of batches per weight training epoch to: 42\n",
      " dataloader preparation - set number of batches per policy training epoch to: 21\n",
      " dataloader preparation - set number of batches per validation to           : 22\n",
      "\n",
      " trainset.y_class                                   :  [(254529, 472), (254529, 624), (254529, 688), (254529, 192), (254529, 620), (254529, 184), (254529, 224), (254529, 148), (254529, 344), (254529, 72)] \n",
      " trainset1.y_class                                  :  [(168649, 472), (168649, 624), (168649, 688), (168649, 192), (168649, 620), (168649, 184), (168649, 224), (168649, 148), (168649, 344), (168649, 72)] \n",
      " trainset2.y_class                                  :  [(85880, 472), (85880, 624), (85880, 688), (85880, 192), (85880, 620), (85880, 184), (85880, 224), (85880, 148), (85880, 344), (85880, 72)] \n",
      " valset.y_class                                     :  [(86274, 472), (86274, 624), (86274, 688), (86274, 192), (86274, 620), (86274, 184), (86274, 224), (86274, 148), (86274, 344), (86274, 72)]  \n",
      "\n",
      "                                Total                :  595332 \n",
      "\n",
      "\n",
      "Training dataset :\n",
      "--------------------\n",
      "  Size of training set 0 (warm up)                   :  254529 \n",
      "  Number of batches in training 0 (warm up)          :  63 \n",
      "  Size of training set 1 (network parms)             :  168649 \n",
      "  Number of batches in training 1 (network parms)    :  42 \n",
      "  Size of training set 2 (policy weights)            :  85880 \n",
      "  Number of batches in training 2 (policy weights)   :  21 \n",
      "  training set num of positive                       :  18631 \n",
      "  training set num of negative                       :  107922 \n",
      "  task_weights_list[0].aggregation_weight sum        :  199.0\n",
      "\n",
      "\n",
      "Validation dataset :\n",
      "----------------------\n",
      "  Rows in dataset                                    : 86274\n",
      "  Number of batches in dataset                       : 22\n",
      "  validation set num of positive                     : 18631\n",
      "  validation set num of negative                     : 107922\n",
      "  task_weights_list[0].aggregation_weight sum        : 199.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dldrs = init_dataloaders(opt, verbose = False)\n",
    "dldrs = init_dataloaders_by_fold_id(opt, verbose = False)\n",
    "disp_dataloader_info(dldrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b8c36",
   "metadata": {},
   "source": [
    "## Setup Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e44458e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:43.428605Z",
     "start_time": "2022-09-06T21:34:39.437476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      " device is  cuda:0\n",
      "--------------------------------------------------\n",
      " SparseChem_Backbone  Ver: 1.0 Init() Start \n",
      "-------------------------------------------------- \n",
      "\n",
      " layer config        : [1, 1, 1, 1, 1, 1] \n",
      " skip residual layers: False   skip hidden layers  : False\n",
      " SparseChem_BackBone() Input Layer  - Input: 32000  output: 4000  non-linearity:<class 'torch.nn.modules.activation.ReLU'>\n",
      " Hidden layer 0 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.8 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.8 bias: True\n",
      " Hidden layer 1 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.8 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.8 bias: True\n",
      " Hidden layer 2 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.8 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.8 bias: True\n",
      " Hidden layer 3 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.8 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.8 bias: True\n",
      " Hidden layer 4 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.8 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.8 bias: True\n",
      " Final Hidden layer 4 : Input size: 4000   output size:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.8 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.8 bias: True\n",
      " Module List \n",
      "--------------------------------------------------\n",
      " Initialize weights \n",
      "-------------------------------------------------- \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " SparseChem Backbone -- Final configuration(2) : \n",
      "                     self.blocks: <class 'torch.nn.modules.container.ModuleList'>  len:6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "\n",
      " Input_Layer  type:<class 'torch.nn.modules.container.Sequential'>  \n",
      "----------------------------------------------------------------------\n",
      "self.Input_layer\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Layers/Blocks    : <class 'torch.nn.modules.container.ModuleList'>   len:6 \n",
      "Resdiual layers  : <class 'torch.nn.modules.container.ModuleList'>   len:6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 1  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 1  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 2  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 2  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 3  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 3  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 4  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 4  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 5  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 5  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 6  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 6  type:<class 'NoneType'> \n",
      " None\n",
      "\n",
      "\n",
      "\n",
      " SparseChem_Backbone Init() End \n",
      "----------------------------------------------------\n",
      "* SparseChemEnv environment successfully created\n",
      "---------------------------------------------------- \n",
      "\n",
      " \n",
      "\n",
      "SparseChemEnv  Configuration       \n",
      "---------------------------------------- \n",
      "\n",
      "----------------\n",
      "networks       :\n",
      "----------------\n",
      " {'mtl-net': MTL3(\n",
      "  (backbone): SparseChem_Backbone(\n",
      "    (Input_Layer): Sequential(\n",
      "      (linear): SparseLinear(in_features=32000, out_features=4000, bias=True)\n",
      "      (non_linear): ReLU()\n",
      "      (dropout): Dropout(p=0.8, inplace=False)\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.8, inplace=False)\n",
      "      )\n",
      "      (1): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.8, inplace=False)\n",
      "      )\n",
      "      (2): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.8, inplace=False)\n",
      "      )\n",
      "      (3): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.8, inplace=False)\n",
      "      )\n",
      "      (4): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.8, inplace=False)\n",
      "      )\n",
      "      (5): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.8, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (residuals): ModuleList(\n",
      "      (0): None\n",
      "      (1): None\n",
      "      (2): None\n",
      "      (3): None\n",
      "      (4): None\n",
      "      (5): None\n",
      "    )\n",
      "  )\n",
      "  (task1_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=472, bias=True)\n",
      "  )\n",
      "  (task2_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=624, bias=True)\n",
      "  )\n",
      "  (task3_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=688, bias=True)\n",
      "  )\n",
      "  (task4_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=192, bias=True)\n",
      "  )\n",
      "  (task5_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=620, bias=True)\n",
      "  )\n",
      "  (task6_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=184, bias=True)\n",
      "  )\n",
      "  (task7_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=224, bias=True)\n",
      "  )\n",
      "  (task8_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=148, bias=True)\n",
      "  )\n",
      "  (task9_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=344, bias=True)\n",
      "  )\n",
      "  (task10_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=72, bias=True)\n",
      "  )\n",
      ")}\n",
      "\n",
      "----------------\n",
      "optimizers     :\n",
      "----------------\n",
      " {}\n",
      "\n",
      "----------------\n",
      "schedulers     :\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "environ = init_environment(ns, opt, is_train = True, display_cfg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "953d8086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:43.861611Z",
     "start_time": "2022-09-06T21:34:43.430347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SparseChemEnv' object has no attribute 'policy1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_608896/2479560891.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(environ.networks['mtl-net'].logits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mtl-net'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SparseChemEnv' object has no attribute 'policy1'"
     ]
    }
   ],
   "source": [
    "# print(environ.networks['mtl-net'].logits)\n",
    "print(environ.networks['mtl-net'].policys)\n",
    "print(environ.policy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d873591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:51.971936Z",
     "start_time": "2022-09-06T21:34:51.934173Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model optimizers defined . . . policy_learning: False\n",
      " Model schedulers defined . . . policy_learning: False\n",
      " Metrics CSV file header written . . . \n",
      " Model initializations complete . . . \n"
     ]
    }
   ],
   "source": [
    "model_initializations(ns, opt, environ, policy_learning = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d738062",
   "metadata": {},
   "source": [
    "## Initiate / Resume Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ac9036",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:53.425968Z",
     "start_time": "2022-09-06T21:34:53.393000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup\n"
     ]
    }
   ],
   "source": [
    "print(opt['train']['which_iter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ed9820c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:34:58.125397Z",
     "start_time": "2022-09-06T21:34:54.051022Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt['train']['which_iter'] :  warmup\n",
      "##################################################\n",
      "################ Resume training #################\n",
      "##################################################\n",
      " Resume training from folder : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8\n",
      " Resume checkpoint filename  : model_warmup_final_ep_78\n",
      " Resume metrics filename     : metrics_warmup_final_ep_78\n",
      "=> loading snapshot from ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8/model_warmup_final_ep_78.tar\n",
      "=> loading snapshot to   cuda:0\n",
      "   Loading to GPU cuda:0\n",
      "  networks -  network:  mtl-net\n",
      "  load snapshot - network:  mtl-net\n",
      "    network mtl-net - item task1_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task2_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task3_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task4_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task5_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task6_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task7_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task8_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task9_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task10_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item backbone.Input_Layer.linear.weight - shape: torch.Size([32000, 4000])\n",
      "    network mtl-net - item backbone.Input_Layer.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.0.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.0.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.1.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.1.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.2.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.2.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.3.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.3.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.4.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.4.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.5.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.5.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item task1_fc1_c0.linear.weight - shape: torch.Size([472, 4000])\n",
      "    network mtl-net - item task1_fc1_c0.linear.bias - shape: torch.Size([472])\n",
      "    network mtl-net - item task2_fc1_c0.linear.weight - shape: torch.Size([624, 4000])\n",
      "    network mtl-net - item task2_fc1_c0.linear.bias - shape: torch.Size([624])\n",
      "    network mtl-net - item task3_fc1_c0.linear.weight - shape: torch.Size([688, 4000])\n",
      "    network mtl-net - item task3_fc1_c0.linear.bias - shape: torch.Size([688])\n",
      "    network mtl-net - item task4_fc1_c0.linear.weight - shape: torch.Size([192, 4000])\n",
      "    network mtl-net - item task4_fc1_c0.linear.bias - shape: torch.Size([192])\n",
      "    network mtl-net - item task5_fc1_c0.linear.weight - shape: torch.Size([620, 4000])\n",
      "    network mtl-net - item task5_fc1_c0.linear.bias - shape: torch.Size([620])\n",
      "    network mtl-net - item task6_fc1_c0.linear.weight - shape: torch.Size([184, 4000])\n",
      "    network mtl-net - item task6_fc1_c0.linear.bias - shape: torch.Size([184])\n",
      "    network mtl-net - item task7_fc1_c0.linear.weight - shape: torch.Size([224, 4000])\n",
      "    network mtl-net - item task7_fc1_c0.linear.bias - shape: torch.Size([224])\n",
      "    network mtl-net - item task8_fc1_c0.linear.weight - shape: torch.Size([148, 4000])\n",
      "    network mtl-net - item task8_fc1_c0.linear.bias - shape: torch.Size([148])\n",
      "    network mtl-net - item task9_fc1_c0.linear.weight - shape: torch.Size([344, 4000])\n",
      "    network mtl-net - item task9_fc1_c0.linear.bias - shape: torch.Size([344])\n",
      "    network mtl-net - item task10_fc1_c0.linear.weight - shape: torch.Size([72, 4000])\n",
      "    network mtl-net - item task10_fc1_c0.linear.bias - shape: torch.Size([72])\n",
      "  optimizers - optimizer:  weights\n",
      "    load snapshot - optimizer: weights \n",
      "  optimizers - optimizer:  alphas\n",
      "    load snapshot - optimizer: alphas \n",
      "  schedulers - scheduler:  alphas\n",
      "    load snapshot - scheduler: alphas \n",
      "  schedulers - scheduler:  weights\n",
      "    load snapshot - scheduler: weights \n",
      "self.gumbel_temperature: 2.5\n",
      "snapshot[iter]         : 4914\n",
      "snapshot[iter]         : 78\n",
      "keys : dict_keys(['mtl-net', 'optimizers', 'schedulers', 'iter', 'epoch', 'temp'])\n",
      " (epoch, iter ) is :  (4914, 78)\n",
      " Checkpoint loaded - loaded epoch:78   loaded iteration:4914\n",
      "opt['train']['retrain_total_iters']:   25000\n",
      "\n",
      " ep:   78    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.5003    0.4997  1    0.5001    0.4999  1    0.4996    0.5004  0    0.5005    0.4995  1    0.5003    0.4997  1    0.5002    0.4998  1    0.5000    0.5000  1    0.4997    0.5003  0    0.5002    0.4998  1    0.5003    0.4997  1\n",
      "  1    0.5002    0.4998  1    0.4999    0.5001  0    0.4997    0.5003  0    0.4997    0.5003  0    0.5002    0.4998  1    0.5000    0.5000  1    0.5001    0.4999  1    0.4994    0.5006  0    0.5001    0.4999  1    0.4996    0.5004  0\n",
      "  2    0.4997    0.5003  0    0.4998    0.5002  0    0.5006    0.4994  1    0.5000    0.5000  1    0.5001    0.4999  1    0.5002    0.4998  1    0.4997    0.5003  0    0.5000    0.5000  0    0.5002    0.4998  1    0.4996    0.5004  0\n",
      "  3    0.4996    0.5004  0    0.5000    0.5000  0    0.5003    0.4997  1    0.4996    0.5004  0    0.5002    0.4998  1    0.5002    0.4998  1    0.4999    0.5001  0    0.5008    0.4992  1    0.4998    0.5002  0    0.5001    0.4999  1\n",
      "  4    0.4994    0.5006  0    0.5001    0.4999  1    0.5003    0.4997  1    0.4994    0.5006  0    0.5001    0.4999  1    0.4999    0.5001  0    0.4995    0.5005  0    0.4995    0.5005  0    0.5008    0.4992  1    0.4999    0.5001  0\n",
      "  5    0.5003    0.4997  1    0.4996    0.5004  0    0.5005    0.4995  1    0.5001    0.4999  1    0.5001    0.4999  1    0.5001    0.4999  1    0.5001    0.4999  1    0.4997    0.5003  0    0.5003    0.4997  1    0.4997    0.5003  0\n",
      "\n",
      "\n",
      " ep:   78   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.0008   -0.0005  1    0.0013    0.0009  1   -0.0001    0.0017  0    0.0017   -0.0002  1    0.0005   -0.0006  1    0.0003   -0.0005  1    0.0010    0.0008  1   -0.0007    0.0006  0    0.0002   -0.0007  1   -0.0003   -0.0013  1\n",
      "  1    0.0004   -0.0003  1   -0.0003    0.0003  0   -0.0009    0.0003  0   -0.0003    0.0010  0    0.0009    0.0000  1   -0.0004   -0.0005  1    0.0012    0.0008  1   -0.0003    0.0020  0    0.0006    0.0001  1   -0.0008    0.0009  0\n",
      "  2    0.0008    0.0018  0   -0.0011   -0.0003  0    0.0016   -0.0010  1   -0.0006   -0.0006  1    0.0016    0.0012  1   -0.0001   -0.0008  1   -0.0016   -0.0004  0   -0.0009   -0.0008  0    0.0006   -0.0002  1   -0.0011    0.0007  0\n",
      "  3   -0.0002    0.0012  0   -0.0003   -0.0002  0    0.0008   -0.0003  1   -0.0006    0.0009  0    0.0011    0.0002  1   -0.0008   -0.0014  1   -0.0004   -0.0001  0    0.0009   -0.0021  1   -0.0006    0.0000  0    0.0001   -0.0002  1\n",
      "  4   -0.0013    0.0009  0    0.0003   -0.0003  1    0.0020    0.0008  1   -0.0016    0.0009  0    0.0006    0.0003  1   -0.0002    0.0004  0   -0.0010    0.0009  0   -0.0015    0.0003  0    0.0011   -0.0021  1   -0.0013   -0.0008  0\n",
      "  5   -0.0001   -0.0014  1   -0.0003    0.0013  0    0.0008   -0.0012  1    0.0001   -0.0004  1   -0.0005   -0.0010  1    0.0007    0.0004  1    0.0000   -0.0005  1   -0.0009    0.0001  0    0.0006   -0.0006  1   -0.0011    0.0001  0\n",
      "\n",
      "dict_keys(['val_metrics', 'best_metrics', 'best_accuracy', 'best_roc_auc', 'best_iter', 'best_epoch'])\n",
      "Resume mode - load successful!!\n",
      "ns.best_accuracy:   0.6751047381789885\n",
      "ns.best_roc_auc :   0.7718396936830088\n",
      "ns.best_iter    :   3087\n",
      "ns.best_epoch   :   49\n"
     ]
    }
   ],
   "source": [
    "check_for_resume_training(ns, opt, environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e2120c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:35:00.658632Z",
     "start_time": "2022-09-06T21:35:00.619814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " load_policy(): load policies from ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8/policy_warmup_final_ep_78.pickle\n",
      "setting policy1 attribute .... to None\n",
      "setting policy2 attribute .... to None\n",
      "setting policy3 attribute .... to None\n",
      "setting policy4 attribute .... to None\n",
      "setting policy5 attribute .... to None\n",
      "setting policy6 attribute .... to None\n",
      "setting policy7 attribute .... to None\n",
      "setting policy8 attribute .... to None\n",
      "setting policy9 attribute .... to None\n",
      "setting policy10 attribute .... to None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.load_policy(label = 'policy_warmup_final_ep_78', path = opt['resume_path'], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb29086d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:35:09.892887Z",
     "start_time": "2022-09-06T21:35:09.857752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None]\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print(environ.networks['mtl-net'].logits)\n",
    "print(environ.networks['mtl-net'].policys)\n",
    "print(environ.policy1)\n",
    "print(environ.policy10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5657c03d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:26:02.824382Z",
     "start_time": "2022-09-06T21:26:02.790520Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for k, v in environ.optimizers.items():\n",
    "#     print(f' key: {k}  values: {v}')\n",
    "#     print(v.state_dict())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e3afa36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:25:06.100476Z",
     "start_time": "2022-09-06T21:25:06.055786Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for k, v in environ.schedulers.items():\n",
    "#     print(f' key: {k}  values: {v}')\n",
    "#     print(v.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b0efe7",
   "metadata": {},
   "source": [
    "## Training Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58454ce",
   "metadata": {},
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c01dd8af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T11:27:45.728532Z",
     "start_time": "2022-08-23T11:27:45.696645Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:18.146907Z",
     "iopub.status.busy": "2022-01-07T22:44:18.145721Z",
     "iopub.status.idle": "2022-01-07T22:44:18.191126Z",
     "shell.execute_reply": "2022-01-07T22:44:18.189994Z",
     "shell.execute_reply.started": "2022-01-07T22:44:18.146867Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(f\"\\n folder: {opt['exp_folder']}\",\n",
    "#       f\"\\n layers: {opt['hidden_sizes']}\",    \n",
    "#       f\"                               \\n\",\n",
    "#       f\"\\n diff_sparsity_weights  : {opt['diff_sparsity_weights']}\",\n",
    "#       f\"\\n skip_layer             : {opt['skip_layer']}\",\n",
    "#       f\"\\n is_curriculum          : {opt['is_curriculum']}\",\n",
    "#       f\"\\n curriculum_speed       : {opt['curriculum_speed']}\",\n",
    "#       f\"                              \\n\",    \n",
    "#       f\"\\n decay_lr_rate          : {opt['train']['decay_lr_rate']}\",      \n",
    "#       f\"\\n decay_lr_freq          : {opt['train']['decay_lr_freq']}\",     \n",
    "#       f\"\\n policy_decay_lr_rate   : {opt['train']['policy_decay_lr_rate']}\",      \n",
    "#       f\"\\n policy_decay_lr_freq   : {opt['train']['policy_decay_lr_freq']}\", \n",
    "#       f\"                              \\n\",    \n",
    "#       f\"\\n policy_lr              : {opt['train']['policy_lr']}\", \n",
    "#       f\"\\n lambda_sparsity        : {opt['train']['lambda_sparsity']}\",      \n",
    "#       f\"\\n lambda_sharing         : {opt['train']['lambda_sharing']}\", \n",
    "#       f\"                              \\n\",    \n",
    "#       f\"\\n lambda_tasks           : {opt['train']['lambda_tasks']}\",  \n",
    "#       f\"\\n init_temp              : {opt['train']['init_temp']}\",\n",
    "#       f\"\\n decay_temp             : {opt['train']['decay_temp']}\",    \n",
    "#       f\"\\n decay_temp_freq        : {opt['train']['decay_temp_freq']}\",   \n",
    "#       f\"\\n init_method            : {opt['train']['init_method']}\", \n",
    "#       f\"\\n init_neg_logits        : {opt['train']['init_neg_logits']}\",    \n",
    "#       f\"\\n hard_sampling          : {opt['train']['hard_sampling']}\",\n",
    "#       f\"\\n Warm-up epochs         : {opt['train']['warm_up_epochs']}\",\n",
    "#       f\"\\n training epochs        : {opt['train']['training_epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948a82fb",
   "metadata": {},
   "source": [
    "## Resume Warmup Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a52406",
   "metadata": {},
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3299eec7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:35:06.367736Z",
     "start_time": "2022-09-06T21:35:06.310658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone Initial LR            :      0.001000      Current LR : 0.00025 \n",
      " Tasks    Initial LR            :      0.001000      Current LR : 0.00025    \n",
      " Policy   Initial LR            :      0.010000      Current LR : 0.01  \n",
      "\n",
      " Backbone (Group 0) Initial LR  : 0.001000 \n",
      " Tasks    (Group 1) Initial LR  : 0.001000    \n",
      " Params : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.00025\n",
      "    weight_decay: 0.0001\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.00025\n",
      "    weight_decay: 0.0001\n",
      ") \n",
      "\n",
      " Policy   Initial LR            : 0.010000  \n",
      " Params : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0.0005\n",
      ")  \n",
      "\n",
      "\n",
      " Backbone Initial LR            : 0.001000      Current LR : 0.00025 \n",
      " Tasks    Initial LR            : 0.001000      Current LR : 0.00025    \n",
      " Policy   Initial LR            : 0.010000      Current LR : 0.01  \n",
      "\n",
      "\n",
      "Weights Scheduler Parameters\n",
      "------------------------------\n",
      "    factor                   value: 0.5\n",
      "    min_lrs                  value: [0, 0]\n",
      "    patience                 value: 20\n",
      "    verbose                  value: True\n",
      "    cooldown                 value: 5\n",
      "    cooldown_counter         value: 0\n",
      "    mode                     value: min\n",
      "    threshold                value: 0.0001\n",
      "    threshold_mode           value: rel\n",
      "    best                     value: 2.1153364644531476\n",
      "    num_bad_epochs           value: 7\n",
      "    mode_worse               value: inf\n",
      "    eps                      value: 1e-08\n",
      "    last_epoch               value: 78\n",
      "    _last_lr                 value: [0.00025, 0.00025]\n",
      "\n",
      "Policy Scheduler Parameters\n",
      "-----------------------------\n",
      "    factor                   value: 0.5\n",
      "    min_lrs                  value: [0]\n",
      "    patience                 value: 20\n",
      "    verbose                  value: True\n",
      "    cooldown                 value: 5\n",
      "    cooldown_counter         value: 0\n",
      "    mode                     value: min\n",
      "    threshold                value: 0.0001\n",
      "    threshold_mode           value: rel\n",
      "    best                     value: inf\n",
      "    num_bad_epochs           value: 0\n",
      "    mode_worse               value: inf\n",
      "    eps                      value: 1e-08\n",
      "    last_epoch               value: 0\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone Initial LR            :      {environ.opt['train']['backbone_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[0]['lr']} \\n\"\n",
    "       f\" Tasks    Initial LR            :      {environ.opt['train']['task_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[1]['lr']}    \\n\"\n",
    "       f\" Policy   Initial LR            :      {environ.opt['train']['policy_lr']:4f}      Current LR : {environ.optimizers['alphas'].param_groups[0]['lr']}  \\n\")\n",
    "\n",
    "print( f\" Backbone (Group 0) Initial LR  : {environ.opt['train']['backbone_lr']:4f} \\n\"\n",
    "       f\" Tasks    (Group 1) Initial LR  : {environ.opt['train']['task_lr']:4f}    \\n Params : {environ.optimizers['weights']} \\n\\n\"\n",
    "       f\" Policy   Initial LR            : {environ.opt['train']['policy_lr']:4f}  \\n Params : {environ.optimizers['alphas']}  \\n\\n\")\n",
    "\n",
    "print( f\" Backbone Initial LR            : {environ.opt['train']['backbone_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[0]['lr']} \\n\"\n",
    "       f\" Tasks    Initial LR            : {environ.opt['train']['task_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[1]['lr']}    \\n\"\n",
    "       f\" Policy   Initial LR            : {environ.opt['train']['policy_lr']:4f}      Current LR : {environ.optimizers['alphas'].param_groups[0]['lr']}  \\n\")\n",
    "\n",
    "\n",
    "\n",
    "print_underline('Weights Scheduler Parameters', verbose = True) \n",
    "for k,i in environ.schedulers['weights'].state_dict().items():\n",
    "    print(f\"    {k:20s}     value: {i}\")\n",
    "\n",
    "print_underline('Policy Scheduler Parameters', verbose = True)\n",
    "for k,i in environ.schedulers['alphas'].state_dict().items():\n",
    "    print(f\"    {k:20s}     value: {i}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f554638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:35:09.892887Z",
     "start_time": "2022-09-06T21:35:09.857752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None]\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print(environ.networks['mtl-net'].logits)\n",
    "print(environ.networks['mtl-net'].policys)\n",
    "print(environ.policy1)\n",
    "print(environ.policy10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91147630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:35:13.338243Z",
     "start_time": "2022-09-06T21:35:12.748869Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training preparation: - check for CUDA - cuda available as device id: [0]\n",
      " --> sparsechem_env.cuda()\n",
      " policy policy1 is None\n",
      " policy policy2 is None\n",
      " policy policy3 is None\n",
      " policy policy4 is None\n",
      " policy policy5 is None\n",
      " policy policy6 is None\n",
      " policy policy7 is None\n",
      " policy policy8 is None\n",
      " policy policy9 is None\n",
      " policy policy10 is None\n",
      "dict_keys(['weights', 'alphas'])\n",
      " opt:  weights  \n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([472, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([472, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([472, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([472, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([472])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([472])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([472])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([472])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([624, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([624, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([624, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([624, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([624])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([624])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([624])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([624])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([688, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([688, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([688, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([688, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([688])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([688])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([688])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([688])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([192, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([192, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([192, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([192, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([192])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([192])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([192])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([192])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([620, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([620, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([620, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([620, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([620])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([620])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([620])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([620])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([184, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([184, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([184, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([184, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([184])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([184])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([184])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([184])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([224, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([224, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([224, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([224, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([224])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([224])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([224])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([224])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([148, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([148, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([148, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([148, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([148])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([148])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([148])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([148])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([344, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([344, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([344, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([344, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([344])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([344])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([344])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([344])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([72, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([72, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([72, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([72, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([72])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([72])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([72])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([72])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([32000, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([32000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([32000, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([32000, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " item [step] not a Tensor ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg] is  Tensor - move  to cuda ... \n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cpu\n",
      " item [exp_avg_sq] is  Tensor - move  to cuda ... \n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " opt:  alphas  \n",
      " training preparation: - set print_freq to                        : 63 \n",
      " training preparation: - set batches per warmup training epoch to : 63\n",
      " training preparation: - set batches per weight training epoch to : 42\n",
      " training preparation: - set batches per policy training epoch to : 21\n",
      " training preparation: - set batches per validation to            : 22\n",
      " training preparation: - warmup_epochs                            : 20\n",
      " training preparation: - weight/policy training epochs            : 250\n",
      " training preparation: - set curriculum speed  to                 : 3\n",
      " training preparation: - set curriculum epochs to                 : 0\n",
      " training preparation: - write checkpoints                        : True\n",
      " training preparation complete . . .\n"
     ]
    }
   ],
   "source": [
    "training_initializations(ns, opt, environ, dldrs,  warmup = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3510563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:35:23.692129Z",
     "start_time": "2022-09-06T21:35:23.649314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sparsity regularization                    : 0.001\n",
      " Sharing  regularization                    : 0.05 \n",
      " Tasks    regularization                    : 1.0   \n",
      " Gumbel Temp                                : 2.500000         \n",
      " Gumbel Temp decay                          : 3\n"
     ]
    }
   ],
   "source": [
    "print(f\" Sparsity regularization                    : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "      f\" Sharing  regularization                    : {environ.opt['train']['lambda_sharing']} \\n\"\n",
    "      f\" Tasks    regularization                    : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "      f\" Gumbel Temp                                : {environ.gumbel_temperature:.6f}         \\n\" #\n",
    "      f\" Gumbel Temp decay                          : {environ.opt['train']['decay_temp_freq']}\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a2fabdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:35:34.010544Z",
     "start_time": "2022-09-06T21:35:33.968016Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_epoch          : 78\n",
      "current_iters          : 4914\n",
      "train_total_epochs     : 250\n",
      "\n",
      "Batches in warmup epoch (trn_iters_warmup) : 63\n",
      "Batches in weight epoch (trn_iters_weight) : 42\n",
      "Batches in policy epoch (trn_iters_policy) : 21\n",
      "Batches in validation epoch (ns.eval_iters): 22\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      " Last Epoch: 78   # of warm-up epochs to do:  250 - Run epochs 79 to 328\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      "[e] Last ep:78  it:4914  -  Losses:   \t Task: 2.2534   \t Sparsity: 1.41826e-05    \t Sharing: 5.65983e-06    \t Total: 2.2535 \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed : 78       # of epochs to run:  250 -->  epochs 79 to 328\n",
      " Backbone Initial LR  : 0.001      Current LR : 0.00025 \n",
      " Heads    Initial LR  : 0.001      Current LR : 0.00025\n",
      " Policy   Initial LR  : 0.01      Current LR : 0.01\n",
      " Regularization tasks : 1.0          Sparsity: 0.001           sharing: 0.05\n",
      " curriculum training  : False      Cirriculum speed: 3     num_training_layers : None\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "\n",
      "\n",
      " ep:   78   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.0008   -0.0005  1    0.0013    0.0009  1   -0.0001    0.0017  0    0.0017   -0.0002  1    0.0005   -0.0006  1    0.0003   -0.0005  1    0.0010    0.0008  1   -0.0007    0.0006  0    0.0002   -0.0007  1   -0.0003   -0.0013  1\n",
      "  1    0.0004   -0.0003  1   -0.0003    0.0003  0   -0.0009    0.0003  0   -0.0003    0.0010  0    0.0009    0.0000  1   -0.0004   -0.0005  1    0.0012    0.0008  1   -0.0003    0.0020  0    0.0006    0.0001  1   -0.0008    0.0009  0\n",
      "  2    0.0008    0.0018  0   -0.0011   -0.0003  0    0.0016   -0.0010  1   -0.0006   -0.0006  1    0.0016    0.0012  1   -0.0001   -0.0008  1   -0.0016   -0.0004  0   -0.0009   -0.0008  0    0.0006   -0.0002  1   -0.0011    0.0007  0\n",
      "  3   -0.0002    0.0012  0   -0.0003   -0.0002  0    0.0008   -0.0003  1   -0.0006    0.0009  0    0.0011    0.0002  1   -0.0008   -0.0014  1   -0.0004   -0.0001  0    0.0009   -0.0021  1   -0.0006    0.0000  0    0.0001   -0.0002  1\n",
      "  4   -0.0013    0.0009  0    0.0003   -0.0003  1    0.0020    0.0008  1   -0.0016    0.0009  0    0.0006    0.0003  1   -0.0002    0.0004  0   -0.0010    0.0009  0   -0.0015    0.0003  0    0.0011   -0.0021  1   -0.0013   -0.0008  0\n",
      "  5   -0.0001   -0.0014  1   -0.0003    0.0013  0    0.0008   -0.0012  1    0.0001   -0.0004  1   -0.0005   -0.0010  1    0.0007    0.0004  1    0.0000   -0.0005  1   -0.0009    0.0001  0    0.0006   -0.0006  1   -0.0011    0.0001  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"current_epoch          : {ns.current_epoch}\") \n",
    "print(f\"current_iters          : {ns.current_iter}\")  \n",
    "print(f\"train_total_epochs     : {ns.training_epochs}\") \n",
    "print()\n",
    "print(f\"Batches in warmup epoch (trn_iters_warmup) : {ns.trn_iters_warmup}\")\n",
    "print(f\"Batches in weight epoch (trn_iters_weight) : {ns.trn_iters_weights}\")\n",
    "print(f\"Batches in policy epoch (trn_iters_policy) : {ns.trn_iters_policy}\")\n",
    "print(f\"Batches in validation epoch (ns.eval_iters): {ns.eval_iters}\")\n",
    "print()\n",
    "\n",
    "print_heading(f\" Last Epoch: {ns.current_epoch}   # of warm-up epochs to do:  {ns.training_epochs} - Run epochs {ns.current_epoch+1} to {ns.current_epoch + ns.training_epochs}\", verbose = True)\n",
    "\n",
    "\n",
    "print_loss(ns.val_metrics, title = f\"[e] Last ep:{ns.current_epoch}  it:{ns.current_iter} \")\n",
    "\n",
    "print_heading(f\" Last Epoch Completed : {ns.current_epoch}       # of epochs to run:  {ns.training_epochs} -->  epochs {ns.current_epoch+1} to {ns.training_epochs + ns.current_epoch}\"\n",
    "              f\"\\n Backbone Initial LR  : {environ.opt['train']['backbone_lr']}      Current LR : {environ.optimizers['weights'].param_groups[0]['lr']} \"\n",
    "              f\"\\n Heads    Initial LR  : {environ.opt['train']['task_lr']}      Current LR : {environ.optimizers['weights'].param_groups[1]['lr']}\"              \n",
    "              f\"\\n Policy   Initial LR  : {environ.opt['train']['policy_lr']}      Current LR : {environ.optimizers['alphas'].param_groups[0]['lr']}\"\n",
    "              f\"\\n Regularization tasks : {environ.opt['train']['lambda_tasks']}          Sparsity: {environ.opt['train']['lambda_sparsity']}           sharing: {environ.opt['train']['lambda_sharing']}\"\n",
    "              f\"\\n curriculum training  : {opt['is_curriculum']}      Cirriculum speed: {opt['curriculum_speed']}     num_training_layers : {ns.num_train_layers}\", \n",
    "              verbose = True)\n",
    "\n",
    "print()\n",
    "environ.display_trained_logits(ns.current_epoch)\n",
    "# environ.display_current_policy(ns.current_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c00e58c",
   "metadata": {},
   "source": [
    "### Resume Warmup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1c0689a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T23:01:40.153196Z",
     "start_time": "2022-09-06T22:14:05.465742Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------\n",
      " Last Epoch: 100   # of warm-up epochs to do:  50 - Run epochs 101 to 150\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Ep  | Trunk LR  Heads LR  Polcy LR  Gmbl Tmp |  trn tsk    trn spar    trn shar   trn ttl |    logloss   bceloss  avg prec    aucroc     aucpr    f1_max |  val tsk    val spar    val shar     total |  time |\n",
      " 101 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.8247   1.530e-05   3.053e-05    0.8248 |  4.519e-06   0.50004   0.66789   0.76590   0.65444   0.69622 |   2.3441   3.073e-06   6.132e-06    2.3441 |  55.8 |\n",
      " 102 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.7696   1.530e-05   3.053e-05    0.7697 |  4.547e-06   0.50393   0.66754   0.76562   0.65400   0.69648 |   2.3588   3.073e-06   6.132e-06    2.3588 |  58.6 |\n",
      " 103 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.7835   1.530e-05   3.053e-05    0.7835 |  4.583e-06   0.50256   0.66757   0.76597   0.65399   0.69610 |   2.3772   3.073e-06   6.132e-06    2.3772 |  56.3 |\n",
      " 104 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.8359   1.530e-05   3.053e-05    0.8360 |  4.568e-06   0.50270   0.66813   0.76598   0.65442   0.69664 |   2.3693   3.073e-06   6.132e-06    2.3693 |  56.9 |\n",
      " 105 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.7008   1.530e-05   3.053e-05    0.7008 |  4.574e-06   0.50171   0.66864   0.76590   0.65534   0.69668 |   2.3727   3.073e-06   6.132e-06    2.3727 |  56.1 |\n",
      " 106 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.8241   1.530e-05   3.053e-05    0.8241 |  4.569e-06   0.50291   0.66817   0.76606   0.65499   0.69649 |   2.3698   3.073e-06   6.132e-06    2.3698 |  57.3 |\n",
      " 107 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.7869   1.530e-05   3.053e-05    0.7870 |  4.627e-06   0.50572   0.66713   0.76553   0.65345   0.69569 |   2.4000   3.073e-06   6.132e-06    2.4000 |  56.6 |\n",
      " 108 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.7261   1.530e-05   3.053e-05    0.7262 |  4.612e-06   0.50529   0.66850   0.76607   0.65514   0.69690 |   2.3921   3.073e-06   6.132e-06    2.3921 |  57.0 |\n",
      " 109 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.8098   1.530e-05   3.053e-05    0.8098 |  4.582e-06   0.50553   0.66839   0.76642   0.65492   0.69647 |   2.3768   3.073e-06   6.132e-06    2.3768 |  56.8 |\n",
      " 110 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.6903   1.530e-05   3.053e-05    0.6903 |  4.654e-06   0.50752   0.66750   0.76541   0.65379   0.69619 |   2.4143   3.073e-06   6.132e-06    2.4143 |  57.9 |\n",
      " 111 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.6620   1.530e-05   3.053e-05    0.6621 |  4.651e-06   0.50875   0.66686   0.76547   0.65349   0.69546 |   2.4126   3.073e-06   6.132e-06    2.4126 |  56.7 |\n",
      " 112 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.7944   1.530e-05   3.053e-05    0.7944 |  4.609e-06   0.51048   0.66681   0.76495   0.65334   0.69531 |   2.3905   3.073e-06   6.132e-06    2.3905 |  56.9 |\n",
      " 113 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.7120   1.530e-05   3.053e-05    0.7121 |  4.653e-06   0.51124   0.66611   0.76499   0.65248   0.69509 |   2.4136   3.073e-06   6.132e-06    2.4136 |  57.0 |\n",
      " 114 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.7106   1.530e-05   3.053e-05    0.7106 |  4.644e-06   0.51135   0.66697   0.76462   0.65345   0.69495 |   2.4089   3.073e-06   6.132e-06    2.4089 |  58.8 |\n",
      " 115 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.7537   1.530e-05   3.053e-05    0.7537 |  4.711e-06   0.51340   0.66667   0.76495   0.65282   0.69525 |   2.4438   3.073e-06   6.132e-06    2.4438 |  57.1 |\n",
      " 116 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.7502   1.530e-05   3.053e-05    0.7502 |  4.671e-06   0.51381   0.66705   0.76461   0.65335   0.69521 |   2.4228   3.073e-06   6.132e-06    2.4228 |  55.9 |\n",
      " 117 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.6765   1.530e-05   3.053e-05    0.6766 |  4.672e-06   0.51546   0.66648   0.76429   0.65270   0.69536 |   2.4233   3.073e-06   6.132e-06    2.4233 |  57.0 |\n",
      " 118 | 1.25e-04  1.25e-04  1.00e-02  2.50e+00 |   0.6681   1.530e-05   3.053e-05    0.6681 |  4.710e-06   0.51877   0.66637   0.76402   0.65290   0.69459 |   2.4430   3.073e-06   6.132e-06    2.4430 |  56.3 |\n",
      "Epoch   118: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch   118: reducing learning rate of group 1 to 6.2500e-05.\n",
      " 119 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6234   1.530e-05   3.053e-05    0.6235 |  4.772e-06   0.52115   0.66693   0.76433   0.65327   0.69490 |   2.4755   3.073e-06   6.132e-06    2.4755 |  56.3 |\n",
      " 120 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6282   1.530e-05   3.053e-05    0.6283 |  4.805e-06   0.52333   0.66653   0.76415   0.65296   0.69484 |   2.4925   3.073e-06   6.132e-06    2.4925 |  56.1 |\n",
      " 121 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.5945   1.530e-05   3.053e-05    0.5946 |  4.823e-06   0.52491   0.66646   0.76418   0.65263   0.69474 |   2.5020   3.073e-06   6.132e-06    2.5020 |  57.1 |\n",
      " 122 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6966   1.530e-05   3.053e-05    0.6967 |  4.787e-06   0.52278   0.66648   0.76431   0.65263   0.69489 |   2.4833   3.073e-06   6.132e-06    2.4833 |  56.0 |\n",
      " 123 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.5516   1.530e-05   3.053e-05    0.5516 |  4.815e-06   0.52913   0.66599   0.76379   0.65224   0.69471 |   2.4976   3.073e-06   6.132e-06    2.4976 |  56.8 |\n",
      " 124 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6685   1.530e-05   3.053e-05    0.6685 |  4.777e-06   0.52743   0.66621   0.76415   0.65236   0.69482 |   2.4777   3.073e-06   6.132e-06    2.4777 |  57.1 |\n",
      " 125 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6511   1.530e-05   3.053e-05    0.6512 |  4.870e-06   0.53034   0.66564   0.76397   0.65175   0.69431 |   2.5261   3.073e-06   6.132e-06    2.5261 |  57.0 |\n",
      " Ep  | Trunk LR  Heads LR  Polcy LR  Gmbl Tmp |  trn tsk    trn spar    trn shar   trn ttl |    logloss   bceloss  avg prec    aucroc     aucpr    f1_max |  val tsk    val spar    val shar     total |  time |\n",
      " 126 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.7239   1.530e-05   3.053e-05    0.7239 |  4.886e-06   0.53032   0.66592   0.76417   0.65208   0.69450 |   2.5345   3.073e-06   6.132e-06    2.5345 |  59.3 |\n",
      " 127 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6048   1.530e-05   3.053e-05    0.6049 |  4.856e-06   0.53164   0.66584   0.76422   0.65222   0.69441 |   2.5191   3.073e-06   6.132e-06    2.5191 |  56.3 |\n",
      " 128 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6276   1.530e-05   3.053e-05    0.6276 |  4.891e-06   0.53344   0.66551   0.76366   0.65174   0.69389 |   2.5369   3.073e-06   6.132e-06    2.5369 |  55.8 |\n",
      " 129 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.5783   1.530e-05   3.053e-05    0.5783 |  4.922e-06   0.53706   0.66550   0.76344   0.65185   0.69407 |   2.5530   3.073e-06   6.132e-06    2.5531 |  56.8 |\n",
      " 130 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6111   1.530e-05   3.053e-05    0.6112 |  4.891e-06   0.53766   0.66477   0.76312   0.65109   0.69358 |   2.5372   3.073e-06   6.132e-06    2.5372 |  56.2 |\n",
      " 131 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.7144   1.530e-05   3.053e-05    0.7145 |  4.925e-06   0.53761   0.66498   0.76313   0.65139   0.69344 |   2.5549   3.073e-06   6.132e-06    2.5549 |  57.0 |\n",
      " 132 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.5805   1.530e-05   3.053e-05    0.5806 |  4.973e-06   0.53918   0.66423   0.76250   0.65046   0.69274 |   2.5795   3.073e-06   6.132e-06    2.5795 |  56.4 |\n",
      " 133 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6295   1.530e-05   3.053e-05    0.6296 |  4.984e-06   0.54302   0.66449   0.76291   0.65045   0.69308 |   2.5853   3.073e-06   6.132e-06    2.5853 |  56.9 |\n",
      " 134 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.5659   1.530e-05   3.053e-05    0.5660 |  4.936e-06   0.54208   0.66470   0.76275   0.65097   0.69348 |   2.5602   3.073e-06   6.132e-06    2.5602 |  55.8 |\n",
      " 135 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6752   1.530e-05   3.053e-05    0.6752 |  5.003e-06   0.54293   0.66520   0.76311   0.65160   0.69358 |   2.5951   3.073e-06   6.132e-06    2.5951 |  56.9 |\n",
      " 136 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.5442   1.530e-05   3.053e-05    0.5442 |  5.037e-06   0.54633   0.66443   0.76271   0.65074   0.69268 |   2.6126   3.073e-06   6.132e-06    2.6126 |  55.6 |\n",
      " 137 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.5703   1.530e-05   3.053e-05    0.5704 |  4.980e-06   0.54444   0.66513   0.76263   0.65148   0.69395 |   2.5830   3.073e-06   6.132e-06    2.5830 |  58.1 |\n",
      " 138 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.5228   1.530e-05   3.053e-05    0.5228 |  5.027e-06   0.54815   0.66473   0.76236   0.65130   0.69354 |   2.6075   3.073e-06   6.132e-06    2.6075 |  56.7 |\n",
      " 139 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6651   1.530e-05   3.053e-05    0.6652 |  5.042e-06   0.55335   0.66384   0.76223   0.65025   0.69280 |   2.6152   3.073e-06   6.132e-06    2.6152 |  56.7 |\n",
      " 140 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.5849   1.530e-05   3.053e-05    0.5849 |  5.075e-06   0.55155   0.66394   0.76243   0.65036   0.69315 |   2.6322   3.073e-06   6.132e-06    2.6323 |  57.2 |\n",
      " 141 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6830   1.530e-05   3.053e-05    0.6831 |  5.067e-06   0.55303   0.66426   0.76206   0.65063   0.69312 |   2.6284   3.073e-06   6.132e-06    2.6284 |  56.8 |\n",
      " 142 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6531   1.530e-05   3.053e-05    0.6531 |  5.173e-06   0.55506   0.66400   0.76226   0.65035   0.69280 |   2.6835   3.073e-06   6.132e-06    2.6835 |  57.3 |\n",
      " 143 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.5923   1.530e-05   3.053e-05    0.5924 |  5.068e-06   0.55480   0.66376   0.76193   0.65001   0.69258 |   2.6286   3.073e-06   6.132e-06    2.6286 |  58.5 |\n",
      " 144 | 6.25e-05  6.25e-05  1.00e-02  2.50e+00 |   0.6021   1.530e-05   3.053e-05    0.6022 |  5.146e-06   0.55685   0.66408   0.76232   0.65054   0.69281 |   2.6693   3.073e-06   6.132e-06    2.6693 |  56.6 |\n",
      "Epoch   144: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch   144: reducing learning rate of group 1 to 3.1250e-05.\n",
      " 145 | 3.13e-05  3.13e-05  1.00e-02  2.50e+00 |   0.5516   1.530e-05   3.053e-05    0.5516 |  5.217e-06   0.56204   0.66364   0.76204   0.64995   0.69232 |   2.7061   3.073e-06   6.132e-06    2.7062 |  57.7 |\n",
      " 146 | 3.13e-05  3.13e-05  1.00e-02  2.50e+00 |   0.5703   1.530e-05   3.053e-05    0.5704 |  5.217e-06   0.56351   0.66368   0.76204   0.64991   0.69254 |   2.7060   3.073e-06   6.132e-06    2.7061 |  57.0 |\n",
      " 147 | 3.13e-05  3.13e-05  1.00e-02  2.50e+00 |   0.4592   1.530e-05   3.053e-05    0.4593 |  5.230e-06   0.56462   0.66377   0.76199   0.64987   0.69276 |   2.7129   3.073e-06   6.132e-06    2.7129 |  57.9 |\n",
      " 148 | 3.13e-05  3.13e-05  1.00e-02  2.50e+00 |   0.6224   1.530e-05   3.053e-05    0.6225 |  5.251e-06   0.56512   0.66379   0.76173   0.65015   0.69279 |   2.7239   3.073e-06   6.132e-06    2.7239 |  56.7 |\n",
      " 149 | 3.13e-05  3.13e-05  1.00e-02  2.50e+00 |   0.5931   1.530e-05   3.053e-05    0.5932 |  5.292e-06   0.56741   0.66397   0.76193   0.65039   0.69279 |   2.7448   3.073e-06   6.132e-06    2.7448 |  59.0 |\n",
      " 150 | 3.13e-05  3.13e-05  1.00e-02  2.50e+00 |   0.5951   1.530e-05   3.053e-05    0.5951 |  5.287e-06   0.56971   0.66344   0.76178   0.64962   0.69253 |   2.7423   3.073e-06   6.132e-06    2.7424 |  56.7 |\n",
      " save_policy(): save policies to ../../experiments/AdaSparseChem-cb29-10task/4000x6_0906_1312_lr0.001_do0.8_RETRAIN_1/policy_warmup_final_ep_150.pickle\n",
      " save warmup checkpoint  to :  warmup_final_ep_150\n",
      " save warmup metrics to     :  warmup_final_ep_150\n",
      "[Final] ep:150  it:9450 -  Losses:   \t Task: 2.7423   \t Sparsity: 3.07319e-06    \t Sharing: 6.13206e-06    \t Total: 2.7424 \n",
      "\n",
      " ep:  150   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.0008   -0.0005  1    0.0013    0.0009  1   -0.0001    0.0017  0    0.0017   -0.0002  1    0.0005   -0.0006  1    0.0003   -0.0005  1    0.0010    0.0008  1   -0.0007    0.0006  0    0.0002   -0.0007  1   -0.0003   -0.0013  1\n",
      "  1    0.0004   -0.0003  1   -0.0003    0.0003  0   -0.0009    0.0003  0   -0.0003    0.0010  0    0.0009    0.0000  1   -0.0004   -0.0005  1    0.0012    0.0008  1   -0.0003    0.0020  0    0.0006    0.0001  1   -0.0008    0.0009  0\n",
      "  2    0.0008    0.0018  0   -0.0011   -0.0003  0    0.0016   -0.0010  1   -0.0006   -0.0006  1    0.0016    0.0012  1   -0.0001   -0.0008  1   -0.0016   -0.0004  0   -0.0009   -0.0008  0    0.0006   -0.0002  1   -0.0011    0.0007  0\n",
      "  3   -0.0002    0.0012  0   -0.0003   -0.0002  0    0.0008   -0.0003  1   -0.0006    0.0009  0    0.0011    0.0002  1   -0.0008   -0.0014  1   -0.0004   -0.0001  0    0.0009   -0.0021  1   -0.0006    0.0000  0    0.0001   -0.0002  1\n",
      "  4   -0.0013    0.0009  0    0.0003   -0.0003  1    0.0020    0.0008  1   -0.0016    0.0009  0    0.0006    0.0003  1   -0.0002    0.0004  0   -0.0010    0.0009  0   -0.0015    0.0003  0    0.0011   -0.0021  1   -0.0013   -0.0008  0\n",
      "  5   -0.0001   -0.0014  1   -0.0003    0.0013  0    0.0008   -0.0012  1    0.0001   -0.0004  1   -0.0005   -0.0010  1    0.0007    0.0004  1    0.0000   -0.0005  1   -0.0009    0.0001  0    0.0006   -0.0006  1   -0.0011    0.0001  0\n",
      "\n",
      "\n",
      " ep:  150    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.5003    0.4997  -    0.5001    0.4999  -    0.4996    0.5004  -    0.5005    0.4995  -    0.5003    0.4997  -    0.5002    0.4998  -    0.5000    0.5000  -    0.4997    0.5003  -    0.5002    0.4998  -    0.5003    0.4997  -\n",
      "  1    0.5002    0.4998  -    0.4999    0.5001  -    0.4997    0.5003  -    0.4997    0.5003  -    0.5002    0.4998  -    0.5000    0.5000  -    0.5001    0.4999  -    0.4994    0.5006  -    0.5001    0.4999  -    0.4996    0.5004  -\n",
      "  2    0.4997    0.5003  -    0.4998    0.5002  -    0.5006    0.4994  -    0.5000    0.5000  -    0.5001    0.4999  -    0.5002    0.4998  -    0.4997    0.5003  -    0.5000    0.5000  -    0.5002    0.4998  -    0.4996    0.5004  -\n",
      "  3    0.4996    0.5004  -    0.5000    0.5000  -    0.5003    0.4997  -    0.4996    0.5004  -    0.5002    0.4998  -    0.5002    0.4998  -    0.4999    0.5001  -    0.5008    0.4992  -    0.4998    0.5002  -    0.5001    0.4999  -\n",
      "  4    0.4994    0.5006  -    0.5001    0.4999  -    0.5003    0.4997  -    0.4994    0.5006  -    0.5001    0.4999  -    0.4999    0.5001  -    0.4995    0.5005  -    0.4995    0.5005  -    0.5008    0.4992  -    0.4999    0.5001  -\n",
      "  5    0.5003    0.4997  -    0.4996    0.5004  -    0.5005    0.4995  -    0.5001    0.4999  -    0.5001    0.4999  -    0.5001    0.4999  -    0.5001    0.4999  -    0.4997    0.5003  -    0.5003    0.4997  -    0.4997    0.5003  -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warmup_phase(ns,opt, environ, dldrs, epochs = 50, verbose = False, disable_tqdm = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98d8d890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T21:31:55.046370Z",
     "start_time": "2022-09-06T21:31:54.974776Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([472, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([472, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([472, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([472])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([472])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([472])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([624, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([624, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([624, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([624])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([624])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([624])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([688, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([688, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([688, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([688])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([688])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([688])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([192, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([192, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([192, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([192])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([192])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([192])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([620, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([620, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([620, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([620])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([620])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([620])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([184, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([184, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([184, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([184])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([184])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([184])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([224, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([224, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([224, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([224])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([224])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([224])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([148, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([148, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([148, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([148])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([148])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([148])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([344, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([344, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([344, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([344])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([344])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([344])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([72, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([72, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([72, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([72])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([72])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([72])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([32000, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([32000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([32000, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([4000, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([4000, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([4000, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([4000, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([4000, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([4000, 4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000, 4000])  location: cuda:0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " optimizer: weights    key: torch.Size([4000])   type: <class 'torch.nn.parameter.Parameter'>   device: cuda:0  value: <class 'dict'>\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      " key: step                  value: 4914         shape: --       location: --\n",
      " key: exp_avg               value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n",
      " key: exp_avg_sq            value: <class 'torch.Tensor'>   shape: torch.Size([4000])  location: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "for o in environ.optimizers.keys():\n",
    "    for k, state in environ.optimizers[o].state.items():\n",
    "        print(\"------------------------------------------------------------------------------------------------------------------\")\n",
    "        print(f' optimizer: {o}    key: {k.shape}   type: {type(k)}   device: {k.device}  value: {type(state)}')\n",
    "#         print(k)\n",
    "        print(\"------------------------------------------------------------------------------------------------------------------\")\n",
    "    #     print(state)\n",
    "\n",
    "        for kk, vv in state.items():\n",
    "            if torch.is_tensor(vv) :\n",
    "                print(f' key: {kk:20s}  value: {type(vv)}   shape: {vv.shape}  location: {vv.device}')\n",
    "            else:\n",
    "                print(f' key: {kk:20s}  value: {vv}         shape: --       location: --')\n",
    "#             print(vv)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf43add",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Resume Weight/Policy Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9ae42",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f0b13dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:54:58.418648Z",
     "start_time": "2022-09-05T20:54:58.319137Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " trainset.y_class                                   :  [(254529, 472), (254529, 624), (254529, 688), (254529, 192), (254529, 620), (254529, 184), (254529, 224), (254529, 148), (254529, 344), (254529, 72)] \n",
      " trainset1.y_class                                  :  [(168649, 472), (168649, 624), (168649, 688), (168649, 192), (168649, 620), (168649, 184), (168649, 224), (168649, 148), (168649, 344), (168649, 72)] \n",
      " trainset2.y_class                                  :  [(85880, 472), (85880, 624), (85880, 688), (85880, 192), (85880, 620), (85880, 184), (85880, 224), (85880, 148), (85880, 344), (85880, 72)] \n",
      " valset.y_class                                     :  [(86274, 472), (86274, 624), (86274, 688), (86274, 192), (86274, 620), (86274, 184), (86274, 224), (86274, 148), (86274, 344), (86274, 72)]  \n",
      "\n",
      "                                Total                :  595332 \n",
      "\n",
      "\n",
      "Training dataset :\n",
      "--------------------\n",
      "  Size of training set 0 (warm up)                   :  254529 \n",
      "  Number of batches in training 0 (warm up)          :  63 \n",
      "  Size of training set 1 (network parms)             :  168649 \n",
      "  Number of batches in training 1 (network parms)    :  42 \n",
      "  Size of training set 2 (policy weights)            :  85880 \n",
      "  Number of batches in training 2 (policy weights)   :  21 \n",
      "  training set num of positive                       :  18631 \n",
      "  training set num of negative                       :  107922 \n",
      "  task_weights_list[0].aggregation_weight sum        :  199.0\n",
      "\n",
      "\n",
      "Validation dataset :\n",
      "----------------------\n",
      "  Rows in dataset                                    : 86274\n",
      "  Number of batches in dataset                       : 22\n",
      "  validation set num of positive                     : 18631\n",
      "  validation set num of negative                     : 107922\n",
      "  task_weights_list[0].aggregation_weight sum        : 199.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "disp_dataloader_info(dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "535ae8a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T21:06:38.449577Z",
     "start_time": "2022-09-05T21:06:38.413520Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model optimizers defined . . . policy_learning: True\n",
      " Model schedulers defined . . . policy_learning: True\n",
      " Metrics CSV file header written . . . \n",
      " Model initializations complete . . . \n"
     ]
    }
   ],
   "source": [
    "ns.flag = 'update_weights'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3c996dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T21:18:31.868311Z",
     "start_time": "2022-09-05T21:18:31.829852Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone Initial LR            :      0.001000      Current LR : 0.001 \n",
      " Tasks    Initial LR            :      0.001000      Current LR : 0.001    \n",
      " Policy   Initial LR            :      0.010000      Current LR : 0.01  \n",
      "\n",
      " Backbone (Group 0) Initial LR  : 0.001000 \n",
      " Tasks    (Group 1) Initial LR  : 0.001000    \n",
      " Params : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      "\n",
      "Parameter Group 1\n",
      "    dampening: 0\n",
      "    lr: 0.001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      ") \n",
      "\n",
      " Policy   Initial LR            : 0.010000  \n",
      " Params : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0.0005\n",
      ")  \n",
      "\n",
      "\n",
      " Backbone Initial LR            : 0.001000      Current LR : 0.001 \n",
      " Tasks    Initial LR            : 0.001000      Current LR : 0.001    \n",
      " Policy   Initial LR            : 0.010000      Current LR : 0.01  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone Initial LR            :      {environ.opt['train']['backbone_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[0]['lr']} \\n\"\n",
    "       f\" Tasks    Initial LR            :      {environ.opt['train']['task_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[1]['lr']}    \\n\"\n",
    "       f\" Policy   Initial LR            :      {environ.opt['train']['policy_lr']:4f}      Current LR : {environ.optimizers['alphas'].param_groups[0]['lr']}  \\n\")\n",
    "\n",
    "print( f\" Backbone (Group 0) Initial LR  : {environ.opt['train']['backbone_lr']:4f} \\n\"\n",
    "       f\" Tasks    (Group 1) Initial LR  : {environ.opt['train']['task_lr']:4f}    \\n Params : {environ.optimizers['weights']} \\n\\n\"\n",
    "       f\" Policy   Initial LR            : {environ.opt['train']['policy_lr']:4f}  \\n Params : {environ.optimizers['alphas']}  \\n\\n\")\n",
    "\n",
    "print( f\" Backbone Initial LR            : {environ.opt['train']['backbone_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[0]['lr']} \\n\"\n",
    "       f\" Tasks    Initial LR            : {environ.opt['train']['task_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[1]['lr']}    \\n\"\n",
    "       f\" Policy   Initial LR            : {environ.opt['train']['policy_lr']:4f}      Current LR : {environ.optimizers['alphas'].param_groups[0]['lr']}  \\n\")\n",
    "\n",
    "print_underline('Weights Scheduler Parameters', verbose = True) \n",
    "for k,i in environ.schedulers['weights'].state_dict().items():\n",
    "    print(f\"    {k:20s}     value: {i}\")\n",
    "\n",
    "print_underline('Policy Scheduler Parameters', verbose = True)\n",
    "for k,i in environ.schedulers['alphas'].state_dict().items():\n",
    "    print(f\"    {k:20s}     value: {i}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a832d2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T09:16:41.125958Z",
     "start_time": "2022-09-06T09:16:41.083776Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training preparation: - check for CUDA - cuda available as device id: [0]\n",
      "sparsechem_env.cuda()\n",
      " training preparation: - set print_freq to                                 : 63 \n",
      " training preparation: - set number of batches per warmup training epoch to: 63\n",
      " training preparation: - set number of batches per weight training epoch to: 42\n",
      " training preparation: - set number of batches per policy training epoch to: 21\n",
      " training preparation: - set number of batches per validation to           : 22\n",
      " training preparation complete . . .\n"
     ]
    }
   ],
   "source": [
    "# training_initializations(ns, opt, environ, dldrs, warmup_iterations = 200, weight_iterations = 200, policy_iterations = 200, eval_iterations = 50, warmup = False)\n",
    "training_initializations(ns, opt, environ, dldrs,  warmup = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e51e61aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T21:15:36.458939Z",
     "start_time": "2022-09-05T21:15:36.420037Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "** 2022-09-05 23:15:36:451140 - Training iteration 497250   flag: update_weights \n",
      "** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\n",
      "** Switch from Warm Up training to Alternate training Weights & Policy \n",
      "** Take checkpoint and block gradient flow through Policy net\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "\n",
      "    folder: 4000x6_0829_2050_lr0.001_do0.8_RETRAIN_1\n",
      "    layers: 6 [4000, 4000, 4000, 4000, 4000, 4000] \n",
      "    \n",
      "    first dropout          : 0.8\n",
      "    middle dropout         : 0.8\n",
      "    last dropout           : 0.8\n",
      "    diff_sparsity_weights  : False\n",
      "    skip_layer             : 0\n",
      "    is_curriculum          : False\n",
      "    curriculum_speed       : 3\n",
      "    \n",
      "    task_lr                : 0.001\n",
      "    backbone_lr            : 0.001\n",
      "    decay_lr_rate          : 0.5\n",
      "    decay_lr_freq          : 20\n",
      "    \n",
      "    policy_lr              : 0.01\n",
      "    policy_decay_lr_rate   : 0.5\n",
      "    policy_decay_lr_freq   : 20\n",
      "    lambda_sparsity        : 0.001\n",
      "    lambda_sharing         : 0.05\n",
      "    lambda_tasks           : 1.0\n",
      "    \n",
      "    Gumbel init_temp       : 2.5\n",
      "    Gumbel decay_temp      : 0.75\n",
      "    Gumbel decay_temp_freq : 3\n",
      "    Logit init_method      : random\n",
      "    Logit init_neg_logits  : None\n",
      "    Logit hard_sampling    : False\n",
      "    Warm-up epochs         : 20\n",
      "    training epochs        : 250\n",
      "    Data split ratios      : [0.725, 0.225, 0.05]\n",
      "\n",
      "\n",
      " ep:  250    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.6666    0.3334  1    0.7313    0.2687  1    0.6986    0.3014  1    0.7278    0.2722  1    0.6860    0.3140  1    0.6426    0.3574  1    0.6520    0.3480  1    0.6728    0.3272  1    0.7488    0.2512  1    0.6202    0.3798  1\n",
      "  1    0.7586    0.2414  1    0.7597    0.2403  1    0.7576    0.2424  1    0.7451    0.2549  1    0.7766    0.2234  1    0.7319    0.2681  1    0.6608    0.3392  1    0.6551    0.3449  1    0.7355    0.2645  1    0.6645    0.3355  1\n",
      "  2    0.7812    0.2188  1    0.7733    0.2267  1    0.8113    0.1887  1    0.6866    0.3134  1    0.7566    0.2434  1    0.7319    0.2681  1    0.6802    0.3198  1    0.7350    0.2650  1    0.6968    0.3032  1    0.6736    0.3264  1\n",
      "  3    0.6450    0.3550  1    0.7116    0.2884  1    0.7051    0.2949  1    0.6634    0.3366  1    0.6711    0.3289  1    0.6117    0.3883  1    0.6344    0.3656  1    0.6809    0.3191  1    0.6927    0.3073  1    0.6905    0.3095  1\n",
      "  4    0.6454    0.3546  1    0.6851    0.3149  1    0.6031    0.3969  1    0.6912    0.3088  1    0.6743    0.3257  1    0.6302    0.3698  1    0.6466    0.3534  1    0.5520    0.4480  1    0.6047    0.3953  1    0.5761    0.4239  1\n",
      "  5    0.6748    0.3252  1    0.6389    0.3611  1    0.7602    0.2398  1    0.6480    0.3520  1    0.6966    0.3034  1    0.6240    0.3760  1    0.6543    0.3457  1    0.6749    0.3251  1    0.6011    0.3989  1    0.6160    0.3840  1\n",
      "\n",
      "\n",
      " ep:  250   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.4905   -0.2025  1    0.4905   -0.5109  1    0.4905   -0.3503  1    0.4905   -0.4931  1    0.4905   -0.2912  1    0.4905   -0.0962  1    0.4905   -0.1371  1    0.4905   -0.2304  1    0.4905   -0.6016  1    0.4904    0.0001  1\n",
      "  1    0.6562   -0.4889  1    0.6286   -0.5225  1    0.6307   -0.5088  1    0.6285   -0.4442  1    0.6598   -0.5863  1    0.6285   -0.3759  1    0.6285   -0.0384  1    0.6285   -0.0130  1    0.5927   -0.4302  1    0.6285   -0.0548  1\n",
      "  2    0.7313   -0.5413  1    0.8301   -0.3967  1    0.7313   -0.7273  1    0.7045   -0.0796  1    0.7313   -0.4029  1    0.7313   -0.2730  1    0.7313   -0.0233  1    0.7313   -0.2888  1    0.7312   -0.1010  1    0.7313    0.0067  1\n",
      "  3    0.4608   -0.1363  1    0.4982   -0.4049  1    0.4801   -0.3918  1    0.4974   -0.1811  1    0.4972   -0.2160  1    0.4974    0.0430  1    0.4974   -0.0539  1    0.4974   -0.2606  1    0.4974   -0.3153  1    0.4974   -0.3050  1\n",
      "  4    0.3852   -0.2136  1    0.3630   -0.4141  1    0.3249   -0.0935  1    0.3630   -0.4427  1    0.3630   -0.3645  1    0.3631   -0.1701  1    0.3630   -0.2411  1    0.3631    0.1543  1    0.3630   -0.0622  1    0.3630    0.0564  1\n",
      "  5    0.4626   -0.2672  1    0.4626   -0.1080  1    0.4626   -0.6909  1    0.4627   -0.1478  1    0.4839   -0.3473  1    0.4626   -0.0438  1    0.4626   -0.1755  1    0.4775   -0.2531  1    0.4626    0.0528  1    0.4627   -0.0100  1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_heading( f\"** {timestring()} - Training iteration {ns.current_iter}   flag: {ns.flag} \\n\"\n",
    "               f\"** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\\n\"\n",
    "               f\"** Switch from Warm Up training to Alternate training Weights & Policy \\n\"\n",
    "               f\"** Take checkpoint and block gradient flow through Policy net\", verbose=True)\n",
    "\n",
    "print(environ.disp_for_excel())\n",
    "\n",
    "environ.display_trained_policy(ns.current_epoch,out=sys.stdout)\n",
    "environ.display_trained_logits(ns.current_epoch,out=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8439e4d4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Resume Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7647211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T21:16:19.727975Z",
     "start_time": "2022-09-05T21:16:19.688327Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sparsity regularization     : 0.001\n",
      " Sharing  regularization     : 0.05 \n",
      " Tasks    regularization     : 1.0   \n",
      " Gumbel Temp                 : 0.000188         \n",
      " Gumbel Temp decay           : 3\n",
      "Batches in warmup epoch (trn_iters_warmup) : 200\n",
      "Batches in weight epoch (trn_iters_weight) : 200\n",
      "Batches in policy epoch (trn_iters_policy) : 200\n",
      "Batches in validation epoch (ns.eval_iters): 50\n"
     ]
    }
   ],
   "source": [
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.6f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #\n",
    "\n",
    "print(f\"Batches in warmup epoch (trn_iters_warmup) : {ns.trn_iters_warmup}\")\n",
    "print(f\"Batches in weight epoch (trn_iters_weight) : {ns.trn_iters_weights}\")\n",
    "print(f\"Batches in policy epoch (trn_iters_policy) : {ns.trn_iters_policy}\")\n",
    "print(f\"Batches in validation epoch (ns.eval_iters): {ns.eval_iters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41c395de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T21:17:11.667852Z",
     "start_time": "2022-09-05T21:17:11.633673Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.opt['train']['lambda_sparsity'] = 0.05\n",
    "environ.opt['train']['lambda_sharing']  = 0.05\n",
    "# environ.opt['train']['decay_temp_freq'] = 3\n",
    "# ns.trn_iters_policy = 100\n",
    "ns.training_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dae5fca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T21:16:30.326534Z",
     "start_time": "2022-09-05T21:16:30.292348Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sparsity regularization     : 0.05\n",
      " Sharing  regularization     : 0.05 \n",
      " Tasks    regularization     : 1.0   \n",
      " Gumbel Temp                 : 0.0002         \n",
      " Gumbel Temp decay           : 3\n"
     ]
    }
   ],
   "source": [
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2de065a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T21:16:56.480658Z",
     "start_time": "2022-09-05T21:16:56.434162Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_epoch          : 250\n",
      "current_iters          : 497250\n",
      "train_total_epochs     : 250\n",
      "Batches in warmup epoch (trn_iters_warmup) : 200\n",
      "Batches in weight epoch (trn_iters_weight) : 200\n",
      "Batches in policy epoch (trn_iters_policy) : 200\n",
      "Batches in validation epoch (ns.eval_iters): 50\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      " Last Epoch: 250   # of warm-up epochs to do:  250 - Run epochs 251 to 500\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      "[e] Last ep:250  it:497250  -  Losses:   \t Task: 2.1423   \t Sparsity: 9.96697e-04    \t Sharing: 1.38397e-03    \t Total: 2.1447 \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed : 250       # of epochs to run:  250 -->  epochs 251 to 500\n",
      " Backbone Initial LR  : 0.001      Current LR : 0.001 \n",
      " Heads    Initial LR  : 0.001      Current LR : 0.001\n",
      " Policy   Initial LR  : 0.01      Current LR : 0.01\n",
      " Regularization tasks : 1.0          Sparsity: 0.05           sharing: 0.05\n",
      " curriculum training  : False      Cirriculum speed: 3     num_training_layers : None\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "\n",
      "\n",
      " ep:  250   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.4905   -0.2025  1    0.4905   -0.5109  1    0.4905   -0.3503  1    0.4905   -0.4931  1    0.4905   -0.2912  1    0.4905   -0.0962  1    0.4905   -0.1371  1    0.4905   -0.2304  1    0.4905   -0.6016  1    0.4904    0.0001  1\n",
      "  1    0.6562   -0.4889  1    0.6286   -0.5225  1    0.6307   -0.5088  1    0.6285   -0.4442  1    0.6598   -0.5863  1    0.6285   -0.3759  1    0.6285   -0.0384  1    0.6285   -0.0130  1    0.5927   -0.4302  1    0.6285   -0.0548  1\n",
      "  2    0.7313   -0.5413  1    0.8301   -0.3967  1    0.7313   -0.7273  1    0.7045   -0.0796  1    0.7313   -0.4029  1    0.7313   -0.2730  1    0.7313   -0.0233  1    0.7313   -0.2888  1    0.7312   -0.1010  1    0.7313    0.0067  1\n",
      "  3    0.4608   -0.1363  1    0.4982   -0.4049  1    0.4801   -0.3918  1    0.4974   -0.1811  1    0.4972   -0.2160  1    0.4974    0.0430  1    0.4974   -0.0539  1    0.4974   -0.2606  1    0.4974   -0.3153  1    0.4974   -0.3050  1\n",
      "  4    0.3852   -0.2136  1    0.3630   -0.4141  1    0.3249   -0.0935  1    0.3630   -0.4427  1    0.3630   -0.3645  1    0.3631   -0.1701  1    0.3630   -0.2411  1    0.3631    0.1543  1    0.3630   -0.0622  1    0.3630    0.0564  1\n",
      "  5    0.4626   -0.2672  1    0.4626   -0.1080  1    0.4626   -0.6909  1    0.4627   -0.1478  1    0.4839   -0.3473  1    0.4626   -0.0438  1    0.4626   -0.1755  1    0.4775   -0.2531  1    0.4626    0.0528  1    0.4627   -0.0100  1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"current_epoch          : {ns.current_epoch}\") \n",
    "print(f\"current_iters          : {ns.current_iter}\")  \n",
    "print(f\"train_total_epochs     : {ns.training_epochs}\") \n",
    "print(f\"Batches in warmup epoch (trn_iters_warmup) : {ns.trn_iters_warmup}\")\n",
    "print(f\"Batches in weight epoch (trn_iters_weight) : {ns.trn_iters_weights}\")\n",
    "print(f\"Batches in policy epoch (trn_iters_policy) : {ns.trn_iters_policy}\")\n",
    "print(f\"Batches in validation epoch (ns.eval_iters): {ns.eval_iters}\")\n",
    "print()\n",
    "\n",
    "print_heading(f\" Last Epoch: {ns.current_epoch}   # of warm-up epochs to do:  {ns.training_epochs} - Run epochs {ns.current_epoch+1} to {ns.current_epoch + ns.training_epochs}\", verbose = True)\n",
    "\n",
    "\n",
    "print_loss(ns.val_metrics, title = f\"[e] Last ep:{ns.current_epoch}  it:{ns.current_iter} \")\n",
    "\n",
    "print_heading(f\" Last Epoch Completed : {ns.current_epoch}       # of epochs to run:  {ns.training_epochs} -->  epochs {ns.current_epoch+1} to {ns.training_epochs + ns.current_epoch}\"\n",
    "              f\"\\n Backbone Initial LR  : {environ.opt['train']['backbone_lr']}      Current LR : {environ.optimizers['weights'].param_groups[0]['lr']} \"\n",
    "              f\"\\n Heads    Initial LR  : {environ.opt['train']['task_lr']}      Current LR : {environ.optimizers['weights'].param_groups[1]['lr']}\"              \n",
    "              f\"\\n Policy   Initial LR  : {environ.opt['train']['policy_lr']}      Current LR : {environ.optimizers['alphas'].param_groups[0]['lr']}\"\n",
    "              f\"\\n Regularization tasks : {environ.opt['train']['lambda_tasks']}          Sparsity: {environ.opt['train']['lambda_sparsity']}           sharing: {environ.opt['train']['lambda_sharing']}\"\n",
    "              f\"\\n curriculum training  : {opt['is_curriculum']}      Cirriculum speed: {opt['curriculum_speed']}     num_training_layers : {ns.num_train_layers}\", \n",
    "              verbose = True)\n",
    "\n",
    "print()\n",
    "environ.display_trained_logits(ns.current_epoch)\n",
    "# environ.display_current_policy(ns.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "39b9d208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-24T08:06:23.420336Z",
     "start_time": "2022-08-24T07:58:37.724017Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed : 42   # of epochs to run:  2 -->  epochs 43 to 44    \n",
      " policy_learning rate : 0.001      \n",
      " lambda_sparsity      : 0.0\n",
      " lambda_sharing       : 0.001 \n",
      " curriculum training  : False     cirriculum speed: 3     num_training_layers : 6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      " Ep  | Trunk LR  Heads LR  Polcy LR  Gmbl Tmp |  trn tsk    trn spar    trn shar   trn ttl |   logloss   bceloss  avg prec    aucroc     aucpr    f1_max |  val tsk    val spar    val shar     total | time |     \n",
      "  43 | 3.00e-04  3.00e-04  1.00e-03  2.25e-01 |   1.8536   0.000e+00   2.754e-04    1.8539 |   0.00006   0.51391   0.75470   0.75609   0.71561   0.79427 |   2.1611   0.000e+00   2.754e-04    2.1614 |195.1 |\n",
      "  43 | 3.00e-04  3.00e-04  1.00e-03  2.25e-01 |   1.6060   0.000e+00   2.751e-04    1.6063 |   0.00006   0.52105   0.73588   0.74258   0.69692   0.77371 |   2.3134   0.000e+00   2.753e-04    2.3137 | 35.4 |     \n",
      " decay gumbel softmax to 0.16894054412841797\n",
      "\n",
      " ep:   43   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0   -0.1210    0.0482  0   -0.0770    0.0168  0   -0.4430    0.4944  0   -0.2184    0.2355  0   -0.2884    0.3315  0   -0.0209   -0.0316  1   -0.1406    0.1331  0   -0.2100    0.2302  0   -0.2566    0.3039  0   -0.0766    0.0241  0\n",
      "  1   -0.1066    0.0741  0   -0.0357   -0.0426  1   -0.3944    0.4579  0   -0.0518    0.0224  0   -0.3213    0.3687  0   -0.0965    0.0476  0   -0.1433    0.1219  0   -0.1173    0.1503  0   -0.1768    0.2131  0   -0.0631    0.0166  0\n",
      "  2   -0.0414   -0.0233  0   -0.0452   -0.0400  0   -0.3661    0.4380  0   -0.0338    0.0197  0   -0.2596    0.3100  0   -0.0583    0.0098  0   -0.0538    0.0264  0   -0.1172    0.1503  0   -0.1529    0.2097  0   -0.0741    0.0194  0\n",
      "  3   -0.0867    0.0367  0   -0.0054   -0.1056  1   -0.5285    0.6074  0   -0.0759    0.0496  0   -0.2570    0.3151  0   -0.0781    0.0302  0   -0.0975    0.0788  0   -0.1863    0.2067  0   -0.1349    0.1807  0   -0.1192    0.0975  0\n",
      "  4   -0.1910    0.1587  0   -0.1232    0.0495  0   -0.5890    0.6732  0   -0.1349    0.0701  0   -0.3134    0.3947  0   -0.1425    0.0946  0   -0.1647    0.0968  0   -0.1565    0.1632  0   -0.1904    0.2523  0   -0.1781    0.1494  0\n",
      "  5   -0.1718    0.1882  0   -0.1338    0.0399  0   -0.5509    0.6448  0   -0.1865    0.1167  0   -0.2804    0.3496  0   -0.1766    0.1300  0   -0.1515    0.1123  0   -0.1730    0.1641  0   -0.2452    0.2939  0   -0.1617    0.1142  0\n",
      "\n",
      "\n",
      " ep:   43    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.4578    0.5422  0    0.4766    0.5234  1    0.2814    0.7186  1    0.3885    0.6115  0    0.3498    0.6502  0    0.5027    0.4973  0    0.4320    0.5680  0    0.3917    0.6083  1    0.3634    0.6366  0    0.4748    0.5252  1\n",
      "  1    0.4549    0.5451  1    0.5017    0.4983  0    0.2989    0.7011  0    0.4814    0.5186  0    0.3340    0.6660  0    0.4640    0.5360  0    0.4341    0.5659  0    0.4335    0.5665  0    0.4038    0.5962  0    0.4801    0.5199  0\n",
      "  2    0.4955    0.5045  1    0.4987    0.5013  1    0.3091    0.6909  0    0.4866    0.5134  1    0.3613    0.6387  0    0.4830    0.5170  1    0.4800    0.5200  1    0.4335    0.5665  1    0.4103    0.5897  1    0.4766    0.5234  1\n",
      "  3    0.4692    0.5308  1    0.5250    0.4750  0    0.2431    0.7569  0    0.4687    0.5313  0    0.3608    0.6392  0    0.4729    0.5271  0    0.4560    0.5440  1    0.4030    0.5970  1    0.4217    0.5783  0    0.4460    0.5540  1\n",
      "  4    0.4135    0.5865  0    0.4569    0.5431  1    0.2206    0.7794  0    0.4489    0.5511  0    0.3300    0.6700  0    0.4410    0.5590  0    0.4350    0.5650  1    0.4207    0.5793  1    0.3911    0.6089  0    0.4188    0.5812  0\n",
      "  5    0.4110    0.5890  0    0.4567    0.5433  1    0.2322    0.7678  1    0.4248    0.5752  0    0.3475    0.6525  0    0.4240    0.5760  1    0.4344    0.5656  1    0.4165    0.5835  1    0.3684    0.6316  0    0.4315    0.5685  0\n",
      "\n",
      "  44 | 3.00e-04  3.00e-04  1.00e-03  1.69e-01 |   2.2897   0.000e+00   2.753e-04    2.2900 |   0.00006   0.53563   0.74933   0.74331   0.71168   0.78611 |   2.2608   0.000e+00   2.753e-04    2.2611 |194.4 |     \n",
      "  44 | 3.00e-04  3.00e-04  1.00e-03  1.69e-01 |   1.9788   0.000e+00   2.786e-04    1.9791 |   0.00006   0.53661   0.74194   0.73235   0.69850   0.78842 |   2.2653   0.000e+00   6.298e-04    2.2659 | 36.0 |     \n",
      "\n",
      " ep:   44   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0   -0.1265    0.0540  0   -0.0957    0.0353  0   -0.4478    0.4996  0   -0.2430    0.2604  0   -0.3036    0.3471  0   -0.0283   -0.0255  0   -0.1234    0.1157  0   -0.2221    0.2423  0   -0.2658    0.3133  0   -0.0782    0.0251  0\n",
      "  1   -0.1002    0.0679  0   -0.0473   -0.0317  0   -0.4069    0.4709  0   -0.0434    0.0127  0   -0.3156    0.3637  0   -0.1065    0.0577  0   -0.1440    0.1235  0   -0.1319    0.1645  0   -0.1778    0.2145  0   -0.0585    0.0115  0\n",
      "  2   -0.0336   -0.0319  0   -0.0423   -0.0431  1   -0.3805    0.4529  0   -0.0466    0.0313  0   -0.2713    0.3224  0   -0.0539    0.0060  0   -0.0474    0.0193  0   -0.1183    0.1517  0   -0.1519    0.2090  0   -0.0579    0.0043  0\n",
      "  3   -0.1083    0.0585  0   -0.0013   -0.1103  1   -0.5372    0.6165  0   -0.0935    0.0658  0   -0.2746    0.3332  0   -0.0769    0.0274  0   -0.1049    0.0863  0   -0.1892    0.2110  0   -0.1251    0.1709  0   -0.1106    0.0897  0\n",
      "  4   -0.1957    0.1650  0   -0.1365    0.0618  0   -0.5950    0.6798  0   -0.1478    0.0824  0   -0.3127    0.3944  0   -0.1271    0.0771  0   -0.1788    0.1121  0   -0.1686    0.1741  0   -0.1886    0.2505  0   -0.1786    0.1511  0\n",
      "  5   -0.1858    0.2019  0   -0.1550    0.0605  0   -0.5675    0.6620  0   -0.1830    0.1154  0   -0.2693    0.3392  0   -0.1439    0.0967  0   -0.1562    0.1151  0   -0.1658    0.1566  0   -0.2473    0.2966  0   -0.1662    0.1184  0\n",
      "\n",
      "\n",
      " ep:   44    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.4550    0.5450  0    0.4673    0.5327  0    0.2794    0.7206  0    0.3768    0.6232  0    0.3428    0.6572  0    0.4993    0.5007  0    0.4405    0.5595  0    0.3859    0.6141  0    0.3591    0.6409  0    0.4742    0.5258  0\n",
      "  1    0.4581    0.5419  1    0.4961    0.5039  0    0.2936    0.7064  0    0.4860    0.5140  0    0.3364    0.6636  0    0.4590    0.5410  0    0.4335    0.5665  0    0.4264    0.5736  1    0.4032    0.5968  0    0.4825    0.5175  0\n",
      "  2    0.4996    0.5004  0    0.5002    0.4998  0    0.3029    0.6971  1    0.4805    0.5195  0    0.3558    0.6442  0    0.4850    0.5150  1    0.4833    0.5167  1    0.4329    0.5671  1    0.4107    0.5893  1    0.4844    0.5156  1\n",
      "  3    0.4584    0.5416  1    0.5272    0.4728  1    0.2398    0.7602  0    0.4603    0.5397  1    0.3526    0.6474  0    0.4739    0.5261  1    0.4523    0.5477  0    0.4013    0.5987  0    0.4265    0.5735  0    0.4501    0.5499  0\n",
      "  4    0.4108    0.5892  0    0.4506    0.5494  1    0.2184    0.7816  0    0.4427    0.5573  0    0.3302    0.6698  0    0.4491    0.5509  0    0.4278    0.5722  1    0.4152    0.5848  0    0.3920    0.6080  1    0.4183    0.5817  0\n",
      "  5    0.4043    0.5957  0    0.4463    0.5537  1    0.2263    0.7737  0    0.4259    0.5741  0    0.3524    0.6476  0    0.4401    0.5599  0    0.4326    0.5674  1    0.4201    0.5799  0    0.3673    0.6327  1    0.4293    0.5707  1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " save train checkpoint  to :  model_train_last_ep_44\n",
      " save train metrics to     :  metrics_train_last_ep_44.pickle\n",
      "[Final] ep:44  it:30090 -  Total Loss: 2.2659     \n",
      "Task: 2.2653   Sparsity: 0.00000e+00    Sharing: 6.29763e-04 \n",
      "\n",
      " ep:   44   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0   -0.1265    0.0540  0   -0.0957    0.0353  0   -0.4478    0.4996  0   -0.2430    0.2604  0   -0.3036    0.3471  0   -0.0283   -0.0255  0   -0.1234    0.1157  0   -0.2221    0.2423  0   -0.2658    0.3133  0   -0.0782    0.0251  0\n",
      "  1   -0.1002    0.0679  0   -0.0473   -0.0317  0   -0.4069    0.4709  0   -0.0434    0.0127  0   -0.3156    0.3637  0   -0.1065    0.0577  0   -0.1440    0.1235  0   -0.1319    0.1645  0   -0.1778    0.2145  0   -0.0585    0.0115  0\n",
      "  2   -0.0336   -0.0319  0   -0.0423   -0.0431  1   -0.3805    0.4529  0   -0.0466    0.0313  0   -0.2713    0.3224  0   -0.0539    0.0060  0   -0.0474    0.0193  0   -0.1183    0.1517  0   -0.1519    0.2090  0   -0.0579    0.0043  0\n",
      "  3   -0.1083    0.0585  0   -0.0013   -0.1103  1   -0.5372    0.6165  0   -0.0935    0.0658  0   -0.2746    0.3332  0   -0.0769    0.0274  0   -0.1049    0.0863  0   -0.1892    0.2110  0   -0.1251    0.1709  0   -0.1106    0.0897  0\n",
      "  4   -0.1957    0.1650  0   -0.1365    0.0618  0   -0.5950    0.6798  0   -0.1478    0.0824  0   -0.3127    0.3944  0   -0.1271    0.0771  0   -0.1788    0.1121  0   -0.1686    0.1741  0   -0.1886    0.2505  0   -0.1786    0.1511  0\n",
      "  5   -0.1858    0.2019  0   -0.1550    0.0605  0   -0.5675    0.6620  0   -0.1830    0.1154  0   -0.2693    0.3392  0   -0.1439    0.0967  0   -0.1562    0.1151  0   -0.1658    0.1566  0   -0.2473    0.2966  0   -0.1662    0.1184  0\n",
      "\n",
      "\n",
      " ep:   44    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.4550    0.5450  0    0.4673    0.5327  0    0.2794    0.7206  0    0.3768    0.6232  0    0.3428    0.6572  0    0.4993    0.5007  0    0.4405    0.5595  0    0.3859    0.6141  0    0.3591    0.6409  0    0.4742    0.5258  0\n",
      "  1    0.4581    0.5419  1    0.4961    0.5039  0    0.2936    0.7064  0    0.4860    0.5140  0    0.3364    0.6636  0    0.4590    0.5410  0    0.4335    0.5665  0    0.4264    0.5736  1    0.4032    0.5968  0    0.4825    0.5175  0\n",
      "  2    0.4996    0.5004  0    0.5002    0.4998  0    0.3029    0.6971  1    0.4805    0.5195  0    0.3558    0.6442  0    0.4850    0.5150  1    0.4833    0.5167  1    0.4329    0.5671  1    0.4107    0.5893  1    0.4844    0.5156  1\n",
      "  3    0.4584    0.5416  1    0.5272    0.4728  1    0.2398    0.7602  0    0.4603    0.5397  1    0.3526    0.6474  0    0.4739    0.5261  1    0.4523    0.5477  0    0.4013    0.5987  0    0.4265    0.5735  0    0.4501    0.5499  0\n",
      "  4    0.4108    0.5892  0    0.4506    0.5494  1    0.2184    0.7816  0    0.4427    0.5573  0    0.3302    0.6698  0    0.4491    0.5509  0    0.4278    0.5722  1    0.4152    0.5848  0    0.3920    0.6080  1    0.4183    0.5817  0\n",
      "  5    0.4043    0.5957  0    0.4463    0.5537  1    0.2263    0.7737  0    0.4259    0.5741  0    0.3524    0.6476  0    0.4401    0.5599  0    0.4326    0.5674  1    0.4201    0.5799  0    0.3673    0.6327  1    0.4293    0.5707  1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weight_policy_training(ns, opt, environ, dldrs, display_policy = True, disable_tqdm = False, epochs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ad4975e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T13:49:16.009392Z",
     "start_time": "2022-08-23T13:49:15.951444Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]], device='cuda:0')\n",
      "tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(environ.policy1)\n",
    "print(environ.networks['mtl-net'].policys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7dbec43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T13:40:07.085466Z",
     "start_time": "2022-08-23T13:40:07.053387Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10928034,  0.03533224],\n",
       "       [-0.11588797,  0.08241694],\n",
       "       [-0.08529188,  0.02049774],\n",
       "       [-0.08840536,  0.03978787],\n",
       "       [-0.1570164 ,  0.12076251],\n",
       "       [-0.1639516 ,  0.18603538]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(environ.logit1)\n",
    "print(environ.networks['mtl-net'].task1_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "89e0bc6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-24T07:43:38.180719Z",
     "start_time": "2022-08-24T07:43:38.116148Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ep:    0   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0   -0.1093    0.0353  0   -0.0769    0.0174  0   -0.4064    0.4563  0   -0.2180    0.2339  0   -0.3018    0.3437  0   -0.0600    0.0115  0   -0.1294    0.1227  0   -0.1851    0.2055  0   -0.2733    0.3198  0   -0.0879    0.0374  0\n",
      "  1   -0.1159    0.0824  0   -0.0333   -0.0434  1   -0.3981    0.4598  0   -0.0347    0.0106  0   -0.2812    0.3267  0   -0.1059    0.0570  0   -0.1659    0.1415  0   -0.1193    0.1536  0   -0.1683    0.2030  0   -0.0852    0.0408  0\n",
      "  2   -0.0853    0.0205  0   -0.0473   -0.0371  0   -0.3778    0.4481  0   -0.0498    0.0429  0   -0.2421    0.2901  0   -0.0435   -0.0016  0   -0.1015    0.0730  0   -0.0998    0.1321  0   -0.1509    0.2068  0   -0.0862    0.0284  0\n",
      "  3   -0.0884    0.0398  0   -0.0323   -0.0769  1   -0.4703    0.5477  0   -0.0754    0.0525  0   -0.2473    0.3036  0   -0.0849    0.0413  0   -0.1033    0.0839  0   -0.1510    0.1664  0   -0.1460    0.1918  0   -0.0946    0.0713  0\n",
      "  4   -0.1570    0.1208  0   -0.1403    0.0675  0   -0.5559    0.6381  0   -0.1272    0.0626  0   -0.2597    0.3397  0   -0.1133    0.0735  0   -0.1188    0.0529  0   -0.1450    0.1545  0   -0.2098    0.2707  0   -0.1692    0.1367  0\n",
      "  5   -0.1640    0.1860  0   -0.1382    0.0478  0   -0.5267    0.6189  0   -0.1527    0.0801  0   -0.2371    0.3040  0   -0.1741    0.1188  0   -0.1829    0.1449  0   -0.1671    0.1648  0   -0.2135    0.2604  0   -0.1996    0.1487  0\n",
      "\n",
      "\n",
      " ep:    0    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.4639    0.5361  0    0.4765    0.5235  0    0.2968    0.7032  0    0.3889    0.6111  0    0.3440    0.6560  0    0.4822    0.5178  0    0.4373    0.5627  0    0.4036    0.5964  0    0.3559    0.6441  0    0.4687    0.5313  0\n",
      "  1    0.4506    0.5494  0    0.5025    0.4975  1    0.2978    0.7022  0    0.4887    0.5113  0    0.3525    0.6475  0    0.4594    0.5406  0    0.4238    0.5762  0    0.4322    0.5678  0    0.4082    0.5918  0    0.4685    0.5315  0\n",
      "  2    0.4736    0.5264  0    0.4974    0.5026  0    0.3045    0.6955  0    0.4768    0.5232  0    0.3700    0.6300  0    0.4895    0.5105  0    0.4565    0.5435  0    0.4423    0.5577  0    0.4115    0.5885  0    0.4714    0.5286  0\n",
      "  3    0.4680    0.5320  0    0.5111    0.4889  1    0.2654    0.7346  0    0.4681    0.5319  0    0.3657    0.6343  0    0.4685    0.5315  0    0.4533    0.5467  0    0.4213    0.5787  0    0.4163    0.5837  0    0.4586    0.5414  0\n",
      "  4    0.4310    0.5690  0    0.4482    0.5518  0    0.2325    0.7675  0    0.4527    0.5473  0    0.3545    0.6455  0    0.4534    0.5466  0    0.4572    0.5428  0    0.4257    0.5743  0    0.3822    0.6178  0    0.4241    0.5759  0\n",
      "  5    0.4134    0.5866  0    0.4536    0.5464  0    0.2413    0.7587  0    0.4421    0.5579  0    0.3679    0.6321  0    0.4273    0.5727  0    0.4188    0.5812  0    0.4178    0.5822  0    0.3837    0.6163  0    0.4138    0.5862  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "environ.display_trained_logits()\n",
    "environ.display_trained_policy()\n",
    "\n",
    "environ.display_current_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a57a91",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3cb32379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T11:00:55.609998Z",
     "start_time": "2022-08-23T11:00:50.563226Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_pr</td><td>▆█▅▆█▁▆▁▅▅</td></tr><tr><td>avg_prec_score</td><td>▇█▅▇█▂▇▁▅▅</td></tr><tr><td>bceloss</td><td>▆▄▇▇▁█▆▃▄▂</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>f1_max</td><td>█▇▅▇▇▃█▁▆▅</td></tr><tr><td>gumbel_temp</td><td>███▆▆▆▃▃▃▁</td></tr><tr><td>kappa</td><td>▅▂▄▄█▄▁▂▅▅</td></tr><tr><td>kappa_max</td><td>▆▇▅▅█▃▇▁▇▅</td></tr><tr><td>lambda_sharing</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_sparsity</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_tasks</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>logloss</td><td>▇▆█▅▁▇▃▅▅▄</td></tr><tr><td>lr_0</td><td>██████▁▁▁▁</td></tr><tr><td>lr_1</td><td>██████▁▁▁▁</td></tr><tr><td>p_f1_max</td><td>▅▁▅█▄▆▄▂▃▃</td></tr><tr><td>p_kappa_max</td><td>▅▂▅█▂▅▅▁▂▂</td></tr><tr><td>policy_lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>roc_auc_score</td><td>▃▅▄▃█▁▆▂▅▅</td></tr><tr><td>sc_loss</td><td>▅▄█▅▁█▃▅▄▅</td></tr><tr><td>train_layers</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_pr</td><td>0.7068</td></tr><tr><td>avg_prec_score</td><td>0.74594</td></tr><tr><td>bceloss</td><td>0.51734</td></tr><tr><td>best_roc_auc</td><td>0.73105</td></tr><tr><td>epoch</td><td>26</td></tr><tr><td>f1_max</td><td>0.78529</td></tr><tr><td>gumbel_temp</td><td>3.34731</td></tr><tr><td>kappa</td><td>0.22928</td></tr><tr><td>kappa_max</td><td>0.58378</td></tr><tr><td>lambda_sharing</td><td>0.1</td></tr><tr><td>lambda_sparsity</td><td>0.0</td></tr><tr><td>lambda_tasks</td><td>1</td></tr><tr><td>logloss</td><td>6e-05</td></tr><tr><td>lr_0</td><td>0.0003</td></tr><tr><td>lr_1</td><td>0.0003</td></tr><tr><td>p_f1_max</td><td>0.41925</td></tr><tr><td>p_kappa_max</td><td>0.48734</td></tr><tr><td>policy_lr</td><td>0.001</td></tr><tr><td>roc_auc_score</td><td>0.75156</td></tr><tr><td>sc_loss</td><td>0.04489</td></tr><tr><td>train_layers</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0822_1755_RESUME_POLICY_1</strong>: <a href=\"https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task/runs/1x50t0va\" target=\"_blank\">https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task/runs/1x50t0va</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220823_042430-1x50t0va/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c4f68",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Post Training Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "879b482b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T09:32:54.474957Z",
     "start_time": "2022-09-06T09:32:54.441513Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alphas': <torch.optim.lr_scheduler.ReduceLROnPlateau at 0x7f7d1c787e50>,\n",
       " 'weights': <torch.optim.lr_scheduler.ReduceLROnPlateau at 0x7f7d1c787e20>}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e103d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T09:32:38.801955Z",
     "start_time": "2022-09-06T09:32:38.712852Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "current_state = {}\n",
    "for k, v in environ.networks.items():\n",
    "    print(f' k: {k}')\n",
    "    if isinstance(v, nn.DataParallel):\n",
    "        current_state[k] = v.module.state_dict()\n",
    "    else:\n",
    "        current_state[k] = v.state_dict()\n",
    "        \n",
    "print(current_state.keys())\n",
    "\n",
    "for k, v in environ.optimizers.items():\n",
    "    print(f' k: {k}')\n",
    "    current_state[k] = v.state_dict()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1ec72419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T10:47:04.270372Z",
     "start_time": "2022-09-06T10:47:04.233459Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " k: alphas    v: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f7d1c787e50>\n",
      "{'factor': 0.5, 'min_lrs': [0], 'patience': 20, 'verbose': True, 'cooldown': 5, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 0.0001, 'threshold_mode': 'rel', 'best': inf, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 0}\n",
      " k: weights    v: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f7d1c787e20>\n",
      "{'factor': 0.5, 'min_lrs': [0, 0], 'patience': 20, 'verbose': True, 'cooldown': 5, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 0.0001, 'threshold_mode': 'rel', 'best': inf, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 0}\n"
     ]
    }
   ],
   "source": [
    "for k, v in environ.schedulers.items():\n",
    "    print(f' k: {k}    v: {v}')\n",
    "    current_state[k] = v.state_dict()\n",
    "    print(current_state[k])\n",
    "# for k in current_state:\n",
    "#     print(f'key: {k}', '\\n', current_state[k].keys(), '\\n')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75c2c1f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T09:02:00.026955Z",
     "start_time": "2022-02-22T09:01:59.964303Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Final] ep:287  it:58757 -  Total Loss: 15.5793     \n",
      "Task: 11.2231   Sparsity: 4.35058e+00    Sharing: 5.58868e-03 \n"
     ]
    }
   ],
   "source": [
    "print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\")\n",
    "# environ.display_trained_policy(current_epoch)\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b0308ba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T18:19:26.942383Z",
     "start_time": "2022-02-21T18:19:26.874453Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone Learning Rate      : 0.001\n",
      " Tasks    Learning Rate      : 0.001\n",
      " Policy   Learning Rate      : 0.01\n",
      "\n",
      " Sparsity regularization     : 0.0\n",
      " Sharing  regularization     : 0.0001 \n",
      " Tasks    regularization     : 1.0   \n",
      " Gumbel Temp                 : 0.7234         \n",
      " Gumbel Temp decay           : 2\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #\n",
    "\n",
    "print( f\" current_iters               : {current_iter}\")  \n",
    "print( f\" current_epochs              : {current_epoch}\") \n",
    "print( f\" train_total_epochs          : {train_total_epochs}\") \n",
    "print( f\" stop_epoch_training         : {stop_epoch_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "cf9ad779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T18:21:08.710199Z",
     "start_time": "2022-02-21T18:21:08.643781Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.opt['train']['lambda_sparsity'] = 0.0000\n",
    "environ.opt['train']['lambda_sharing']  = 0.001\n",
    "environ.opt['train']['lambda_tasks']    = 1.0\n",
    "environ.opt['train']['decay_temp_freq'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c173609c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T18:21:25.092070Z",
     "start_time": "2022-02-21T18:21:25.028026Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sparsity regularization     : 0.0\n",
      " Sharing  regularization     : 0.001 \n",
      " Tasks    regularization     : 1.0   \n",
      " Gumbel Temp                 : 0.7234         \n",
      " Gumbel Temp decay           : 2\n",
      "\n",
      " current_iters               : 38669\n",
      " current_epochs              : 192\n",
      " train_total_epochs          : 5\n",
      " stop_epoch_training         : 192\n"
     ]
    }
   ],
   "source": [
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\\n\") #\n",
    "\n",
    "\n",
    "print( f\" current_iters               : {current_iter}\")  \n",
    "print( f\" current_epochs              : {current_epoch}\") \n",
    "print( f\" train_total_epochs          : {train_total_epochs}\") \n",
    "print( f\" stop_epoch_training         : {stop_epoch_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b375cd1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T21:26:56.154438Z",
     "start_time": "2022-02-17T21:26:56.128548Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_iters         : 10908\n",
      "current_epochs        : 51\n",
      "train_total_epochs    : 50\n",
      "stop_epoch_training   : 101\n"
     ]
    }
   ],
   "source": [
    "# train_total_epochs = 50\n",
    "stop_epoch_training = current_epoch + train_total_epochs     \n",
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs        : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") \n",
    "print(f\"stop_epoch_training   : {stop_epoch_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8abf65",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with np.printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', precision=7, formatter={'float': lambda x: f\"{x:12.5e}\"}):\n",
    "    environ.print_logit_grads('gradients')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f8ef378f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T19:00:55.473607Z",
     "start_time": "2022-02-22T19:00:55.086430Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epch: 312   logits        sel          logits       sel         logits        sel \n",
      " -----  -----------------  ---    ----------------   ---    ----------------   --- \n",
      "   1   -0.4585     0.6026   0    -0.4601     0.8096   0    -0.4597     0.5298   0\n",
      "   2   -0.1734    -0.9305   1    -0.1718    -1.0447   1    -0.1615    -0.9853   1\n",
      "   3   -0.1602    -1.1804   1    -0.1241    -1.2051   1    -0.1391    -1.3729   1\n",
      "   4   -0.3442     0.1300   0    -0.3490     0.0837   0    -0.3420     0.6391   0\n",
      "   5   -0.2803     0.3260   0    -0.2921    -0.8131   1    -0.2676    -0.2554   0\n",
      "   6   -0.4716     1.7158   0    -0.4718     1.5023   0    -0.4718     1.1004   0\n",
      "\n",
      "\n",
      "\n",
      " epch: 312   softmax       sel        softmax        sel        softmax        sel \n",
      " -----  -----------------  ---    -----------------  ---    -----------------  --- \n",
      "   1    0.2571     0.7429   0     0.2193     0.7807   0     0.2710     0.7290   0\n",
      "   2    0.6807     0.3193   1     0.7054     0.2946   1     0.6950     0.3050   1\n",
      "   3    0.7350     0.2650   1     0.7467     0.2533   1     0.7745     0.2255   1\n",
      "   4    0.3836     0.6164   0     0.3935     0.6065   0     0.2727     0.7273   0\n",
      "   5    0.3529     0.6471   0     0.6274     0.3726   1     0.4970     0.5030   0\n",
      "   6    0.1009     0.8991   0     0.1219     0.8781   0     0.1719     0.8281   0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "environ.display_trained_logits(current_epoch)\n",
    "environ.display_trained_policy(current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f92f6a6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T17:24:17.346992Z",
     "start_time": "2022-02-22T17:24:17.274105Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sample Policy (Testing mode - hard_sampling: True) \n",
      " 312 epochs  logits         sel        logits         sel         logits         sel \n",
      " -----   ----------------  -----    ----------------  -----    ---------------   ----- \n",
      "   1    -0.4585    0.6026  [0 1]   -0.4601    0.8096  [0 1]   -0.4597    0.5298  [0 1]\n",
      "   2    -0.1734   -0.9305  [1 0]   -0.1718   -1.0447  [1 0]   -0.1615   -0.9853  [1 0]\n",
      "   3    -0.1602   -1.1804  [1 0]   -0.1241   -1.2051  [1 0]   -0.1391   -1.3729  [1 0]\n",
      "   4    -0.3442    0.1300  [0 1]   -0.3490    0.0837  [0 1]   -0.3420    0.6391  [0 1]\n",
      "   5    -0.2803    0.3260  [0 1]   -0.2921   -0.8131  [1 0]   -0.2676   -0.2554  [0 1]\n",
      "   6    -0.4716    1.7158  [0 1]   -0.4718    1.5023  [0 1]   -0.4718    1.1004  [0 1]\n",
      "\n",
      "\n",
      " Sample Policy (Training mode - hard_sampling: True) \n",
      " 312 epochs    logits          gumbel                logits           gumbel               logits             gumbel \n",
      " -----   ----------------------------------     ----------------------------------     ------------------------------------ \n",
      "   1    -0.4585   0.6026    1.0000   0.0000    -0.4601   0.8096    1.0000   0.0000    -0.4597    0.5298     1.0000   0.0000\n",
      "   2    -0.1734  -0.9305    0.0000   1.0000    -0.1718  -1.0447    1.0000   0.0000    -0.1615   -0.9853     1.0000   0.0000\n",
      "   3    -0.1602  -1.1804    0.0000   1.0000    -0.1241  -1.2051    0.0000   1.0000    -0.1391   -1.3729     1.0000   0.0000\n",
      "   4    -0.3442   0.1300    1.0000   0.0000    -0.3490   0.0837    0.0000   1.0000    -0.3420    0.6391     1.0000   0.0000\n",
      "   5    -0.2803   0.3260    0.0000   1.0000    -0.2921  -0.8131    1.0000   0.0000    -0.2676   -0.2554     0.0000   1.0000\n",
      "   6    -0.4716   1.7158    1.0000   0.0000    -0.4718   1.5023    0.0000   1.0000    -0.4718    1.1004     0.0000   1.0000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "environ.display_test_sample_policy(current_epoch, hard_sampling = True)\n",
    "environ.display_train_sample_policy(current_epoch, hard_sampling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b7f0d1e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T17:24:13.311258Z",
     "start_time": "2022-02-22T17:24:13.231883Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sample Policy (Testing mode - hard_sampling: False) \n",
      " 312 epochs  logits         sel        logits         sel         logits         sel \n",
      " -----   ----------------  -----    ----------------  -----    ---------------   ----- \n",
      "   1    -0.4585    0.6026  [0 1]   -0.4601    0.8096  [0 1]   -0.4597    0.5298  [1 0]\n",
      "   2    -0.1734   -0.9305  [1 0]   -0.1718   -1.0447  [0 1]   -0.1615   -0.9853  [1 0]\n",
      "   3    -0.1602   -1.1804  [1 0]   -0.1241   -1.2051  [1 0]   -0.1391   -1.3729  [1 0]\n",
      "   4    -0.3442    0.1300  [1 0]   -0.3490    0.0837  [0 1]   -0.3420    0.6391  [1 0]\n",
      "   5    -0.2803    0.3260  [0 1]   -0.2921   -0.8131  [1 0]   -0.2676   -0.2554  [0 1]\n",
      "   6    -0.4716    1.7158  [1 0]   -0.4718    1.5023  [0 1]   -0.4718    1.1004  [0 1]\n",
      "\n",
      "\n",
      " Sample Policy (Training mode - hard_sampling: False) \n",
      " 312 epochs    logits          gumbel                logits           gumbel               logits             gumbel \n",
      " -----   ----------------------------------     ----------------------------------     ------------------------------------ \n",
      "   1    -0.4585   0.6026    0.0000   1.0000    -0.4601   0.8096    0.0015   0.9985    -0.4597    0.5298     0.9999   0.0001\n",
      "   2    -0.1734  -0.9305    1.0000   0.0000    -0.1718  -1.0447    1.0000   0.0000    -0.1615   -0.9853     1.0000   0.0000\n",
      "   3    -0.1602  -1.1804    1.0000   0.0000    -0.1241  -1.2051    0.9997   0.0003    -0.1391   -1.3729     1.0000   0.0000\n",
      "   4    -0.3442   0.1300    0.0617   0.9383    -0.3490   0.0837    1.0000   0.0000    -0.3420    0.6391     0.0000   1.0000\n",
      "   5    -0.2803   0.3260    0.0015   0.9985    -0.2921  -0.8131    0.9998   0.0002    -0.2676   -0.2554     0.5530   0.4470\n",
      "   6    -0.4716   1.7158    0.0000   1.0000    -0.4718   1.5023    0.0000   1.0000    -0.4718    1.1004     0.9781   0.0219\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "environ.display_test_sample_policy(current_epoch, hard_sampling = False)\n",
    "environ.display_train_sample_policy(current_epoch, hard_sampling = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "58b3a520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T21:24:03.057711Z",
     "start_time": "2022-02-22T21:24:02.894864Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.opt['train']['hard_sampling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b96903d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:25:11.319751Z",
     "start_time": "2022-02-20T21:25:11.210062Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "p = environ.get_current_state(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baf3df02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:25:26.324030Z",
     "start_time": "2022-02-20T21:25:26.112782Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'alphas': {   'param_groups': [   {   'amsgrad': False,\n",
      "                                          'betas': (0.9, 0.999),\n",
      "                                          'eps': 1e-08,\n",
      "                                          'initial_lr': 0.01,\n",
      "                                          'lr': 0.01,\n",
      "                                          'params': [0, 1, 2],\n",
      "                                          'weight_decay': 0.0005}],\n",
      "                  'state': {}},\n",
      "    'iter': 0,\n",
      "    'mtl-net': OrderedDict([   (   'task1_logits',\n",
      "                                   tensor([[ 0.001544,  0.002121],\n",
      "        [ 0.000495,  0.001111],\n",
      "        [ 0.000426, -0.000401],\n",
      "        [ 0.000426, -0.000470],\n",
      "        [ 0.000497,  0.000899],\n",
      "        [ 0.002776, -0.000226]])),\n",
      "                               (   'task2_logits',\n",
      "                                   tensor([[ 0.000482, -0.001070],\n",
      "        [-0.000505, -0.001076],\n",
      "        [ 0.000701, -0.000132],\n",
      "        [-0.000171, -0.001668],\n",
      "        [ 0.000262, -0.000324],\n",
      "        [-0.000923,  0.000983]])),\n",
      "                               (   'task3_logits',\n",
      "                                   tensor([[-3.087851e-03, -8.307507e-04],\n",
      "        [ 1.173737e-03, -5.455576e-04],\n",
      "        [ 2.034111e-04,  1.213794e-03],\n",
      "        [-1.567433e-03,  2.006002e-03],\n",
      "        [-5.546124e-04,  6.461411e-04],\n",
      "        [ 2.584132e-05, -3.491096e-04]])),\n",
      "                               (   'backbone.Input_linear.weight',\n",
      "                                   tensor([[ 0.011877, -0.003479, -0.003222,  ...,  0.005207, -0.016466, -0.015547],\n",
      "        [-0.015472,  0.009346, -0.018358,  ..., -0.018817, -0.010756, -0.000343],\n",
      "        [ 0.012137, -0.016257,  0.011343,  ...,  0.012979, -0.018544,  0.003306],\n",
      "        ...,\n",
      "        [-0.012243, -0.015527,  0.010133,  ...,  0.018429,  0.015107,  0.007935],\n",
      "        [-0.003038,  0.011575,  0.015501,  ..., -0.003206,  0.007815, -0.016358],\n",
      "        [ 0.000226, -0.017647, -0.008884,  ...,  0.001924,  0.006879,  0.012186]])),\n",
      "                               (   'backbone.Input_linear.bias',\n",
      "                                   tensor([0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000])),\n",
      "                               (   'backbone.blocks.0.0.linear.weight',\n",
      "                                   tensor([[ 0.070083,  0.295764,  0.007544,  ...,  0.212668,  0.326867, -0.094248],\n",
      "        [ 0.282620, -0.202875, -0.020508,  ..., -0.275984,  0.330726, -0.031024],\n",
      "        [ 0.174788, -0.085481,  0.166456,  ...,  0.249244,  0.080852,  0.221105],\n",
      "        ...,\n",
      "        [ 0.120898, -0.311046, -0.228328,  ...,  0.200665, -0.241114, -0.142918],\n",
      "        [ 0.296798,  0.006982,  0.182333,  ...,  0.173949,  0.099857,  0.320347],\n",
      "        [-0.027677, -0.271296,  0.262181,  ...,  0.244533,  0.254750,  0.264827]])),\n",
      "                               (   'backbone.blocks.0.0.linear.bias',\n",
      "                                   tensor([0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000])),\n",
      "                               (   'backbone.blocks.1.0.linear.weight',\n",
      "                                   tensor([[-0.262710, -0.059907, -0.318869,  ...,  0.094074, -0.123467,  0.220033],\n",
      "        [-0.132702,  0.148725,  0.081642,  ..., -0.047020,  0.340107, -0.054925],\n",
      "        [-0.155770,  0.019683, -0.270133,  ...,  0.112723,  0.239421,  0.045410],\n",
      "        ...,\n",
      "        [ 0.134953,  0.339018,  0.228553,  ..., -0.258702, -0.021538, -0.308228],\n",
      "        [-0.273121, -0.179135,  0.271294,  ..., -0.033256, -0.344136,  0.164898],\n",
      "        [ 0.161579, -0.029544,  0.073345,  ...,  0.094105, -0.186621,  0.180998]])),\n",
      "                               (   'backbone.blocks.1.0.linear.bias',\n",
      "                                   tensor([0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000])),\n",
      "                               (   'backbone.blocks.2.0.linear.weight',\n",
      "                                   tensor([[ 0.124438, -0.057025,  0.125489,  ...,  0.199924, -0.089486, -0.136742],\n",
      "        [ 0.299533,  0.217293, -0.010629,  ...,  0.041254, -0.265489,  0.274995],\n",
      "        [ 0.324284, -0.024549, -0.074056,  ...,  0.302506, -0.186204,  0.067132],\n",
      "        ...,\n",
      "        [ 0.283617, -0.095315, -0.034831,  ..., -0.083354, -0.011911,  0.226963],\n",
      "        [ 0.029767, -0.199141, -0.143800,  ...,  0.210772,  0.070565,  0.136708],\n",
      "        [-0.297940,  0.069080,  0.134716,  ...,  0.177471, -0.128550,  0.163709]])),\n",
      "                               (   'backbone.blocks.2.0.linear.bias',\n",
      "                                   tensor([0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000])),\n",
      "                               (   'backbone.blocks.3.0.linear.weight',\n",
      "                                   tensor([[-0.136827, -0.336762, -0.152565,  ..., -0.293125, -0.073244, -0.276273],\n",
      "        [-0.065896,  0.229843,  0.144965,  ..., -0.271245, -0.059682,  0.119686],\n",
      "        [-0.008983, -0.004903,  0.167265,  ..., -0.033209, -0.131518, -0.297970],\n",
      "        ...,\n",
      "        [ 0.254635, -0.154657, -0.001700,  ...,  0.283864,  0.285011, -0.305744],\n",
      "        [ 0.111002, -0.316274, -0.210123,  ..., -0.190702,  0.292608,  0.088679],\n",
      "        [ 0.320975,  0.202720,  0.284592,  ...,  0.254166,  0.092898, -0.119838]])),\n",
      "                               (   'backbone.blocks.3.0.linear.bias',\n",
      "                                   tensor([0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000])),\n",
      "                               (   'backbone.blocks.4.0.linear.weight',\n",
      "                                   tensor([[-0.237551,  0.168774,  0.344240,  ..., -0.030710,  0.065549,  0.135396],\n",
      "        [-0.190008,  0.323222, -0.295110,  ..., -0.319170,  0.200568,  0.029289],\n",
      "        [ 0.206324,  0.095989, -0.116152,  ...,  0.097544,  0.285436,  0.260790],\n",
      "        ...,\n",
      "        [-0.221269,  0.303044,  0.328936,  ..., -0.287953,  0.280423, -0.162932],\n",
      "        [ 0.326980,  0.221447,  0.174286,  ..., -0.003726,  0.244081,  0.337860],\n",
      "        [ 0.146178, -0.272182,  0.106632,  ..., -0.308803,  0.295727, -0.079188]])),\n",
      "                               (   'backbone.blocks.4.0.linear.bias',\n",
      "                                   tensor([0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000])),\n",
      "                               (   'backbone.blocks.5.0.linear.weight',\n",
      "                                   tensor([[-0.011502,  0.031681, -0.072106,  ..., -0.145910,  0.143012, -0.319184],\n",
      "        [-0.032186,  0.093586, -0.068248,  ...,  0.324096, -0.007160,  0.005705],\n",
      "        [ 0.293723,  0.313214, -0.081413,  ...,  0.073983, -0.027747, -0.203449],\n",
      "        ...,\n",
      "        [ 0.126407,  0.333879, -0.243354,  ...,  0.012070, -0.167367,  0.052821],\n",
      "        [ 0.119283, -0.253329, -0.294958,  ...,  0.280173,  0.105842, -0.163566],\n",
      "        [-0.039883, -0.235602,  0.082544,  ..., -0.015153,  0.140987, -0.262337]])),\n",
      "                               (   'backbone.blocks.5.0.linear.bias',\n",
      "                                   tensor([0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000, 0.100000,\n",
      "        0.100000, 0.100000])),\n",
      "                               (   'task1_fc1_c0.linear.weight',\n",
      "                                   tensor([[-3.197714e-02,  1.053948e-01,  5.896002e-02,  1.052323e-04, -9.141210e-02,  1.243433e-01,  1.027332e-01, -1.157296e-01,\n",
      "         -7.121476e-02, -1.004322e-01, -1.343686e-01,  4.183945e-02,  7.712570e-02,  3.769007e-03, -1.090174e-01,  4.758283e-02,\n",
      "         -8.533834e-02,  1.287281e-01,  7.378084e-02, -3.220829e-02,  9.277613e-02, -1.123369e-01,  1.209502e-01, -3.198487e-02,\n",
      "          8.027226e-02,  1.046995e-02, -2.093180e-02, -1.098710e-01, -9.550038e-02, -6.676374e-02, -6.470346e-02,  1.202221e-01,\n",
      "         -1.230852e-01, -1.090669e-01,  1.290290e-01,  5.336641e-02, -9.341054e-02, -7.453608e-02, -2.566522e-02,  2.494561e-02,\n",
      "         -2.121281e-02,  1.242437e-01, -7.189508e-02, -8.810917e-02,  1.974900e-02,  1.377320e-01,  7.272185e-02, -9.168393e-02,\n",
      "         -9.849938e-02, -9.150361e-02],\n",
      "        [-3.644259e-02,  1.211666e-01,  1.939237e-02,  2.328511e-02,  1.302462e-01,  1.332753e-01,  6.871877e-02,  4.503737e-02,\n",
      "         -6.679557e-02, -1.027662e-01,  1.328787e-01,  6.382088e-02, -1.055589e-01, -1.286427e-01,  4.992249e-02, -3.289651e-02,\n",
      "          2.339002e-02, -1.107108e-01,  1.237562e-01,  5.092132e-03,  7.552671e-02,  1.349627e-01, -7.518735e-02,  1.395457e-01,\n",
      "         -1.075729e-01,  6.254742e-02,  8.149178e-03,  7.196238e-02,  1.367026e-01, -6.264671e-02,  9.715433e-02,  6.348760e-02,\n",
      "         -1.862830e-02,  9.170890e-02, -3.634180e-02,  1.064014e-01, -1.030957e-01, -1.073653e-01, -8.347654e-02,  2.475874e-02,\n",
      "         -6.074191e-02, -1.195925e-01,  3.024861e-02, -1.059624e-01,  1.193464e-03, -7.508343e-02, -3.048588e-02,  1.148558e-01,\n",
      "         -1.635131e-02,  3.421269e-02],\n",
      "        [-3.963535e-02, -1.092500e-01,  5.379201e-02,  1.359039e-01, -2.574899e-02,  1.309895e-02,  1.381896e-01, -1.194365e-01,\n",
      "          4.958464e-02, -9.147362e-02,  4.289293e-02,  1.306277e-01, -1.130732e-01, -8.578462e-02,  3.386541e-02,  7.569338e-02,\n",
      "         -1.353384e-01,  5.917728e-02, -9.008719e-02,  3.398277e-02, -1.052502e-01, -1.066874e-01, -1.125124e-01, -7.200516e-02,\n",
      "         -1.167582e-02,  2.041054e-03,  8.633300e-02, -8.896396e-02,  1.203938e-01, -3.819626e-02, -8.402535e-02,  9.449416e-02,\n",
      "          7.608864e-02,  1.219253e-01,  6.035281e-02,  1.178611e-01,  9.044276e-03,  1.344078e-02, -8.259545e-02,  3.700359e-03,\n",
      "          9.896410e-02,  7.563126e-02, -1.941714e-02, -1.388818e-01, -6.475705e-02,  4.488151e-02,  6.921474e-03, -1.342665e-02,\n",
      "          1.336819e-01, -8.198421e-02],\n",
      "        [-1.574001e-02, -3.555217e-02,  2.834360e-02,  5.388353e-02,  8.578149e-03, -8.682165e-02, -7.139847e-02,  2.884785e-02,\n",
      "          1.150206e-02,  1.056201e-01,  3.471449e-02, -6.271337e-02,  1.260643e-01,  4.638660e-02,  5.022353e-03,  1.280759e-01,\n",
      "          1.124192e-01,  1.074097e-01, -1.145620e-01,  3.084504e-02, -5.912839e-02, -4.648005e-03, -1.062064e-01, -9.678153e-02,\n",
      "          1.219195e-02, -3.435535e-02, -9.070287e-02,  1.289463e-02, -4.826479e-02,  5.752246e-02,  1.441842e-02,  3.779365e-02,\n",
      "         -7.937879e-02,  3.487264e-03, -9.189107e-02,  3.836309e-02, -4.826447e-02, -1.366063e-01,  1.393774e-02, -1.046589e-01,\n",
      "          5.781853e-02,  1.887973e-02, -1.308225e-01, -5.434160e-02,  1.246633e-01,  1.086161e-01,  1.051756e-02,  3.030203e-02,\n",
      "         -1.372572e-01, -1.088030e-01],\n",
      "        [ 5.447669e-02,  3.675930e-03, -4.626841e-02, -2.885791e-02, -4.618610e-02,  1.301045e-02, -8.842743e-02, -1.098193e-01,\n",
      "          1.026842e-02,  6.016498e-02,  6.774972e-02, -3.676952e-02,  1.292492e-01, -6.379693e-02, -1.336322e-01, -8.195186e-02,\n",
      "          4.885562e-02, -1.856923e-02,  1.357412e-02,  8.720706e-03, -5.631316e-02, -1.606746e-02,  1.104198e-01,  1.114791e-01,\n",
      "          9.865573e-02, -2.980202e-02,  5.029163e-02,  3.364162e-03, -2.430107e-02, -6.743560e-02, -3.989191e-02,  1.322188e-01,\n",
      "          7.655126e-02, -1.334194e-01,  8.943891e-02, -1.361419e-01, -9.232479e-02,  1.328523e-02,  1.306193e-02,  9.533181e-02,\n",
      "         -3.772087e-02,  2.407566e-02, -1.241092e-01, -1.322974e-01, -3.347578e-02,  7.905734e-02,  1.286716e-01, -4.828527e-02,\n",
      "          1.647374e-02, -9.043834e-02]])),\n",
      "                               (   'task1_fc1_c0.linear.bias',\n",
      "                                   tensor([-0.006670,  0.089440,  0.129995,  0.097807, -0.127006])),\n",
      "                               (   'task2_fc1_c0.linear.weight',\n",
      "                                   tensor([[ 0.119821,  0.023089, -0.084288, -0.118884, -0.063549,  0.120820,  0.100246,  0.136902,  0.028708, -0.037786, -0.095133,\n",
      "          0.134228, -0.013382, -0.111075,  0.010022, -0.029068,  0.087903, -0.069343,  0.051942,  0.103524,  0.090567, -0.063112,\n",
      "          0.103373, -0.017096,  0.110879, -0.078980, -0.097232,  0.056133, -0.058492, -0.062724,  0.064087, -0.002996, -0.051346,\n",
      "         -0.129739, -0.023535, -0.113548, -0.128162,  0.063519,  0.004721, -0.088711,  0.127904,  0.075021, -0.141378, -0.005961,\n",
      "         -0.127315,  0.128697,  0.133419, -0.013490, -0.062236,  0.054499],\n",
      "        [-0.019735, -0.140760,  0.085444,  0.070673,  0.001566, -0.096185,  0.066916,  0.098080,  0.029130, -0.115595, -0.027964,\n",
      "         -0.080664,  0.130167,  0.083018, -0.029475, -0.114825,  0.125248, -0.128081, -0.079910, -0.037986, -0.063971,  0.022634,\n",
      "         -0.002564, -0.132980,  0.050354, -0.050210, -0.110787,  0.005346, -0.055693, -0.130360, -0.095461,  0.054182,  0.106069,\n",
      "         -0.134779,  0.113409, -0.109642,  0.118557,  0.110405, -0.011946, -0.122023, -0.007370, -0.059529,  0.041958, -0.034991,\n",
      "          0.099820,  0.004331,  0.121166,  0.077173,  0.031076,  0.013932],\n",
      "        [ 0.077829,  0.004426, -0.122747, -0.043009, -0.087351,  0.036547, -0.107955, -0.085494, -0.045310, -0.015092, -0.019086,\n",
      "          0.049593,  0.018235,  0.056153, -0.083031,  0.004852, -0.064778, -0.075437, -0.030070, -0.126022,  0.062187,  0.038593,\n",
      "         -0.124638, -0.134356,  0.016503, -0.087666,  0.130973, -0.100207,  0.127379, -0.097512,  0.108835, -0.002832, -0.138472,\n",
      "         -0.045478,  0.133336,  0.055231, -0.078719,  0.035910, -0.004125,  0.016659, -0.131835, -0.138777, -0.013123,  0.036503,\n",
      "         -0.037925, -0.017064, -0.020002, -0.101055,  0.105964, -0.008565],\n",
      "        [ 0.102767,  0.052064,  0.090498, -0.079675,  0.130660,  0.058627,  0.006198, -0.055439, -0.039264,  0.043892, -0.025229,\n",
      "         -0.128758,  0.098006,  0.044415, -0.108409,  0.068190, -0.068370,  0.105285,  0.072321, -0.102453,  0.043429, -0.027178,\n",
      "         -0.114536,  0.069062,  0.041782,  0.126015,  0.005002,  0.137652,  0.135242, -0.090155, -0.053506,  0.012871,  0.002981,\n",
      "         -0.115751,  0.121751,  0.061266, -0.053321, -0.129133, -0.062741, -0.039369,  0.044951,  0.105567,  0.116105,  0.127594,\n",
      "          0.079200, -0.115609, -0.132011,  0.084890, -0.040175, -0.103059],\n",
      "        [-0.070919,  0.102750,  0.128607, -0.049538, -0.007769,  0.109544,  0.136918, -0.050819, -0.065790, -0.108721, -0.127523,\n",
      "         -0.063593,  0.047422,  0.022001, -0.100839, -0.072999, -0.015976,  0.022227, -0.081068, -0.139359,  0.049071, -0.066154,\n",
      "         -0.077901,  0.096593,  0.037769,  0.014259,  0.028433, -0.117100,  0.042493, -0.088432, -0.003588,  0.064358, -0.007141,\n",
      "         -0.089107,  0.094068,  0.139006,  0.071067, -0.104510, -0.121440, -0.083192, -0.031573, -0.038007, -0.132647, -0.022424,\n",
      "          0.075271,  0.000923,  0.063163,  0.113811, -0.097645, -0.139000]])),\n",
      "                               (   'task2_fc1_c0.linear.bias',\n",
      "                                   tensor([-0.090995,  0.049215, -0.055856,  0.043955,  0.127098])),\n",
      "                               (   'task3_fc1_c0.linear.weight',\n",
      "                                   tensor([[ 6.463658e-02, -1.211976e-01,  8.581772e-02, -4.526971e-02, -3.337626e-03, -1.246453e-01, -5.946416e-02,  1.341118e-01,\n",
      "          9.303037e-02, -1.177442e-01, -2.938558e-02, -1.205174e-01,  1.349941e-01, -1.158899e-01,  1.608939e-02, -7.452602e-02,\n",
      "          7.766051e-02, -1.288702e-01, -2.672495e-02,  5.277603e-02,  1.255317e-01, -8.718218e-02,  3.750151e-02,  7.223915e-02,\n",
      "          3.523129e-02,  1.362326e-01, -3.400880e-02, -1.082424e-01,  8.015862e-02,  9.019591e-02,  9.881717e-03, -1.014569e-01,\n",
      "          1.220065e-01,  1.059581e-01,  5.046839e-02,  3.686838e-04,  3.868319e-02, -6.209657e-02,  1.895516e-02, -8.982158e-02,\n",
      "         -1.862840e-03,  7.600362e-02,  1.111318e-01, -1.214815e-01, -7.389516e-02,  5.484300e-03, -7.519741e-02,  1.717713e-02,\n",
      "          7.336887e-02, -8.255130e-02],\n",
      "        [ 3.790964e-02,  1.173748e-01,  9.120443e-02,  6.534415e-02, -7.979997e-02, -7.977723e-02, -1.087723e-01, -1.050619e-01,\n",
      "          8.900169e-02, -8.795112e-02, -4.027507e-02,  1.087542e-01, -1.005680e-01, -1.603871e-02, -5.512103e-02,  6.959743e-03,\n",
      "         -8.919647e-02, -1.202932e-01, -6.285916e-02, -5.450274e-02, -8.784463e-02,  6.381741e-02, -5.573864e-02, -7.991432e-02,\n",
      "          2.514387e-02,  5.352141e-02,  6.105421e-02, -1.090888e-01, -1.322520e-01,  1.411462e-01,  3.879845e-02,  9.781665e-02,\n",
      "          1.142904e-01,  6.176368e-03,  2.964345e-02, -7.699623e-03, -1.289898e-01,  1.170556e-01,  9.261437e-02, -1.366277e-01,\n",
      "          1.413072e-01,  1.181761e-01, -1.171319e-01, -9.095705e-02,  1.176098e-01,  3.471206e-02,  9.855990e-02, -1.330232e-01,\n",
      "         -3.539211e-02,  8.966473e-02],\n",
      "        [-1.052857e-01,  7.432673e-02, -2.330802e-02, -1.374264e-01, -5.128916e-02,  1.040100e-01, -4.426515e-03, -7.676729e-03,\n",
      "         -6.822626e-02,  4.853682e-02,  1.206556e-01, -8.258672e-02,  3.611607e-02, -6.503788e-02,  6.757477e-02,  9.385874e-02,\n",
      "          1.348821e-01, -5.746367e-02,  3.883332e-02, -5.209789e-03,  4.831610e-02,  2.823483e-02,  1.034752e-01,  9.131870e-02,\n",
      "          8.817286e-02, -4.451070e-02, -1.402274e-01,  5.968503e-02,  7.339400e-02,  1.068010e-01, -7.571135e-02, -1.087688e-01,\n",
      "         -9.221731e-06,  2.923479e-02, -4.883173e-02,  1.339428e-01,  5.600372e-02, -6.247493e-02,  1.292910e-01,  6.462055e-02,\n",
      "         -1.648370e-02,  1.386112e-01,  8.625805e-02, -8.253881e-02,  8.459052e-02, -9.800112e-02,  1.074871e-01, -1.510769e-02,\n",
      "         -2.389034e-02,  8.642729e-02],\n",
      "        [-2.361392e-02, -8.961095e-02,  1.386609e-02, -3.206507e-02, -7.492013e-02,  8.737379e-04, -1.037581e-02, -5.897838e-02,\n",
      "          5.320512e-02, -1.293851e-01,  1.117666e-01,  2.988618e-02,  4.985672e-02, -8.181778e-02, -7.256042e-02, -1.292501e-02,\n",
      "          1.829613e-02,  3.050154e-02, -8.928289e-02, -9.996683e-02, -1.116625e-01, -5.788971e-02,  5.895520e-02,  6.132353e-02,\n",
      "         -1.323122e-01,  1.226201e-01, -5.278935e-02,  5.842319e-02, -6.288619e-02,  6.721583e-02, -1.003063e-01, -1.598301e-02,\n",
      "         -1.365057e-01, -2.488219e-02, -3.534283e-02, -1.804910e-02,  2.693297e-02,  1.509923e-02, -5.833161e-02, -9.447234e-03,\n",
      "         -8.101240e-02, -1.094703e-01,  1.163015e-01,  1.065121e-01,  1.007128e-02,  4.910214e-02,  3.400224e-02, -7.896003e-02,\n",
      "          8.222176e-04, -1.349928e-01],\n",
      "        [-1.258565e-01,  1.167193e-01, -1.155948e-01, -2.781380e-02, -2.927980e-02,  1.044283e-01, -1.226837e-01, -9.649162e-02,\n",
      "          5.664876e-02,  1.104791e-01, -7.188348e-03,  1.265452e-01,  1.121863e-02,  8.350167e-03, -1.210640e-01,  1.507448e-02,\n",
      "          9.572662e-03, -1.389331e-01,  1.283768e-01, -1.232460e-01, -7.064997e-02, -1.241287e-02, -3.888106e-02, -1.158906e-01,\n",
      "          1.322256e-01,  2.815939e-02,  1.261662e-01, -3.804163e-02, -3.214112e-02, -4.466892e-04, -8.102848e-02,  1.187149e-01,\n",
      "         -9.809957e-02, -4.665338e-02, -3.772479e-02, -8.410847e-02,  7.369638e-02,  7.898094e-02, -5.189370e-02,  1.261017e-01,\n",
      "         -7.951256e-04,  1.209631e-01,  1.613550e-04,  2.411599e-02,  5.506526e-02,  6.157817e-02,  1.037118e-01,  2.868794e-02,\n",
      "         -4.825695e-02,  7.737290e-02]])),\n",
      "                               (   'task3_fc1_c0.linear.bias',\n",
      "                                   tensor([-0.096360,  0.078072,  0.019686,  0.016263, -0.076240]))]),\n",
      "    'temp': 4,\n",
      "    'weights': {   'param_groups': [   {   'amsgrad': False,\n",
      "                                           'betas': (0.5, 0.999),\n",
      "                                           'eps': 1e-08,\n",
      "                                           'initial_lr': 0.001,\n",
      "                                           'lr': 0.001,\n",
      "                                           'params': [0, 1, 2, 3, 4, 5],\n",
      "                                           'weight_decay': 0.0001},\n",
      "                                       {   'amsgrad': False,\n",
      "                                           'betas': (0.5, 0.999),\n",
      "                                           'eps': 1e-08,\n",
      "                                           'initial_lr': 0.001,\n",
      "                                           'lr': 0.001,\n",
      "                                           'params': [   6,\n",
      "                                                         7,\n",
      "                                                         8,\n",
      "                                                         9,\n",
      "                                                         10,\n",
      "                                                         11,\n",
      "                                                         12,\n",
      "                                                         13,\n",
      "                                                         14,\n",
      "                                                         15,\n",
      "                                                         16,\n",
      "                                                         17,\n",
      "                                                         18,\n",
      "                                                         19],\n",
      "                                           'weight_decay': 0.0001}],\n",
      "                   'state': {}}}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aedfc8",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Post Warm-up Training stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7fb765e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:45:43.999959Z",
     "start_time": "2022-02-01T12:45:43.862475Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'aggregated': {   'auc_pr': 0.5683542231355692,\n",
      "                      'avg_prec_score': 0.5686955149511226,\n",
      "                      'bceloss': 0.6940069357554117,\n",
      "                      'f1_max': 0.6753742658177068,\n",
      "                      'kappa': 0.08318090860174578,\n",
      "                      'kappa_max': 0.11385237142207795,\n",
      "                      'logloss': tensor(0.0002, device='cuda:0', dtype=torch.float64),\n",
      "                      'p_f1_max': 0.29707588851451877,\n",
      "                      'p_kappa_max': 0.48534467220306404,\n",
      "                      'roc_auc_score': 0.5679242272843051,\n",
      "                      'sc_loss': tensor(0.2891, device='cuda:0', dtype=torch.float64)},\n",
      "    'epoch': 1,\n",
      "    'loss': {   'task1': 3.5098743182605396,\n",
      "                'task2': 3.4508372449718867,\n",
      "                'task3': 3.4480013587242775,\n",
      "                'total': 10.408712921956704},\n",
      "    'loss_mean': {   'task1': 0.701974863652108,\n",
      "                     'task2': 0.6901674489943774,\n",
      "                     'task3': 0.6896002717448555,\n",
      "                     'total': 2.081742584391341},\n",
      "    'sharing': {'total': 0.0},\n",
      "    'sparsity': {   'task1': 0.006931469672256046,\n",
      "                    'task2': 0.006931469672256046,\n",
      "                    'task3': 0.006931469672256046,\n",
      "                    'total': 0.02079441025853157},\n",
      "    'task1': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.481316  0.429663        0.430056  0.621828  0.471980  0.007806   0.011740     0.501525  0.711726\n",
      "1          0.614529  0.563585        0.563966  0.592718  0.274593  0.163883   0.197754     0.467472  0.666188\n",
      "2          0.522325  0.502621        0.502973  0.674570  0.496948  0.023925   0.051563     0.584286  0.737475\n",
      "3          0.604399  0.573962        0.574392  0.654175  0.170357  0.120525   0.155403     0.545623  0.686908\n",
      "4          0.547591  0.537607        0.537968  0.682173  0.107585  0.035985   0.094520     0.418316  0.706954,\n",
      "                 'classification_agg': {   'auc_pr': 0.5214877235862244,\n",
      "                                           'avg_prec_score': 0.5218710163685921,\n",
      "                                           'bceloss': 0.701850187778473,\n",
      "                                           'f1_max': 0.6450929564660765,\n",
      "                                           'kappa': 0.07042502365080995,\n",
      "                                           'kappa_max': 0.10219606455150174,\n",
      "                                           'logloss': 0.005540691754324903,\n",
      "                                           'p_f1_max': 0.30429269671440123,\n",
      "                                           'p_kappa_max': 0.5034442186355592,\n",
      "                                           'roc_auc_score': 0.55403197977543,\n",
      "                                           'sc_loss': 3.5098743182605396}},\n",
      "    'task2': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.534265  0.559859        0.560165  0.693035  0.218099  0.060112   0.080040     0.485316  0.695036\n",
      "1          0.530896  0.552645        0.553118  0.693306  0.425663  0.026862   0.048743     0.510863  0.689872\n",
      "2          0.576279  0.542077        0.542489  0.661162  0.428496  0.099542   0.110405     0.489080  0.690190\n",
      "3          0.570442  0.599299        0.599621  0.687941  0.390608  0.066299   0.108004     0.535856  0.683957\n",
      "4          0.573253  0.563653        0.563954  0.670703  0.355411  0.064108   0.122336     0.415524  0.693014,\n",
      "                 'classification_agg': {   'auc_pr': 0.5635064814369257,\n",
      "                                           'avg_prec_score': 0.5638693726843218,\n",
      "                                           'bceloss': 0.6904138207435608,\n",
      "                                           'f1_max': 0.68122964433069,\n",
      "                                           'kappa': 0.06338457615584966,\n",
      "                                           'kappa_max': 0.09390563833389994,\n",
      "                                           'logloss': 0.005447495760534441,\n",
      "                                           'p_f1_max': 0.36365539729595187,\n",
      "                                           'p_kappa_max': 0.48732774853706357,\n",
      "                                           'roc_auc_score': 0.5570268805789104,\n",
      "                                           'sc_loss': 3.4508372449718867}},\n",
      "    'task3': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.614326  0.669207        0.669500  0.741408  0.294902  0.156246   0.192341     0.449188  0.678097\n",
      "1          0.622672  0.643428        0.643670  0.700539  0.259311  0.175533   0.185877     0.495724  0.678892\n",
      "2          0.599966  0.585534        0.585907  0.656115  0.252795  0.146259   0.153308     0.452810  0.678784\n",
      "3          0.565999  0.629145        0.629346  0.716296  0.062077  0.041028   0.092855     0.403423  0.724491\n",
      "4          0.560606  0.573028        0.573308  0.684643  0.247313  0.059600   0.102897     0.525165  0.688519,\n",
      "                 'classification_agg': {   'auc_pr': 0.6200684643835576,\n",
      "                                           'avg_prec_score': 0.6203461558004543,\n",
      "                                           'bceloss': 0.6897567987442017,\n",
      "                                           'f1_max': 0.699800196656354,\n",
      "                                           'kappa': 0.11573312599857777,\n",
      "                                           'kappa_max': 0.1454554113808322,\n",
      "                                           'logloss': 0.005443019027146415,\n",
      "                                           'p_f1_max': 0.22327957153320316,\n",
      "                                           'p_kappa_max': 0.4652620494365692,\n",
      "                                           'roc_auc_score': 0.5927138214985748,\n",
      "                                           'sc_loss': 3.4480013587242775}},\n",
      "    'train_time': 17.335111618041992}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d81b9d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:36.700361Z",
     "start_time": "2022-02-01T12:46:36.367037Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.5000, 0.5000],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5000, 0.5000]], device='cuda:0'),\n",
       " Parameter containing:\n",
       " tensor([[0.5000, 0.5000],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5000, 0.5000]], device='cuda:0'),\n",
       " Parameter containing:\n",
       " tensor([[0.5000, 0.5000],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5000, 0.5000]], device='cuda:0')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.networks['mtl-net'].arch_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16997489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:37:10.158440Z",
     "start_time": "2022-01-28T16:37:09.742327Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]], device='cuda:0'), tensor([[0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1]], device='cuda:0'), tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1]], device='cuda:0')], [array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32), array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32), array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32)])\n",
      "[array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32), array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32), array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32)]\n",
      "[array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32), array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32), array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "p = environ.get_sample_policy(hard_sampling = False)\n",
    "print(p)\n",
    "p = environ.get_policy_prob()\n",
    "print(p)\n",
    "p = environ.get_all_task_logits()\n",
    "print(p)\n",
    "\n",
    "# p = environ.get_current_policy()\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90d02d9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:40:37.799917Z",
     "start_time": "2022-01-28T16:40:37.773177Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26894142 0.73105858]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "a = softmax([0.0, 1])\n",
    "print(a)\n",
    "sampled = np.random.choice((1, 0), p=a)\n",
    "print(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9af0e3ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:13:16.205889Z",
     "start_time": "2022-01-28T16:13:16.179303Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.5, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    weight_decay: 0.0001\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.5, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "[0.01, 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(environ.optimizers['weights'])\n",
    "print(environ.schedulers['weights'].get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "388df0c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:50.411465Z",
     "start_time": "2022-02-01T12:46:50.020540Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses.keys      :  dict_keys(['parms', 'losses', 'losses_mean', 'sparsity', 'sharing', 'total', 'total_mean', 'task1', 'task2', 'task3'])\n",
      "losses[task]keys :  dict_keys(['cls_loss', 'cls_loss_mean'])\n",
      "{   'losses': {   'task1': tensor(3.5704, device='cuda:0', dtype=torch.float64),\n",
      "                  'task2': tensor(3.3313, device='cuda:0', dtype=torch.float64),\n",
      "                  'task3': tensor(3.3721, device='cuda:0', dtype=torch.float64),\n",
      "                  'total': tensor(10.2737, device='cuda:0', dtype=torch.float64)},\n",
      "    'losses_mean': {   'task1': tensor(0.7141, device='cuda:0', dtype=torch.float64),\n",
      "                       'task2': tensor(0.6663, device='cuda:0', dtype=torch.float64),\n",
      "                       'task3': tensor(0.6744, device='cuda:0', dtype=torch.float64),\n",
      "                       'total': tensor(2.0547, device='cuda:0', dtype=torch.float64)},\n",
      "    'parms': {'gumbel_temp': 5, 'lr_0': 0.01, 'lr_1': 0.01, 'train_layers': 0},\n",
      "    'sharing': {'total': tensor(0., device='cuda:0')},\n",
      "    'sparsity': {   'task1_logits': tensor(0.0069, device='cuda:0'),\n",
      "                    'task2_logits': tensor(0.0069, device='cuda:0'),\n",
      "                    'task3_logits': tensor(0.0069, device='cuda:0'),\n",
      "                    'total': tensor(0.0208, device='cuda:0')},\n",
      "    'task1': {   'cls_loss': tensor(3.5704, device='cuda:0', dtype=torch.float64),\n",
      "                 'cls_loss_mean': tensor(0.7141, device='cuda:0', dtype=torch.float64)},\n",
      "    'task2': {   'cls_loss': tensor(3.3313, device='cuda:0', dtype=torch.float64),\n",
      "                 'cls_loss_mean': tensor(0.6663, device='cuda:0', dtype=torch.float64)},\n",
      "    'task3': {   'cls_loss': tensor(3.3721, device='cuda:0', dtype=torch.float64),\n",
      "                 'cls_loss_mean': tensor(0.6744, device='cuda:0', dtype=torch.float64)},\n",
      "    'total': {},\n",
      "    'total_mean': {}}\n"
     ]
    }
   ],
   "source": [
    "print('losses.keys      : ', environ.losses.keys())\n",
    "print('losses[task]keys : ', environ.losses['task1'].keys())\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7f4b449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T22:57:02.151169Z",
     "start_time": "2022-01-15T22:57:02.056562Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'loss_mean', 'task1', 'task2', 'task3', 'aggregated', 'train_time', 'epoch'])\n",
      "<class 'dict'>\n",
      "\n",
      "<class 'dict'>\n",
      "\n",
      "{   'aggregated': {   'auc_pr': 0.8163426647572675,\n",
      "                      'avg_prec_score': 0.8164138615123665,\n",
      "                      'bceloss': 0.7729340473810831,\n",
      "                      'f1_max': 0.7574111413660235,\n",
      "                      'kappa': 0.4593877004350045,\n",
      "                      'kappa_max': 0.4722816344851592,\n",
      "                      'logloss': tensor(0.0002, device='cuda:0', dtype=torch.float64),\n",
      "                      'p_f1_max': 0.1918067594369252,\n",
      "                      'p_kappa_max': 0.545021508137385,\n",
      "                      'roc_auc_score': 0.8101998985724014,\n",
      "                      'sc_loss': tensor(0.3217, device='cuda:0', dtype=torch.float64)},\n",
      "    'epoch': 4000,\n",
      "    'loss': {   'task1': 3.990690022259455,\n",
      "                'task2': 3.7726694706664947,\n",
      "                'task3': 3.817710672775008,\n",
      "                'total': 11.581070165700957},\n",
      "    'loss_mean': {   'task1': 0.7981380044518911,\n",
      "                     'task2': 0.7545338941332989,\n",
      "                     'task3': 0.7635421345550015,\n",
      "                     'total': 2.316214033140191},\n",
      "    'task1': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.840926  0.819320        0.819383  0.744605  0.188466  0.505203   \n",
      "1          0.817256  0.785624        0.785697  0.706325  0.234966  0.461667   \n",
      "2          0.821726  0.819394        0.819462  0.768309  0.103616  0.482997   \n",
      "3          0.772370  0.766114        0.766202  0.713072  0.197119  0.414875   \n",
      "4          0.785095  0.803825        0.803897  0.735945  0.241081  0.416901   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.524762     0.693089  0.702767  \n",
      "1      0.474705     0.729373  0.757761  \n",
      "2      0.496770     0.312012  0.779951  \n",
      "3      0.423936     0.581922  0.935489  \n",
      "4      0.427422     0.811243  0.819495  ,\n",
      "                 'classification_agg': {   'auc_pr': 0.798855508429197,\n",
      "                                           'avg_prec_score': 0.7989281568935325,\n",
      "                                           'bceloss': 0.799092447757721,\n",
      "                                           'f1_max': 0.7336512000971758,\n",
      "                                           'kappa': 0.4563288316147501,\n",
      "                                           'kappa_max': 0.46951913050242283,\n",
      "                                           'logloss': 0.006299707993919771,\n",
      "                                           'p_f1_max': 0.19304971992969516,\n",
      "                                           'p_kappa_max': 0.6255278527736664,\n",
      "                                           'roc_auc_score': 0.807474721566956,\n",
      "                                           'sc_loss': 3.990690022259455}},\n",
      "    'task2': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.833828  0.843551        0.843636  0.786776  0.286642  0.512757   \n",
      "1          0.784282  0.798552        0.798620  0.756201  0.065474  0.405454   \n",
      "2          0.794011  0.798233        0.798299  0.733455  0.167343  0.431454   \n",
      "3          0.839064  0.860586        0.860625  0.781065  0.199097  0.508344   \n",
      "4          0.841909  0.844915        0.844966  0.774130  0.124443  0.519265   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.518114     0.426390  0.753670  \n",
      "1      0.422608     0.354472  0.840536  \n",
      "2      0.436441     0.481076  0.776165  \n",
      "3      0.518856     0.430450  0.718333  \n",
      "4      0.526225     0.478729  0.695051  ,\n",
      "                 'classification_agg': {   'auc_pr': 0.8291675538480338,\n",
      "                                           'avg_prec_score': 0.8292292868467086,\n",
      "                                           'bceloss': 0.7567508101463318,\n",
      "                                           'f1_max': 0.7663254180716083,\n",
      "                                           'kappa': 0.4754547147763093,\n",
      "                                           'kappa_max': 0.48444883865167504,\n",
      "                                           'logloss': 0.005955540493049498,\n",
      "                                           'p_f1_max': 0.16859976947307587,\n",
      "                                           'p_kappa_max': 0.4342232346534729,\n",
      "                                           'roc_auc_score': 0.8186188467896192,\n",
      "                                           'sc_loss': 3.7726694706664947}},\n",
      "    'task3': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.789143  0.818832        0.818915  0.795256  0.131201  0.430588   \n",
      "1          0.773360  0.795295        0.795367  0.746918  0.344915  0.380806   \n",
      "2          0.863028  0.864169        0.864209  0.780428  0.294887  0.545351   \n",
      "3          0.807607  0.821005        0.821136  0.791405  0.165901  0.457213   \n",
      "4          0.789393  0.805724        0.805793  0.747277  0.131950  0.417939   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.437650     0.549203  0.781711  \n",
      "1      0.414754     0.814326  0.928911  \n",
      "2      0.565829     0.637907  0.605613  \n",
      "3      0.469116     0.303002  0.703193  \n",
      "4      0.427037     0.572130  0.795366  ,\n",
      "                 'classification_agg': {   'auc_pr': 0.8210049319945718,\n",
      "                                           'avg_prec_score': 0.8210841407968588,\n",
      "                                           'bceloss': 0.7629588842391969,\n",
      "                                           'f1_max': 0.7722568059292869,\n",
      "                                           'kappa': 0.4463795549139541,\n",
      "                                           'kappa_max': 0.46287693430137955,\n",
      "                                           'logloss': 0.006026642588024569,\n",
      "                                           'p_f1_max': 0.21377078890800477,\n",
      "                                           'p_kappa_max': 0.5753134369850159,\n",
      "                                           'roc_auc_score': 0.8045061273606293,\n",
      "                                           'sc_loss': 3.817710672775008}},\n",
      "    'train_time': 47.46593999862671}\n"
     ]
    }
   ],
   "source": [
    "print( environ.val_metrics.keys())\n",
    "# pp.pprint(val_metrics)\n",
    "print(type(environ.val_metrics['aggregated']))\n",
    "print()\n",
    "print(type(environ.val_metrics['task1']['classification_agg']))\n",
    "print()\n",
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38c9d578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:14:58.034384Z",
     "start_time": "2022-01-07T23:14:58.004850Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17988/3181484359.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" val_metric keys               : {val_metrics.keys()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" loss keys                     : {val_metrics['loss'].keys()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" task1 keys                    : {val_metrics['task1'].keys()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" task1 classification keys     : {val_metrics['task1']['classification'].keys()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" task1 classification_agg keys : {val_metrics['task1']['classification_agg'].keys()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "print(f\" val_metric keys               : {val_metrics.keys()}\")\n",
    "print(f\" loss keys                     : {val_metrics['loss'].keys()}\")\n",
    "print(f\" task1 keys                    : {val_metrics['task1'].keys()}\")\n",
    "print(f\" task1 classification keys     : {val_metrics['task1']['classification'].keys()}\")\n",
    "print(f\" task1 classification_agg keys : {val_metrics['task1']['classification_agg'].keys()}\")\n",
    "print()\n",
    "print(f\" task1                       : {val_metrics['task1']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task2                       : {val_metrics['task2']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task3                       : {val_metrics['task3']['classification_agg']['loss']:5f}\")\n",
    "print(f\" loss                        : {val_metrics['loss']['total']:5f}\")\n",
    "print(f\" train_time                  : {val_metrics['train_time']:2f}\")\n",
    "print(f\" epoch                       : {val_metrics['epoch']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78a55ac",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Post Weight + Policy Training Stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1804a770",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:22:20.634818Z",
     "start_time": "2022-01-27T00:22:20.444566Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.networks['mtl-net'].backbone.layer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5fa9d122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:30:31.940280Z",
     "start_time": "2022-01-26T19:30:31.910058Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0])\n",
      "tensor([0.1667, 0.3333, 0.5000, 0.6667, 0.8333, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "num_blocks = 6\n",
    "num_policy_layers = 6\n",
    "gt =  torch.ones((num_blocks)).long()\n",
    "gt0 =  torch.zeros((num_blocks)).long()\n",
    "print(gt)\n",
    "print(gt0)\n",
    "\n",
    "loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "print(loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "514f6d98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:42:31.300891Z",
     "start_time": "2022-01-26T19:42:31.257774Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond 2\n",
      "Compute CrossEntropyLoss between \n",
      " Logits   : \n",
      "tensor([[0.3306, 0.4518],\n",
      "        [0.3532, 0.5529],\n",
      "        [0.3888, 0.6125],\n",
      "        [0.4204, 0.7685],\n",
      "        [0.4520, 0.7994],\n",
      "        [0.4840, 0.8021]]) \n",
      " and gt: \n",
      "tensor([1, 1, 1, 1, 1, 1]) \n",
      "\n",
      "task1_logits sparsity error:  0.5725929141044617\n",
      "\n",
      " cond 2\n",
      "Compute CrossEntropyLoss between Logits      : tensor([[0.4840, 0.8021]])  and gt: 1 \n",
      "task1_logits sparsity error:  0.5467103123664856 \n",
      "\n",
      "Compute CrossEntropyLoss between Logits      : tensor([[0.4840, 0.8021]])  and gt: 0 \n",
      "task1_logits sparsity error:  0.864768385887146 \n",
      "\n",
      "\n",
      " cond 3\n",
      "Compute CrossEntropyLoss between Logits   : tensor([[0.3306, 0.4518]])  and gt: tensor([1]) \n",
      "task1_logits sparsity error:  0.634384036064148 \n",
      "\n",
      "Compute CrossEntropyLoss between Logits   : tensor([[0.3306, 0.4518]])  and gt: tensor([0]) \n",
      "task1_logits sparsity error:  0.7555801868438721 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if environ.opt['diff_sparsity_weights'] and not environ.opt['is_sharing']:\n",
    "    print(' cond 1')\n",
    "    ## Assign higher weights to higher layers \n",
    "    loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "    print(f\"{task_key} sparsity error:  {2 * (loss_weights[-num_blocks:] * environ.cross_entropy2(logits[-num_blocks:], gt)).mean()})\")\n",
    "    print_dbg(f\" loss_weights :  {loss_weights}\", verbose = True)\n",
    "    print_dbg(f\" cross_entropy:  {environ.cross_entropy2(logits[-num_blocks:], gt)}  \", verbose = True)\n",
    "    print_dbg(f\" loss[sparsity][{task_key}]: {self.losses['sparsity'][task_key] } \", verbose = True)\n",
    "\n",
    "else:\n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between \\n Logits   : \\n{logits[-num_blocks:]} \\n and gt: \\n{gt} \\n\", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-num_blocks:], gt)}\")\n",
    "    \n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt[-1:])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt0[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt0[-1:])} \\n\")\n",
    "    \n",
    "    print('\\n cond 3')    \n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt[0:1])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt0[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt0[0:1])} \\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "672c91c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:30.155045Z",
     "start_time": "2022-01-26T00:14:30.107095Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# flag = 'update_w'\n",
    "# environ.fix_alpha\n",
    "# environ.free_w(opt['fix_BN'])\n",
    "\n",
    "flag = 'update_alpha'\n",
    "environ.fix_weights()\n",
    "environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2128a652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:31.184285Z",
     "start_time": "2022-01-25T23:43:31.159229Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.networks['mtl-net'].num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ac0d199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:34.993711Z",
     "start_time": "2022-01-26T00:14:34.968623Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_iters         : 6580\n",
      "curr_epochs           : 60\n",
      "train_total_epochs    : 60\n"
     ]
    }
   ],
   "source": [
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") \n",
    "\n",
    "train_total_epochs += 5\n",
    "\n",
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0032bf7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:41.628847Z",
     "start_time": "2022-01-25T23:43:41.602238Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-05, 1e-05]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.schedulers['weights'].get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef5240a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:36:17.129535Z",
     "start_time": "2022-01-08T01:36:16.006144Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state dict for weights = SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.0001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      "\n",
      "Parameter Group 1\n",
      "    dampening: 0\n",
      "    lr: 0.0001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "state dict for alphas = Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "{   'alphas': {   'param_groups': [   {   'amsgrad': False,\n",
      "                                          'betas': (0.9, 0.999),\n",
      "                                          'eps': 1e-08,\n",
      "                                          'lr': 0.0001,\n",
      "                                          'params': [0, 1, 2],\n",
      "                                          'weight_decay': 0.0005}],\n",
      "                  'state': {   0: {   'exp_avg': tensor([[ 0.0607, -0.0007],\n",
      "        [-0.0428, -0.0069],\n",
      "        [-0.1218,  0.0138],\n",
      "        [ 0.0086,  0.0238]], device='cuda:0'),\n",
      "                                      'exp_avg_sq': tensor([[0.0523, 0.0112],\n",
      "        [0.1734, 0.0073],\n",
      "        [0.3830, 0.0086],\n",
      "        [0.6783, 0.0108]], device='cuda:0'),\n",
      "                                      'step': 8613},\n",
      "                               1: {   'exp_avg': tensor([[ 0.0535, -0.0901],\n",
      "        [-0.0352, -0.0387],\n",
      "        [ 0.1020, -0.0073],\n",
      "        [-0.0796, -0.0576]], device='cuda:0'),\n",
      "                                      'exp_avg_sq': tensor([[0.0549, 0.0120],\n",
      "        [0.1729, 0.0070],\n",
      "        [0.3925, 0.0042],\n",
      "        [0.6830, 0.0098]], device='cuda:0'),\n",
      "                                      'step': 8613},\n",
      "                               2: {   'exp_avg': tensor([[-0.0127, -0.0090],\n",
      "        [ 0.1781, -0.0526],\n",
      "        [ 0.0248, -0.0095],\n",
      "        [ 0.1182, -0.0113]], device='cuda:0'),\n",
      "                                      'exp_avg_sq': tensor([[0.0501, 0.0096],\n",
      "        [0.1758, 0.0075],\n",
      "        [0.3727, 0.0086],\n",
      "        [0.6747, 0.0059]], device='cuda:0'),\n",
      "                                      'step': 8613}}},\n",
      "    'weights': {   'param_groups': [   {   'dampening': 0,\n",
      "                                           'lr': 0.0001,\n",
      "                                           'momentum': 0.9,\n",
      "                                           'nesterov': False,\n",
      "                                           'params': [0, 1, 2, 3, 4, 5],\n",
      "                                           'weight_decay': 0.0001},\n",
      "                                       {   'dampening': 0,\n",
      "                                           'lr': 0.0001,\n",
      "                                           'momentum': 0.9,\n",
      "                                           'nesterov': False,\n",
      "                                           'params': [   6,\n",
      "                                                         7,\n",
      "                                                         8,\n",
      "                                                         9,\n",
      "                                                         10,\n",
      "                                                         11,\n",
      "                                                         12,\n",
      "                                                         13,\n",
      "                                                         14,\n",
      "                                                         15],\n",
      "                                           'weight_decay': 0.0001}],\n",
      "                   'state': {   0: {   'momentum_buffer': tensor([[-5.4482e-01, -2.7512e-01,  4.6711e-02, -4.5902e-01, -2.5247e-01, -2.1980e-01,  9.4069e-02, -1.7776e-01, -2.0681e-01,\n",
      "         -1.0892e-01, -2.7464e-01,  9.3985e-03, -3.7082e-01, -2.7459e-01,  3.1315e-01, -2.4067e-01, -2.3865e-01, -2.0458e-01,\n",
      "         -3.9198e-01, -1.3971e-01, -2.2085e-01,  2.9561e-01, -3.2675e-01, -4.4961e-01, -2.5565e-01, -1.9292e-01,  2.3961e-02,\n",
      "         -1.4747e-01, -2.0461e-01, -2.9271e-01, -1.2636e-01, -3.2118e-01, -1.3085e-02, -3.2467e-01,  7.6504e-02, -3.8073e-01,\n",
      "         -3.4652e-01, -4.8136e-01, -1.0855e-01, -4.6362e-01],\n",
      "        [ 7.5279e-02,  5.0053e-01, -6.5901e-02,  4.2624e-01, -1.1979e-01,  1.3010e-01, -5.5052e-03,  6.0068e-02,  1.6456e-01,\n",
      "          6.9727e-02,  5.5028e-01,  7.4976e-02,  2.0544e-01, -1.8356e-01,  5.8646e-03,  3.8858e-01,  5.8229e-01, -6.4714e-02,\n",
      "         -9.7311e-02,  1.5540e-02,  2.6569e-01,  1.2685e-01,  3.5929e-01,  6.1809e-02,  6.5516e-02,  1.7281e-01,  2.4054e-01,\n",
      "          2.5444e-01,  8.1368e-02,  1.7834e-01,  6.4536e-01,  2.9524e-01,  5.1240e-02,  1.0327e-01,  5.0252e-01, -1.2009e-01,\n",
      "          5.2004e-01,  3.6589e-01,  2.5036e-02,  1.1756e-01],\n",
      "        [-2.6041e-02,  3.7978e-01, -2.9577e-02,  1.2583e-01, -1.9533e-01,  1.3204e-01, -2.4134e-01, -2.2500e-01,  1.1932e-01,\n",
      "         -2.8338e-02, -1.2620e-01,  4.1562e-02, -1.4164e-01,  1.0466e-02, -7.2124e-03, -1.7311e-01, -1.0594e-02, -1.1018e-01,\n",
      "         -4.0215e-01,  2.2231e-01, -3.5036e-01, -1.2274e-01, -2.5909e-01, -4.9505e-01,  2.7185e-01, -6.1372e-02, -3.2376e-01,\n",
      "         -4.9975e-01,  4.8624e-01, -2.4463e-03, -5.9059e-02, -2.9173e-02, -8.6035e-02,  2.1797e-02, -3.9157e-02, -1.6863e-01,\n",
      "          5.4898e-01,  1.9727e-01, -1.3099e-01,  2.3543e-01],\n",
      "        [ 2.3553e-01,  3.4450e-01, -7.3627e-02,  4.6605e-01,  4.3280e-02, -6.7811e-02,  7.9972e-02,  5.1132e-01, -2.0549e-02,\n",
      "          3.1941e-01,  7.4393e-01,  8.0956e-01,  5.7910e-02, -5.3678e-02,  2.2120e-01,  8.8379e-01,  8.9871e-01, -1.4795e-01,\n",
      "         -2.7687e-02,  3.6311e-01,  4.9540e-01,  3.6264e-01,  3.9721e-01,  3.3454e-01,  5.2051e-01,  1.9513e-01,  3.0391e-01,\n",
      "          1.0195e-01, -1.7816e-01,  5.9080e-01,  1.0638e+00, -2.2466e-01,  1.3106e-01,  2.6890e-01,  4.8539e-01, -1.6549e-01,\n",
      "          1.6727e-01,  1.9687e-01, -5.7773e-02,  6.5643e-04],\n",
      "        [-1.4043e+00, -4.7333e-01, -2.1537e-01, -6.8192e-01, -4.0019e-01, -3.0406e-01, -3.6066e-01, -8.0768e-01, -3.2529e-02,\n",
      "         -6.8346e-01, -1.1644e+00, -8.0557e-01, -7.2629e-01, -6.1576e-02, -2.6680e-01, -1.1771e+00, -9.3424e-01, -3.5853e-01,\n",
      "         -5.4122e-01, -5.1141e-01, -6.5359e-01, -5.1459e-01, -8.0336e-01, -8.5221e-01, -5.7714e-01, -4.6222e-01, -6.1317e-01,\n",
      "         -8.5647e-01,  1.8005e-02, -1.0541e+00, -1.6143e+00, -3.8753e-01, -6.1965e-01, -6.0904e-01, -6.1653e-01, -3.2613e-01,\n",
      "         -4.6098e-01, -5.1365e-01, -5.4302e-01, -6.4716e-01]], device='cuda:0')},\n",
      "                                1: {   'momentum_buffer': tensor([-0.0579,  0.2361, -0.0467,  0.4477, -0.6013], device='cuda:0')},\n",
      "                                2: {   'momentum_buffer': tensor([[-0.2612, -0.1668, -0.0060, -0.4843,  0.0824,  0.2120, -0.0110, -0.2463,  0.0614, -0.1931, -0.0739, -0.3940, -0.1723,\n",
      "         -0.0844, -0.0420, -0.3581, -0.3555,  0.1027,  0.3321, -0.2004,  0.0719, -0.1718, -0.1382, -0.2087, -0.4006,  0.1659,\n",
      "         -0.0612,  0.2602, -0.3789, -0.5442, -0.6798, -0.0991,  0.1144,  0.0608, -0.3799,  0.1046, -0.5230, -0.1794,  0.2387,\n",
      "         -0.3948],\n",
      "        [-0.7644, -0.4455,  0.1079, -0.6770, -0.0285, -0.0317, -0.0798, -0.5369, -0.1481, -0.5042, -0.6391, -0.6097, -0.4634,\n",
      "         -0.3808, -0.4200, -0.5469, -0.9528, -0.0851,  0.2172, -0.3774, -0.0737, -0.6040, -0.4646, -0.6076, -0.3767,  0.0727,\n",
      "         -0.1834,  0.3338, -0.3549, -0.7231, -1.1620,  0.0138, -0.1620, -0.3471, -0.4770,  0.0757, -0.6643, -0.6895,  0.0787,\n",
      "         -0.4058],\n",
      "        [ 0.2805, -0.0582,  0.1003,  0.0825,  0.2279, -0.3497,  0.1211,  0.5327,  0.0040,  0.5895,  0.3208,  0.3248,  0.1391,\n",
      "          0.3223,  0.3612,  0.3953, -0.0528,  0.2579,  0.6889,  0.3003,  0.2949,  0.3943,  0.3399,  0.3902,  0.2274,  0.1454,\n",
      "          0.2639,  0.4317,  0.0282,  0.2718,  0.7873,  0.1240, -0.0545, -0.0371, -0.2902,  0.1248,  0.0531,  0.4477,  0.1740,\n",
      "          0.3522],\n",
      "        [-0.1528, -0.1209,  0.0156, -0.2532, -0.0495, -0.1200,  0.2843, -0.2697,  0.0212, -0.3180, -0.1699,  0.0696, -0.0441,\n",
      "         -0.2312,  0.0227,  0.0530,  0.4047, -0.4066,  0.1157, -0.0749,  0.0571, -0.2684,  0.0121,  0.2005, -0.0978,  0.0283,\n",
      "          0.1963, -0.2490, -0.3016, -0.0356,  0.0103,  0.0743,  0.2626,  0.0507, -0.0169, -0.3918, -0.1736,  0.0629, -0.0922,\n",
      "         -0.0151],\n",
      "        [-0.1752,  0.0017, -0.0910, -0.4192, -0.1514,  0.1885, -0.0909, -0.2453,  0.0872, -0.2964, -0.3132, -0.5285, -0.0679,\n",
      "         -0.0362, -0.2413, -0.5825, -0.5508,  0.1931, -0.0183, -0.3240, -0.0980, -0.0574, -0.3542, -0.1842, -0.1074,  0.2090,\n",
      "         -0.1148,  0.0744, -0.1232, -0.2965, -0.8092,  0.1216,  0.0491,  0.0700,  0.0853,  0.0258,  0.0286, -0.4716,  0.1206,\n",
      "         -0.0628]], device='cuda:0')},\n",
      "                                3: {   'momentum_buffer': tensor([-0.1741, -0.3002,  0.2925,  0.2971, -0.3722], device='cuda:0')},\n",
      "                                4: {   'momentum_buffer': tensor([[-0.0849, -0.1597,  0.2053, -0.1966, -0.0118, -0.2330, -0.0241, -0.6122, -0.2113, -0.3294, -0.2063, -0.3181,  0.0481,\n",
      "         -0.4093, -0.4637, -0.7161, -0.4272, -0.1147,  0.2656, -0.4111,  0.0617, -0.3495, -0.3421, -0.1997,  0.0105,  0.0609,\n",
      "         -0.0572,  0.1777, -0.0505, -0.6948, -0.4959,  0.2197,  0.1054, -0.3540, -0.4853,  0.2524, -0.3534, -0.1041,  0.0436,\n",
      "         -0.0729],\n",
      "        [-0.2884, -0.0777, -0.1561, -0.0193, -0.2145,  0.1506,  0.0461, -0.1056,  0.1115,  0.0735,  0.0143, -0.1489, -0.1132,\n",
      "         -0.1654, -0.0719, -0.0780,  0.0905, -0.1635,  0.0411,  0.0230, -0.1094,  0.2141,  0.2209,  0.2538, -0.2747, -0.0911,\n",
      "          0.2328, -0.0246, -0.2137,  0.0164,  0.4605,  0.0623,  0.1916,  0.0445,  0.2819,  0.0821, -0.2006,  0.0480, -0.2465,\n",
      "         -0.0939],\n",
      "        [-0.3999, -0.1251, -0.2381, -0.1985, -0.1385, -0.0977, -0.1711, -0.1430, -0.2113, -0.3605, -0.0474, -0.3035,  0.0633,\n",
      "         -0.0959, -0.1873, -0.3301, -0.1024, -0.2385, -0.4791, -0.1046, -0.2390, -0.2179, -0.3163, -0.2241, -0.5092,  0.1025,\n",
      "         -0.1386, -0.4020, -0.2547, -0.1484, -0.6128, -0.2314, -0.0788,  0.2300, -0.0069, -0.2817, -0.1210, -0.0113, -0.4520,\n",
      "         -0.2268],\n",
      "        [ 0.2257,  0.3765,  0.1650, -0.1478,  0.0906,  0.1179,  0.1602, -0.1910,  0.4880, -0.0549, -0.0863,  0.1077,  0.3084,\n",
      "          0.1151, -0.0719, -0.2795,  0.0179,  0.6149,  0.4591, -0.0565, -0.0812,  0.2760, -0.0342,  0.0169,  0.0639, -0.0015,\n",
      "          0.0713,  0.1656,  0.2635,  0.0067, -0.1705,  0.2555,  0.2492, -0.0994,  0.1673,  0.3523,  0.3903,  0.0610,  0.2200,\n",
      "          0.0149],\n",
      "        [ 0.4827,  0.3845,  0.2594,  0.7605,  0.4389,  0.4478,  0.4341,  0.6531,  0.1451,  0.5494,  0.8218,  0.7176,  0.2111,\n",
      "          0.1574,  0.5871,  1.1305,  0.7570,  0.1728,  0.4147,  0.5044,  0.3479,  0.4095,  0.6468,  0.4890,  0.3662,  0.0461,\n",
      "          0.3462,  0.2534,  0.3233,  0.7041,  1.0300,  0.2806,  0.3191,  0.6002,  0.5828,  0.2223,  0.5332,  0.5004,  0.1183,\n",
      "          0.3750]], device='cuda:0')},\n",
      "                                5: {   'momentum_buffer': tensor([-0.3636,  0.1302, -0.1584, -0.0355,  0.4779], device='cuda:0')},\n",
      "                                6: {   'momentum_buffer': tensor([[ 1.5304e-01, -5.9271e-03,  4.8917e-01,  ..., -2.2712e-01, -1.2944e-01, -1.5610e-01],\n",
      "        [ 2.3775e-02, -9.0718e-03,  2.1647e-02,  ...,  3.9088e-02,  2.5611e-02, -2.9572e-02],\n",
      "        [ 1.6747e-02, -1.2741e-02,  1.7129e-02,  ...,  1.8492e-02, -8.0235e-03, -2.1392e-02],\n",
      "        ...,\n",
      "        [-3.1285e-06, -2.0295e-06,  7.8620e-06,  ...,  1.1699e-06,  3.7180e-07,  5.9421e-07],\n",
      "        [ 7.3640e-06, -1.7594e-05,  7.4498e-05,  ..., -2.5983e-05,  1.2307e-05,  3.2505e-05],\n",
      "        [-9.6068e-06, -8.5949e-06,  1.0171e-05,  ..., -6.1072e-06, -8.3978e-07, -6.7925e-06]], device='cuda:0')},\n",
      "                                7: {   'momentum_buffer': tensor([ 0.3887, -0.0579,  0.3107,  0.1551,  0.8331, -0.1376, -0.3844, -0.0353,  0.4420, -0.5766,  0.0788, -0.0751, -0.1867,\n",
      "         0.1001, -0.3312, -0.2118, -0.3287, -0.0677,  0.3000, -0.2234,  0.1245, -0.1919, -0.2328,  0.3670,  0.0290, -0.1925,\n",
      "         0.4300, -0.1144, -0.4987, -0.1107, -0.3611,  0.4313, -0.4842,  0.6604,  0.0137,  0.0144,  0.2782, -0.2992, -0.2614,\n",
      "        -0.2438], device='cuda:0')},\n",
      "                                8: {   'momentum_buffer': tensor([[ 1.5098e-01,  6.8066e-02, -1.1790e-01,  ...,  9.2484e-02, -4.3672e-02,  6.0582e-02],\n",
      "        [-2.7928e-02, -3.8709e-02,  1.1351e-02,  ...,  1.4022e-02,  1.4181e-02, -2.3581e-02],\n",
      "        [ 1.2368e-05,  1.6269e-04, -2.8662e-04,  ..., -4.4968e-05, -1.8164e-04, -3.3822e-04],\n",
      "        ...,\n",
      "        [-4.0677e-02,  2.7337e-02,  1.5571e-02,  ..., -4.8724e-02, -3.2856e-02, -1.0650e-02],\n",
      "        [ 1.6598e-01,  9.5019e-02, -4.6000e-02,  ...,  6.4921e-02,  3.7100e-02,  8.7817e-02],\n",
      "        [-8.4905e-03,  2.2479e-02, -2.5620e-03,  ..., -7.5068e-03, -5.1343e-03, -1.6064e-02]], device='cuda:0')},\n",
      "                                9: {   'momentum_buffer': tensor([ 3.4776e-01, -3.5319e-02,  1.0072e-04,  3.8190e-03,  4.6922e-01, -1.4719e-02, -1.9333e-01, -1.0430e-01, -4.9097e-02,\n",
      "        -3.4282e-01, -1.2632e-01,  1.1640e-01,  1.4245e-01,  3.9221e-01, -1.5241e-01,  1.0361e-01,  2.8693e-01, -3.8438e-02,\n",
      "         5.4297e-01,  2.2322e-02,  2.2954e-01, -2.4616e-01,  8.4137e-02,  2.5481e-01, -9.6045e-02,  4.1123e-02,  1.7366e-01,\n",
      "        -3.3607e-02, -7.8799e-02, -8.1003e-02, -1.5968e-01,  1.4050e-01,  7.0586e-02,  2.4685e-01,  8.4280e-02,  1.2348e-01,\n",
      "        -1.0331e-01, -9.8404e-02,  2.8721e-01, -3.6698e-02], device='cuda:0')},\n",
      "                                10: {   'momentum_buffer': tensor([[ 0.0122, -0.0239, -0.0222,  ...,  0.0248,  0.0130, -0.0082],\n",
      "        [ 0.0409, -0.0863, -0.0585,  ...,  0.0649, -0.0058,  0.0468],\n",
      "        [ 0.0525,  0.0079, -0.0112,  ...,  0.0785,  0.0505,  0.0502],\n",
      "        ...,\n",
      "        [ 0.2707,  0.1044, -0.0254,  ...,  0.1337,  0.0744,  0.0592],\n",
      "        [ 0.0154,  0.0331,  0.0019,  ...,  0.0142, -0.0596, -0.0396],\n",
      "        [-0.0857,  0.0114, -0.0162,  ..., -0.0332, -0.1018, -0.0657]], device='cuda:0')},\n",
      "                                11: {   'momentum_buffer': tensor([ 0.0760, -0.0063,  0.1234, -0.0805,  0.1407, -0.0494,  0.0783,  0.1751, -0.0619, -0.1029,  0.0626, -0.1621,  0.0215,\n",
      "         0.0589,  0.0777, -0.0114,  0.0356,  0.0869,  0.1138,  0.0837,  0.0116, -0.0266,  0.1767,  0.2595,  0.0828, -0.0264,\n",
      "         0.1041,  0.0221,  0.0534, -0.0933,  0.0266, -0.0506, -0.0109, -0.0572, -0.0290,  0.0525, -0.0016,  0.2201, -0.0559,\n",
      "        -0.0764], device='cuda:0')},\n",
      "                                12: {   'momentum_buffer': tensor([[ 0.0542,  0.0008, -0.0059,  ...,  0.0547,  0.0933,  0.0654],\n",
      "        [-0.0124, -0.0217, -0.0174,  ...,  0.0780, -0.0404,  0.0119],\n",
      "        [-0.0024, -0.0011, -0.0005,  ...,  0.0003, -0.0004, -0.0003],\n",
      "        ...,\n",
      "        [ 0.0027,  0.0664,  0.0873,  ...,  0.0592,  0.0687,  0.0510],\n",
      "        [ 0.0913,  0.0534, -0.0025,  ...,  0.0306, -0.0440,  0.0299],\n",
      "        [-0.0215,  0.0202, -0.0636,  ..., -0.0170, -0.0338, -0.0677]], device='cuda:0')},\n",
      "                                13: {   'momentum_buffer': tensor([ 0.1389, -0.0492, -0.0026, -0.1231, -0.0199,  0.0288,  0.0002,  0.0369,  0.0689,  0.0349, -0.0123, -0.0443, -0.0297,\n",
      "         0.0026,  0.0345,  0.0489,  0.0253,  0.0764,  0.0739,  0.0602, -0.0033,  0.0222, -0.0743,  0.0255,  0.0509,  0.1373,\n",
      "         0.0104,  0.0234, -0.0108,  0.0034, -0.0159,  0.0054,  0.0429,  0.0476, -0.0150, -0.0057, -0.0413,  0.0307,  0.0383,\n",
      "        -0.0091], device='cuda:0')},\n",
      "                                14: {   'momentum_buffer': tensor([[ 0.1029,  0.0980,  0.0202,  ...,  0.1078,  0.0647,  0.0686],\n",
      "        [ 0.1083,  0.0676,  0.0507,  ...,  0.1634,  0.0056,  0.0213],\n",
      "        [ 0.0021, -0.0008, -0.0076,  ...,  0.0037, -0.0008, -0.0021],\n",
      "        ...,\n",
      "        [ 0.0117,  0.0903,  0.0301,  ..., -0.0045,  0.0020,  0.0292],\n",
      "        [ 0.0616,  0.0727, -0.0032,  ...,  0.0555,  0.0145,  0.0146],\n",
      "        [-0.0441, -0.0322, -0.0147,  ...,  0.0057, -0.0240, -0.0302]], device='cuda:0')},\n",
      "                                15: {   'momentum_buffer': tensor([ 0.0819,  0.0197, -0.0006, -0.0349,  0.0058,  0.0291, -0.0123, -0.0388, -0.0164, -0.0855,  0.0779,  0.0347, -0.0715,\n",
      "        -0.0225,  0.0360,  0.0105, -0.0919,  0.2164,  0.0061,  0.0852,  0.1488, -0.1035,  0.0128, -0.0246,  0.1463,  0.0421,\n",
      "         0.0069, -0.0251,  0.0041, -0.0824, -0.1332, -0.0114, -0.0141,  0.0515,  0.0716,  0.0047, -0.0701, -0.0178,  0.0446,\n",
      "        -0.0167], device='cuda:0')}}}}\n"
     ]
    }
   ],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.optimizers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    current_state[k] = v.state_dict()\n",
    "pp.pprint(current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "35ab97ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:40:22.032247Z",
     "start_time": "2022-01-08T01:40:22.006953Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state dict for weights = <torch.optim.lr_scheduler.StepLR object at 0x7f90c01c0ca0>\n",
      "{'step_size': 4000, 'gamma': 0.5, 'base_lrs': [0.0001, 0.0001], 'last_epoch': 9100, '_step_count': 9101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [2.5e-05, 2.5e-05]}\n"
     ]
    }
   ],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.schedulers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    print(v.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc24362",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Policy / Logit stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "03a4dea9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:35:14.041577Z",
     "start_time": "2022-02-08T20:35:14.018303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.special          import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f0932e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:30.103364Z",
     "start_time": "2022-02-08T20:00:30.068021Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2248288",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_task_logits(n)` Get logits for task group n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b98fa4c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:56:35.652087Z",
     "start_time": "2022-02-08T20:56:35.327406Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.00035114, -0.06397165],\n",
      "        [ 0.00056738, -0.03663344],\n",
      "        [ 0.00056098, -0.02617791],\n",
      "        [-0.00044851, -0.07137010],\n",
      "        [ 0.00013184, -0.05879313],\n",
      "        [ 0.00079021, -0.05743587]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "task_logits = environ.get_task_logits(1)\n",
    "print(task_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26560f69",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_arch_parameters()`: Get last used logits from network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b76ebc27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:31.101960Z",
     "start_time": "2022-02-08T20:00:30.757064Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.00035120, -0.06617914],\n",
      "        [ 0.00056736, -0.04341661],\n",
      "        [ 0.00056091, -0.01096974],\n",
      "        [-0.00044879, -0.01083876],\n",
      "        [ 0.00013163,  0.00874004],\n",
      "        [ 0.00079006, -0.00861552]], device='cuda:0'), Parameter containing:\n",
      "tensor([[-0.00035114, -0.06397165],\n",
      "        [ 0.00056738, -0.03663344],\n",
      "        [ 0.00056098, -0.02617791],\n",
      "        [-0.00044851, -0.07137010],\n",
      "        [ 0.00013184, -0.05879313],\n",
      "        [ 0.00079021, -0.05743587]], device='cuda:0'), Parameter containing:\n",
      "tensor([[-0.00035016, -0.06321616],\n",
      "        [ 0.00056696, -0.03072025],\n",
      "        [ 0.00056129, -0.01022454],\n",
      "        [-0.00044983, -0.00021709],\n",
      "        [ 0.00013071,  0.00484093],\n",
      "        [ 0.00078938, -0.02230957]], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeead541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:06.054699Z",
     "start_time": "2022-02-09T15:43:05.689327Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 1.873275e-03, -5.276022e-01],\n",
      "        [ 2.345233e-03, -2.740704e-01],\n",
      "        [ 2.614364e-03,  1.604760e-02],\n",
      "        [ 2.143114e-04,  2.198091e-02],\n",
      "        [ 4.191113e-04,  5.969038e-02],\n",
      "        [ 2.007700e-03,  3.544179e-02]], device='cuda:0'), Parameter containing:\n",
      "tensor([[ 1.873281e-03, -4.892288e-01],\n",
      "        [ 2.345207e-03, -2.255457e-01],\n",
      "        [ 2.614349e-03, -2.191145e-01],\n",
      "        [ 2.143144e-04, -3.354620e-01],\n",
      "        [ 4.190930e-04, -3.310193e-01],\n",
      "        [ 2.007697e-03, -2.532191e-01]], device='cuda:0'), Parameter containing:\n",
      "tensor([[ 1.873283e-03, -6.248206e-01],\n",
      "        [ 2.345208e-03, -2.149665e-01],\n",
      "        [ 2.614360e-03, -1.423603e-01],\n",
      "        [ 2.143196e-04, -1.089546e-01],\n",
      "        [ 4.191188e-04, -7.532501e-02],\n",
      "        [ 2.007698e-03, -1.407905e-01]], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228518c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_all_task_logits()`:  Get Policy Logits - returns same as `get_arch_parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4a1de1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:24.972390Z",
     "start_time": "2022-02-09T15:43:24.636629Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.8732749e-03 -5.2760220e-01]\n",
      " [ 2.3452332e-03 -2.7407044e-01]\n",
      " [ 2.6143640e-03  1.6047601e-02]\n",
      " [ 2.1431143e-04  2.1980910e-02]\n",
      " [ 4.1911125e-04  5.9690382e-02]\n",
      " [ 2.0077003e-03  3.5441790e-02]] \n",
      "\n",
      "[[ 1.8732806e-03 -4.8922884e-01]\n",
      " [ 2.3452067e-03 -2.2554573e-01]\n",
      " [ 2.6143489e-03 -2.1911447e-01]\n",
      " [ 2.1431442e-04 -3.3546203e-01]\n",
      " [ 4.1909298e-04 -3.3101928e-01]\n",
      " [ 2.0076970e-03 -2.5321913e-01]] \n",
      "\n",
      "[[ 1.8732828e-03 -6.2482059e-01]\n",
      " [ 2.3452076e-03 -2.1496648e-01]\n",
      " [ 2.6143598e-03 -1.4236034e-01]\n",
      " [ 2.1431963e-04 -1.0895463e-01]\n",
      " [ 4.1911882e-04 -7.5325012e-02]\n",
      " [ 2.0076977e-03 -1.4079048e-01]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs = environ.get_all_task_logits()\n",
    "for i in logs:\n",
    "    print(i, '\\n')\n",
    "# probs = softmax(logs, axis= -1)\n",
    "# for i in probs:\n",
    "#     print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5254ca",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_prob()` : Gets the softmax of the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69bd4409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:29.733732Z",
     "start_time": "2022-02-09T15:43:29.699600Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6293608  0.37063923]\n",
      " [0.5686673  0.43133274]\n",
      " [0.49664173 0.5033582 ]\n",
      " [0.4945586  0.5054415 ]\n",
      " [0.48518652 0.5148135 ]\n",
      " [0.49164233 0.50835776]] \n",
      "\n",
      "[[0.62036604 0.379634  ]\n",
      " [0.55672747 0.44327256]\n",
      " [0.5552062  0.44479376]\n",
      " [0.58313996 0.4168601 ]\n",
      " [0.58210933 0.41789067]\n",
      " [0.5634626  0.4365374 ]] \n",
      "\n",
      "[[0.6517394  0.34826055]\n",
      " [0.5541151  0.44588488]\n",
      " [0.5361803  0.46381968]\n",
      " [0.5272652  0.47273484]\n",
      " [0.518927   0.48107296]\n",
      " [0.535639   0.464361  ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "for i in policy_softmaxs:\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b8ef4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = False)` : Calls test_sample_policy of network with random choices based on softmax of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "57c0a9e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:21:15.636722Z",
     "start_time": "2022-02-08T22:21:15.165456Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00035120 -0.06617914] \t [0 1] \t [0.51645106 0.48354897]\n",
      "[ 0.00056736 -0.04341661] \t [0 1] \t [0.51099426 0.48900577]\n",
      "[ 0.00056091 -0.01096974] \t [1 0] \t [0.50288266 0.49711737]\n",
      "[-0.00044879 -0.01083876] \t [0 1] \t [0.50259751 0.49740252]\n",
      "[0.00013163 0.00874004] \t [0 1] \t [0.49784794 0.50215214]\n",
      "[ 0.00079006 -0.00861552] \t [0 1] \t [0.50235140 0.49764863]\n",
      "\n",
      "\n",
      "[-0.00035114 -0.06397165] \t [0 1] \t [0.51589972 0.48410025]\n",
      "[ 0.00056738 -0.03663344] \t [1 0] \t [0.50929916 0.49070087]\n",
      "[ 0.00056098 -0.02617791] \t [1 0] \t [0.5066843 0.4933157]\n",
      "[-0.00044851 -0.07137010] \t [0 1] \t [0.51772296 0.48227707]\n",
      "[ 0.00013184 -0.05879313] \t [0 1] \t [0.514727 0.485273]\n",
      "[ 0.00079021 -0.05743587] \t [0 1] \t [0.51455247 0.48544762]\n",
      "\n",
      "\n",
      "[-0.00035016 -0.06321616] \t [0 1] \t [0.51571137 0.48428872]\n",
      "[ 0.00056696 -0.03072025] \t [1 0] \t [0.50782120 0.49217883]\n",
      "[ 0.00056129 -0.01022454] \t [1 0] \t [0.50269639 0.49730355]\n",
      "[-0.00044983 -0.00021709] \t [0 1] \t [0.4999418 0.5000582]\n",
      "[0.00013071 0.00484093] \t [1 0] \t [0.49882248 0.50117755]\n",
      "[ 0.00078938 -0.02230957] \t [0 1] \t [0.50577444 0.49422547]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "policies,logits = environ.get_sample_policy(hard_sampling = False)\n",
    "\n",
    "for l, p, s in zip(logits, policies, policy_softmaxs) :\n",
    "    for  l_row, p_row, s_row in zip(l, p, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac0461d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `gumbel_softmax()`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e0b6b03f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:28:17.107529Z",
     "start_time": "2022-02-08T21:28:17.084910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', floatmode = 'maxprec_equal')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "0645d47a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:35:11.617269Z",
     "start_time": "2022-02-08T21:35:11.569599Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001180506617226113\n",
      "   [-0.00035016 -0.06321616]   \t [0.17155227 0.82844770]            \t [1. 0.]\n",
      "   [ 0.00056696 -0.03072025]   \t [0.04782803 0.95217192]            \t [1. 0.]\n",
      "   [ 0.00056129 -0.01022454]   \t [0.52678031 0.47321963]            \t [0. 1.]\n",
      "   [-0.00044983 -0.00021709]   \t [0.74226642 0.25773358]            \t [0. 1.]\n",
      "   [0.00013071 0.00484093]   \t [0.81233245 0.18766758]            \t [1. 0.]\n",
      "   [ 0.00078938 -0.02230957]   \t [0.76270294 0.23729712]            \t [1. 0.]\n",
      "\n",
      "   [-0.00035016 -0.06321616]   \t [0.01975500 0.98024493]            \t [0. 1.]\n",
      "   [ 0.00056696 -0.03072025]   \t [0.33801472 0.66198522]            \t [1. 0.]\n",
      "   [ 0.00056129 -0.01022454]   \t [0.2644645 0.7355355]            \t [0. 1.]\n",
      "   [-0.00044983 -0.00021709]   \t [0.08984101 0.91015899]            \t [1. 0.]\n",
      "   [0.00013071 0.00484093]   \t [0.17066659 0.82933342]            \t [1. 0.]\n",
      "   [ 0.00078938 -0.02230957]   \t [0.74648136 0.25351864]            \t [0. 1.]\n",
      "\n",
      "   [-0.00035016 -0.06321616]   \t [0.5077298 0.4922701]            \t [0. 1.]\n",
      "   [ 0.00056696 -0.03072025]   \t [0.97178763 0.02821237]            \t [0. 1.]\n",
      "   [ 0.00056129 -0.01022454]   \t [0.15721972 0.84278023]            \t [1. 0.]\n",
      "   [-0.00044983 -0.00021709]   \t [0.13137119 0.86862880]            \t [1. 0.]\n",
      "   [0.00013071 0.00484093]   \t [0.89678597 0.10321394]            \t [1. 0.]\n",
      "   [ 0.00078938 -0.02230957]   \t [0.36205515 0.63794482]            \t [1. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(environ.temp)\n",
    "# tau = environ.temp\n",
    "tau = 1\n",
    "for i in range(3): \n",
    "    logits_tensor = torch.tensor(logits[0])\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=tau, hard=False).cpu().numpy() \n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=tau, hard=True).cpu().numpy()\n",
    "    \n",
    "    for l, gs, gh in zip(lgts, gumbel_soft, gumbel_hard):\n",
    "        print(f\"   {l}   \\t {gs}            \\t {gh}\")\n",
    "#     print(lgts)\n",
    "#     print(gumbel_soft)\n",
    "#     print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfeeff3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "399px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "888d4fda4588b3bfc9793c8a97c6f83877963bb7385ca7ca0c08738cf63adc49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
