{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408f1261",
   "metadata": {},
   "source": [
    "## Initialization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55604c43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:31.202842Z",
     "start_time": "2022-08-18T13:29:31.170114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0c686b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:33.133351Z",
     "start_time": "2022-08-18T13:29:31.204766Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:08.233990Z",
     "iopub.status.busy": "2022-01-07T22:44:08.233053Z",
     "iopub.status.idle": "2022-01-07T22:44:08.273284Z",
     "shell.execute_reply": "2022-01-07T22:44:08.271908Z",
     "shell.execute_reply.started": "2022-01-07T22:44:08.233943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "# sys.path.insert(0, '/home/kbardool/kusanagi/AdaSparseChem/src') ; print(sys.path)\n",
    "import time\n",
    "import argparse\n",
    "import yaml\n",
    "import types, copy, pprint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "## Set visible GPU device \n",
    "##----------------------------------------------\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "# from pynvml import *\n",
    "from utils import (initialize, init_dataloaders, init_environment, init_wandb, training_initializations, model_initializations, \n",
    "                   check_for_resume_training, disp_dataloader_info, disp_info_1, warmup_phase, weight_policy_training, \n",
    "                   display_gpu_info, init_dataloaders_by_fold_id, print_separator, print_heading, \n",
    "                   timestring, print_loss, get_command_line_args, load_from_pickle) \n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "pd.options.display.width = 132\n",
    "# torch.set_printoptions(precision=6, threshold=None, edgeitems=None, linewidth=132, profile=None, sci_mode=None)\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Train.ipynb\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a84e6bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:33.161778Z",
     "start_time": "2022-08-18T13:29:33.135137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33ac6e",
   "metadata": {},
   "source": [
    "## Create Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee652c57",
   "metadata": {},
   "source": [
    "### Parse Input Args  - Read YAML config file - wandb initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a42bb98b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:33.193300Z",
     "start_time": "2022-08-18T13:29:33.164150Z"
    }
   },
   "outputs": [],
   "source": [
    "# input_args = \" --config yamls/chembl_3task_train.yaml \" \\\n",
    "#              \" --resume \" \\\n",
    "#              \" --exp_id      330i85cg\" \\\n",
    "#              \" --exp_name    0308_1204\" \\\n",
    "#              \" --lambda_sparsity  0.01\"\\\n",
    "#              \" --lambda_sharing   0.01\" \n",
    "#========================================================================\n",
    "#              \" --no_residual \"\n",
    "#              \" --exp_name       0410_1934 \" \\\n",
    "#              \" --hidden_size   100 100 100 100 100 100\" \\\n",
    "#              \" --tail_hidden_size  100 \" \\\n",
    "#              \" --decay_lr_rate      0.75\"  \\\n",
    "#              \" --decay_lr_freq       20\"  \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca1c17d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:33.218584Z",
     "start_time": "2022-08-18T13:29:33.194969Z"
    }
   },
   "outputs": [],
   "source": [
    "# synthetic_1task_config = \"../yamls/chembl_synt_train_1task.yaml\"\n",
    "# synthetic_3task_config = \"../yamls/chembl_synt_train_3task.yaml\"\n",
    "# synthetic_5task_config = \"../yamls/chembl_synt_train_5task.yaml\"\n",
    "# synthetic_config_file  = \"../yamls/chembl_synt_train.yaml\"\n",
    "# config_file      = \"../yamls/chembl_mini_train.yaml\"\n",
    "config_file      = \"../yamls/chembl_cb29_train_1task.yaml\"\n",
    "config_file      = \"../yamls/chembl_cb29_train_10task.yaml\"\n",
    "batch_size=4098\n",
    "# batch_size=2048\n",
    "# RESUME_MODEL_CKPT = 'model_train_ep_25_seed_0088'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d87ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4edb398",
   "metadata": {},
   "source": [
    "####   For Resume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c33f25d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:33.244737Z",
     "start_time": "2022-08-18T13:29:33.220158Z"
    }
   },
   "outputs": [],
   "source": [
    "restart_input_args = f\" --config  {config_file} \" \\\n",
    "             \" --exp_desc     weight 105 bch/ep policy 105 bch/ep \" \\\n",
    "             \" --warmup_epochs        10 \"  \\\n",
    "             \" --hidden_size         4000 4000 4000 4000\"  \\\n",
    "             \" --tail_hidden_size    4000 \"  \\\n",
    "             \" --first_dropout       0.80 \"  \\\n",
    "             \" --middle_dropout      0.80\"  \\\n",
    "             \" --last_dropout        0.80 \"  \\\n",
    "             \" --seed_idx              0 \"  \\\n",
    "             f\" --batch_size        {batch_size} \"  \\\n",
    "             \" --task_lr           0.001 \"  \\\n",
    "             \" --backbone_lr       0.001 \"  \\\n",
    "             \" --decay_lr_rate       0.3 \"  \\\n",
    "             \" --decay_lr_freq        10 \"  \\\n",
    "             \" --policy_lr         0.001 \"  \\\n",
    "             \" --lambda_sparsity    0.02 \"  \\\n",
    "             \" --lambda_sharing     0.01 \"  \\\n",
    "             \" --pytorch_threads       7 \"  \\\n",
    "             \" --cuda_devices          2\"   \\\n",
    "             \" --gpu_ids               0 \"  \\\n",
    "             \" --resume\"                    \\\n",
    "             \" --resume_path        ../../experiments/AdaSparseChem-cb29-10task/4000x6_0817_1521_lr0.001_do0.8/\" \\\n",
    "             \" --resume_ckpt        model_best_model\" \\\n",
    "             \" --resume_metrics     metrics_best.pickle\" \\\n",
    "             \" --exp_id             2h7wyaua\" \\\n",
    "             \" --exp_name           0817_1521\" \\\n",
    "             \" --folder_sfx         POLICY_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68145e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T17:38:07.664270Z",
     "start_time": "2022-06-24T17:38:07.630274Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "source": [
    "####  For Initiating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd3a7f00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:33.286112Z",
     "start_time": "2022-08-18T13:29:33.246268Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [],
   "source": [
    "input_args = f\" --config  {config_file} \" \\\n",
    "             \" --exp_desc            10-task with policy training \" \\\n",
    "             \" --warmup_epochs         10 \"  \\\n",
    "             \" --hidden_size         4000 4000 4000 4000 4000 4000 \"  \\\n",
    "             \" --tail_hidden_size    4000 \"  \\\n",
    "             \" --first_dropout       0.80 \"  \\\n",
    "             \" --middle_dropout      0.80\"  \\\n",
    "             \" --last_dropout        0.80 \"  \\\n",
    "             \" --seed_idx              0 \"  \\\n",
    "             f\" --batch_size        {batch_size} \"  \\\n",
    "             \" --task_lr           0.001 \"  \\\n",
    "             \" --backbone_lr       0.001 \"  \\\n",
    "             \" --decay_lr_rate       0.3 \"  \\\n",
    "             \" --decay_lr_freq        10 \"  \\\n",
    "             \" --policy_lr         0.001 \"  \\\n",
    "             \" --lambda_sparsity    0.02 \"  \\\n",
    "             \" --lambda_sharing     0.01 \"  \\\n",
    "             \" --pytorch_threads       7 \"  \\\n",
    "             \" --cuda_devices          2\"   \\\n",
    "             \" --gpu_ids               0 \"  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ffb30",
   "metadata": {},
   "source": [
    "### Read Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98fcbe87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:33.323908Z",
     "start_time": "2022-08-18T13:29:33.287702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  command line parms : \n",
      "------------------------\n",
      " config...................  ../yamls/chembl_cb29_train_10task.yaml\n",
      " project_name.............  None\n",
      " exp_id...................  30ugid3y\n",
      " exp_name.................  None\n",
      " folder_sfx...............  None\n",
      " exp_desc.................  10-task with policy training\n",
      " hidden_sizes.............  [4000, 4000, 4000, 4000, 4000, 4000]\n",
      " tail_hidden_size.........  [4000]\n",
      " warmup_epochs............  10\n",
      " training_epochs..........  None\n",
      " seed_idx.................  0\n",
      " batch_size...............  4098\n",
      " first_dropout............  0.8\n",
      " middle_dropout...........  0.8\n",
      " last_dropout.............  0.8\n",
      " backbone_lr..............  0.001\n",
      " task_lr..................  0.001\n",
      " policy_lr................  0.001\n",
      " decay_lr_rate............  0.3\n",
      " decay_lr_freq............  10.0\n",
      " lambda_sparsity..........  0.02\n",
      " lambda_sharing...........  0.01\n",
      " cuda_devices.............  2\n",
      " gpu_ids..................  [0]\n",
      " pytorch_threads..........  7\n",
      " skip_residual............  False\n",
      " skip_hidden..............  False\n",
      " resume...................  False\n",
      " resume_path..............  None\n",
      " resume_ckpt..............  None\n",
      " resume_metrics...........  None\n",
      " cpu......................  False\n",
      " min_samples_class........  None\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ns = types.SimpleNamespace()\n",
    "input_args = input_args.split() if input_args is not None else input_args\n",
    "# input_args = restart_input_args.split() \n",
    "ns.args = get_command_line_args(input_args, display = True)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=ns.args.cuda_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0c6844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:33.352772Z",
     "start_time": "2022-08-18T13:29:33.325514Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# display_gpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ddaf625",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:37.942037Z",
     "start_time": "2022-08-18T13:29:33.356614Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "################### READ YAML ####################\n",
      "##################################################\n",
      " Pytorch thread count: 20\n",
      " Set Pytorch thread count to : 7\n",
      " Pytorch thread count set to : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkbardool\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kevin/WSL-projs/AdaSparseChem/notebooks/wandb/run-20220818_152933-30ugid3y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task/runs/30ugid3y\" target=\"_blank\">0818_1529</a></strong> to <a href=\"https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WandB Initialization -----------------------------------------------------------\n",
      " PROJECT NAME: AdaSparseChem-cb29-10Task\n",
      " RUN ID      : 30ugid3y \n",
      " RUN NAME    : 0818_1529\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " log_dir              create folder:  ../../experiments/AdaSparseChem-cb29-10task/4000x6_0818_1529_lr0.001_do0.8\n",
      " result_dir           folder exists:  ../../experiments/AdaSparseChem-cb29-10task/4000x6_0818_1529_lr0.001_do0.8\n",
      " checkpoint_dir       folder exists:  ../../experiments/AdaSparseChem-cb29-10task/4000x6_0818_1529_lr0.001_do0.8\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " experiment name       : 0818_1529 \n",
      " experiment id         : 30ugid3y \n",
      " folder_name           : 4000x6_0818_1529_lr0.001_do0.8 \n",
      " experiment description: 10-task with policy training\n",
      " Random seeds          : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      " Random  seed used     : 88 \n",
      " log folder            : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0818_1529_lr0.001_do0.8\n",
      " checkpoint folder     : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0818_1529_lr0.001_do0.8\n",
      " Gpu ids               : [0]\n",
      " Seed index            : 0\n",
      " policy_iter           : best\n",
      " Data Split ratios     : [0.725, 0.225, 0.05]\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "        project_name : AdaSparseChem-cb29-10Task\n",
      "              exp_id : 30ugid3y\n",
      "        exp_name_pfx : 0818_1529\n",
      "            exp_name : 0818_1529\n",
      "          exp_folder : 4000x6_0818_1529_lr0.001_do0.8\n",
      "     exp_description : 10-task with policy training\n",
      "          folder_sfx : None\n",
      "         random_seed : 88\n",
      "           seed_list : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      "              config : ../yamls/chembl_cb29_train_10task.yaml\n",
      "                 cpu : None\n",
      "             gpu_ids : [0]\n",
      "            backbone : SparseChem\n",
      "               tasks : ['class', 'class', 'class', 'class', 'class', 'class', 'class', 'class', 'class', 'class']\n",
      "     tasks_num_class : [472, 624, 688, 192, 620, 184, 224, 148, 344, 72]\n",
      "             lambdas : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "             verbose : False\n",
      "     input_size_freq : None\n",
      "          input_size : 32000\n",
      "        hidden_sizes : [4000, 4000, 4000, 4000, 4000, 4000]\n",
      "    tail_hidden_size : [4000]\n",
      " first_non_linearity : relu\n",
      "middle_non_linearity : relu\n",
      "  last_non_linearity : relu\n",
      "       first_dropout : 0.8\n",
      "      middle_dropout : 0.8\n",
      "        last_dropout : 0.8\n",
      "   class_output_size : None\n",
      "    regr_output_size : None\n",
      "              policy : True\n",
      "        policy_model : task-specific\n",
      "       skip_residual : False\n",
      "         skip_hidden : False\n",
      "           is_sparse : True\n",
      "          is_sharing : True\n",
      "diff_sparsity_weights : False\n",
      "          skip_layer : 0\n",
      "       is_curriculum : False\n",
      "    curriculum_speed : 3\n",
      "              fix_BN : False\n",
      "     retrain_from_pl : False\n",
      "\n",
      "train\n",
      "-----\n",
      "          batch_size : 128\n",
      "       warmup_epochs : 10\n",
      "     training_epochs : 250\n",
      "         total_iters : 25000\n",
      "       warm_up_iters : None\n",
      "             task_lr : 0.001\n",
      "         backbone_lr : 0.001\n",
      "    weight_optimizer : adam\n",
      "    policy_optimizer : adam\n",
      "       decay_lr_rate : 0.3\n",
      "       decay_lr_freq : 10.0\n",
      "   decay_lr_cooldown : 0\n",
      "           policy_lr : 0.001\n",
      "policy_decay_lr_rate : 0.75\n",
      "policy_decay_lr_freq : 50\n",
      "policy_decay_lr_cooldown : 0\n",
      "     lambda_sparsity : 0.02\n",
      "      lambda_sharing : 0.01\n",
      "        lambda_tasks : 1\n",
      "         init_method : random\n",
      "           init_temp : 4\n",
      "          decay_temp : 0.965\n",
      "     decay_temp_freq : 16\n",
      "     init_neg_logits : None\n",
      "       hard_sampling : False\n",
      "            val_freq : 500\n",
      "          print_freq : -1\n",
      "warmup_iter_alternate : -1\n",
      "weight_iter_alternate : -1\n",
      "alpha_iter_alternate : -1\n",
      "           val_iters : -1\n",
      "              resume : False\n",
      "      retrain_resume : False\n",
      "         policy_iter : best\n",
      "          which_iter : warmup\n",
      "\n",
      "paths\n",
      "-----\n",
      "             log_dir : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0818_1529_lr0.001_do0.8\n",
      "          result_dir : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0818_1529_lr0.001_do0.8\n",
      "      checkpoint_dir : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0818_1529_lr0.001_do0.8\n",
      "\n",
      "dataload\n",
      "--------\n",
      "             dataset : Chembl29\n",
      "            dataroot : ../../MLDatasets/chembl29_10task\n",
      "                   x : chembl_29_X.npy\n",
      "      x_split_ratios : [0.725, 0.225, 0.05]\n",
      "             folding : chembl_29_folding.npy\n",
      "             y_tasks : ['chembl_29_Y_tg_0_cols_472.npy', 'chembl_29_Y_tg_1_cols_624.npy', 'chembl_29_Y_tg_6_cols_688.npy', 'chembl_29_Y_tg_10_cols_192.npy', 'chembl_29_Y_tg_11_cols_620.npy', 'chembl_29_Y_tg_643_cols_184.npy', 'chembl_29_Y_tg_836_cols_224.npy', 'chembl_29_Y_tg_1005_cols_148.npy', 'chembl_29_Y_tg_1028_cols_344.npy', 'chembl_29_Y_tg_1031_cols_72.npy']\n",
      "            y_censor : None\n",
      "         fold_inputs : 32000\n",
      "     input_transform : None\n",
      "       weights_class : None\n",
      "   min_samples_class : 1\n",
      "           fold_test : [0]\n",
      "             fold_va : [1]\n",
      "         fold_warmup : [2, 3, 4]\n",
      "        fold_weights : [2, 3]\n",
      "         fold_policy : [4]\n",
      "\n",
      "SC\n",
      "--\n",
      "      normalize_loss : None\n",
      "     pytorch_threads : 7\n",
      "            seed_idx : 0\n",
      "         resume_path : None\n",
      "         resume_ckpt : None\n",
      "      resume_metrics : None\n"
     ]
    }
   ],
   "source": [
    "opt = initialize(ns, build_folders = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8e71cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:37.986996Z",
     "start_time": "2022-08-18T13:29:37.950738Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.wandb_run.finish()\n",
    "\n",
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58caea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T07:40:24.684944Z",
     "start_time": "2022-07-04T07:40:24.654093Z"
    }
   },
   "source": [
    "### Setup Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a2edeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:45.013500Z",
     "start_time": "2022-08-18T13:29:37.988657Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Warmup folds    : [2, 3, 4]\n",
      " Weights folds   : [2, 3]\n",
      " Policy folds    : [4]\n",
      " Validation folds: [1]\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      "  Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      "  Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 472  Y rows with populated labels: 21581  non zero cols: 53309\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      "  Task 2 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      "  Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 624  Y rows with populated labels: 22820  non zero cols: 55015\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      "  Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      "  Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 688  Y rows with populated labels: 53858  non zero cols: 186792\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      "  Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n",
      "\n",
      "  Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 192  Y rows with populated labels: 12262  non zero cols: 27798\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n",
      "\n",
      "  Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n",
      "\n",
      "  Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 620  Y rows with populated labels: 30988  non zero cols: 86678\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      "  Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n",
      "\n",
      "  Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 184  Y rows with populated labels: 9818  non zero cols: 27152\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n",
      "\n",
      "  Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n",
      "\n",
      "  Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 224  Y rows with populated labels: 7090  non zero cols: 22638\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      "  Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n",
      "\n",
      "  Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 148  Y rows with populated labels: 13262  non zero cols: 28925\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      "  Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 344  Y rows with populated labels: 20684  non zero cols: 63517\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      "  Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n",
      "\n",
      "  Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 72  Y rows with populated labels: 4475  non zero cols: 10677\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      "  Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      "  Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 472  Y rows with populated labels: 15323  non zero cols: 38126\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      "  Task 2 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      "  Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 624  Y rows with populated labels: 15572  non zero cols: 38310\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      "  Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      "  Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 688  Y rows with populated labels: 34821  non zero cols: 121231\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      "  Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n",
      "\n",
      "  Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 192  Y rows with populated labels: 7752  non zero cols: 17657\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n",
      "\n",
      "  Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n",
      "\n",
      "  Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 620  Y rows with populated labels: 20914  non zero cols: 58596\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      "  Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n",
      "\n",
      "  Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 184  Y rows with populated labels: 7179  non zero cols: 19397\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n",
      "\n",
      "  Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 224  Y rows with populated labels: 4476  non zero cols: 14840\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      "  Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n",
      "\n",
      "  Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 148  Y rows with populated labels: 8900  non zero cols: 19704\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n",
      "\n",
      "  Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      "  Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 344  Y rows with populated labels: 12593  non zero cols: 39248\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      "  Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n",
      "\n",
      "  Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 72  Y rows with populated labels: 2897  non zero cols: 6734\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      "  Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      "  Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 472  Y rows with populated labels: 6258  non zero cols: 15183\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      "  Task 2 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      "  Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 624  Y rows with populated labels: 7248  non zero cols: 16705\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      "  Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      "  Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 688  Y rows with populated labels: 19037  non zero cols: 65561\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      "  Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n",
      "\n",
      "  Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 192  Y rows with populated labels: 4510  non zero cols: 10141\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n",
      "\n",
      "  Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n",
      "\n",
      "  Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 620  Y rows with populated labels: 10074  non zero cols: 28082\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      "  Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n",
      "\n",
      "  Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 184  Y rows with populated labels: 2639  non zero cols: 7755\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n",
      "\n",
      "  Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 224  Y rows with populated labels: 2614  non zero cols: 7798\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      "  Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n",
      "\n",
      "  Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 148  Y rows with populated labels: 4362  non zero cols: 9221\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n",
      "\n",
      "  Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      "  Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 344  Y rows with populated labels: 8091  non zero cols: 24269\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      "  Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n",
      "\n",
      "  Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 72  Y rows with populated labels: 1578  non zero cols: 3943\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      "  Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      "  Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 472  Y rows with populated labels: 5643  non zero cols: 14167\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      "  Task 2 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      "  Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 624  Y rows with populated labels: 8661  non zero cols: 20196\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      "  Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      "  Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 688  Y rows with populated labels: 17973  non zero cols: 61209\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      "  Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n",
      "\n",
      "  Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 192  Y rows with populated labels: 3776  non zero cols: 8372\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n",
      "\n",
      "  Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 620  Y rows with populated labels: 10004  non zero cols: 27223\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      "  Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n",
      "\n",
      "  Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 184  Y rows with populated labels: 2519  non zero cols: 6085\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n",
      "\n",
      "  Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n",
      "\n",
      "  Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 224  Y rows with populated labels: 2379  non zero cols: 7992\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      "  Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n",
      "\n",
      "  Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 148  Y rows with populated labels: 4764  non zero cols: 9313\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n",
      "\n",
      "  Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      "  Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 344  Y rows with populated labels: 7460  non zero cols: 21553\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      "  Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n",
      "\n",
      "  Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 72  Y rows with populated labels: 1916  non zero cols: 4391\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      " dataloader preparation - set number of batches per warmup training epoch to: 1989\n",
      " dataloader preparation - set number of batches per weight training epoch to: 1318\n",
      " dataloader preparation - set number of batches per policy training epoch to: 671\n",
      " dataloader preparation - set number of batches per validation to           : 675\n",
      "\n",
      " trainset.y_class                                   :  [(254529, 472), (254529, 624), (254529, 688), (254529, 192), (254529, 620), (254529, 184), (254529, 224), (254529, 148), (254529, 344), (254529, 72)] \n",
      " trainset1.y_class                                  :  [(168649, 472), (168649, 624), (168649, 688), (168649, 192), (168649, 620), (168649, 184), (168649, 224), (168649, 148), (168649, 344), (168649, 72)] \n",
      " trainset2.y_class                                  :  [(85880, 472), (85880, 624), (85880, 688), (85880, 192), (85880, 620), (85880, 184), (85880, 224), (85880, 148), (85880, 344), (85880, 72)] \n",
      " valset.y_class                                     :  [(86274, 472), (86274, 624), (86274, 688), (86274, 192), (86274, 620), (86274, 184), (86274, 224), (86274, 148), (86274, 344), (86274, 72)]  \n",
      "\n",
      "                                Total                :  595332 \n",
      "\n",
      "\n",
      " Training dataset :\n",
      "--------------------\n",
      "  Size of training set 0 (warm up)                   :  254529 \n",
      "  Number of batches in training 0 (warm up)          :  1989 \n",
      "  Size of training set 1 (network parms)             :  168649 \n",
      "  Number of batches in training 1 (network parms)    :  1318 \n",
      "  Size of training set 2 (policy weights)            :  85880 \n",
      "  Number of batches in training 2 (policy weights)   :  671 \n",
      "  training set num of positive                       :  18631 \n",
      "  training set num of negative                       :  107922 \n",
      "  task_weights_list[0].aggregation_weight sum        :  199.0\n",
      "\n",
      "\n",
      " Validation dataset :\n",
      "----------------------\n",
      "  Rows in dataset                                    : 86274\n",
      "  Number of batches in dataset                       : 675\n",
      "  validation set num of positive                     : 18631\n",
      "  validation set num of negative                     : 107922\n",
      "  task_weights_list[0].aggregation_weight sum        : 199.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dldrs = init_dataloaders(opt, verbose = False)\n",
    "dldrs = init_dataloaders_by_fold_id(opt, verbose = False)\n",
    "disp_dataloader_info(dldrs)\n",
    "# folding  = np.load(os.path.join('/mnt/f/Chembl29', opt['dataload']['folding']))\n",
    "# print(folding.shape)\n",
    "# print(folding.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff214af1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:45.140563Z",
     "start_time": "2022-08-18T13:29:45.017371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[472, 624, 688, 192, 620, 184, 224, 148, 344, 72]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dldrs.valset.class_output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bfa8d",
   "metadata": {},
   "source": [
    "## Setup Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62717fa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:49.062680Z",
     "start_time": "2022-08-18T13:29:45.145842Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      " device is  cuda:0\n",
      "--------------------------------------------------\n",
      " SparseChem_Backbone  Ver: 1.0 Init() Start \n",
      "-------------------------------------------------- \n",
      "\n",
      " layer config        : [1, 1, 1, 1, 1, 1] \n",
      " skip residual layers: False   skip hidden layers  : False\n",
      " SparseChem_BackBone() Input Layer  - Input: 32000  output: 4000  non-linearity:<class 'torch.nn.modules.activation.ReLU'>\n",
      " Hidden layer 0 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.8 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.8 bias: True\n",
      " Hidden layer 1 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.8 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.8 bias: True\n",
      " Hidden layer 2 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.8 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.8 bias: True\n",
      " Hidden layer 3 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.8 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.8 bias: True\n",
      " Hidden layer 4 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.8 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.8 bias: True\n",
      " Final Hidden layer 4 : Input size: 4000   output size:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.8 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.8 bias: True\n",
      " Module List \n",
      "--------------------------------------------------\n",
      " Initialize weights \n",
      "-------------------------------------------------- \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " SparseChem Backbone -- Final configuration(2) : \n",
      "                     self.blocks: <class 'torch.nn.modules.container.ModuleList'>  len:6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "\n",
      "  Input_Layer  type:<class 'torch.nn.modules.container.Sequential'>  \n",
      "----------------------------------------------------------------------\n",
      "self.Input_layer\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Layers/Blocks    : <class 'torch.nn.modules.container.ModuleList'>   len:6 \n",
      "Resdiual layers  : <class 'torch.nn.modules.container.ModuleList'>   len:6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 1  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 1  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 2  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 2  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 3  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 3  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 4  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 4  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 5  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 5  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 6  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 6  type:<class 'NoneType'> \n",
      " None\n",
      "\n",
      "\n",
      "\n",
      " SparseChem_Backbone Init() End \n",
      "policies : [None, None, None, None, None, None, None, None, None, None]\n",
      "----------------------------------------------------\n",
      "* SparseChemEnv environment successfully created\n",
      "---------------------------------------------------- \n",
      "\n",
      " \n",
      "\n",
      "SparseChemEnv  Configuration       \n",
      "---------------------------------------- \n",
      "\n",
      "----------------\n",
      "networks       :\n",
      "----------------\n",
      " {'mtl-net': MTL3(\n",
      "  (backbone): SparseChem_Backbone(\n",
      "    (Input_Layer): Sequential(\n",
      "      (linear): SparseLinear(in_features=32000, out_features=4000, bias=True)\n",
      "      (non_linear): ReLU()\n",
      "      (dropout): Dropout(p=0.8, inplace=False)\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.8, inplace=False)\n",
      "      )\n",
      "      (1): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.8, inplace=False)\n",
      "      )\n",
      "      (2): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.8, inplace=False)\n",
      "      )\n",
      "      (3): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.8, inplace=False)\n",
      "      )\n",
      "      (4): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.8, inplace=False)\n",
      "      )\n",
      "      (5): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.8, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (residuals): ModuleList(\n",
      "      (0): None\n",
      "      (1): None\n",
      "      (2): None\n",
      "      (3): None\n",
      "      (4): None\n",
      "      (5): None\n",
      "    )\n",
      "  )\n",
      "  (task1_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=472, bias=True)\n",
      "  )\n",
      "  (task2_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=624, bias=True)\n",
      "  )\n",
      "  (task3_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=688, bias=True)\n",
      "  )\n",
      "  (task4_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=192, bias=True)\n",
      "  )\n",
      "  (task5_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=620, bias=True)\n",
      "  )\n",
      "  (task6_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=184, bias=True)\n",
      "  )\n",
      "  (task7_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=224, bias=True)\n",
      "  )\n",
      "  (task8_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=148, bias=True)\n",
      "  )\n",
      "  (task9_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=344, bias=True)\n",
      "  )\n",
      "  (task10_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=72, bias=True)\n",
      "  )\n",
      ")}\n",
      "\n",
      "----------------\n",
      "optimizers     :\n",
      "----------------\n",
      " {}\n",
      "\n",
      "----------------\n",
      "schedulers     :\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "environ = init_environment(ns, opt, is_train = True, display_cfg = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb86f4aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:49.098097Z",
     "start_time": "2022-08-18T13:29:49.064912Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.optimizers['weights'].param_groups[0]\n",
    "# print(environ.print_configuration())\n",
    "# print(environ.networks['mtl-net']._arch_parameters)\n",
    "# pp.pprint(environ.networks['mtl-net'].__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d738062",
   "metadata": {},
   "source": [
    "## Initiate / Resume Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba16a95c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:49.160195Z",
     "start_time": "2022-08-18T13:29:49.100155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt['train']['which_iter'] :  warmup\n",
      "##################################################\n",
      "######## Initiate Training from scratch  #########\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "check_for_resume_training(ns, opt, environ, epoch = 0 , iter = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "964c4940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:49.191610Z",
     "start_time": "2022-08-18T13:29:49.162446Z"
    }
   },
   "outputs": [],
   "source": [
    "# loaded_metrics\n",
    "# ns.val_metrics\n",
    "# ns.best_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73116275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:49.250839Z",
     "start_time": "2022-08-18T13:29:49.193560Z"
    }
   },
   "outputs": [],
   "source": [
    "# a = environ.load_checkpoint('warmup_ep_40_seed_0088', path = '../experiments/AdaSparseChem/50x6_0304_1549_plr0.01_sp0.0001_sh0.01/')\n",
    "# current_iter = environ.load_checkpoint('latest_weights_policy')\n",
    "# priRant('Evaluating the snapshot saved at %d iter' % current_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278d6d1",
   "metadata": {},
   "source": [
    "## Warmup Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa99797",
   "metadata": {},
   "source": [
    "### Warmup Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e7ce6a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:49.285104Z",
     "start_time": "2022-08-18T13:29:49.253159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model optimizers defined . . . policy_learning: False\n",
      " Model schedulers defined . . . policy_learning: False\n",
      " Metrics CSV file header written . . . \n",
      " Model initializations complete . . . \n"
     ]
    }
   ],
   "source": [
    "model_initializations(ns, opt, environ, phase = 'update_weights', policy_learning = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac570e85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:49.313859Z",
     "start_time": "2022-08-18T13:29:49.286857Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(hasattr(environ, 'policy%d' % (1)))\n",
    "# print(getattr(environ, \"policy1\"))\n",
    "# print(environ.networks['mtl-net'].policys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33100539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:49.605773Z",
     "start_time": "2022-08-18T13:29:49.315732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training preparation: - check for CUDA - cuda available as device id: [0]\n",
      "sparsechem_env.cuda()\n",
      " training preparation: - set print_freq to                                 : 1989 \n",
      " training preparation: - set number of batches per warmup training epoch to: 1989\n",
      " training preparation: - set number of batches per weight training epoch to: 1318\n",
      " training preparation: - set number of batches per policy training epoch to: 671\n",
      " training preparation: - set number of batches per validation to           : 675\n",
      " training preparation complete . . .\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    folder: 4000x6_0818_1529_lr0.001_do0.8\n",
      "    layers: 6 [4000, 4000, 4000, 4000, 4000, 4000] \n",
      "    \n",
      "    first dropout          : 0.8\n",
      "    middle dropout         : 0.8\n",
      "    last dropout           : 0.8\n",
      "    diff_sparsity_weights  : False\n",
      "    skip_layer             : 0\n",
      "    is_curriculum          : False\n",
      "    curriculum_speed       : 3\n",
      "    \n",
      "    task_lr                : 0.001\n",
      "    backbone_lr            : 0.001\n",
      "    decay_lr_rate          : 0.3\n",
      "    decay_lr_freq          : 10.0\n",
      "    \n",
      "    policy_lr              : 0.001\n",
      "    policy_decay_lr_rate   : 0.75\n",
      "    policy_decay_lr_freq   : 50\n",
      "    lambda_sparsity        : 0.02\n",
      "    lambda_sharing         : 0.01\n",
      "    lambda_tasks           : 1\n",
      "    \n",
      "    Gumbel init_temp       : 4\n",
      "    Gumbel decay_temp      : 0.965\n",
      "    Gumbel decay_temp_freq : 16\n",
      "    Logit init_method      : random\n",
      "    Logit init_neg_logits  : None\n",
      "    Logit hard_sampling    : False\n",
      "    Warm-up epochs         : 10\n",
      "    training epochs        : 250\n",
      "    Data split ratios      : [0.725, 0.225, 0.05]\n",
      "\n",
      "\n",
      " ep:    0    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.5003    0.4997  1    0.5001    0.4999  1    0.4996    0.5004  0    0.5005    0.4995  1    0.5003    0.4997  1    0.5002    0.4998  1    0.5000    0.5000  1    0.4997    0.5003  0    0.5002    0.4998  1    0.5003    0.4997  1\n",
      "  1    0.5002    0.4998  1    0.4999    0.5001  0    0.4997    0.5003  0    0.4997    0.5003  0    0.5002    0.4998  1    0.5000    0.5000  1    0.5001    0.4999  1    0.4994    0.5006  0    0.5001    0.4999  1    0.4996    0.5004  0\n",
      "  2    0.4997    0.5003  0    0.4998    0.5002  0    0.5006    0.4994  1    0.5000    0.5000  1    0.5001    0.4999  1    0.5002    0.4998  1    0.4997    0.5003  0    0.5000    0.5000  0    0.5002    0.4998  1    0.4996    0.5004  0\n",
      "  3    0.4996    0.5004  0    0.5000    0.5000  0    0.5003    0.4997  1    0.4996    0.5004  0    0.5002    0.4998  1    0.5002    0.4998  1    0.4999    0.5001  0    0.5008    0.4992  1    0.4998    0.5002  0    0.5001    0.4999  1\n",
      "  4    0.4994    0.5006  0    0.5001    0.4999  1    0.5003    0.4997  1    0.4994    0.5006  0    0.5001    0.4999  1    0.4999    0.5001  0    0.4995    0.5005  0    0.4995    0.5005  0    0.5008    0.4992  1    0.4999    0.5001  0\n",
      "  5    0.5003    0.4997  1    0.4996    0.5004  0    0.5005    0.4995  1    0.5001    0.4999  1    0.5001    0.4999  1    0.5001    0.4999  1    0.5001    0.4999  1    0.4997    0.5003  0    0.5003    0.4997  1    0.4997    0.5003  0\n",
      "\n",
      "\n",
      " ep:    0   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.0008   -0.0005  1    0.0013    0.0009  1   -0.0001    0.0017  0    0.0017   -0.0002  1    0.0005   -0.0006  1    0.0003   -0.0005  1    0.0010    0.0008  1   -0.0007    0.0006  0    0.0002   -0.0007  1   -0.0003   -0.0013  1\n",
      "  1    0.0004   -0.0003  1   -0.0003    0.0003  0   -0.0009    0.0003  0   -0.0003    0.0010  0    0.0009    0.0000  1   -0.0004   -0.0005  1    0.0012    0.0008  1   -0.0003    0.0020  0    0.0006    0.0001  1   -0.0008    0.0009  0\n",
      "  2    0.0008    0.0018  0   -0.0011   -0.0003  0    0.0016   -0.0010  1   -0.0006   -0.0006  1    0.0016    0.0012  1   -0.0001   -0.0008  1   -0.0016   -0.0004  0   -0.0009   -0.0008  0    0.0006   -0.0002  1   -0.0011    0.0007  0\n",
      "  3   -0.0002    0.0012  0   -0.0003   -0.0002  0    0.0008   -0.0003  1   -0.0006    0.0009  0    0.0011    0.0002  1   -0.0008   -0.0014  1   -0.0004   -0.0001  0    0.0009   -0.0021  1   -0.0006    0.0000  0    0.0001   -0.0002  1\n",
      "  4   -0.0013    0.0009  0    0.0003   -0.0003  1    0.0020    0.0008  1   -0.0016    0.0009  0    0.0006    0.0003  1   -0.0002    0.0004  0   -0.0010    0.0009  0   -0.0015    0.0003  0    0.0011   -0.0021  1   -0.0013   -0.0008  0\n",
      "  5   -0.0001   -0.0014  1   -0.0003    0.0013  0    0.0008   -0.0012  1    0.0001   -0.0004  1   -0.0005   -0.0010  1    0.0007    0.0004  1    0.0000   -0.0005  1   -0.0009    0.0001  0    0.0006   -0.0006  1   -0.0011    0.0001  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training_initializations(ns, opt, environ, dldrs, warmup_iterations = 200, weight_iterations = 200, policy_iterations = 200, eval_iterations = 50, warmup = True)\n",
    "training_initializations(ns, opt, environ, dldrs, warmup = True)\n",
    "# print('-'*80)\n",
    "# disp_info_1(ns, opt, environ)\n",
    "print('-'*80)\n",
    "print(environ.disp_for_excel())\n",
    "\n",
    "environ.display_trained_policy(ns.current_epoch,out=sys.stdout)\n",
    "environ.display_trained_logits(ns.current_epoch,out=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73de409d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:29:49.637854Z",
     "start_time": "2022-08-18T13:29:49.607734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675\n",
      "1989\n",
      "1318\n",
      "671\n",
      "------------------------------------------------------------------------\n",
      " Last Epoch: 0   # of warm-up epochs to do:  10 - Run epochs 1 to 10\n",
      "------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ns.eval_iters )\n",
    "print(ns.trn_iters_warmup)\n",
    "print(ns.trn_iters_weights)\n",
    "print(ns.trn_iters_policy)\n",
    "\n",
    "# ns.check_for_improvment_wait = 0\n",
    "# ns.current_epoch =0 \n",
    "# ns.write_checkpoint = False\n",
    "print_heading(f\" Last Epoch: {ns.current_epoch}   # of warm-up epochs to do:  {ns.warmup_epochs} - Run epochs {ns.current_epoch+1} to {ns.current_epoch + ns.warmup_epochs}\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bd29e74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T14:40:52.376725Z",
     "start_time": "2022-08-18T13:52:38.789346Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      " Last Epoch: 3   # of warm-up epochs to do:  7 - Run epochs 4 to 10\n",
      "----------------------------------------------------------------------- \n",
      "\n",
      " Ep  | Trunk LR  Heads LR  Polcy LR  Gmbl Tmp |  trn tsk    trn spar    trn shar   trn ttl |   logloss   bceloss  avg prec    aucroc     aucpr    f1_max |  val tsk    val spar    val shar     total | time |\n",
      "   4 | 1.00e-03  1.00e-03  1.00e-03  4.00e+00 |   2.5792   2.133e-03   4.256e-05    2.5814 |   0.00000   0.49965   0.62771   0.71521   0.61453   0.67172 |   2.4291   1.184e-03   2.363e-05    2.4303 |389.0 |\n",
      "Previous best_epoch:     3   best iter:  5967   best_accuracy: 0.62762    best ROC auc: 0.71362\n",
      "Previous best_epoch:     4   best iter:  7956   best_accuracy: 0.62771    best ROC auc: 0.71521\n",
      " save best metrics to     :  metrics_best.pickle\n",
      " save  best checkpoint to :  model_best\n",
      "   5 | 1.00e-03  1.00e-03  1.00e-03  4.00e+00 |   2.8063   2.133e-03   4.256e-05    2.8085 |   0.00000   0.49510   0.63099   0.71711   0.61855   0.67446 |   2.3816   1.184e-03   2.363e-05    2.3828 |390.1 |\n",
      "Previous best_epoch:     4   best iter:  7956   best_accuracy: 0.62771    best ROC auc: 0.71521\n",
      "Previous best_epoch:     5   best iter:  9945   best_accuracy: 0.63099    best ROC auc: 0.71711\n",
      " save best metrics to     :  metrics_best.pickle\n",
      " save  best checkpoint to :  model_best\n",
      "   6 | 1.00e-03  1.00e-03  1.00e-03  4.00e+00 |   2.1338   2.133e-03   4.256e-05    2.1360 |   0.00000   0.49068   0.63405   0.72026   0.62179   0.67456 |   2.3145   1.184e-03   2.363e-05    2.3158 |389.1 |\n",
      "Previous best_epoch:     5   best iter:  9945   best_accuracy: 0.63099    best ROC auc: 0.71711\n",
      "Previous best_epoch:     6   best iter: 11934   best_accuracy: 0.63405    best ROC auc: 0.72026\n",
      " save best metrics to     :  metrics_best.pickle\n",
      " save  best checkpoint to :  model_best\n",
      "   7 | 1.00e-03  1.00e-03  1.00e-03  4.00e+00 |   2.0891   2.133e-03   4.256e-05    2.0912 |   0.00000   0.49006   0.63618   0.72587   0.62366   0.67504 |   2.2904   1.184e-03   2.363e-05    2.2916 |390.7 |\n",
      "Previous best_epoch:     6   best iter: 11934   best_accuracy: 0.63405    best ROC auc: 0.72026\n",
      "Previous best_epoch:     7   best iter: 13923   best_accuracy: 0.63618    best ROC auc: 0.72587\n",
      " save best metrics to     :  metrics_best.pickle\n",
      " save  best checkpoint to :  model_best\n",
      "   8 | 1.00e-03  1.00e-03  1.00e-03  4.00e+00 |   1.7854   2.133e-03   4.256e-05    1.7876 |   0.00000   0.48683   0.63135   0.72188   0.61814   0.67385 |   2.2845   1.184e-03   2.363e-05    2.2857 |393.4 |\n",
      "   9 | 1.00e-03  1.00e-03  1.00e-03  4.00e+00 |   2.6616   2.133e-03   4.256e-05    2.6637 |   0.00000   0.48292   0.63795   0.72560   0.62531   0.68023 |   2.2681   1.184e-03   2.363e-05    2.2693 |386.9 |\n",
      "  10 | 1.00e-03  1.00e-03  1.00e-03  4.00e+00 |   2.0416   2.133e-03   4.256e-05    2.0437 |   0.00000   0.48419   0.63667   0.72628   0.62380   0.67717 |   2.2617   1.184e-03   2.363e-05    2.2629 |392.3 |\n",
      "Previous best_epoch:     7   best iter: 13923   best_accuracy: 0.63618    best ROC auc: 0.72587\n",
      "Previous best_epoch:    10   best iter: 19890   best_accuracy: 0.63667    best ROC auc: 0.72628\n",
      " save best metrics to     :  metrics_best.pickle\n",
      " save  best checkpoint to :  model_best\n",
      " save warmup checkpoint  to :  model_warmup_last_ep_10\n",
      " save warmup metrics to     :  metrics_warmup_last_ep_10.pickle\n",
      "[Final] ep:10  it:19890 -  Total Loss: 2.2629     \n",
      "Task: 2.2617   Sparsity: 1.18412e-03    Sharing: 2.36274e-05 \n",
      "\n",
      " ep:   10    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.5003    0.4997  1    0.5001    0.4999  1    0.4996    0.5004  0    0.5005    0.4995  1    0.5003    0.4997  1    0.5002    0.4998  1    0.5000    0.5000  1    0.4997    0.5003  0    0.5002    0.4998  1    0.5003    0.4997  1\n",
      "  1    0.5002    0.4998  1    0.4999    0.5001  0    0.4997    0.5003  0    0.4997    0.5003  0    0.5002    0.4998  1    0.5000    0.5000  1    0.5001    0.4999  1    0.4994    0.5006  0    0.5001    0.4999  1    0.4996    0.5004  0\n",
      "  2    0.4997    0.5003  0    0.4998    0.5002  0    0.5006    0.4994  1    0.5000    0.5000  1    0.5001    0.4999  1    0.5002    0.4998  1    0.4997    0.5003  0    0.5000    0.5000  0    0.5002    0.4998  1    0.4996    0.5004  0\n",
      "  3    0.4996    0.5004  0    0.5000    0.5000  0    0.5003    0.4997  1    0.4996    0.5004  0    0.5002    0.4998  1    0.5002    0.4998  1    0.4999    0.5001  0    0.5008    0.4992  1    0.4998    0.5002  0    0.5001    0.4999  1\n",
      "  4    0.4994    0.5006  0    0.5001    0.4999  1    0.5003    0.4997  1    0.4994    0.5006  0    0.5001    0.4999  1    0.4999    0.5001  0    0.4995    0.5005  0    0.4995    0.5005  0    0.5008    0.4992  1    0.4999    0.5001  0\n",
      "  5    0.5003    0.4997  1    0.4996    0.5004  0    0.5005    0.4995  1    0.5001    0.4999  1    0.5001    0.4999  1    0.5001    0.4999  1    0.5001    0.4999  1    0.4997    0.5003  0    0.5003    0.4997  1    0.4997    0.5003  0\n",
      "\n",
      "\n",
      " ep:   10   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.0008   -0.0005  1    0.0013    0.0009  1   -0.0001    0.0017  0    0.0017   -0.0002  1    0.0005   -0.0006  1    0.0003   -0.0005  1    0.0010    0.0008  1   -0.0007    0.0006  0    0.0002   -0.0007  1   -0.0003   -0.0013  1\n",
      "  1    0.0004   -0.0003  1   -0.0003    0.0003  0   -0.0009    0.0003  0   -0.0003    0.0010  0    0.0009    0.0000  1   -0.0004   -0.0005  1    0.0012    0.0008  1   -0.0003    0.0020  0    0.0006    0.0001  1   -0.0008    0.0009  0\n",
      "  2    0.0008    0.0018  0   -0.0011   -0.0003  0    0.0016   -0.0010  1   -0.0006   -0.0006  1    0.0016    0.0012  1   -0.0001   -0.0008  1   -0.0016   -0.0004  0   -0.0009   -0.0008  0    0.0006   -0.0002  1   -0.0011    0.0007  0\n",
      "  3   -0.0002    0.0012  0   -0.0003   -0.0002  0    0.0008   -0.0003  1   -0.0006    0.0009  0    0.0011    0.0002  1   -0.0008   -0.0014  1   -0.0004   -0.0001  0    0.0009   -0.0021  1   -0.0006    0.0000  0    0.0001   -0.0002  1\n",
      "  4   -0.0013    0.0009  0    0.0003   -0.0003  1    0.0020    0.0008  1   -0.0016    0.0009  0    0.0006    0.0003  1   -0.0002    0.0004  0   -0.0010    0.0009  0   -0.0015    0.0003  0    0.0011   -0.0021  1   -0.0013   -0.0008  0\n",
      "  5   -0.0001   -0.0014  1   -0.0003    0.0013  0    0.0008   -0.0012  1    0.0001   -0.0004  1   -0.0005   -0.0010  1    0.0007    0.0004  1    0.0000   -0.0005  1   -0.0009    0.0001  0    0.0006   -0.0006  1   -0.0011    0.0001  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warmup_phase(ns,opt, environ, dldrs, epochs = 7, verbose = False, disable_tqdm = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1c6e1c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T17:12:51.201081Z",
     "start_time": "2022-08-18T17:12:51.096517Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'policy': 0.0012077480350853875,\n",
      "    'task': 2.261661641804446,\n",
      "    'total': 2.2628693898395316,\n",
      "    'total_mean': nan}\n",
      "2.2628693898395316\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(environ.val_metrics['total'])\n",
    "print(environ.val_metrics['total']['task'] + environ.val_metrics['total']['policy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a485e604",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:03:47.730338Z",
     "start_time": "2022-08-18T13:03:47.680615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone Initial LR            :      0.001000      Current LR : 0.001 \n",
      " Tasks    Initial LR            :      0.001000      Current LR : 0.001    \n",
      " Policy   Initial LR            :      0.001000      Current LR : 0.001  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone Initial LR            :      {environ.opt['train']['backbone_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[0]['lr']} \\n\"\n",
    "       f\" Tasks    Initial LR            :      {environ.opt['train']['task_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[1]['lr']}    \\n\"\n",
    "       f\" Policy   Initial LR            :      {environ.opt['train']['policy_lr']:4f}      Current LR : {environ.optimizers['alphas'].param_groups[0]['lr']}  \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "952bb1e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:03:40.219139Z",
     "start_time": "2022-08-18T12:03:40.185713Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.wandb_run.finish()\n",
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c03a5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Aggregate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "146a7fde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T16:43:04.282818Z",
     "start_time": "2022-08-16T16:43:04.246814Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011841206578537822\n",
      "2.362737723160535e-05\n",
      "0.0012077480350853875\n",
      "{   'task1': 0.22806914488911734,\n",
      "    'task10': 0.07729441115807154,\n",
      "    'task2': 0.2615806116049444,\n",
      "    'task3': 0.6873060537261522,\n",
      "    'task4': 0.1177855923062318,\n",
      "    'task5': 0.352459824837004,\n",
      "    'task6': 0.08289676805336933,\n",
      "    'task7': 0.1123096017483592,\n",
      "    'task8': 0.17276770787165321,\n",
      "    'task9': 0.2891627654132546,\n",
      "    'total': 2.381632481608156}\n",
      "{   'policy': 0.0012077480350853875,\n",
      "    'task': 2.381632481608156,\n",
      "    'total': 2.3828402296432416,\n",
      "    'total_mean': nan}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(environ.val_metrics['sparsity']['total'])\n",
    "pp.pprint(environ.val_metrics['sharing']['total'])\n",
    "pp.pprint(environ.val_metrics['sharing']['total'] +environ.val_metrics['sparsity']['total'])\n",
    "pp.pprint(environ.val_metrics['task'])\n",
    "pp.pprint(environ.val_metrics['total'])\n",
    "pp.pprint(environ.val_metrics['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ffbb96d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T07:56:30.866019Z",
     "start_time": "2022-08-16T07:56:30.793987Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258.0\n",
      "[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "1          0.637037  0.778888        0.793752  0.789474  0.705071  0.000000   0.363636     0.752714  0.670283\n",
      "2          0.333333  0.381494        0.431970  0.685714  0.284085  0.000000   0.083333     0.284085  0.767408\n",
      "3          0.380952  0.093922        0.132289  0.240000  0.011812  0.000000   0.030303     0.030620  0.519829\n",
      "4          0.895785  0.940747        0.941210  0.911290  0.772889  0.473859   0.707979     0.772889  0.391612\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "619             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "620        0.826667  0.939015        0.940316  0.869565  0.742233  0.119171   0.603113     0.742233  0.439226\n",
      "621        0.913043  0.831354        0.841654  0.800000  0.472201  0.615094   0.686347     0.472201  0.456259\n",
      "622        0.763441  0.152862        0.239057  0.428571  0.045218  0.000000   0.336585     0.045218  0.305232\n",
      "623             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[624 rows x 9 columns]\n",
      "{'roc_auc_score': 0.7264691601690758, 'auc_pr': 0.63870543071269, 'avg_prec_score': 0.651959703396813, 'f1_max': 0.6954697552654789, 'p_f1_max': 0.368966169476639, 'kappa': 0.18080473130459035, 'kappa_max': 0.4420930648311257, 'p_kappa_max': 0.4361852161052038, 'bceloss': 0.5201728982316662, 'sc_loss': 0.00038752683200732503, 'logloss': 3.983986895807737e-06}\n",
      " wsum: 258.0   df.shape: (624, 9)   df2: (624, 9)  df2.sum(axis=0): \n",
      " roc_auc_score     258.0\n",
      "auc_pr            258.0\n",
      "avg_prec_score    258.0\n",
      "f1_max            258.0\n",
      "p_f1_max          258.0\n",
      "kappa             258.0\n",
      "kappa_max         258.0\n",
      "p_kappa_max       258.0\n",
      "bceloss           258.0\n",
      "dtype: float64\n",
      "\n",
      "  DIVISOR \n",
      "-----------\n",
      "roc_auc_score     0.003876\n",
      "auc_pr            0.003876\n",
      "avg_prec_score    0.003876\n",
      "f1_max            0.003876\n",
      "p_f1_max          0.003876\n",
      "kappa             0.003876\n",
      "kappa_max         0.003876\n",
      "p_kappa_max       0.003876\n",
      "bceloss           0.003876\n",
      "dtype: float64\n",
      "\n",
      "  DF \n",
      "------\n",
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "1          0.637037  0.778888        0.793752  0.789474  0.705071  0.000000   0.363636     0.752714  0.670283\n",
      "2          0.333333  0.381494        0.431970  0.685714  0.284085  0.000000   0.083333     0.284085  0.767408\n",
      "3          0.380952  0.093922        0.132289  0.240000  0.011812  0.000000   0.030303     0.030620  0.519829\n",
      "4          0.895785  0.940747        0.941210  0.911290  0.772889  0.473859   0.707979     0.772889  0.391612\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "619             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "620        0.826667  0.939015        0.940316  0.869565  0.742233  0.119171   0.603113     0.742233  0.439226\n",
      "621        0.913043  0.831354        0.841654  0.800000  0.472201  0.615094   0.686347     0.472201  0.456259\n",
      "622        0.763441  0.152862        0.239057  0.428571  0.045218  0.000000   0.336585     0.045218  0.305232\n",
      "623             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[624 rows x 9 columns]\n",
      "\n",
      "  DF2 \n",
      "-------\n",
      "      roc_auc_score  auc_pr  avg_prec_score  f1_max  p_f1_max  kappa  kappa_max  p_kappa_max  bceloss\n",
      "task                                                                                                 \n",
      "0               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "1               0.0     0.0             0.0     0.0       0.0    0.0        0.0          0.0      0.0\n",
      "2               0.0     0.0             0.0     0.0       0.0    0.0        0.0          0.0      0.0\n",
      "3               0.0     0.0             0.0     0.0       0.0    0.0        0.0          0.0      0.0\n",
      "4               1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "...             ...     ...             ...     ...       ...    ...        ...          ...      ...\n",
      "619             NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "620             1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "621             1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "622             0.0     0.0             0.0     0.0       0.0    0.0        0.0          0.0      0.0\n",
      "623             NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "\n",
      "[624 rows x 9 columns]\n",
      "\n",
      "  RESULT \n",
      "----------\n",
      "roc_auc_score     0.726469\n",
      "auc_pr            0.638705\n",
      "avg_prec_score    0.651960\n",
      "f1_max            0.695470\n",
      "p_f1_max          0.368966\n",
      "kappa             0.180805\n",
      "kappa_max         0.442093\n",
      "p_kappa_max       0.436185\n",
      "bceloss           0.520173\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from utils             import censored_mse_loss, censored_mae_loss, aggregate_results\n",
    "task_key = 'task2'\n",
    "print(environ.val_data[task_key]['yc_aggr_weights'].sum())\n",
    "print(environ.val_data[task_key]['yc_aggr_weights'])\n",
    "print(environ.val_metrics[task_key]['classification'])\n",
    "# print(environ.val_metrics[task_key]['classification'].sum())\n",
    "print(environ.val_metrics[task_key]['classification_agg'])\n",
    "# print(environ.val_data[task_key]['yc_aggr_weights'])\n",
    "# print((environ.batch_data[task_key]['yc_aggr_weights']==environ.val_data[task_key]['yc_aggr_weights']).all())\n",
    "\n",
    "\n",
    "tmp = aggregate_results(environ.val_metrics[task_key][\"classification\"], \n",
    "                      environ.val_data[task_key]['yc_aggr_weights'],\n",
    "                      verbose = True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ed7b40c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T07:17:18.629009Z",
     "start_time": "2022-08-16T07:17:18.396695Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'con' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_942638/1987916288.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# del all_tgs, all_tgs2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcon2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'con' is not defined"
     ]
    }
   ],
   "source": [
    "# del all_tgs, all_tgs2\n",
    "del con,con2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d52214fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T07:20:29.718039Z",
     "start_time": "2022-08-16T07:20:29.611094Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 task1  shape:  (472,) classifiaction: (472, 9)\n",
      "roc_auc_score     293.0\n",
      "auc_pr            293.0\n",
      "avg_prec_score    293.0\n",
      "f1_max            293.0\n",
      "p_f1_max          293.0\n",
      "kappa             293.0\n",
      "kappa_max         293.0\n",
      "p_kappa_max       293.0\n",
      "bceloss           293.0\n",
      "dtype: float64\n",
      "initialize (472,) (472, 9)\n",
      "2 task2  shape:  (624,) classifiaction: (624, 9)\n",
      "roc_auc_score     386.0\n",
      "auc_pr            386.0\n",
      "avg_prec_score    386.0\n",
      "f1_max            386.0\n",
      "p_f1_max          386.0\n",
      "kappa             386.0\n",
      "kappa_max         386.0\n",
      "p_kappa_max       386.0\n",
      "bceloss           386.0\n",
      "dtype: float64\n",
      "concatenate:  task2      (1096,) (1096, 9)\n",
      "3 task3  shape:  (688,) classifiaction: (688, 9)\n",
      "roc_auc_score     610.0\n",
      "auc_pr            610.0\n",
      "avg_prec_score    610.0\n",
      "f1_max            610.0\n",
      "p_f1_max          610.0\n",
      "kappa             610.0\n",
      "kappa_max         610.0\n",
      "p_kappa_max       610.0\n",
      "bceloss           610.0\n",
      "dtype: float64\n",
      "concatenate:  task3      (1784,) (1784, 9)\n",
      "4 task4  shape:  (192,) classifiaction: (192, 9)\n",
      "roc_auc_score     143.0\n",
      "auc_pr            143.0\n",
      "avg_prec_score    143.0\n",
      "f1_max            143.0\n",
      "p_f1_max          143.0\n",
      "kappa             143.0\n",
      "kappa_max         143.0\n",
      "p_kappa_max       143.0\n",
      "bceloss           143.0\n",
      "dtype: float64\n",
      "concatenate:  task4      (1976,) (1976, 9)\n",
      "5 task5  shape:  (620,) classifiaction: (620, 9)\n",
      "roc_auc_score     513.0\n",
      "auc_pr            513.0\n",
      "avg_prec_score    513.0\n",
      "f1_max            513.0\n",
      "p_f1_max          513.0\n",
      "kappa             513.0\n",
      "kappa_max         513.0\n",
      "p_kappa_max       513.0\n",
      "bceloss           513.0\n",
      "dtype: float64\n",
      "concatenate:  task5      (2596,) (2596, 9)\n",
      "6 task6  shape:  (184,) classifiaction: (184, 9)\n",
      "roc_auc_score     129.0\n",
      "auc_pr            129.0\n",
      "avg_prec_score    129.0\n",
      "f1_max            129.0\n",
      "p_f1_max          129.0\n",
      "kappa             129.0\n",
      "kappa_max         129.0\n",
      "p_kappa_max       129.0\n",
      "bceloss           129.0\n",
      "dtype: float64\n",
      "concatenate:  task6      (2780,) (2780, 9)\n",
      "7 task7  shape:  (224,) classifiaction: (224, 9)\n",
      "roc_auc_score     147.0\n",
      "auc_pr            147.0\n",
      "avg_prec_score    147.0\n",
      "f1_max            147.0\n",
      "p_f1_max          147.0\n",
      "kappa             147.0\n",
      "kappa_max         147.0\n",
      "p_kappa_max       147.0\n",
      "bceloss           147.0\n",
      "dtype: float64\n",
      "concatenate:  task7      (3004,) (3004, 9)\n",
      "8 task8  shape:  (148,) classifiaction: (148, 9)\n",
      "roc_auc_score     109.0\n",
      "auc_pr            109.0\n",
      "avg_prec_score    109.0\n",
      "f1_max            109.0\n",
      "p_f1_max          109.0\n",
      "kappa             109.0\n",
      "kappa_max         109.0\n",
      "p_kappa_max       109.0\n",
      "bceloss           109.0\n",
      "dtype: float64\n",
      "concatenate:  task8      (3152,) (3152, 9)\n",
      "9 task9  shape:  (344,) classifiaction: (344, 9)\n",
      "roc_auc_score     267.0\n",
      "auc_pr            267.0\n",
      "avg_prec_score    267.0\n",
      "f1_max            267.0\n",
      "p_f1_max          267.0\n",
      "kappa             267.0\n",
      "kappa_max         267.0\n",
      "p_kappa_max       267.0\n",
      "bceloss           267.0\n",
      "dtype: float64\n",
      "concatenate:  task9      (3496,) (3496, 9)\n",
      "10 task10  shape:  (72,) classifiaction: (72, 9)\n",
      "roc_auc_score     64.0\n",
      "auc_pr            64.0\n",
      "avg_prec_score    64.0\n",
      "f1_max            64.0\n",
      "p_f1_max          64.0\n",
      "kappa             64.0\n",
      "kappa_max         64.0\n",
      "p_kappa_max       64.0\n",
      "bceloss           64.0\n",
      "dtype: float64\n",
      "concatenate:  task10      (3568,) (3568, 9)\n",
      "ttl :  3568 con.shape: (3568,) all_tgs.shape (3568, 9)\n"
     ]
    }
   ],
   "source": [
    "# del con\n",
    "ttl = 0\n",
    "\n",
    "# con = np.ndarray()\n",
    "appd_df = []\n",
    "for i in range(1,11):\n",
    "    task_key = f\"task{i}\"\n",
    "    print(i, task_key, ' shape: ', environ.val_data[task_key]['yc_aggr_weights'].shape,  'classifiaction:', environ.val_metrics[task_key]['classification'].shape)\n",
    "    tmp_df = environ.val_metrics[task_key]['classification'].where(pd.isnull,1)\n",
    "    print(tmp_df.sum(axis=0))\n",
    "    \n",
    "    if i == 1:\n",
    "        con = np.copy(environ.val_data[task_key]['yc_aggr_weights'])\n",
    "        all_tgs = environ.val_metrics[task_key]['classification'].copy()\n",
    "        print(\"initialize\", con.shape, all_tgs.shape)\n",
    "    else:\n",
    "        con = np.hstack((con, environ.val_data[task_key]['yc_aggr_weights']))\n",
    "        all_tgs = all_tgs.append(environ.val_metrics[task_key]['classification'])\n",
    "        print(\"concatenate: \",task_key, \"    \", con.shape, all_tgs.shape)\n",
    "        \n",
    "    ttl += environ.val_data[task_key]['yc_aggr_weights'].shape[0]\n",
    "    \n",
    "print('ttl : ', ttl,  'con.shape:', con.shape, 'all_tgs.shape', all_tgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22870bf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-16T07:17:56.700Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_tgs2 = pd.concat(environ.val_metrics[f\"task{i}\"]['classification'] for i in range(1,11))\n",
    "\n",
    "all_tgs2.info()\n",
    "all_tgs2.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8bfb4137",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:53:27.145197Z",
     "start_time": "2022-08-02T08:53:27.076862Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3568,)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con2 = np.hstack([ environ.val_data[f\"task{i}\"]['yc_aggr_weights'] for i in range(1,11)])\n",
    "con2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9ecbee89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:51:56.737396Z",
     "start_time": "2022-08-02T08:51:56.667161Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# all_tgs.index = range(all_tgs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b8334f68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:52:05.606811Z",
     "start_time": "2022-08-02T08:52:05.540830Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(all_tgs2[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ac56e5a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:53:38.557041Z",
     "start_time": "2022-08-02T08:53:38.479724Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "roc_auc_score     448.0\n",
       "auc_pr            448.0\n",
       "avg_prec_score    448.0\n",
       "f1_max            448.0\n",
       "p_f1_max          448.0\n",
       "kappa             448.0\n",
       "kappa_max         448.0\n",
       "p_kappa_max       448.0\n",
       "bceloss           448.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tgs2_mod = all_tgs2.where(pd.isnull, 1) * con2[:,None]\n",
    "all_tgs2_mod.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "71ba25bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:40:54.050290Z",
     "start_time": "2022-08-02T08:40:53.982441Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# con3 = pd.concat([environ.val_metrics['task1']['classification'],environ.val_metrics['task2']['classification'] ])\n",
    "# print(con3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4e3cc76f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:53:46.438201Z",
     "start_time": "2022-08-02T08:53:46.318451Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wsum: 1314.0   df.shape: (3568, 9)   df2: (3568, 9)  df2.sum(axis=0): \n",
      " roc_auc_score     448.0\n",
      "auc_pr            448.0\n",
      "avg_prec_score    448.0\n",
      "f1_max            448.0\n",
      "p_f1_max          448.0\n",
      "kappa             448.0\n",
      "kappa_max         448.0\n",
      "p_kappa_max       448.0\n",
      "bceloss           448.0\n",
      "dtype: float64\n",
      "\n",
      "  DIVISOR \n",
      "-----------\n",
      "roc_auc_score     0.002232\n",
      "auc_pr            0.002232\n",
      "avg_prec_score    0.002232\n",
      "f1_max            0.002232\n",
      "p_f1_max          0.002232\n",
      "kappa             0.002232\n",
      "kappa_max         0.002232\n",
      "p_kappa_max       0.002232\n",
      "bceloss           0.002232\n",
      "dtype: float64\n",
      "\n",
      "  DF \n",
      "------\n",
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max  kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                      \n",
      "0               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "1          0.000000  0.250000        0.500000  0.666667  0.320208    0.0        0.0     0.587646  0.780148\n",
      "2               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "3               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "4          0.333333  0.166667        0.333333  0.500000  0.328739    0.0        0.2     0.328739  0.575516\n",
      "...             ...       ...             ...       ...       ...    ...        ...          ...       ...\n",
      "67              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "68              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "69              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "70              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "71              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "\n",
      "[3568 rows x 9 columns]\n",
      "\n",
      "  DF2 \n",
      "-------\n",
      "      roc_auc_score  auc_pr  avg_prec_score  f1_max  p_f1_max  kappa  kappa_max  p_kappa_max  bceloss\n",
      "task                                                                                                 \n",
      "0               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "1               1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "2               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "3               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "4               1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "...             ...     ...             ...     ...       ...    ...        ...          ...      ...\n",
      "67              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "68              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "69              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "70              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "71              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "\n",
      "[3568 rows x 9 columns]\n",
      "\n",
      "  RESULT \n",
      "----------\n",
      "roc_auc_score     0.685598\n",
      "auc_pr            0.681871\n",
      "avg_prec_score    0.744206\n",
      "f1_max            0.799004\n",
      "p_f1_max          0.484420\n",
      "kappa             0.080060\n",
      "kappa_max         0.582045\n",
      "p_kappa_max       0.532944\n",
      "bceloss           0.636030\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tmp2 = aggregate_results(all_tgs2, con2, verbose = True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f8aa6cb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T09:20:37.470235Z",
     "start_time": "2022-08-02T09:20:37.391995Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'auc_pr': 0.6818710653441948,\n",
      "    'avg_prec_score': 0.7442062851089334,\n",
      "    'bceloss': 0.6360303774875189,\n",
      "    'f1_max': 0.7990044449679128,\n",
      "    'kappa': 0.08006046274015079,\n",
      "    'kappa_max': 0.5820449674723311,\n",
      "    'logloss': 0.00032448763622636064,\n",
      "    'p_f1_max': 0.48441957962599447,\n",
      "    'p_kappa_max': 0.532944236640885,\n",
      "    'roc_auc_score': 0.6855984778924409,\n",
      "    'sc_loss': 0.24956344102169398}\n",
      "0.24956344102169398\n",
      "0.00032448763622636064\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(environ.val_metrics['aggregated'])\n",
    "print(environ.val_metrics['aggregated']['sc_loss'] )\n",
    "print(environ.val_metrics['aggregated'][\"logloss\"] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "46f21fac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T09:02:49.573973Z",
     "start_time": "2022-08-02T09:02:49.497930Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score     0.685598\n",
      "auc_pr            0.681871\n",
      "avg_prec_score    0.744206\n",
      "f1_max            0.799004\n",
      "p_f1_max          0.484420\n",
      "kappa             0.080060\n",
      "kappa_max         0.582045\n",
      "p_kappa_max       0.532944\n",
      "bceloss           0.636030\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(tmp2)\n",
    "pp.pprint(tmp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c58a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f0711df0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:53:56.393951Z",
     "start_time": "2022-08-02T08:53:56.231370Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 task1  shape:  (472,) classifiaction: (472, 9)\n",
      "roc_auc_score     60.0\n",
      "auc_pr            60.0\n",
      "avg_prec_score    60.0\n",
      "f1_max            60.0\n",
      "p_f1_max          60.0\n",
      "kappa             60.0\n",
      "kappa_max         60.0\n",
      "p_kappa_max       60.0\n",
      "bceloss           60.0\n",
      "dtype: float64\n",
      "2 task2  shape:  (624,) classifiaction: (624, 9)\n",
      "roc_auc_score     46.0\n",
      "auc_pr            46.0\n",
      "avg_prec_score    46.0\n",
      "f1_max            46.0\n",
      "p_f1_max          46.0\n",
      "kappa             46.0\n",
      "kappa_max         46.0\n",
      "p_kappa_max       46.0\n",
      "bceloss           46.0\n",
      "dtype: float64\n",
      "3 task3  shape:  (688,) classifiaction: (688, 9)\n",
      "roc_auc_score     126.0\n",
      "auc_pr            126.0\n",
      "avg_prec_score    126.0\n",
      "f1_max            126.0\n",
      "p_f1_max          126.0\n",
      "kappa             126.0\n",
      "kappa_max         126.0\n",
      "p_kappa_max       126.0\n",
      "bceloss           126.0\n",
      "dtype: float64\n",
      "4 task4  shape:  (192,) classifiaction: (192, 9)\n",
      "roc_auc_score     29.0\n",
      "auc_pr            29.0\n",
      "avg_prec_score    29.0\n",
      "f1_max            29.0\n",
      "p_f1_max          29.0\n",
      "kappa             29.0\n",
      "kappa_max         29.0\n",
      "p_kappa_max       29.0\n",
      "bceloss           29.0\n",
      "dtype: float64\n",
      "5 task5  shape:  (620,) classifiaction: (620, 9)\n",
      "roc_auc_score     107.0\n",
      "auc_pr            107.0\n",
      "avg_prec_score    107.0\n",
      "f1_max            107.0\n",
      "p_f1_max          107.0\n",
      "kappa             107.0\n",
      "kappa_max         107.0\n",
      "p_kappa_max       107.0\n",
      "bceloss           107.0\n",
      "dtype: float64\n",
      "6 task6  shape:  (184,) classifiaction: (184, 9)\n",
      "roc_auc_score     27.0\n",
      "auc_pr            27.0\n",
      "avg_prec_score    27.0\n",
      "f1_max            27.0\n",
      "p_f1_max          27.0\n",
      "kappa             27.0\n",
      "kappa_max         27.0\n",
      "p_kappa_max       27.0\n",
      "bceloss           27.0\n",
      "dtype: float64\n",
      "7 task7  shape:  (224,) classifiaction: (224, 9)\n",
      "roc_auc_score     27.0\n",
      "auc_pr            27.0\n",
      "avg_prec_score    27.0\n",
      "f1_max            27.0\n",
      "p_f1_max          27.0\n",
      "kappa             27.0\n",
      "kappa_max         27.0\n",
      "p_kappa_max       27.0\n",
      "bceloss           27.0\n",
      "dtype: float64\n",
      "8 task8  shape:  (148,) classifiaction: (148, 9)\n",
      "roc_auc_score     24.0\n",
      "auc_pr            24.0\n",
      "avg_prec_score    24.0\n",
      "f1_max            24.0\n",
      "p_f1_max          24.0\n",
      "kappa             24.0\n",
      "kappa_max         24.0\n",
      "p_kappa_max       24.0\n",
      "bceloss           24.0\n",
      "dtype: float64\n",
      "9 task9  shape:  (344,) classifiaction: (344, 9)\n",
      "roc_auc_score     57.0\n",
      "auc_pr            57.0\n",
      "avg_prec_score    57.0\n",
      "f1_max            57.0\n",
      "p_f1_max          57.0\n",
      "kappa             57.0\n",
      "kappa_max         57.0\n",
      "p_kappa_max       57.0\n",
      "bceloss           57.0\n",
      "dtype: float64\n",
      "10 task10  shape:  (72,) classifiaction: (72, 9)\n",
      "roc_auc_score     22.0\n",
      "auc_pr            22.0\n",
      "avg_prec_score    22.0\n",
      "f1_max            22.0\n",
      "p_f1_max          22.0\n",
      "kappa             22.0\n",
      "kappa_max         22.0\n",
      "p_kappa_max       22.0\n",
      "bceloss           22.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "all_tasks_classification_metrics = []\n",
    "all_tasks_aggregation_weights    = [] \n",
    "\n",
    "for i in range(1,11):\n",
    "    task_key = f\"task{i}\"\n",
    "    print(i, task_key, ' shape: ', environ.val_data[task_key]['yc_aggr_weights'].shape,  'classifiaction:', environ.val_metrics[task_key]['classification'].shape)\n",
    "    tmp_df = environ.val_metrics[task_key]['classification'].where(pd.isnull,1)\n",
    "    print(tmp_df.sum(axis=0))\n",
    "    \n",
    "    all_tasks_classification_metrics.append(environ.val_metrics[task_key]['classification'])\n",
    "    all_tasks_aggregation_weights.append(environ.val_data[task_key]['yc_aggr_weights'])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9616c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:50:55.310369Z",
     "start_time": "2022-08-02T08:50:55.205109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_tgs3 = pd.concat(all_tasks_classification_metrics)\n",
    "con3 = np.concatenate(all_tasks_aggregation_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e9cdf412",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:54:37.322219Z",
     "start_time": "2022-08-02T08:54:37.193928Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3568 entries, 0 to 71\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   roc_auc_score   525 non-null    float64\n",
      " 1   auc_pr          525 non-null    float64\n",
      " 2   avg_prec_score  525 non-null    float64\n",
      " 3   f1_max          525 non-null    float64\n",
      " 4   p_f1_max        525 non-null    float32\n",
      " 5   kappa           525 non-null    float64\n",
      " 6   kappa_max       525 non-null    float64\n",
      " 7   p_kappa_max     525 non-null    float32\n",
      " 8   bceloss         525 non-null    float64\n",
      "dtypes: float32(2), float64(7)\n",
      "memory usage: 250.9 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>avg_prec_score</th>\n",
       "      <th>f1_max</th>\n",
       "      <th>p_f1_max</th>\n",
       "      <th>kappa</th>\n",
       "      <th>kappa_max</th>\n",
       "      <th>p_kappa_max</th>\n",
       "      <th>bceloss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.320208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587646</td>\n",
       "      <td>0.780148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.328739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.328739</td>\n",
       "      <td>0.575516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max  kappa  kappa_max  p_kappa_max   bceloss\n",
       "task                                                                                                      \n",
       "0               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "1          0.000000  0.250000        0.500000  0.666667  0.320208    0.0        0.0     0.587646  0.780148\n",
       "2               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "3               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "4          0.333333  0.166667        0.333333  0.500000  0.328739    0.0        0.2     0.328739  0.575516\n",
       "5               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "6               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "7               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "8               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "9               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "10              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "11              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "12              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "13              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "14              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "15              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "16              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "17              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "18              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "19              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tgs3.info()\n",
    "all_tgs3.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9f29ee1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T09:02:16.745152Z",
     "start_time": "2022-08-02T09:02:16.608823Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wsum: 1314.0   df.shape: (3568, 9)   df2: (3568, 9)  df2.sum(axis=0): \n",
      " roc_auc_score     448.0\n",
      "auc_pr            448.0\n",
      "avg_prec_score    448.0\n",
      "f1_max            448.0\n",
      "p_f1_max          448.0\n",
      "kappa             448.0\n",
      "kappa_max         448.0\n",
      "p_kappa_max       448.0\n",
      "bceloss           448.0\n",
      "dtype: float64\n",
      "\n",
      "  DIVISOR \n",
      "-----------\n",
      "roc_auc_score     0.002232\n",
      "auc_pr            0.002232\n",
      "avg_prec_score    0.002232\n",
      "f1_max            0.002232\n",
      "p_f1_max          0.002232\n",
      "kappa             0.002232\n",
      "kappa_max         0.002232\n",
      "p_kappa_max       0.002232\n",
      "bceloss           0.002232\n",
      "dtype: float64\n",
      "\n",
      "  DF \n",
      "------\n",
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max  kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                      \n",
      "0               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "1          0.000000  0.250000        0.500000  0.666667  0.320208    0.0        0.0     0.587646  0.780148\n",
      "2               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "3               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "4          0.333333  0.166667        0.333333  0.500000  0.328739    0.0        0.2     0.328739  0.575516\n",
      "...             ...       ...             ...       ...       ...    ...        ...          ...       ...\n",
      "67              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "68              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "69              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "70              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "71              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "\n",
      "[3568 rows x 9 columns]\n",
      "\n",
      "  DF2 \n",
      "-------\n",
      "      roc_auc_score  auc_pr  avg_prec_score  f1_max  p_f1_max  kappa  kappa_max  p_kappa_max  bceloss\n",
      "task                                                                                                 \n",
      "0               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "1               1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "2               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "3               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "4               1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "...             ...     ...             ...     ...       ...    ...        ...          ...      ...\n",
      "67              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "68              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "69              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "70              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "71              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "\n",
      "[3568 rows x 9 columns]\n",
      "\n",
      "  RESULT \n",
      "----------\n",
      "roc_auc_score     0.685598\n",
      "auc_pr            0.681871\n",
      "avg_prec_score    0.744206\n",
      "f1_max            0.799004\n",
      "p_f1_max          0.484420\n",
      "kappa             0.080060\n",
      "kappa_max         0.582045\n",
      "p_kappa_max       0.532944\n",
      "bceloss           0.636030\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tmp3 = aggregate_results( all_tgs3, con3, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e5c12369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:59:51.408133Z",
     "start_time": "2022-08-02T08:59:51.294153Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task\n",
      "0   NaN\n",
      "Name: roc_auc_score, dtype: float64\n",
      "task\n",
      "0   NaN\n",
      "Name: roc_auc_score, dtype: float64\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_tgs2[0:1]['roc_auc_score'])\n",
    "print(all_tgs3[0:1]['roc_auc_score'])\n",
    "print((all_tgs2[0:1]['roc_auc_score'] == all_tgs3[0:1]['roc_auc_score']).all())\n",
    "all_tgs2.compare(all_tgs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "399eae39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T15:18:30.544168Z",
     "start_time": "2022-08-01T15:18:30.511229Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(344,) (344,)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(environ.val_data['task9']['yc_aggr_weights'].shape, con[3152:3496].shape)\n",
    "print((environ.val_data['task9']['yc_aggr_weights'] == con[3152:3496]).all())a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8183a98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T14:53:09.749812Z",
     "start_time": "2022-08-01T14:53:09.749793Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best ROC AUC   :   {ns.best_roc_auc:.5f}\\n\"\n",
    "      f\"Best Precision :   {ns.best_accuracy:.5f}\\n\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76406f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T13:56:23.922805Z",
     "start_time": "2022-07-08T13:56:23.891800Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch :       3\n",
      "Best Iteration :   7977 \n",
      "Best ROC AUC   :   0.73690\n",
      "Best Precision :   0.64175\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best ROC AUC   :   {ns.best_roc_auc:.5f}\\n\"\n",
    "      f\"Best Precision :   {ns.best_accuracy:.5f}\\n\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60564cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:50:02.608053Z",
     "start_time": "2022-07-07T13:50:02.553468Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch :       1\n",
      "Best Iteration :   2659 \n",
      "Best ROC AUC   :   0.71991\n",
      "Best Precision :   0.63031\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best ROC AUC   :   {ns.best_roc_auc:.5f}\\n\"\n",
    "      f\"Best Precision :   {ns.best_accuracy:.5f}\\n\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a8071",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bc9c724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T11:20:10.987625Z",
     "start_time": "2022-07-28T11:20:10.957009Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch :       2\n",
      "Best Iteration :   6258 \n",
      "Best ROC AUC   :   0.79359\n",
      "Best Precision :   0.72131\n",
      "\n",
      "\n",
      "roc_auc_score           0.7936\n",
      "auc_pr                  0.6974\n",
      "avg_prec_score          0.7213\n",
      "f1_max                  0.7534\n",
      "p_f1_max                0.4367\n",
      "kappa                   0.3055\n",
      "kappa_max               0.5732\n",
      "p_kappa_max             0.4947\n",
      "bceloss                 0.4300\n",
      "sc_loss                 0.0106\n",
      "logloss                 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best ROC AUC   :   {ns.best_roc_auc:.5f}\\n\"\n",
    "      f\"Best Precision :   {ns.best_accuracy:.5f}\\n\")\n",
    "print()\n",
    "for key in environ.val_metrics['aggregated']:\n",
    "    print(f\"{key:20s}    {environ.val_metrics['aggregated'][key]:0.4f}\")\n",
    "# pp.pprint(environ.val_metrics['aggregated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48528a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb49645c",
   "metadata": {},
   "source": [
    "## Weight & Policy Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aade16",
   "metadata": {},
   "source": [
    "### Weight/Policy Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f750fcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:03:48.800684Z",
     "start_time": "2022-08-18T12:03:42.137201Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.opt['is_curriculum'] = True\n",
    "# environ.opt['curriculum_speed'] = 4\n",
    "# ns.num_train_layers = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6231ff38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T17:12:55.994073Z",
     "start_time": "2022-08-18T17:12:55.916091Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model optimizers defined . . . policy_learning: True\n",
      " Model schedulers defined . . . policy_learning: True\n",
      " Metrics CSV file header written . . . \n",
      " Model initializations complete . . . \n",
      " training preparation: - check for CUDA - cuda available as device id: [0]\n",
      "sparsechem_env.cuda()\n",
      " policy policy1 is None\n",
      " policy policy2 is None\n",
      " policy policy3 is None\n",
      " policy policy4 is None\n",
      " policy policy5 is None\n",
      " policy policy6 is None\n",
      " policy policy7 is None\n",
      " policy policy8 is None\n",
      " policy policy9 is None\n",
      " policy policy10 is None\n",
      " training preparation: - set print_freq to                                 : 1989 \n",
      " training preparation: - set number of batches per warmup training epoch to: 1989\n",
      " training preparation: - set number of batches per weight training epoch to: 1318\n",
      " training preparation: - set number of batches per policy training epoch to: 671\n",
      " training preparation: - set number of batches per validation to           : 675\n",
      " training preparation complete . . .\n"
     ]
    }
   ],
   "source": [
    "ns.flag = 'update_weights'\n",
    "model_initializations(ns, opt, environ, phase = ns.flag, policy_learning = True)\n",
    "training_initializations(ns, opt, environ, dldrs, warmup = False)\n",
    "# training_initializations(ns, opt, environ, dldrs, warmup_iterations = 200,  weight_iterations = 200, policy_iterations = 200, eval_iterations = 50, warmup = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8ed1774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T17:12:57.348915Z",
     "start_time": "2022-08-18T17:12:57.284521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone Initial LR            :      0.001000      Current LR : 0.001 \n",
      " Tasks    Initial LR            :      0.001000      Current LR : 0.001    \n",
      " Policy   Initial LR            :      0.001000      Current LR : 0.001  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone Initial LR            :      {environ.opt['train']['backbone_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[0]['lr']} \\n\"\n",
    "       f\" Tasks    Initial LR            :      {environ.opt['train']['task_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[1]['lr']}    \\n\"\n",
    "       f\" Policy   Initial LR            :      {environ.opt['train']['policy_lr']:4f}      Current LR : {environ.optimizers['alphas'].param_groups[0]['lr']}  \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90b1ace9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T17:12:57.990414Z",
     "start_time": "2022-08-18T17:12:57.925805Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "** 2022-08-18 19:12:57:984486 \n",
      "** Training epoch: 10 iter: 19890   flag: update_weights \n",
      "** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\n",
      "** Switch from Warm Up training to Alternate training Weights & Policy \n",
      "** Take checkpoint and block gradient flow through Policy net\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_heading( f\"** {timestring()} \\n\"\n",
    "               f\"** Training epoch: {ns.current_epoch} iter: {ns.current_iter}   flag: {ns.flag} \\n\"\n",
    "               f\"** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\\n\"\n",
    "               f\"** Switch from Warm Up training to Alternate training Weights & Policy \\n\"\n",
    "               f\"** Take checkpoint and block gradient flow through Policy net\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6191a942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T17:13:00.741949Z",
     "start_time": "2022-08-18T17:13:00.677626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "None\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(hasattr(environ, 'policy%d' % (1)))\n",
    "print(getattr(environ, \"policy1\"))\n",
    "print(environ.networks['mtl-net'].policys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66affd0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T17:13:04.599037Z",
     "start_time": "2022-08-18T17:13:04.534123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n",
      "0.01\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(environ.opt['train']['lambda_sparsity'])\n",
    "print(environ.opt['train']['lambda_sharing'])\n",
    "print(environ.opt['train']['decay_temp_freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d143c29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T20:47:49.510769Z",
     "start_time": "2022-08-18T20:47:49.435941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "0.01\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "environ.opt['train']['lambda_sparsity'] = 0.001\n",
    "environ.opt['train']['lambda_sharing']  = 0.01\n",
    "environ.opt['train']['decay_temp_freq'] = 6\n",
    "print(environ.opt['train']['lambda_sparsity'])\n",
    "print(environ.opt['train']['lambda_sharing'])\n",
    "print(environ.opt['train']['decay_temp_freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef3a11fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T20:47:52.036039Z",
     "start_time": "2022-08-18T20:47:51.960123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ns.flag                        :      update_weights\n",
      " num_train_layers               :      6\n",
      " environ.opt['is_curriculum']   :      False\n",
      " environ.opt['curriculum_speed']:      3\n",
      "\n",
      " Backbone Initial LR            :      0.001000      Current LR : 0.001 \n",
      " Tasks    Initial LR            :      0.001000      Current LR : 0.001    \n",
      " Policy   Initial LR            :      0.001000      Current LR : 0.001  \n",
      "\n",
      " Hard Sampling                  :      False\n",
      "\n",
      " Sparsity regularization        :      0.001\n",
      " Sharing  regularization        :      0.01 \n",
      " Tasks    regularization        :      1   \n",
      "\n",
      "\n",
      " Gumbel Temp                    :      4.0000         \n",
      " Gumbel Temp decay              :      6 \n",
      "\n",
      " ns.current_epoch               :      12\n",
      " ns.training_epochs             :      2 \n",
      "\n",
      " ns.current_iters               :      23868\n",
      " Batches in warmup epoch        :      1989\n",
      " Batches in weight epoch        :      1318\n",
      " Batches in policy epoch        :      671\n",
      " Batches in validation          :      675\n",
      " num_train_layers               :      6 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print( f\" ns.flag                        :      {ns.flag}\")\n",
    "print( f\" num_train_layers               :      {ns.num_train_layers}\")\n",
    "print( f\" environ.opt['is_curriculum']   :      {environ.opt['is_curriculum']}\")\n",
    "print( f\" environ.opt['curriculum_speed']:      {environ.opt['curriculum_speed']}\\n\")\n",
    "print( f\" Backbone Initial LR            :      {environ.opt['train']['backbone_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[0]['lr']} \\n\"\n",
    "       f\" Tasks    Initial LR            :      {environ.opt['train']['task_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[1]['lr']}    \\n\"\n",
    "       f\" Policy   Initial LR            :      {environ.opt['train']['policy_lr']:4f}      Current LR : {environ.optimizers['alphas'].param_groups[0]['lr']}  \\n\")\n",
    "\n",
    "print( f\" Hard Sampling                  :      {environ.opt['train']['hard_sampling']}\\n\")\n",
    "\n",
    "print( f\" Sparsity regularization        :      {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization        :      {environ.opt['train']['lambda_sharing']} \\n\"\n",
    "       f\" Tasks    regularization        :      {environ.opt['train']['lambda_tasks']}   \\n\\n\")\n",
    "\n",
    "print( f\" Gumbel Temp                    :      {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay              :      {environ.opt['train']['decay_temp_freq']} \\n\") #\n",
    "\n",
    "print( f\" ns.current_epoch               :      {ns.current_epoch}\")\n",
    "print( f\" ns.training_epochs             :      {ns.training_epochs} \\n\") \n",
    "print( f\" ns.current_iters               :      {ns.current_iter}\")  \n",
    "print( f\" Batches in warmup epoch        :      {ns.trn_iters_warmup}\")\n",
    "print( f\" Batches in weight epoch        :      {ns.trn_iters_weights}\")\n",
    "print( f\" Batches in policy epoch        :      {ns.trn_iters_policy}\")\n",
    "print( f\" Batches in validation          :      {ns.eval_iters}\")\n",
    "print( f\" num_train_layers               :      {ns.num_train_layers} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a037fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T20:47:53.019721Z",
     "start_time": "2022-08-18T20:47:52.915252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[e] Last ep:12  it:23868  -  Total Loss: 2.2310     \n",
      "Task: 2.2300   Sparsity: 1.04549e-03    Sharing: 1.00072e-05 \n",
      "\n",
      "\n",
      " ep:   12    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.4538    0.5462  0    0.4652    0.5348  0    0.3973    0.6027  0    0.4549    0.5451  0    0.4204    0.5796  0    0.4631    0.5369  0    0.4475    0.5525  0    0.4489    0.5511  0    0.4307    0.5693  0    0.4526    0.5474  0\n",
      "  1    0.4668    0.5332  0    0.4763    0.5237  0    0.4055    0.5945  0    0.4575    0.5425  0    0.4332    0.5668  0    0.4727    0.5273  0    0.4581    0.5419  0    0.4557    0.5443  0    0.4548    0.5452  0    0.4640    0.5360  0\n",
      "  2    0.4721    0.5279  0    0.4725    0.5275  0    0.4129    0.5871  0    0.4752    0.5248  0    0.4469    0.5531  0    0.4788    0.5212  0    0.4725    0.5275  0    0.4569    0.5431  0    0.4590    0.5410  0    0.4684    0.5316  0\n",
      "  3    0.4646    0.5354  0    0.4794    0.5206  0    0.4221    0.5779  0    0.4604    0.5396  0    0.4471    0.5529  0    0.4752    0.5248  0    0.4738    0.5262  0    0.4579    0.5421  0    0.4629    0.5371  0    0.4713    0.5287  0\n",
      "  4    0.4727    0.5273  0    0.4761    0.5239  0    0.4246    0.5754  0    0.4692    0.5308  0    0.4582    0.5418  0    0.4687    0.5313  0    0.4618    0.5382  0    0.4620    0.5380  0    0.4559    0.5441  0    0.4679    0.5321  0\n",
      "  5    0.4670    0.5330  0    0.4721    0.5279  0    0.4256    0.5744  0    0.4716    0.5284  0    0.4522    0.5478  0    0.4710    0.5290  0    0.4626    0.5374  0    0.4681    0.5319  0    0.4626    0.5374  0    0.4670    0.5330  0\n",
      "\n",
      "\n",
      " ep:   12   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0   -0.1188    0.0666  0   -0.1194    0.0199  0   -0.1189    0.2980  0   -0.1183    0.0628  0   -0.1207    0.2002  0   -0.1186    0.0292  0   -0.1177    0.0929  0   -0.1201    0.0850  0   -0.1201    0.1588  0   -0.1182    0.0720  0\n",
      "  1   -0.0938    0.0392  0   -0.0937    0.0012  0   -0.0938    0.2888  0   -0.0938    0.0766  0   -0.0946    0.1742  0   -0.0939    0.0154  0   -0.0939    0.0739  0   -0.0937    0.0840  0   -0.0939    0.0874  0   -0.0937    0.0504  0\n",
      "  2   -0.0781    0.0336  0   -0.0781    0.0321  0   -0.0787    0.2734  0   -0.0781    0.0213  0   -0.0787    0.1347  0   -0.0784    0.0064  0   -0.0782    0.0320  0   -0.0784    0.0943  0   -0.0786    0.0857  0   -0.0783    0.0483  0\n",
      "  3   -0.0762    0.0657  0   -0.0761    0.0062  0   -0.0761    0.2381  0   -0.0761    0.0825  0   -0.0758    0.1366  0   -0.0758    0.0235  0   -0.0761    0.0290  0   -0.0759    0.0929  0   -0.0762    0.0726  0   -0.0763    0.0387  0\n",
      "  4   -0.0732    0.0362  0   -0.0732    0.0224  0   -0.0750    0.2291  0   -0.0732    0.0500  0   -0.0733    0.0943  0   -0.0735    0.0521  0   -0.0731    0.0801  0   -0.0730    0.0792  0   -0.0731    0.1038  0   -0.0734    0.0554  0\n",
      "  5   -0.0725    0.0596  0   -0.0724    0.0394  0   -0.0730    0.2266  0   -0.0725    0.0414  0   -0.0726    0.1194  0   -0.0728    0.0432  0   -0.0726    0.0773  0   -0.0728    0.0549  0   -0.0726    0.0775  0   -0.0727    0.0596  0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed : 12       # of epochs to run:  2 -->  epochs 13 to 14\n",
      " policy_learning rate : 0.001 \n",
      " lambda_sparsity      : 0.001\n",
      " lambda_sharing       : 0.01\n",
      " curriculum training  : False     cirriculum speed: 3     num_training_layers : 6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_loss(ns.val_metrics, title = f\"[e] Last ep:{ns.current_epoch}  it:{ns.current_iter} \")\n",
    "print()\n",
    "environ.display_trained_policy(ns.current_epoch)\n",
    "environ.display_trained_logits(ns.current_epoch)\n",
    "print_heading(f\" Last Epoch Completed : {ns.current_epoch}       # of epochs to run:  {ns.training_epochs} -->  epochs {ns.current_epoch+1} to {ns.training_epochs + ns.current_epoch}\"\n",
    "              f\"\\n policy_learning rate : {environ.opt['train']['policy_lr']} \"\n",
    "              f\"\\n lambda_sparsity      : {environ.opt['train']['lambda_sparsity']}\"\n",
    "              f\"\\n lambda_sharing       : {environ.opt['train']['lambda_sharing']}\"\n",
    "              f\"\\n curriculum training  : {opt['is_curriculum']}     cirriculum speed: {opt['curriculum_speed']}     num_training_layers : {ns.num_train_layers}\", \n",
    "              verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c71af",
   "metadata": {},
   "source": [
    "### Weight/Policy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d10ad7d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T21:48:55.930604Z",
     "start_time": "2022-08-18T20:47:55.082591Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed : 12   # of epochs to run:  2 -->  epochs 13 to 14    \n",
      " policy_learning rate : 0.001      \n",
      " lambda_sparsity      : 0.001\n",
      " lambda_sharing       : 0.01 \n",
      " curriculum training  : False     cirriculum speed: 3     num_training_layers : 6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      " Ep  | Trunk LR  Heads LR  Polcy LR  Gmbl Tmp |  trn tsk    trn spar    trn shar   trn ttl |   logloss   bceloss  avg prec    aucroc     aucpr    f1_max |  val tsk    val spar    val shar     total | time |\n",
      "  13 | 1.00e-03  1.00e-03  1.00e-03  4.00e+00 |   1.5934   8.383e-05   1.605e-05    1.5935 |   0.00000   0.47630   0.63846   0.72964   0.62506   0.67845 |   2.2253   5.227e-05   1.001e-05    2.2253 |1456.5 |\n",
      "Previous best_epoch:    12   best iter: 23197   best_accuracy: 0.63875    best ROC auc: 0.72942\n",
      "Previous best_epoch:    13   best iter: 25186   best_accuracy: 0.63846    best ROC auc: 0.72964\n",
      " save best metrics to     :  metrics_best.pickle\n",
      " save  best checkpoint to :  model_best\n",
      "  13 | 1.00e-03  1.00e-03  1.00e-03  4.00e+00 |   1.5863   5.027e-05   1.201e-05    1.5863 |   0.00000   0.47627   0.63890   0.72965   0.62566   0.67847 |   2.2248   5.153e-05   1.200e-05    2.2249 |339.7 |\n",
      "Previous best_epoch:    13   best iter: 25186   best_accuracy: 0.63846    best ROC auc: 0.72964\n",
      "Previous best_epoch:    13   best iter: 25857   best_accuracy: 0.63890    best ROC auc: 0.72965\n",
      " save best metrics to     :  metrics_best.pickle\n",
      " save  best checkpoint to :  model_best\n",
      "\n",
      " ep:   13   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0   -0.1603    0.0908  0   -0.1604    0.0578  0   -0.1606    0.4062  0   -0.1611    0.0847  0   -0.1607    0.2831  0   -0.1593    0.0218  0   -0.1595    0.1235  0   -0.1603    0.1064  0   -0.1601    0.2220  0   -0.1616    0.0648  0\n",
      "  1   -0.1152    0.0724  0   -0.1173   -0.0149  0   -0.1172    0.3729  0   -0.1163    0.0870  0   -0.1167    0.1854  0   -0.1175    0.0324  0   -0.1160    0.0754  0   -0.1165    0.0930  0   -0.1165    0.1459  0   -0.1165    0.0598  0\n",
      "  2   -0.0885    0.0053  0   -0.0890    0.0111  0   -0.0882    0.3213  0   -0.0887    0.0117  0   -0.0888    0.2001  0   -0.0894    0.0051  0   -0.0888    0.0521  0   -0.0891    0.0672  0   -0.0888    0.1243  0   -0.0879    0.0285  0\n",
      "  3   -0.0760    0.0399  0   -0.0751    0.0092  0   -0.0767    0.2605  0   -0.0756    0.0455  0   -0.0751    0.1764  0   -0.0753   -0.0065  0   -0.0755    0.0389  0   -0.0756    0.0689  0   -0.0753    0.0611  0   -0.0753    0.0217  0\n",
      "  4   -0.0790    0.0088  0   -0.0788    0.0283  0   -0.0789    0.2745  0   -0.0790    0.0568  0   -0.0792    0.0957  0   -0.0788    0.0133  0   -0.0788    0.1027  0   -0.0789    0.0487  0   -0.0790    0.1332  0   -0.0787    0.0247  0\n",
      "  5   -0.0719    0.0531  0   -0.0710    0.0247  0   -0.0711    0.2442  0   -0.0710    0.0274  0   -0.0714    0.1234  0   -0.0710    0.0394  0   -0.0709    0.0469  0   -0.0713    0.0347  0   -0.0713    0.0831  0   -0.0715    0.0201  0\n",
      "\n",
      "  14 | 1.00e-03  1.00e-03  1.00e-03  4.00e+00 |   1.8567   8.264e-05   1.925e-05    1.8568 |   0.00000   0.47532   0.64029   0.73060   0.62711   0.67955 |   2.2196   5.153e-05   1.200e-05    2.2197 |1441.6 |\n",
      "Previous best_epoch:    13   best iter: 25857   best_accuracy: 0.63890    best ROC auc: 0.72965\n",
      "Previous best_epoch:    14   best iter: 27175   best_accuracy: 0.64029    best ROC auc: 0.73060\n",
      " save best metrics to     :  metrics_best.pickle\n",
      " save  best checkpoint to :  model_best\n",
      "  14 | 1.00e-03  1.00e-03  1.00e-03  4.00e+00 |   1.7055   4.958e-05   2.153e-05    1.7056 |   0.00000   0.47532   0.63977   0.73040   0.62645   0.67926 |   2.2200   5.081e-05   2.173e-05    2.2201 |353.2 |\n",
      "\n",
      " ep:   14   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0   -0.1904    0.0621  0   -0.1929    0.0743  0   -0.2042    0.5378  0   -0.1906    0.1085  0   -0.1917    0.3519  0   -0.1908    0.0455  0   -0.1914    0.1095  0   -0.1903    0.1672  0   -0.1942    0.2395  0   -0.1908    0.0687  0\n",
      "  1   -0.1324    0.0553  0   -0.1324    0.0042  0   -0.1348    0.4377  0   -0.1325    0.0851  0   -0.1321    0.2425  0   -0.1324    0.0327  0   -0.1322    0.0722  0   -0.1323    0.1108  0   -0.1327    0.1631  0   -0.1325    0.0529  0\n",
      "  2   -0.1023    0.0217  0   -0.1018    0.0177  0   -0.1018    0.3803  0   -0.1025    0.0538  0   -0.1021    0.2001  0   -0.1023    0.0231  0   -0.1027    0.0576  0   -0.1022    0.0774  0   -0.1023    0.1476  0   -0.1022    0.0220  0\n",
      "  3   -0.0753    0.0245  0   -0.0764   -0.0055  0   -0.0760    0.2905  0   -0.0756    0.0187  0   -0.0759    0.1619  0   -0.0758    0.0100  0   -0.0759    0.0408  0   -0.0754    0.0595  0   -0.0763    0.0979  0   -0.0753    0.0156  0\n",
      "  4   -0.0834    0.0409  0   -0.0838    0.0395  0   -0.0835    0.3063  0   -0.0836    0.0589  0   -0.0836    0.1040  0   -0.0839    0.0112  0   -0.0837    0.0392  0   -0.0836    0.0596  0   -0.0840    0.1550  0   -0.0835    0.0185  0\n",
      "  5   -0.0654    0.0359  0   -0.0662    0.0231  0   -0.0659    0.2542  0   -0.0659    0.0309  0   -0.0661    0.0956  0   -0.0660    0.0114  0   -0.0659    0.0366  0   -0.0660    0.0507  0   -0.0654    0.0812  0   -0.0660    0.0158  0\n",
      "\n",
      " save train checkpoint  to :  model_train_last_ep_14\n",
      " save train metrics to     :  metrics_train_last_ep_14.pickle\n",
      "[Final] ep:14  it:27846 -  Total Loss: 2.2201     \n",
      "Task: 2.2200   Sparsity: 5.08144e-05    Sharing: 2.17293e-05 \n",
      "\n",
      " ep:   14    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.4372    0.5628  0    0.4336    0.5664  0    0.3226    0.6774  0    0.4258    0.5742  0    0.3674    0.6326  0    0.4412    0.5588  0    0.4253    0.5747  0    0.4116    0.5884  0    0.3932    0.6068  0    0.4355    0.5645  0\n",
      "  1    0.4532    0.5468  0    0.4659    0.5341  0    0.3607    0.6393  0    0.4458    0.5542  0    0.4074    0.5926  0    0.4588    0.5412  0    0.4491    0.5509  0    0.4395    0.5605  0    0.4266    0.5734  0    0.4538    0.5462  0\n",
      "  2    0.4690    0.5310  0    0.4702    0.5298  0    0.3818    0.6182  0    0.4610    0.5390  0    0.4250    0.5750  0    0.4687    0.5313  0    0.4600    0.5400  0    0.4552    0.5448  0    0.4378    0.5622  0    0.4690    0.5310  0\n",
      "  3    0.4751    0.5249  0    0.4823    0.5177  0    0.4094    0.5906  0    0.4765    0.5235  0    0.4408    0.5592  0    0.4786    0.5214  0    0.4709    0.5291  0    0.4663    0.5337  0    0.4566    0.5434  0    0.4773    0.5227  0\n",
      "  4    0.4690    0.5310  0    0.4692    0.5308  0    0.4038    0.5962  0    0.4644    0.5356  0    0.4532    0.5468  0    0.4763    0.5237  0    0.4693    0.5307  0    0.4643    0.5357  0    0.4405    0.5595  0    0.4745    0.5255  0\n",
      "  5    0.4747    0.5253  0    0.4777    0.5223  0    0.4206    0.5794  0    0.4758    0.5242  0    0.4597    0.5403  0    0.4807    0.5193  0    0.4744    0.5256  0    0.4709    0.5291  0    0.4634    0.5366  0    0.4796    0.5204  0\n",
      "\n",
      "\n",
      " ep:   14   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0   -0.1904    0.0621  0   -0.1929    0.0743  0   -0.2042    0.5378  0   -0.1906    0.1085  0   -0.1917    0.3519  0   -0.1908    0.0455  0   -0.1914    0.1095  0   -0.1903    0.1672  0   -0.1942    0.2395  0   -0.1908    0.0687  0\n",
      "  1   -0.1324    0.0553  0   -0.1324    0.0042  0   -0.1348    0.4377  0   -0.1325    0.0851  0   -0.1321    0.2425  0   -0.1324    0.0327  0   -0.1322    0.0722  0   -0.1323    0.1108  0   -0.1327    0.1631  0   -0.1325    0.0529  0\n",
      "  2   -0.1023    0.0217  0   -0.1018    0.0177  0   -0.1018    0.3803  0   -0.1025    0.0538  0   -0.1021    0.2001  0   -0.1023    0.0231  0   -0.1027    0.0576  0   -0.1022    0.0774  0   -0.1023    0.1476  0   -0.1022    0.0220  0\n",
      "  3   -0.0753    0.0245  0   -0.0764   -0.0055  0   -0.0760    0.2905  0   -0.0756    0.0187  0   -0.0759    0.1619  0   -0.0758    0.0100  0   -0.0759    0.0408  0   -0.0754    0.0595  0   -0.0763    0.0979  0   -0.0753    0.0156  0\n",
      "  4   -0.0834    0.0409  0   -0.0838    0.0395  0   -0.0835    0.3063  0   -0.0836    0.0589  0   -0.0836    0.1040  0   -0.0839    0.0112  0   -0.0837    0.0392  0   -0.0836    0.0596  0   -0.0840    0.1550  0   -0.0835    0.0185  0\n",
      "  5   -0.0654    0.0359  0   -0.0662    0.0231  0   -0.0659    0.2542  0   -0.0659    0.0309  0   -0.0661    0.0956  0   -0.0660    0.0114  0   -0.0659    0.0366  0   -0.0660    0.0507  0   -0.0654    0.0812  0   -0.0660    0.0158  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weight_policy_training(ns, opt, environ, dldrs, display_policy = True, disable_tqdm = False, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27779c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:28.065212Z",
     "start_time": "2022-03-28T05:13:27.897193Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d3dcb54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:28:06.496112Z",
     "start_time": "2022-08-18T13:28:06.457166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ep:    8    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.4589    0.5411  0    0.4410    0.5590  0    0.3997    0.6003  0    0.4436    0.5564  0    0.4145    0.5855  0    0.4546    0.5454  0    0.4417    0.5583  0    0.4384    0.5616  0    0.4293    0.5707  0    0.4569    0.5431  0\n",
      "  1    0.4520    0.5480  0    0.4419    0.5581  0    0.4097    0.5903  0    0.4369    0.5631  0    0.4200    0.5800  0    0.4551    0.5449  0    0.4419    0.5581  0    0.4401    0.5599  0    0.4460    0.5540  0    0.4531    0.5469  0\n",
      "  2    0.4522    0.5478  0    0.4316    0.5684  0    0.4212    0.5788  0    0.4299    0.5701  0    0.4246    0.5754  0    0.4473    0.5527  0    0.4513    0.5487  0    0.4324    0.5676  0    0.4300    0.5700  0    0.4496    0.5504  0\n",
      "  3    0.4426    0.5574  0    0.4427    0.5573  0    0.4212    0.5788  0    0.4278    0.5722  0    0.4292    0.5708  0    0.4395    0.5605  0    0.4401    0.5599  0    0.4374    0.5626  0    0.4421    0.5579  0    0.4454    0.5546  0\n",
      "  4    0.4502    0.5498  0    0.4381    0.5619  0    0.4234    0.5766  0    0.4397    0.5603  0    0.4170    0.5830  0    0.4407    0.5593  0    0.4427    0.5573  0    0.4350    0.5650  0    0.4337    0.5663  0    0.4478    0.5522  0\n",
      "  5    0.4601    0.5399  0    0.4398    0.5602  0    0.4343    0.5657  0    0.4420    0.5580  0    0.4343    0.5657  0    0.4450    0.5550  0    0.4448    0.5552  0    0.4381    0.5619  0    0.4456    0.5544  0    0.4498    0.5502  0\n",
      "\n",
      "\n",
      " ep:    8   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0   -0.1147    0.0499  0   -0.1165    0.1207  0   -0.1846    0.2221  0   -0.1233    0.1031  0   -0.1576    0.1879  0   -0.1098    0.0722  0   -0.1232    0.1111  0   -0.1180    0.1298  0   -0.1307    0.1539  0   -0.1153    0.0573  0\n",
      "  1   -0.1238    0.0686  0   -0.1148    0.1185  0   -0.1648    0.2003  0   -0.1197    0.1342  0   -0.1416    0.1813  0   -0.1162    0.0639  0   -0.1234    0.1102  0   -0.1187    0.1221  0   -0.1141    0.1028  0   -0.1176    0.0705  0\n",
      "  2   -0.1275    0.0641  0   -0.1297    0.1456  0   -0.1540    0.1637  0   -0.1340    0.1481  0   -0.1343    0.1696  0   -0.1228    0.0886  0   -0.1215    0.0739  0   -0.1275    0.1447  0   -0.1282    0.1537  0   -0.1235    0.0787  0\n",
      "  3   -0.1264    0.1041  0   -0.1280    0.1023  0   -0.1385    0.1795  0   -0.1343    0.1566  0   -0.1310    0.1541  0   -0.1316    0.1114  0   -0.1288    0.1119  0   -0.1307    0.1209  0   -0.1263    0.1064  0   -0.1268    0.0924  0\n",
      "  4   -0.1268    0.0731  0   -0.1282    0.1205  0   -0.1440    0.1650  0   -0.1347    0.1076  0   -0.1411    0.1938  0   -0.1245    0.1137  0   -0.1280    0.1023  0   -0.1296    0.1317  0   -0.1300    0.1367  0   -0.1274    0.0820  0\n",
      "  5   -0.1128    0.0473  0   -0.1175    0.1246  0   -0.1152    0.1494  0   -0.1156    0.1176  0   -0.1184    0.1458  0   -0.1174    0.1035  0   -0.1163    0.1054  0   -0.1169    0.1320  0   -0.1169    0.1017  0   -0.1153    0.0860  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "environ.display_trained_policy(ns.current_epoch)\n",
    "environ.display_trained_logits(ns.current_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e42e43",
   "metadata": {},
   "source": [
    "### Close WandB run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f6b31da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:28:51.468007Z",
     "start_time": "2022-08-18T13:28:45.740666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_pr</td><td></td></tr><tr><td>avg_prec_score</td><td></td></tr><tr><td>bceloss</td><td></td></tr><tr><td>best_accuracy</td><td></td></tr><tr><td>best_epoch</td><td></td></tr><tr><td>best_iter</td><td></td></tr><tr><td>best_roc_auc</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>f1_max</td><td></td></tr><tr><td>gumbel_temp</td><td></td></tr><tr><td>kappa</td><td></td></tr><tr><td>kappa_max</td><td></td></tr><tr><td>lambda_sharing</td><td></td></tr><tr><td>lambda_sparsity</td><td></td></tr><tr><td>lambda_tasks</td><td></td></tr><tr><td>logloss</td><td></td></tr><tr><td>lr_0</td><td></td></tr><tr><td>lr_1</td><td></td></tr><tr><td>p_f1_max</td><td></td></tr><tr><td>p_kappa_max</td><td></td></tr><tr><td>policy_lr</td><td></td></tr><tr><td>roc_auc_score</td><td></td></tr><tr><td>sc_loss</td><td></td></tr><tr><td>train_layers</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_pr</td><td>0.66292</td></tr><tr><td>avg_prec_score</td><td>0.70491</td></tr><tr><td>bceloss</td><td>0.56926</td></tr><tr><td>best_roc_auc</td><td>0.71527</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>f1_max</td><td>0.75477</td></tr><tr><td>gumbel_temp</td><td>4</td></tr><tr><td>kappa</td><td>0.13622</td></tr><tr><td>kappa_max</td><td>0.52869</td></tr><tr><td>lambda_sharing</td><td>0.001</td></tr><tr><td>lambda_sparsity</td><td>0.1</td></tr><tr><td>lambda_tasks</td><td>1</td></tr><tr><td>logloss</td><td>6e-05</td></tr><tr><td>lr_0</td><td>0.001</td></tr><tr><td>lr_1</td><td>0.001</td></tr><tr><td>p_f1_max</td><td>0.43963</td></tr><tr><td>p_kappa_max</td><td>0.49352</td></tr><tr><td>policy_lr</td><td>0.001</td></tr><tr><td>roc_auc_score</td><td>0.70067</td></tr><tr><td>sc_loss</td><td>0.04945</td></tr><tr><td>train_layers</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0818_1458</strong>: <a href=\"https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task/runs/sowqiavw\" target=\"_blank\">https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task/runs/sowqiavw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220818_145825-sowqiavw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab259da4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.253924Z",
     "start_time": "2022-03-28T05:13:32.221329Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.best_epoch = 0\n",
    "# from utils.notebook_modules import wrapup_phase\n",
    "# wrapup_phase(ns, opt, environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb718c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.307351Z",
     "start_time": "2022-03-28T05:13:32.262822Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['policy_lr']       = 0.002\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.05\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# # environ.opt['train']['decay_temp_freq'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8accefdf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-12T07:35:36.625Z"
    }
   },
   "outputs": [],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" \n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\\n\") \n",
    "\n",
    "print( f\" current_iters               : {ns.current_iter}   \\n\"\n",
    "       f\" current_epochs              : {ns.current_epoch}  \\n\" \n",
    "       f\" train_total_epochs          : {ns.training_epochs}\\n\" \n",
    "       f\" stop_epoch_training         : {ns.stop_epoch_training}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b05db1",
   "metadata": {},
   "source": [
    "## Post Weight + Policy Training Stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67be2583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:20:45.610411Z",
     "start_time": "2022-08-18T12:20:45.568020Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c289a9c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:21:59.334999Z",
     "start_time": "2022-08-18T12:21:59.301538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "SparseChem\n"
     ]
    }
   ],
   "source": [
    "print(isinstance(environ.networks['mtl-net'], nn.DataParallel))\n",
    "print(environ.opt['backbone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eed489b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:24:06.014379Z",
     "start_time": "2022-08-18T12:24:05.974633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " task1_logits                              torch.Size([6, 2]) \n",
      " task2_logits                              torch.Size([6, 2]) \n",
      " task3_logits                              torch.Size([6, 2]) \n",
      " task4_logits                              torch.Size([6, 2]) \n",
      " task5_logits                              torch.Size([6, 2]) \n",
      " task6_logits                              torch.Size([6, 2]) \n",
      " task7_logits                              torch.Size([6, 2]) \n",
      " task8_logits                              torch.Size([6, 2]) \n",
      " task9_logits                              torch.Size([6, 2]) \n",
      " task10_logits                             torch.Size([6, 2]) \n",
      " backbone.Input_Layer.linear.weight        torch.Size([32000, 4000]) \n",
      " backbone.Input_Layer.linear.bias          torch.Size([4000]) \n",
      " backbone.blocks.0.linear.weight           torch.Size([4000, 4000]) \n",
      " backbone.blocks.0.linear.bias             torch.Size([4000]) \n",
      " backbone.blocks.1.linear.weight           torch.Size([4000, 4000]) \n",
      " backbone.blocks.1.linear.bias             torch.Size([4000]) \n",
      " backbone.blocks.2.linear.weight           torch.Size([4000, 4000]) \n",
      " backbone.blocks.2.linear.bias             torch.Size([4000]) \n",
      " backbone.blocks.3.linear.weight           torch.Size([4000, 4000]) \n",
      " backbone.blocks.3.linear.bias             torch.Size([4000]) \n",
      " backbone.blocks.4.linear.weight           torch.Size([4000, 4000]) \n",
      " backbone.blocks.4.linear.bias             torch.Size([4000]) \n",
      " backbone.blocks.5.linear.weight           torch.Size([4000, 4000]) \n",
      " backbone.blocks.5.linear.bias             torch.Size([4000]) \n",
      " task1_fc1_c0.linear.weight                torch.Size([472, 4000]) \n",
      " task1_fc1_c0.linear.bias                  torch.Size([472]) \n",
      " task2_fc1_c0.linear.weight                torch.Size([624, 4000]) \n",
      " task2_fc1_c0.linear.bias                  torch.Size([624]) \n",
      " task3_fc1_c0.linear.weight                torch.Size([688, 4000]) \n",
      " task3_fc1_c0.linear.bias                  torch.Size([688]) \n",
      " task4_fc1_c0.linear.weight                torch.Size([192, 4000]) \n",
      " task4_fc1_c0.linear.bias                  torch.Size([192]) \n",
      " task5_fc1_c0.linear.weight                torch.Size([620, 4000]) \n",
      " task5_fc1_c0.linear.bias                  torch.Size([620]) \n",
      " task6_fc1_c0.linear.weight                torch.Size([184, 4000]) \n",
      " task6_fc1_c0.linear.bias                  torch.Size([184]) \n",
      " task7_fc1_c0.linear.weight                torch.Size([224, 4000]) \n",
      " task7_fc1_c0.linear.bias                  torch.Size([224]) \n",
      " task8_fc1_c0.linear.weight                torch.Size([148, 4000]) \n",
      " task8_fc1_c0.linear.bias                  torch.Size([148]) \n",
      " task9_fc1_c0.linear.weight                torch.Size([344, 4000]) \n",
      " task9_fc1_c0.linear.bias                  torch.Size([344]) \n",
      " task10_fc1_c0.linear.weight               torch.Size([72, 4000]) \n",
      " task10_fc1_c0.linear.bias                 torch.Size([72]) \n"
     ]
    }
   ],
   "source": [
    "for name, param in environ.networks['mtl-net'].named_parameters():\n",
    "    print(f\" {name:40s}  {param.shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33193377",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:25:02.887603Z",
     "start_time": "2022-08-18T12:25:02.846964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input_Layer.linear.weight                 torch.Size([32000, 4000]) \n",
      " Input_Layer.linear.bias                   torch.Size([4000]) \n",
      " blocks.0.linear.weight                    torch.Size([4000, 4000]) \n",
      " blocks.0.linear.bias                      torch.Size([4000]) \n",
      " blocks.1.linear.weight                    torch.Size([4000, 4000]) \n",
      " blocks.1.linear.bias                      torch.Size([4000]) \n",
      " blocks.2.linear.weight                    torch.Size([4000, 4000]) \n",
      " blocks.2.linear.bias                      torch.Size([4000]) \n",
      " blocks.3.linear.weight                    torch.Size([4000, 4000]) \n",
      " blocks.3.linear.bias                      torch.Size([4000]) \n",
      " blocks.4.linear.weight                    torch.Size([4000, 4000]) \n",
      " blocks.4.linear.bias                      torch.Size([4000]) \n",
      " blocks.5.linear.weight                    torch.Size([4000, 4000]) \n",
      " blocks.5.linear.bias                      torch.Size([4000]) \n"
     ]
    }
   ],
   "source": [
    "for name, param in environ.networks['mtl-net'].backbone.named_parameters():\n",
    "        print(f\" {name:40s}  {param.shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95a6d417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:34:17.484632Z",
     "start_time": "2022-08-18T12:34:17.320204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " task1_fc1_c0.linear.weight                torch.Size([472, 4000]) \n",
      " task1_fc1_c0.linear.bias                  torch.Size([472]) \n",
      " task2_fc1_c0.linear.weight                torch.Size([624, 4000]) \n",
      " task2_fc1_c0.linear.bias                  torch.Size([624]) \n",
      " task3_fc1_c0.linear.weight                torch.Size([688, 4000]) \n",
      " task3_fc1_c0.linear.bias                  torch.Size([688]) \n",
      " task4_fc1_c0.linear.weight                torch.Size([192, 4000]) \n",
      " task4_fc1_c0.linear.bias                  torch.Size([192]) \n",
      " task5_fc1_c0.linear.weight                torch.Size([620, 4000]) \n",
      " task5_fc1_c0.linear.bias                  torch.Size([620]) \n",
      " task6_fc1_c0.linear.weight                torch.Size([184, 4000]) \n",
      " task6_fc1_c0.linear.bias                  torch.Size([184]) \n",
      " task7_fc1_c0.linear.weight                torch.Size([224, 4000]) \n",
      " task7_fc1_c0.linear.bias                  torch.Size([224]) \n",
      " task8_fc1_c0.linear.weight                torch.Size([148, 4000]) \n",
      " task8_fc1_c0.linear.bias                  torch.Size([148]) \n",
      " task9_fc1_c0.linear.weight                torch.Size([344, 4000]) \n",
      " task9_fc1_c0.linear.bias                  torch.Size([344]) \n",
      " task10_fc1_c0.linear.weight               torch.Size([72, 4000]) \n",
      " task10_fc1_c0.linear.bias                 torch.Size([72]) \n"
     ]
    }
   ],
   "source": [
    "for name, param in environ.networks['mtl-net'].named_parameters():\n",
    "    if 'task' in name and 'fc' in name:    \n",
    "        print(f\" {name:40s}  {param.shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9547ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04de4040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:13:33.800419Z",
     "start_time": "2022-08-18T12:13:33.765474Z"
    }
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "# pp.pprint(environ.val_metrics)\n",
    "# environ.num_layers, environ.networks['mtl-net'].num_layers\n",
    "# environ.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ca92e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T16:22:55.037557Z",
     "start_time": "2022-04-05T16:22:54.888980Z"
    }
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e5cec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T17:44:36.218784Z",
     "start_time": "2022-02-21T17:44:36.063411Z"
    }
   },
   "outputs": [],
   "source": [
    "# print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "# environ.display_trained_policy(current_epoch)\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0f60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74828d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1c3a3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:22:20.634818Z",
     "start_time": "2022-01-27T00:22:20.444566Z"
    }
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].backbone.layer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62568b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:30:31.940280Z",
     "start_time": "2022-01-26T19:30:31.910058Z"
    }
   },
   "outputs": [],
   "source": [
    "num_blocks = 6\n",
    "num_policy_layers = 6\n",
    "gt =  torch.ones((num_blocks)).long()\n",
    "gt0 =  torch.zeros((num_blocks)).long()\n",
    "print(gt)\n",
    "print(gt0)\n",
    "\n",
    "loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "print(loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61487657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:42:31.300891Z",
     "start_time": "2022-01-26T19:42:31.257774Z"
    }
   },
   "outputs": [],
   "source": [
    "if environ.opt['diff_sparsity_weights'] and not environ.opt['is_sharing']:\n",
    "    print(' cond 1')\n",
    "    ## Assign higher weights to higher layers \n",
    "    loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "    print(f\"{task_key} sparsity error:  {2 * (loss_weights[-num_blocks:] * environ.cross_entropy2(logits[-num_blocks:], gt)).mean()})\")\n",
    "    print_dbg(f\" loss_weights :  {loss_weights}\", verbose = True)\n",
    "    print_dbg(f\" cross_entropy:  {environ.cross_entropy2(logits[-num_blocks:], gt)}  \", verbose = True)\n",
    "    print_dbg(f\" loss[sparsity][{task_key}]: {self.losses['sparsity'][task_key] } \", verbose = True)\n",
    "\n",
    "else:\n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between \\n Logits   : \\n{logits[-num_blocks:]} \\n and gt: \\n{gt} \\n\", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-num_blocks:], gt)}\")\n",
    "    \n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt[-1:])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt0[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt0[-1:])} \\n\")\n",
    "    \n",
    "    print('\\n cond 3')    \n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt[0:1])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt0[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt0[0:1])} \\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b9e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00d0c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:30.155045Z",
     "start_time": "2022-01-26T00:14:30.107095Z"
    }
   },
   "outputs": [],
   "source": [
    "# flag = 'update_w'\n",
    "# environ.fix_alpha\n",
    "# environ.free_w(opt['fix_BN'])\n",
    "\n",
    "flag = 'update_alpha'\n",
    "environ.fix_weights()\n",
    "environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f5cfcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:31.184285Z",
     "start_time": "2022-01-25T23:43:31.159229Z"
    }
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f717b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:34.993711Z",
     "start_time": "2022-01-26T00:14:34.968623Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") \n",
    "\n",
    "train_total_epochs += 5\n",
    "\n",
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57103a9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Check values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12352a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T10:02:21.600933Z",
     "start_time": "2022-04-28T10:02:21.561452Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\" ns.check_for_improvment_wait:  {ns.check_for_improvment_wait}\")\n",
    "print(\" ns.curriculum_epochs:          {ns.curriculum_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dad034",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T11:09:14.782725Z",
     "start_time": "2022-04-28T11:09:14.692205Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.val_metrics)\n",
    "df = environ.val_metrics['task1']['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27ebed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T11:09:15.186827Z",
     "start_time": "2022-04-28T11:09:15.090906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df[pd.notna(df.roc_auc_score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4e2d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T11:09:44.692326Z",
     "start_time": "2022-04-28T11:09:44.611694Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[pd.notna(df.roc_auc_score)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a1a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:39:22.031664Z",
     "start_time": "2022-06-15T17:39:21.964660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.display_trained_policy(ns.current_epoch,out=[sys.stdout])\n",
    "# environ.num_tasks\n",
    "# print(environ.get_policy_prob().shape)\n",
    "# print(environ.val_data['task1'].keys())\n",
    "# print(environ.val_data['task1']['yc_ind'][0][:40])\n",
    "# print(environ.val_data['task1']['yc_ind'][1][:40])\n",
    "# print(environ.val_data['task1']['yc_data'][:40])\n",
    "# print(environ.val_data['task1']['yc_hat'][:40])\n",
    "# environ.display_trained_policy(ns.current_epoch,out=[sys.stdout])\n",
    "# environ.display_trained_logits(ns.current_epoch,out=[sys.stdout])\n",
    "batch = next(dldrs.warmup_trn_loader)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f163b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:39:22.757684Z",
     "start_time": "2022-06-15T17:39:22.679466Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6662777",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:39:23.282940Z",
     "start_time": "2022-06-15T17:39:23.218734Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(batch['x_ind'].shape)\n",
    "print(batch['x_ind'][:,:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d5dc14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:43:06.352600Z",
     "start_time": "2022-06-15T17:43:06.288637Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(type(batch['x_data']))\n",
    "print(batch['x_data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb9cb34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:39:45.873056Z",
     "start_time": "2022-06-15T17:39:45.812606Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(batch['row_id']))\n",
    "print(batch['row_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08467352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:44:07.505660Z",
     "start_time": "2022-06-15T17:44:07.448666Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(batch['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de083fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T09:25:02.534297Z",
     "start_time": "2022-04-13T09:25:02.503118Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.val_metrics['task1'])\n",
    "pp.pprint(environ.val_metrics)\n",
    "# pp.pprint(ns.val_metrics)\n",
    "# print((environ.val_data['task1']['yc_data']).sum())\n",
    "# print(len(environ.val_data['task1']['yc_ind'][1]))\n",
    "# print(len(environ.val_data['task1']['yc_data']))\n",
    "# print(len(environ.val_data['task1']['yc_hat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90151319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T09:12:32.452187Z",
     "start_time": "2022-04-13T09:12:32.420905Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "type(ns.val_metrics['aggregated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c031eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T08:47:30.057623Z",
     "start_time": "2022-04-13T08:47:29.588103Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(ns.trn_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb45fcf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:31:55.581510Z",
     "start_time": "2022-04-02T13:31:55.526855Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(environ.val_data['task1']['yc_data'][0] == environ.val_data['task1']['yc_data']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02211ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:20:55.327255Z",
     "start_time": "2022-04-02T14:20:55.026238Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.sparsechem_utils import compute_metrics, aggregate_results\n",
    "import pandas\n",
    "cc = compute_metrics(cols   = environ.val_data['task1']['yc_ind'][1], \n",
    "                     y_true = environ.val_data['task1']['yc_data'], \n",
    "                     y_score= environ.val_data['task1']['yc_hat'] ,\n",
    "                     num_tasks=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0a5712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:34:57.196163Z",
     "start_time": "2022-04-02T13:34:57.130013Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " df   = pd.DataFrame({\"task\"   : environ.val_data['task1']['yc_ind'][1], \n",
    "                      \"y_true\" : environ.val_data['task1']['yc_data'],  \n",
    "                      \"y_score\": environ.val_data['task1']['yc_hat']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde23676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:44:52.754320Z",
     "start_time": "2022-04-02T13:44:52.611945Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for task, frame in df.groupby(\"task\", sort=True):\n",
    "    print(f\" task {task}\")\n",
    "    print(frame.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b887a79b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:46:29.715440Z",
     "start_time": "2022-04-02T13:46:29.640674Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df\n",
    "df.groupby(\"task\", sort=True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5862488b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T11:10:20.301689Z",
     "start_time": "2022-04-28T11:10:20.151621Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e466147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:26:58.189057Z",
     "start_time": "2022-04-02T14:26:58.126134Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.batch_data['task1']['yc_aggr_weights'])\n",
    "environ.batch['task1']['aggr_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007f28d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c2 = aggregate_results(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4570a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T17:11:11.578048Z",
     "start_time": "2022-04-02T17:11:11.535763Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dldrs.trainset0.tasks_weights_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32a63e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:47.803657Z",
     "start_time": "2022-03-28T04:02:47.736497Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# environ.opt['train']['policy_lr'] = 0.01\n",
    "# opt['train']['policy_lr']         = 0.01\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.1\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# environ.opt['train']['decay_temp_freq'] = 2\n",
    "# print(environ.optimizers['alphas'].param_groups)\n",
    "# print(environ.optimizers['weights'].param_groups)\n",
    "# print('current lr: ', environ.optimizers['alphas'].param_groups[0]['lr'],)\n",
    "# print('current lr: ', environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "# print('current lr: ', environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82a453",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Post Warm-up Training stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb74c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:45:43.999959Z",
     "start_time": "2022-02-01T12:45:43.862475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b47da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:36.700361Z",
     "start_time": "2022-02-01T12:46:36.367037Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].arch_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f0235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:37:10.158440Z",
     "start_time": "2022-01-28T16:37:09.742327Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p = environ.get_sample_policy(hard_sampling = False)\n",
    "print(p)\n",
    "p = environ.get_policy_prob()\n",
    "print(p)\n",
    "p = environ.get_policy_logits()\n",
    "print(p)\n",
    "\n",
    "# p = environ.get_current_policy()\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bddd44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:40:37.799917Z",
     "start_time": "2022-01-28T16:40:37.773177Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = softmax([0.0, 1])\n",
    "print(a)\n",
    "sampled = np.random.choice((1, 0), p=a)\n",
    "print(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8f376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:13:16.205889Z",
     "start_time": "2022-01-28T16:13:16.179303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.optimizers['weights'])\n",
    "print(environ.schedulers['weights'].get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf9c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:50.411465Z",
     "start_time": "2022-02-01T12:46:50.020540Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('losses.keys      : ', environ.losses.keys())\n",
    "print('losses[task]keys : ', environ.losses['task1'].keys())\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20950069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T22:57:02.151169Z",
     "start_time": "2022-01-15T22:57:02.056562Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print( environ.val_metrics.keys())\n",
    "# pp.pprint(val_metrics)\n",
    "print(type(environ.val_metrics['aggregated']))\n",
    "print()\n",
    "print(type(environ.val_metrics['task1']['classification_agg']))\n",
    "print()\n",
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6e311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.266303Z",
     "start_time": "2022-01-14T18:57:26.166878Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"val_metrics.pkl\", mode= 'wb') as f:\n",
    "#         pickle.dump(val_metrics, f)\n",
    "    \n",
    "# with open('val_metrics.pkl', 'rb') as f:    \n",
    "#     tst_val_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00a8aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.297444Z",
     "start_time": "2022-01-14T18:57:26.269323Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(environ.input.shape) \n",
    "# a = getattr(environ, 'task1_pred')\n",
    "# yc_data = environ.batch['task1_data']\n",
    "# print(yc_data.shape)\n",
    "# yc_ind = environ.batch['task1_ind']\n",
    "# print(yc_ind.shape)\n",
    "# yc_hat_all = getattr(environ, 'task1_pred')\n",
    "# print(yc_hat_all.shape)\n",
    "# yc_hat  = yc_hat_all[yc_ind[0], yc_ind[1]]\n",
    "# print(yc_hat_all.shape, yc_hat.shape)\n",
    "\n",
    "# \n",
    "# environ.losses\n",
    "# loss = {}\n",
    "# for key in environ.losses.keys():\n",
    "#     loss[key] = {}\n",
    "#     for subkey, v in environ.losses[key].items():\n",
    "#         print(f\" key:  {key}   subkey: {subkey} \")\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             loss[key][subkey] = v.data\n",
    "#             print(f\" Tensor  -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "#         else:\n",
    "#             loss[key][subkey] = v\n",
    "#             print(f\" integer -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "# pp.pprint(tst_val_metrics)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987f89f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.340792Z",
     "start_time": "2022-01-14T18:57:26.302528Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print('metrics.keys: ', environ.metrics.keys())\n",
    "# print('metrics[task].keys: ', environ.metrics['task1'].keys())\n",
    "# pp.pprint(environ.metrics['task1'])\n",
    "# pp.pprint(environ.losses['task1']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ae417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.373399Z",
     "start_time": "2022-01-14T18:57:26.345065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# title='Iteration'\n",
    "# for t_id, _ in enumerate(environ.tasks):\n",
    "#     task_key = f\"task{t_id+1}\"\n",
    "# #     print_heading(f\"{title}  {current_iter}  {task_key} : {val_metrics[task_key]['classification_agg']}\", verbose = True)\n",
    "\n",
    "#     for key, _  in val_metrics[task_key]['classification_agg'].items():\n",
    "#         print('%s/%-20s'%(task_key, key), val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print(f\"{task_key:s}/{key:20s}\", val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print()\n",
    "#             # print_current_errors(os.path.join(self.log_dir, 'loss.txt'), current_iter,key, loss[key], time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b73b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:48.162261Z",
     "start_time": "2022-01-07T22:52:48.140423Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.print_loss(current_iter, start_time, metrics = val_metrics['loss'], verbose=True)\n",
    "# print(opt['lambdas'])\n",
    "# p = (opt['lambdas'][0] * environ.losses['tasks']['task1'])\n",
    "# print(p)\n",
    "\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics , title='validation', verbose=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850378b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:47.661019Z",
     "start_time": "2022-01-07T22:52:47.639094Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(current_iter)\n",
    "# print_metrics_cr(current_iter, t1 - t0, None, val_metrics , True)\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics, title='validation', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a80b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:14:58.034384Z",
     "start_time": "2022-01-07T23:14:58.004850Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\" val_metric keys               : {val_metrics.keys()}\")\n",
    "print(f\" loss keys                     : {val_metrics['loss'].keys()}\")\n",
    "print(f\" task1 keys                    : {val_metrics['task1'].keys()}\")\n",
    "print(f\" task1 classification keys     : {val_metrics['task1']['classification'].keys()}\")\n",
    "print(f\" task1 classification_agg keys : {val_metrics['task1']['classification_agg'].keys()}\")\n",
    "print()\n",
    "print(f\" task1                       : {val_metrics['task1']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task2                       : {val_metrics['task2']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task3                       : {val_metrics['task3']['classification_agg']['loss']:5f}\")\n",
    "print(f\" loss                        : {val_metrics['loss']['total']:5f}\")\n",
    "print(f\" train_time                  : {val_metrics['train_time']:2f}\")\n",
    "print(f\" epoch                       : {val_metrics['epoch']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd497e72",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Losses and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66169a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T16:34:44.555617Z",
     "start_time": "2022-02-09T16:34:44.507417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_losses = environ.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb8234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:35:11.758429Z",
     "start_time": "2022-02-10T03:35:11.278211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0301f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:21:49.107793Z",
     "start_time": "2022-02-10T03:21:49.084484Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498b6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:20:32.866010Z",
     "start_time": "2022-02-10T03:20:32.442919Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "pp.pprint(trn_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe30724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:34:21.945701Z",
     "start_time": "2022-02-10T03:34:21.411234Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d81167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:49.364883Z",
     "start_time": "2022-01-27T00:58:49.342931Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['Lambda_sharing'] = 0.5\n",
    "# opt['train']['Lambda_sharing'] = 0.5\n",
    "\n",
    "# environ.opt['train']['policy_lr'] = 0.001\n",
    "# opt['train']['policy_lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73aa06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T01:00:41.996410Z",
     "start_time": "2022-01-26T01:00:41.559006Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.losses.keys()\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ece74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:19:43.683550Z",
     "start_time": "2022-01-08T01:19:43.571450Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = environ.get_loss_dict()\n",
    "print(tmp.keys())\n",
    "pp.pprint(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac0256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:50.458223Z",
     "start_time": "2022-01-27T00:58:50.430889Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(opt['diff_sparsity_weights'])\n",
    "print(opt['is_sharing'])\n",
    "print(opt['diff_sparsity_weights'] and not opt['is_sharing'])\n",
    "print(environ.opt['train']['Lambda_sharing'])\n",
    "print(opt['train']['Lambda_sharing'])\n",
    "print(environ.opt['train']['Lambda_sparsity'])\n",
    "print(opt['train']['Lambda_sparsity'])\n",
    "print(environ.opt['train']['policy_lr'])\n",
    "print(opt['train']['policy_lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2d510",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Policy / Logit stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb628497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:35:14.041577Z",
     "start_time": "2022-02-08T20:35:14.018303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.special          import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eed454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:30.103364Z",
     "start_time": "2022-02-08T20:00:30.068021Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03b5cc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_task_logits(n)` Get logits for task group n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed8b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:56:35.652087Z",
     "start_time": "2022-02-08T20:56:35.327406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task_logits = environ.get_task_logits(1)\n",
    "print(task_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66fa5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_arch_parameters()`: Get last used logits from network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85521e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:31.101960Z",
     "start_time": "2022-02-08T20:00:30.757064Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b0bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:06.054699Z",
     "start_time": "2022-02-09T15:43:05.689327Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea1743",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_logits()`:  Get Policy Logits - returns same as `get_arch_parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb40c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:24.972390Z",
     "start_time": "2022-02-09T15:43:24.636629Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs = environ.get_policy_logits()\n",
    "for i in logs:\n",
    "    print(i, '\\n')\n",
    "# probs = softmax(logs, axis= -1)\n",
    "# for i in probs:\n",
    "#     print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080a364",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_prob()` : Gets the softmax of the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c75af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:29.733732Z",
     "start_time": "2022-02-09T15:43:29.699600Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "for i in policy_softmaxs:\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3160d9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = False)` : Calls test_sample_policy of network with random choices based on softmax of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f411444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:21:15.636722Z",
     "start_time": "2022-02-08T22:21:15.165456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "policies,logits = environ.get_sample_policy(hard_sampling = False)\n",
    "\n",
    "for l, p, s in zip(logits, policies, policy_softmaxs) :\n",
    "    for  l_row, p_row, s_row in zip(l, p, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802664ec",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = True)` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea65bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:59:40.790899Z",
     "start_time": "2022-02-08T20:59:40.726657Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "hard_policies, logits = environ.get_sample_policy(hard_sampling = True)\n",
    "\n",
    "for p,l,s in zip(hard_policies, logits, policy_softmaxs) :\n",
    "    for  p_row, l_row, s_row in zip(p, l, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c39cf",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fe096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:00:47.452220Z",
     "start_time": "2022-02-08T21:00:47.422902Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\" Layer    task 1      task 2      task 3\")\n",
    "print(f\" -----    ------      ------      ------\")\n",
    "for idx, (l1, l2, l3) in enumerate(zip(hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1}       {l2}       {l3}\")\n",
    "    \n",
    "\n",
    "    print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade0ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:39:39.936555Z",
     "start_time": "2022-02-08T22:39:39.911591Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_trained_policy(iter):\n",
    "\n",
    "    policy_softmaxs = environ.get_policy_prob()\n",
    "    policy_argmaxs = 1-np.argmax(policy_softmaxs, axis = -1)\n",
    "    print(f\"  Trained polcies at iteration: {iter} \")\n",
    "    print(f\"                   task 1                           task 2                         task 3        \")\n",
    "    print(f\" Layer       softmax        select          softmax        select          softmax        select   \")\n",
    "    print(f\" -----    ---------------   ------       ---------------   ------       ---------------   ------   \")\n",
    "    for idx, (l1,l2,l3,  p1,p2,p3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2], policy_argmaxs[0], policy_argmaxs[1], policy_argmaxs[2]),1):\n",
    "        print(f\"   {idx}      {l1[0]:.4f}   {l1[1]:.4f}   {p1:4d}    {l2[0]:11.4f}   {l2[1]:.4f}   {p2:4d}    {l3[0]:11.4f}   {l3[1]:.4f}   {p3:4d}\")\n",
    "\n",
    "    print()\n",
    "# print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec208dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:42:12.650813Z",
     "start_time": "2022-02-08T22:42:12.330169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display_trained_policy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec517e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:07:30.836214Z",
     "start_time": "2022-02-08T22:07:30.804575Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"                        POLICIES (SOFTMAX)                                       task 3          \")\n",
    "print(f\" Layer    task1              task2            task3 softmax         softmax         argmax         softmax         argmax   \")\n",
    "print(f\" -----    -------------     -------------     -------------   ------   \")\n",
    "for idx, (l1,l2,l3, h1,h2,h3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2],hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1[0]:.4f} {l1[1]:.4f}     {l2[0]:.4f} {l2[1]:.4f}     {l3[0]:.4f} {l3[1]:.4f}    {h3}\")\n",
    "    \n",
    "print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbeacb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:04:50.757406Z",
     "start_time": "2022-02-08T22:04:50.731736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(policy_softmaxs[2], np.argmax(1-policy_softmaxs[2], axis = -1))\n",
    "print(policy_softmaxs, np.argmax(policy_softmaxs, axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be0240",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_logits()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb7240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:19:06.155425Z",
     "start_time": "2022-02-08T21:19:06.118640Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits  = (environ.get_current_logits())\n",
    "for i in logits:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e84662",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_policy()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cfa24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:40:06.543376Z",
     "start_time": "2022-02-08T20:40:06.230711Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pols  = (environ.get_current_policy())\n",
    "\n",
    "for i in pols:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f556a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T18:27:33.593255Z",
     "start_time": "2022-01-27T18:27:33.553141Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792710e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `gumbel_softmax()`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265490e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:28:17.107529Z",
     "start_time": "2022-02-08T21:28:17.084910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', floatmode = 'maxprec_equal')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb0087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:35:11.617269Z",
     "start_time": "2022-02-08T21:35:11.569599Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.temp)\n",
    "# tau = environ.temp\n",
    "tau = 1\n",
    "for i in range(3): \n",
    "    logits_tensor = torch.tensor(logits[0])\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=tau, hard=False).cpu().numpy() \n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=tau, hard=True).cpu().numpy()\n",
    "    \n",
    "    for l, gs, gh in zip(lgts, gumbel_soft, gumbel_hard):\n",
    "        print(f\"   {l}   \\t {gs}            \\t {gh}\")\n",
    "#     print(lgts)\n",
    "#     print(gumbel_soft)\n",
    "#     print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5ef7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e0e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:21:35.524957Z",
     "start_time": "2022-02-08T21:21:35.488812Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for lgts in logits:\n",
    "    logits_tensor = torch.tensor(lgts)\n",
    "    print(lgts)\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=1, hard=False)\n",
    "    print(gumbel_soft)\n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=1, hard=True)\n",
    "    print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34a06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T20:49:37.643349Z",
     "start_time": "2022-02-03T20:49:37.580786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smax = scipy.special.softmax(logs, axis =1)\n",
    "# smax = np.array( \n",
    "# [[0.46973792, 0.530262  ],\n",
    "#  [0.45025694, 0.549743  ],\n",
    "#  [0.4443086 , 0.5556915 ],\n",
    "#  [0.4138397 , 0.58616036],\n",
    "#  [0.4140113 , 0.5859887 ],\n",
    "#  [0.42114905, 0.57885087]])\n",
    "\n",
    "print(smax.shape)\n",
    "print(smax)\n",
    "print(smax[0])\n",
    "print(smax[0].sum())\n",
    "print(np.random.choice((1,0), p =smax[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7de25c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:15:19.893888Z",
     "start_time": "2022-02-08T21:15:19.870899Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logs = np.array(\n",
    "[[0.33064184, 0.42053092],\n",
    " [0.3532089 , 0.52056104],\n",
    " [0.3888512 , 0.5680909 ],\n",
    " [0.42039296, 0.694217  ],\n",
    " [0.4519742 , 0.73311865],\n",
    " [0.48401102, 0.7522658 ]],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "399px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "888d4fda4588b3bfc9793c8a97c6f83877963bb7385ca7ca0c08738cf63adc49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
