{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408f1261",
   "metadata": {},
   "source": [
    "## Initialization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55604c43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:11.767564Z",
     "start_time": "2022-08-26T19:44:11.734879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0c686b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:13.589047Z",
     "start_time": "2022-08-26T19:44:11.769985Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:08.233990Z",
     "iopub.status.busy": "2022-01-07T22:44:08.233053Z",
     "iopub.status.idle": "2022-01-07T22:44:08.273284Z",
     "shell.execute_reply": "2022-01-07T22:44:08.271908Z",
     "shell.execute_reply.started": "2022-01-07T22:44:08.233943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "# sys.path.insert(0, '/home/kbardool/kusanagi/AdaSparseChem/src') ; print(sys.path)\n",
    "import time\n",
    "import argparse\n",
    "import yaml\n",
    "import types, copy, pprint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from utils import (initialize, init_dataloaders, init_environment, init_wandb, training_initializations, model_initializations, \n",
    "                   check_for_resume_training, disp_dataloader_info, disp_info_1, warmup_phase, weight_policy_training, \n",
    "                   display_gpu_info, init_dataloaders_by_fold_id, print_separator, print_heading, print_underline,\n",
    "                   timestring, print_loss, print_metrics_cr, get_command_line_args, load_from_pickle) \n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "pd.options.display.width = 132\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Train.ipynb\"\n",
    "\n",
    "## Set visible GPU device \n",
    "##----------------------------------------------\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33ac6e",
   "metadata": {},
   "source": [
    "# Initialization and  Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee652c57",
   "metadata": {},
   "source": [
    "### Parse Input Args  - Read YAML config file - wandb initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca1c17d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:13.614943Z",
     "start_time": "2022-08-26T19:44:13.591060Z"
    }
   },
   "outputs": [],
   "source": [
    "# synthetic_config_file  = \"../yamls/chembl_synt_train.yaml\"\n",
    "# config_file      = \"../yamls/chembl_mini_train.yaml\"\n",
    "config_file      = \"../yamls/chembl_cb29_train_1task.yaml\"\n",
    "config_file      = \"../yamls/chembl_cb29_train_10task.yaml\"\n",
    "batch_size=4098\n",
    "# batch_size=2048\n",
    "# RESUME_MODEL_CKPT = 'model_train_ep_25_seed_0088'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4edb398",
   "metadata": {},
   "source": [
    "####   For Resume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c33f25d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:13.647426Z",
     "start_time": "2022-08-26T19:44:13.617704Z"
    }
   },
   "outputs": [],
   "source": [
    "restart_input_args = f\" --config  {config_file} \" \\\n",
    "             f\" --batch_size       {batch_size} \"  \\\n",
    "             \" --exp_desc            10-task warmup with policy training \" \\\n",
    "             \" --hidden_size             4000 4000 4000 4000 4000 4000 \"  \\\n",
    "             \" --warmup_epochs             50 \"  \\\n",
    "             \" --tail_hidden_size        4000 \"  \\\n",
    "             \" --first_dropout           0.80 \"  \\\n",
    "             \" --middle_dropout          0.80 \"  \\\n",
    "             \" --last_dropout            0.80 \"  \\\n",
    "             \" --seed_idx                   0 \"  \\\n",
    "             \" --task_lr                0.001 \"  \\\n",
    "             \" --backbone_lr            0.001 \"  \\\n",
    "             \" --decay_lr_rate            0.5 \"  \\\n",
    "             \" --decay_lr_freq             40 \"  \\\n",
    "             \" --decay_lr_cooldown         10 \"  \\\n",
    "             \" --policy_lr               0.01 \"  \\\n",
    "             \" --policy_decay_lr_rate     0.5 \"  \\\n",
    "             \" --policy_decay_lr_freq      40 \"  \\\n",
    "             \" --policy_decay_lr_cooldown  10 \"  \\\n",
    "             \" --lambda_tasks             1.0 \"  \\\n",
    "             \" --lambda_sparsity        0.001 \"  \\\n",
    "             \" --lambda_sharing          0.05 \"  \\\n",
    "             \" --pytorch_threads            7 \"  \\\n",
    "             \" --cuda_devices               2\"   \\\n",
    "             \" --gpu_ids                    0 \"  \\\n",
    "             \" --resume\"                       \\\n",
    "             \" --resume_path        ../../experiments/AdaSparseChem-cb29-10task/4000x6_0822_1755_lr0.001_do0.8\" \\\n",
    "             \" --resume_ckpt        model_warmup_last_ep_10\" \\\n",
    "             \" --resume_metrics     metrics_warmup_last_ep_10.pickle\" \\\n",
    "             \" --exp_id             1x50t0va\" \\\n",
    "             \" --exp_name           0822_1755 \" \\\n",
    "             \" --folder_sfx         RESUME_2 \"\n",
    "\n",
    "#              \" --resume_ckpt        model_best_model\" \\\n",
    "#              \" --resume_metrics     metrics_best.pickle\" \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68145e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T17:38:07.664270Z",
     "start_time": "2022-06-24T17:38:07.630274Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "source": [
    "####  For Initiating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3a7f00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:13.676412Z",
     "start_time": "2022-08-26T19:44:13.649278Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [],
   "source": [
    "input_args = f\" --config          {config_file} \" \\\n",
    "             f\" --batch_size       {batch_size} \"  \\\n",
    "             \" --exp_desc            10-task warmup with policy training \" \\\n",
    "             \" --exp_desc            10-task with policy training \" \\\n",
    "             \" --hidden_size             4000 4000 4000 4000 4000 4000 \"  \\\n",
    "             \" --tail_hidden_size        4000 \"  \\\n",
    "             \" --warmup_epochs             20 \"  \\\n",
    "             \" --first_dropout           0.70 \"  \\\n",
    "             \" --middle_dropout          0.70 \"  \\\n",
    "             \" --last_dropout            0.70 \"  \\\n",
    "             \" --seed_idx                   0 \"  \\\n",
    "             \" --task_lr                0.001 \"  \\\n",
    "             \" --backbone_lr            0.001 \"  \\\n",
    "             \" --decay_lr_rate            0.5 \"  \\\n",
    "             \" --decay_lr_freq             30 \"  \\\n",
    "             \" --decay_lr_cooldown         10 \"  \\\n",
    "             \" --policy_lr               0.01 \"  \\\n",
    "             \" --policy_decay_lr_rate     0.5 \"  \\\n",
    "             \" --policy_decay_lr_freq      30 \"  \\\n",
    "             \" --policy_decay_lr_cooldown  10 \"  \\\n",
    "             \" --lambda_tasks             1.0 \"  \\\n",
    "             \" --lambda_sparsity        0.001 \"  \\\n",
    "             \" --lambda_sharing          0.05 \"  \\\n",
    "             \" --pytorch_threads            7 \"  \\\n",
    "             \" --cuda_devices               2\"   \\\n",
    "             \" --gpu_ids                    0 \"  \\\n",
    "\n",
    "#              \" --decay_lr_rate       0.3 \"  \\\n",
    "#              \" --decay_lr_freq        10 \"  \\\n",
    "#              \" --policy_lr         0.001 \"  \\\n",
    "#              \" --lambda_sparsity    0.02 \"  \\\n",
    "#              \" --lambda_sharing     0.01 \"  \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ffb30",
   "metadata": {},
   "source": [
    "### Read yaml Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98fcbe87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:13.725658Z",
     "start_time": "2022-08-26T19:44:13.678259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " command line parms : \n",
      "------------------------\n",
      " config...................  ../yamls/chembl_cb29_train_10task.yaml\n",
      " project_name.............  None\n",
      " exp_id...................  31vs18ta\n",
      " exp_name.................  None\n",
      " folder_sfx...............  None\n",
      " exp_desc.................  10-task with policy training\n",
      " hidden_sizes.............  [4000, 4000, 4000, 4000, 4000, 4000]\n",
      " tail_hidden_size.........  [4000]\n",
      " warmup_epochs............  20\n",
      " training_epochs..........  None\n",
      " seed_idx.................  0\n",
      " batch_size...............  4098\n",
      " first_dropout............  0.7\n",
      " middle_dropout...........  0.7\n",
      " last_dropout.............  0.7\n",
      " backbone_lr..............  0.001\n",
      " task_lr..................  0.001\n",
      " policy_lr................  0.01\n",
      " decay_lr_rate............  0.5\n",
      " decay_lr_freq............  30\n",
      " decay_lr_cooldown........  10\n",
      " policy_decay_lr_rate.....  0.5\n",
      " policy_decay_lr_freq.....  30\n",
      " policy_decay_lr_cooldown.  10\n",
      " lambda_tasks.............  1.0\n",
      " lambda_sparsity..........  0.001\n",
      " lambda_sharing...........  0.05\n",
      " cuda_devices.............  2\n",
      " gpu_ids..................  [0]\n",
      " pytorch_threads..........  7\n",
      " skip_residual............  False\n",
      " skip_hidden..............  False\n",
      " resume...................  False\n",
      " resume_path..............  None\n",
      " resume_ckpt..............  None\n",
      " resume_metrics...........  None\n",
      " cpu......................  False\n",
      " min_samples_class........  None\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ns = types.SimpleNamespace()\n",
    "input_args = input_args.split() if input_args is not None else input_args\n",
    "# input_args = restart_input_args.split() \n",
    "ns.args = get_command_line_args(input_args, display = True)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=ns.args.cuda_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d0c6844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:13.753782Z",
     "start_time": "2022-08-26T19:44:13.727705Z"
    }
   },
   "outputs": [],
   "source": [
    "# display_gpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ddaf625",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:18.263356Z",
     "start_time": "2022-08-26T19:44:13.755449Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "################### READ YAML ####################\n",
      "##################################################\n",
      " Pytorch thread count: 20\n",
      " Set Pytorch thread count to : 7\n",
      " Pytorch thread count set to : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkbardool\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kevin/WSL-projs/AdaSparseChem/notebooks/wandb/run-20220826_214414-31vs18ta</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task/runs/31vs18ta\" target=\"_blank\">0826_2144</a></strong> to <a href=\"https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WandB Initialization -----------------------------------------------------------\n",
      " PROJECT NAME: AdaSparseChem-cb29-10Task\n",
      " RUN ID      : 31vs18ta \n",
      " RUN NAME    : 0826_2144\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " log_dir              create folder:  ../../experiments/AdaSparseChem-cb29-10task/4000x6_0826_2144_lr0.001_do0.7\n",
      " result_dir           folder exists:  ../../experiments/AdaSparseChem-cb29-10task/4000x6_0826_2144_lr0.001_do0.7\n",
      " checkpoint_dir       folder exists:  ../../experiments/AdaSparseChem-cb29-10task/4000x6_0826_2144_lr0.001_do0.7\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " experiment name       : 0826_2144 \n",
      " experiment id         : 31vs18ta \n",
      " folder_name           : 4000x6_0826_2144_lr0.001_do0.7 \n",
      " experiment description: 10-task with policy training\n",
      " Random seeds          : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      " Random  seed used     : 88 \n",
      " log folder            : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0826_2144_lr0.001_do0.7\n",
      " checkpoint folder     : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0826_2144_lr0.001_do0.7\n",
      " Gpu ids               : [0]\n",
      " Seed index            : 0\n",
      " policy_iter           : best\n",
      " Data Split ratios     : [0.725, 0.225, 0.05]\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "        project_name : AdaSparseChem-cb29-10Task\n",
      "              exp_id : 31vs18ta\n",
      "        exp_name_pfx : 0826_2144\n",
      "            exp_name : 0826_2144\n",
      "          exp_folder : 4000x6_0826_2144_lr0.001_do0.7\n",
      "     exp_description : 10-task with policy training\n",
      "          folder_sfx : None\n",
      "         random_seed : 88\n",
      "           seed_list : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      "              config : ../yamls/chembl_cb29_train_10task.yaml\n",
      "                 cpu : None\n",
      "             gpu_ids : [0]\n",
      "            backbone : SparseChem\n",
      "               tasks : ['class', 'class', 'class', 'class', 'class', 'class', 'class', 'class', 'class', 'class']\n",
      "     tasks_num_class : [472, 624, 688, 192, 620, 184, 224, 148, 344, 72]\n",
      "             lambdas : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "             verbose : False\n",
      "     input_size_freq : None\n",
      "          input_size : 32000\n",
      "        hidden_sizes : [4000, 4000, 4000, 4000, 4000, 4000]\n",
      "    tail_hidden_size : [4000]\n",
      " first_non_linearity : relu\n",
      "middle_non_linearity : relu\n",
      "  last_non_linearity : relu\n",
      "       first_dropout : 0.7\n",
      "      middle_dropout : 0.7\n",
      "        last_dropout : 0.7\n",
      "   class_output_size : None\n",
      "    regr_output_size : None\n",
      "              policy : True\n",
      "        policy_model : task-specific\n",
      "       skip_residual : False\n",
      "         skip_hidden : False\n",
      "           is_sparse : True\n",
      "diff_sparsity_weights : False\n",
      "          is_sharing : True\n",
      "diff_sharing_weights : False\n",
      "          skip_layer : 0\n",
      "       is_curriculum : False\n",
      "    curriculum_speed : 3\n",
      "              fix_BN : False\n",
      "     retrain_from_pl : False\n",
      "\n",
      "train\n",
      "-----\n",
      "          batch_size : 128\n",
      "       warmup_epochs : 20\n",
      "     training_epochs : 250\n",
      "         total_iters : 25000\n",
      "       warm_up_iters : None\n",
      "             task_lr : 0.001\n",
      "         backbone_lr : 0.001\n",
      "    weight_optimizer : adam\n",
      "    policy_optimizer : adam\n",
      "       decay_lr_rate : 0.5\n",
      "       decay_lr_freq : 30\n",
      "   decay_lr_cooldown : 10\n",
      "           policy_lr : 0.01\n",
      "policy_decay_lr_rate : 0.5\n",
      "policy_decay_lr_freq : 30\n",
      "policy_decay_lr_cooldown : 10\n",
      "     lambda_sparsity : 0.001\n",
      "      lambda_sharing : 0.05\n",
      "        lambda_tasks : 1.0\n",
      "         init_method : random\n",
      "           init_temp : 2.5\n",
      "          decay_temp : 0.75\n",
      "     decay_temp_freq : 3\n",
      "     init_neg_logits : None\n",
      "       hard_sampling : False\n",
      "            val_freq : 500\n",
      "          print_freq : -1\n",
      "warmup_iter_alternate : -1\n",
      "weight_iter_alternate : -1\n",
      "alpha_iter_alternate : -1\n",
      "           val_iters : -1\n",
      "              resume : False\n",
      "      retrain_resume : False\n",
      "         policy_iter : best\n",
      "          which_iter : warmup\n",
      "\n",
      "paths\n",
      "-----\n",
      "             log_dir : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0826_2144_lr0.001_do0.7\n",
      "          result_dir : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0826_2144_lr0.001_do0.7\n",
      "      checkpoint_dir : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0826_2144_lr0.001_do0.7\n",
      "\n",
      "dataload\n",
      "--------\n",
      "             dataset : Chembl29\n",
      "            dataroot : ../../MLDatasets/chembl29_10task\n",
      "                   x : chembl_29_X.npy\n",
      "      x_split_ratios : [0.725, 0.225, 0.05]\n",
      "             folding : chembl_29_folding.npy\n",
      "             y_tasks : ['chembl_29_Y_tg_0_cols_472.npy', 'chembl_29_Y_tg_1_cols_624.npy', 'chembl_29_Y_tg_6_cols_688.npy', 'chembl_29_Y_tg_10_cols_192.npy', 'chembl_29_Y_tg_11_cols_620.npy', 'chembl_29_Y_tg_643_cols_184.npy', 'chembl_29_Y_tg_836_cols_224.npy', 'chembl_29_Y_tg_1005_cols_148.npy', 'chembl_29_Y_tg_1028_cols_344.npy', 'chembl_29_Y_tg_1031_cols_72.npy']\n",
      "            y_censor : None\n",
      "         fold_inputs : 32000\n",
      "     input_transform : None\n",
      "       weights_class : None\n",
      "   min_samples_class : 1\n",
      "           fold_test : [0]\n",
      "             fold_va : [1]\n",
      "         fold_warmup : [2, 3, 4]\n",
      "        fold_weights : [2, 3]\n",
      "         fold_policy : [4]\n",
      "\n",
      "SC\n",
      "--\n",
      "      normalize_loss : None\n",
      "     pytorch_threads : 7\n",
      "            seed_idx : 0\n",
      "         resume_path : None\n",
      "         resume_ckpt : None\n",
      "      resume_metrics : None\n"
     ]
    }
   ],
   "source": [
    "opt = initialize(ns, build_folders = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f8e71cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:18.307415Z",
     "start_time": "2022-08-26T19:44:18.265608Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.wandb_run.finish()\n",
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58caea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T07:40:24.684944Z",
     "start_time": "2022-07-04T07:40:24.654093Z"
    }
   },
   "source": [
    "### Setup Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3a2edeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-28T09:26:45.680489Z",
     "start_time": "2022-08-28T09:26:37.444926Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Warmup folds    : [2, 3, 4]\n",
      " Weights folds   : [2, 3]\n",
      " Policy folds    : [4]\n",
      " Validation folds: [1]\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      " Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      " Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 472  Y rows with populated labels: 21581  non zero cols: 53309\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      " Task 2 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      " Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 624  Y rows with populated labels: 22820  non zero cols: 55015\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      " Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      " Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 688  Y rows with populated labels: 53858  non zero cols: 186792\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      " Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n",
      "\n",
      " Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 192  Y rows with populated labels: 12262  non zero cols: 27798\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n",
      "\n",
      " Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n",
      "\n",
      " Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 620  Y rows with populated labels: 30988  non zero cols: 86678\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      " Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n",
      "\n",
      " Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 184  Y rows with populated labels: 9818  non zero cols: 27152\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n",
      "\n",
      " Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n",
      "\n",
      " Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 224  Y rows with populated labels: 7090  non zero cols: 22638\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      " Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n",
      "\n",
      " Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 148  Y rows with populated labels: 13262  non zero cols: 28925\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      " Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 344  Y rows with populated labels: 20684  non zero cols: 63517\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      " Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n",
      "\n",
      " Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  254529     # Features per Sample: 32000 \n",
      "Y file : # Samples :  254529     # Labels per Sample  : 72  Y rows with populated labels: 4475  non zero cols: 10677\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      " Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      " Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 472  Y rows with populated labels: 15323  non zero cols: 38126\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      " Task 2 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      " Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 624  Y rows with populated labels: 15572  non zero cols: 38310\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      " Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      " Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 688  Y rows with populated labels: 34821  non zero cols: 121231\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      " Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n",
      "\n",
      " Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 192  Y rows with populated labels: 7752  non zero cols: 17657\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n",
      "\n",
      " Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n",
      "\n",
      " Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 620  Y rows with populated labels: 20914  non zero cols: 58596\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      " Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n",
      "\n",
      " Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 184  Y rows with populated labels: 7179  non zero cols: 19397\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n",
      "\n",
      " Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n",
      "\n",
      " Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 224  Y rows with populated labels: 4476  non zero cols: 14840\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      " Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 148  Y rows with populated labels: 8900  non zero cols: 19704\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n",
      "\n",
      " Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      " Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 344  Y rows with populated labels: 12593  non zero cols: 39248\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      " Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n",
      "\n",
      " Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  168649     # Features per Sample: 32000 \n",
      "Y file : # Samples :  168649     # Labels per Sample  : 72  Y rows with populated labels: 2897  non zero cols: 6734\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      " Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      " Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 472  Y rows with populated labels: 6258  non zero cols: 15183\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      " Task 2 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      " Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 624  Y rows with populated labels: 7248  non zero cols: 16705\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      " Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      " Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 688  Y rows with populated labels: 19037  non zero cols: 65561\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      " Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n",
      "\n",
      " Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 192  Y rows with populated labels: 4510  non zero cols: 10141\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n",
      "\n",
      " Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n",
      "\n",
      " Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 620  Y rows with populated labels: 10074  non zero cols: 28082\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      " Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n",
      "\n",
      " Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 184  Y rows with populated labels: 2639  non zero cols: 7755\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n",
      "\n",
      " Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n",
      "\n",
      " Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 224  Y rows with populated labels: 2614  non zero cols: 7798\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      " Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n",
      "\n",
      " Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 148  Y rows with populated labels: 4362  non zero cols: 9221\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n",
      "\n",
      " Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      " Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 344  Y rows with populated labels: 8091  non zero cols: 24269\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      " Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n",
      "\n",
      " Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  85880     # Features per Sample: 32000 \n",
      "Y file : # Samples :  85880     # Labels per Sample  : 72  Y rows with populated labels: 1578  non zero cols: 3943\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      " Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      " Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 472  Y rows with populated labels: 5643  non zero cols: 14167\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      " Task 2 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      " Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 624  Y rows with populated labels: 8661  non zero cols: 20196\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      " Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      " Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 688  Y rows with populated labels: 17973  non zero cols: 61209\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      " Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n",
      "\n",
      " Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 192  Y rows with populated labels: 3776  non zero cols: 8372\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n",
      "\n",
      " Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 620  Y rows with populated labels: 10004  non zero cols: 27223\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      " Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n",
      "\n",
      " Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 184  Y rows with populated labels: 2519  non zero cols: 6085\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n",
      "\n",
      " Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n",
      "\n",
      " Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 224  Y rows with populated labels: 2379  non zero cols: 7992\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      " Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n",
      "\n",
      " Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 148  Y rows with populated labels: 4764  non zero cols: 9313\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n",
      "\n",
      " Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      " Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 344  Y rows with populated labels: 7460  non zero cols: 21553\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      " Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n",
      "\n",
      " Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  86274     # Features per Sample: 32000 \n",
      "Y file : # Samples :  86274     # Labels per Sample  : 72  Y rows with populated labels: 1916  non zero cols: 4391\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      " dataloader preparation - set number of batches per warmup training epoch to: 1989\n",
      " dataloader preparation - set number of batches per weight training epoch to: 1318\n",
      " dataloader preparation - set number of batches per policy training epoch to: 671\n",
      " dataloader preparation - set number of batches per validation to           : 675\n",
      "\n",
      " trainset.y_class                                   :  [(254529, 472), (254529, 624), (254529, 688), (254529, 192), (254529, 620), (254529, 184), (254529, 224), (254529, 148), (254529, 344), (254529, 72)] \n",
      " trainset1.y_class                                  :  [(168649, 472), (168649, 624), (168649, 688), (168649, 192), (168649, 620), (168649, 184), (168649, 224), (168649, 148), (168649, 344), (168649, 72)] \n",
      " trainset2.y_class                                  :  [(85880, 472), (85880, 624), (85880, 688), (85880, 192), (85880, 620), (85880, 184), (85880, 224), (85880, 148), (85880, 344), (85880, 72)] \n",
      " valset.y_class                                     :  [(86274, 472), (86274, 624), (86274, 688), (86274, 192), (86274, 620), (86274, 184), (86274, 224), (86274, 148), (86274, 344), (86274, 72)]  \n",
      "\n",
      "                                Total                :  595332 \n",
      "\n",
      "\n",
      "Training dataset :\n",
      "--------------------\n",
      "  Size of training set 0 (warm up)                   :  254529 \n",
      "  Number of batches in training 0 (warm up)          :  1989 \n",
      "  Size of training set 1 (network parms)             :  168649 \n",
      "  Number of batches in training 1 (network parms)    :  1318 \n",
      "  Size of training set 2 (policy weights)            :  85880 \n",
      "  Number of batches in training 2 (policy weights)   :  671 \n",
      "  training set num of positive                       :  18631 \n",
      "  training set num of negative                       :  107922 \n",
      "  task_weights_list[0].aggregation_weight sum        :  199.0\n",
      "\n",
      "\n",
      "Validation dataset :\n",
      "----------------------\n",
      "  Rows in dataset                                    : 86274\n",
      "  Number of batches in dataset                       : 675\n",
      "  validation set num of positive                     : 18631\n",
      "  validation set num of negative                     : 107922\n",
      "  task_weights_list[0].aggregation_weight sum        : 199.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dldrs = init_dataloaders(opt, verbose = False)\n",
    "dldrs = init_dataloaders_by_fold_id(opt, verbose = False)\n",
    "disp_dataloader_info(dldrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bfa8d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62717fa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:29.144537Z",
     "start_time": "2022-08-26T19:44:25.060427Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      " device is  cuda:0\n",
      "--------------------------------------------------\n",
      " SparseChem_Backbone  Ver: 1.0 Init() Start \n",
      "-------------------------------------------------- \n",
      "\n",
      " layer config        : [1, 1, 1, 1, 1, 1] \n",
      " skip residual layers: False   skip hidden layers  : False\n",
      " SparseChem_BackBone() Input Layer  - Input: 32000  output: 4000  non-linearity:<class 'torch.nn.modules.activation.ReLU'>\n",
      " Hidden layer 0 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.7 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.7 bias: True\n",
      " Hidden layer 1 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.7 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.7 bias: True\n",
      " Hidden layer 2 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.7 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.7 bias: True\n",
      " Hidden layer 3 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.7 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.7 bias: True\n",
      " Hidden layer 4 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.7 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.7 bias: True\n",
      " Final Hidden layer 4 : Input size: 4000   output size:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.7 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.7 bias: True\n",
      " Module List \n",
      "--------------------------------------------------\n",
      " Initialize weights \n",
      "-------------------------------------------------- \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " SparseChem Backbone -- Final configuration(2) : \n",
      "                     self.blocks: <class 'torch.nn.modules.container.ModuleList'>  len:6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "\n",
      " Input_Layer  type:<class 'torch.nn.modules.container.Sequential'>  \n",
      "----------------------------------------------------------------------\n",
      "self.Input_layer\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Layers/Blocks    : <class 'torch.nn.modules.container.ModuleList'>   len:6 \n",
      "Resdiual layers  : <class 'torch.nn.modules.container.ModuleList'>   len:6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 1  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.7, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 1  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 2  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.7, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 2  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 3  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.7, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 3  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 4  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.7, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 4  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 5  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.7, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 5  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 6  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.7, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 6  type:<class 'NoneType'> \n",
      " None\n",
      "\n",
      "\n",
      "\n",
      " SparseChem_Backbone Init() End \n",
      "----------------------------------------------------\n",
      "* SparseChemEnv environment successfully created\n",
      "---------------------------------------------------- \n",
      "\n",
      " \n",
      "\n",
      "SparseChemEnv  Configuration       \n",
      "---------------------------------------- \n",
      "\n",
      "----------------\n",
      "networks       :\n",
      "----------------\n",
      " {'mtl-net': MTL3(\n",
      "  (backbone): SparseChem_Backbone(\n",
      "    (Input_Layer): Sequential(\n",
      "      (linear): SparseLinear(in_features=32000, out_features=4000, bias=True)\n",
      "      (non_linear): ReLU()\n",
      "      (dropout): Dropout(p=0.7, inplace=False)\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.7, inplace=False)\n",
      "      )\n",
      "      (1): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.7, inplace=False)\n",
      "      )\n",
      "      (2): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.7, inplace=False)\n",
      "      )\n",
      "      (3): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.7, inplace=False)\n",
      "      )\n",
      "      (4): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.7, inplace=False)\n",
      "      )\n",
      "      (5): SparseChemBlock(\n",
      "        (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "        (non_linear): ReLU()\n",
      "        (dropout): Dropout(p=0.7, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (residuals): ModuleList(\n",
      "      (0): None\n",
      "      (1): None\n",
      "      (2): None\n",
      "      (3): None\n",
      "      (4): None\n",
      "      (5): None\n",
      "    )\n",
      "  )\n",
      "  (task1_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=472, bias=True)\n",
      "  )\n",
      "  (task2_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=624, bias=True)\n",
      "  )\n",
      "  (task3_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=688, bias=True)\n",
      "  )\n",
      "  (task4_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=192, bias=True)\n",
      "  )\n",
      "  (task5_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=620, bias=True)\n",
      "  )\n",
      "  (task6_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=184, bias=True)\n",
      "  )\n",
      "  (task7_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=224, bias=True)\n",
      "  )\n",
      "  (task8_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=148, bias=True)\n",
      "  )\n",
      "  (task9_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=344, bias=True)\n",
      "  )\n",
      "  (task10_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=4000, out_features=72, bias=True)\n",
      "  )\n",
      ")}\n",
      "\n",
      "----------------\n",
      "optimizers     :\n",
      "----------------\n",
      " {}\n",
      "\n",
      "----------------\n",
      "schedulers     :\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "environ = init_environment(ns, opt, is_train = True, display_cfg = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d738062",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Initiate / Resume Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba16a95c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:29.178512Z",
     "start_time": "2022-08-26T19:44:29.146770Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt['train']['which_iter'] :  warmup\n",
      "##################################################\n",
      "######## Initiate Training from scratch  #########\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "check_for_resume_training(ns, opt, environ, epoch = 0 , iter = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278d6d1",
   "metadata": {},
   "source": [
    "# Warmup Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa99797",
   "metadata": {},
   "source": [
    "### Warmup Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f8a21db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:29.463836Z",
     "start_time": "2022-08-26T19:44:29.211211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model optimizers defined . . . policy_learning: False\n",
      " Model schedulers defined . . . policy_learning: False\n",
      " Metrics CSV file header written . . . \n",
      " Model initializations complete . . . \n",
      " training preparation: - check for CUDA - cuda available as device id: [0]\n",
      "sparsechem_env.cuda()\n",
      " training preparation: - set print_freq to                                 : 1989 \n",
      " training preparation: - set number of batches per warmup training epoch to: 1000\n",
      " training preparation: - set number of batches per weight training epoch to: 750\n",
      " training preparation: - set number of batches per policy training epoch to: 250\n",
      " training preparation: - set number of batches per validation to           : 250\n",
      " training preparation complete . . .\n"
     ]
    }
   ],
   "source": [
    "model_initializations(ns, opt, environ, phase = 'update_weights', policy_learning = False)\n",
    "training_initializations(ns, opt, environ, dldrs, warmup_iterations = 1000, weight_iterations = 750, policy_iterations = 250, eval_iterations = 250, warmup = True)\n",
    "\n",
    "# training_initializations(ns, opt, environ, dldrs, warmup_iterations = 2, eval_iterations = 2, warmup = True)\n",
    "# training_initializations(ns, opt, environ, dldrs, warmup = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e7ce6a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:29.498531Z",
     "start_time": "2022-08-26T19:44:29.465536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Num_blocks                : 6                                \n",
      "\n",
      " batch size                : 128 \n",
      " # batches / Warmup epoch  : 750 \n",
      " # batches / Weight epoch  : 750 \n",
      " # batches / Policy epoch  : 250                                 \n",
      "\n",
      " Print Frequency           : -1 \n",
      " Config Val Frequency      : 500 \n",
      " Config Val Iterations     : 675 \n",
      " Val iterations            : 250 \n",
      " which_iter                : warmup \n",
      " train_resume              : False                                 \n",
      " \n",
      " fix BN parms              : False \n",
      " Task LR                   : 0.001 \n",
      " Backbone LR               : 0.001                                 \n",
      "\n",
      " Sharing  regularization   : 0.05 \n",
      " Sparsity regularization   : 0.001 \n",
      " Task     regularization   : 1.0                                 \n",
      "\n",
      " Current epoch             : 0  \n",
      " Warm-up epochs            : 20 \n",
      " Training epochs           : 250\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    folder: 4000x6_0826_2144_lr0.001_do0.7\n",
      "    layers: 6 [4000, 4000, 4000, 4000, 4000, 4000] \n",
      "    \n",
      "    first dropout          : 0.7\n",
      "    middle dropout         : 0.7\n",
      "    last dropout           : 0.7\n",
      "    diff_sparsity_weights  : False\n",
      "    skip_layer             : 0\n",
      "    is_curriculum          : False\n",
      "    curriculum_speed       : 3\n",
      "    \n",
      "    task_lr                : 0.001\n",
      "    backbone_lr            : 0.001\n",
      "    decay_lr_rate          : 0.5\n",
      "    decay_lr_freq          : 30\n",
      "    \n",
      "    policy_lr              : 0.01\n",
      "    policy_decay_lr_rate   : 0.5\n",
      "    policy_decay_lr_freq   : 30\n",
      "    lambda_sparsity        : 0.001\n",
      "    lambda_sharing         : 0.05\n",
      "    lambda_tasks           : 1.0\n",
      "    \n",
      "    Gumbel init_temp       : 2.5\n",
      "    Gumbel decay_temp      : 0.75\n",
      "    Gumbel decay_temp_freq : 3\n",
      "    Logit init_method      : random\n",
      "    Logit init_neg_logits  : None\n",
      "    Logit hard_sampling    : False\n",
      "    Warm-up epochs         : 20\n",
      "    training epochs        : 250\n",
      "    Data split ratios      : [0.725, 0.225, 0.05]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print('-'*80)\n",
    "disp_info_1(ns, opt, environ)\n",
    "print('-'*80)\n",
    "print(environ.disp_for_excel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33100539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:29.523723Z",
     "start_time": "2022-08-26T19:44:29.500199Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# environ.display_trained_logits(ns.current_epoch,out=sys.stdout) \n",
    "# environ.display_trained_policy(ns.current_epoch,out=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73de409d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:44:29.555158Z",
     "start_time": "2022-08-26T19:44:29.525698Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "1000\n",
      "750\n",
      "250\n",
      "------------------------------------------------------------------------\n",
      " Last Epoch: 0   # of warm-up epochs to do:  20 - Run epochs 1 to 20\n",
      "------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ns.eval_iters = 250\n",
    "# ns.trn_iters_warmup = 750\n",
    "# ns.eval_iters = 2\n",
    "# ns.trn_iters_warmup = 2\n",
    "print(ns.eval_iters )\n",
    "print(ns.trn_iters_warmup)\n",
    "print(ns.trn_iters_weights)\n",
    "print(ns.trn_iters_policy)\n",
    "\n",
    "# ns.check_for_improvment_wait = 0\n",
    "# ns.current_epoch =0 \n",
    "# ns.write_checkpoint = False\n",
    "print_heading(f\" Last Epoch: {ns.current_epoch}   # of warm-up epochs to do:  {ns.warmup_epochs} - Run epochs {ns.current_epoch+1} to {ns.current_epoch + ns.warmup_epochs}\", verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f7eb2",
   "metadata": {},
   "source": [
    "### Warmup Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bd29e74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T23:25:07.914933Z",
     "start_time": "2022-08-26T22:14:00.229478Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      " Last Epoch: 40   # of warm-up epochs to do:  20 - Run epochs 41 to 60\n",
      "-------------------------------------------------------------------------- \n",
      "\n",
      " Ep  | Trunk LR  Heads LR  Polcy LR  Gmbl Tmp |  trn tsk    trn spar    trn shar   trn ttl |    logloss   bceloss  avg prec    aucroc     aucpr    f1_max |  val tsk    val spar    val shar     total |  time |   \n",
      "  41 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.3877   5.415e-05   1.081e-04    1.3879 |  1.144e-05   0.48170   0.68711   0.75195   0.66377   0.72837 |   2.1953   6.780e-05   1.353e-04    2.1955 | 297.0 |\n",
      "  42 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.7095   5.415e-05   1.081e-04    1.7097 |  1.134e-05   0.48116   0.69207   0.75059   0.67056   0.72807 |   2.1722   5.415e-05   1.081e-04    2.1724 | 292.7 |   \n",
      "  43 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   2.1004   5.415e-05   1.081e-04    2.1006 |  1.132e-05   0.47564   0.68530   0.75445   0.66369   0.72221 |   2.1754   5.415e-05   1.081e-04    2.1755 | 270.8 |   \n",
      "  44 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.8141   5.415e-05   1.081e-04    1.8142 |  1.135e-05   0.48183   0.69244   0.75264   0.67006   0.72815 |   2.1784   6.780e-05   1.353e-04    2.1786 | 246.8 |   \n",
      "  45 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.5935   5.415e-05   1.081e-04    1.5937 |  1.127e-05   0.47762   0.69102   0.75522   0.66967   0.72520 |   2.1811   5.415e-05   1.081e-04    2.1813 | 244.0 |   \n",
      "  46 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.6991   5.415e-05   1.081e-04    1.6993 |  1.131e-05   0.47930   0.69013   0.75695   0.66809   0.72810 |   2.1556   6.780e-05   1.353e-04    2.1558 | 226.3 |   \n",
      "  47 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.5153   5.415e-05   1.081e-04    1.5155 |  1.132e-05   0.47832   0.68651   0.75034   0.66544   0.72097 |   2.1846   5.415e-05   1.081e-04    2.1848 | 189.9 |   \n",
      "  48 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.4107   5.415e-05   1.081e-04    1.4108 |  1.137e-05   0.48051   0.68596   0.75092   0.66482   0.72218 |   2.1748   5.415e-05   1.081e-04    2.1749 | 193.0 |   \n",
      "  49 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.6498   5.415e-05   1.081e-04    1.6499 |  1.119e-05   0.47876   0.69118   0.75137   0.66860   0.72664 |   2.1556   6.780e-05   1.353e-04    2.1558 | 191.6 |   \n",
      "  50 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.3064   5.415e-05   1.081e-04    1.3065 |  1.139e-05   0.48353   0.68862   0.75497   0.66644   0.72557 |   2.1839   5.415e-05   1.081e-04    2.1841 | 192.4 |   \n",
      "  51 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.6050   5.415e-05   1.081e-04    1.6052 |  1.124e-05   0.47658   0.69011   0.75514   0.66810   0.72660 |   2.1665   5.415e-05   1.081e-04    2.1667 | 194.2 |   \n",
      "  52 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.5041   5.415e-05   1.081e-04    1.5042 |  1.129e-05   0.47840   0.69594   0.75668   0.67349   0.73183 |   2.1647   6.780e-05   1.353e-04    2.1649 | 193.2 |   \n",
      "  53 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.9302   5.415e-05   1.081e-04    1.9303 |  1.133e-05   0.48420   0.68657   0.75047   0.66363   0.72289 |   2.1710   5.415e-05   1.081e-04    2.1711 | 190.2 |   \n",
      "  54 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.3382   5.415e-05   1.081e-04    1.3384 |  1.136e-05   0.47797   0.68241   0.74991   0.66036   0.72117 |   2.1859   6.780e-05   1.353e-04    2.1861 | 189.4 |   \n",
      "  55 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.7637   5.415e-05   1.081e-04    1.7638 |  1.127e-05   0.48085   0.68032   0.74540   0.65857   0.71845 |   2.1631   5.415e-05   1.081e-04    2.1632 | 190.5 |   \n",
      "  56 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.7984   5.415e-05   1.081e-04    1.7985 |  1.130e-05   0.47421   0.69159   0.75167   0.67094   0.72667 |   2.1788   5.415e-05   1.081e-04    2.1790 | 195.8 |   \n",
      "  57 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.6017   5.415e-05   1.081e-04    1.6019 |  1.131e-05   0.47783   0.69039   0.75002   0.66619   0.72725 |   2.1717   6.780e-05   1.353e-04    2.1719 | 190.3 |   \n",
      "  58 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   2.3722   5.415e-05   1.081e-04    2.3723 |  1.131e-05   0.47711   0.68475   0.74865   0.66278   0.72218 |   2.1914   5.415e-05   1.081e-04    2.1916 | 189.7 |   \n",
      "  59 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.5126   5.415e-05   1.081e-04    1.5128 |  1.130e-05   0.47850   0.68702   0.75091   0.66620   0.72221 |   2.1654   5.415e-05   1.081e-04    2.1656 | 191.2 |   \n",
      "  60 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.1585   5.415e-05   1.081e-04    1.1586 |  1.123e-05   0.47535   0.69222   0.75139   0.66947   0.72744 |   2.1407   6.780e-05   1.353e-04    2.1409 | 191.4 |   \n",
      " save warmup checkpoint  to :  model_warmup_last_ep_60\n",
      " save warmup metrics to     :  metrics_warmup_last_ep_60.pickle\n",
      "[Final] ep:60  it:60000 -  Total Loss: 2.1409     \n",
      "Task: 2.1407   Sparsity: 6.77984e-05    Sharing: 1.35281e-04 \n",
      "\n",
      " ep:   60   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.0008   -0.0005  1    0.0013    0.0009  1   -0.0001    0.0017  0    0.0017   -0.0002  1    0.0005   -0.0006  1    0.0003   -0.0005  1    0.0010    0.0008  1   -0.0007    0.0006  0    0.0002   -0.0007  1   -0.0003   -0.0013  1\n",
      "  1    0.0004   -0.0003  1   -0.0003    0.0003  0   -0.0009    0.0003  0   -0.0003    0.0010  0    0.0009    0.0000  1   -0.0004   -0.0005  1    0.0012    0.0008  1   -0.0003    0.0020  0    0.0006    0.0001  1   -0.0008    0.0009  0\n",
      "  2    0.0008    0.0018  0   -0.0011   -0.0003  0    0.0016   -0.0010  1   -0.0006   -0.0006  1    0.0016    0.0012  1   -0.0001   -0.0008  1   -0.0016   -0.0004  0   -0.0009   -0.0008  0    0.0006   -0.0002  1   -0.0011    0.0007  0\n",
      "  3   -0.0002    0.0012  0   -0.0003   -0.0002  0    0.0008   -0.0003  1   -0.0006    0.0009  0    0.0011    0.0002  1   -0.0008   -0.0014  1   -0.0004   -0.0001  0    0.0009   -0.0021  1   -0.0006    0.0000  0    0.0001   -0.0002  1\n",
      "  4   -0.0013    0.0009  0    0.0003   -0.0003  1    0.0020    0.0008  1   -0.0016    0.0009  0    0.0006    0.0003  1   -0.0002    0.0004  0   -0.0010    0.0009  0   -0.0015    0.0003  0    0.0011   -0.0021  1   -0.0013   -0.0008  0\n",
      "  5   -0.0001   -0.0014  1   -0.0003    0.0013  0    0.0008   -0.0012  1    0.0001   -0.0004  1   -0.0005   -0.0010  1    0.0007    0.0004  1    0.0000   -0.0005  1   -0.0009    0.0001  0    0.0006   -0.0006  1   -0.0011    0.0001  0\n",
      "\n",
      "\n",
      " ep:   60    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.5003    0.4997  -    0.5001    0.4999  -    0.4996    0.5004  -    0.5005    0.4995  -    0.5003    0.4997  -    0.5002    0.4998  -    0.5000    0.5000  -    0.4997    0.5003  -    0.5002    0.4998  -    0.5003    0.4997  -\n",
      "  1    0.5002    0.4998  -    0.4999    0.5001  -    0.4997    0.5003  -    0.4997    0.5003  -    0.5002    0.4998  -    0.5000    0.5000  -    0.5001    0.4999  -    0.4994    0.5006  -    0.5001    0.4999  -    0.4996    0.5004  -\n",
      "  2    0.4997    0.5003  -    0.4998    0.5002  -    0.5006    0.4994  -    0.5000    0.5000  -    0.5001    0.4999  -    0.5002    0.4998  -    0.4997    0.5003  -    0.5000    0.5000  -    0.5002    0.4998  -    0.4996    0.5004  -\n",
      "  3    0.4996    0.5004  -    0.5000    0.5000  -    0.5003    0.4997  -    0.4996    0.5004  -    0.5002    0.4998  -    0.5002    0.4998  -    0.4999    0.5001  -    0.5008    0.4992  -    0.4998    0.5002  -    0.5001    0.4999  -\n",
      "  4    0.4994    0.5006  -    0.5001    0.4999  -    0.5003    0.4997  -    0.4994    0.5006  -    0.5001    0.4999  -    0.4999    0.5001  -    0.4995    0.5005  -    0.4995    0.5005  -    0.5008    0.4992  -    0.4999    0.5001  -\n",
      "  5    0.5003    0.4997  -    0.4996    0.5004  -    0.5005    0.4995  -    0.5001    0.4999  -    0.5001    0.4999  -    0.5001    0.4999  -    0.5001    0.4999  -    0.4997    0.5003  -    0.5003    0.4997  -    0.4997    0.5003  -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warmup_phase(ns,opt, environ, dldrs, epochs = 20, verbose = False, disable_tqdm = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1c6e1c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T05:54:12.374923Z",
     "start_time": "2022-08-27T05:54:12.334967Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'policy': 0.00020307948580011725,\n",
      "    'task': 2.140690733723222,\n",
      "    'total': 2.140893813209022,\n",
      "    'total_mean': nan}\n",
      "2.140893813209022\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(environ.val_metrics['total'])\n",
    "print(environ.val_metrics['total']['task'] + environ.val_metrics['total']['policy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a605c58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T05:54:14.644861Z",
     "start_time": "2022-08-27T05:54:14.561616Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  60 | 1.00e-03  1.00e-03  1.00e-02  2.50e+00 |   1.1585   5.415e-05   1.081e-04    1.1586 |  1.123e-05   0.47535   0.69222   0.75139   0.66947   0.72744 |   2.1407   6.780e-05   1.353e-04    2.1409 |  -0.0 |\n",
      "[e] Last ep:60  it:60000  -  Total Loss: 2.1409     \n",
      "Task: 2.1407   Sparsity: 6.77984e-05    Sharing: 1.35281e-04 \n"
     ]
    }
   ],
   "source": [
    "print_metrics_cr(ns.current_epoch,  time.time() - time.time() , ns.trn_losses, ns.val_metrics, 1, out=[sys.stdout, environ.log_file]) \n",
    "print_loss(ns.val_metrics, title = f\"[e] Last ep:{ns.current_epoch}  it:{ns.current_iter} \")\n",
    "\n",
    "# print()\n",
    "# environ.display_trained_logits(ns.current_epoch)\n",
    "# environ.display_trained_policy(ns.current_epoch)\n",
    "# environ.display_current_policy(ns.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b025642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7862099d",
   "metadata": {},
   "source": [
    "### End WandB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "952bb1e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T18:38:29.974583Z",
     "start_time": "2022-08-26T18:38:25.641511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_pr</td><td></td></tr><tr><td>avg_prec_score</td><td></td></tr><tr><td>bceloss</td><td></td></tr><tr><td>best_accuracy</td><td></td></tr><tr><td>best_epoch</td><td></td></tr><tr><td>best_iter</td><td></td></tr><tr><td>best_roc_auc</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>f1_max</td><td></td></tr><tr><td>gumbel_temp</td><td></td></tr><tr><td>kappa</td><td></td></tr><tr><td>kappa_max</td><td></td></tr><tr><td>lambda_sharing</td><td></td></tr><tr><td>lambda_sparsity</td><td></td></tr><tr><td>lambda_tasks</td><td></td></tr><tr><td>logloss</td><td></td></tr><tr><td>lr_0</td><td></td></tr><tr><td>lr_1</td><td></td></tr><tr><td>p_f1_max</td><td></td></tr><tr><td>p_kappa_max</td><td></td></tr><tr><td>policy_lr</td><td></td></tr><tr><td>roc_auc_score</td><td></td></tr><tr><td>sc_loss</td><td></td></tr><tr><td>train_layers</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_pr</td><td>0.57</td></tr><tr><td>avg_prec_score</td><td>0.59695</td></tr><tr><td>bceloss</td><td>0.54252</td></tr><tr><td>best_roc_auc</td><td>0.65833</td></tr><tr><td>epoch</td><td>60</td></tr><tr><td>f1_max</td><td>0.66896</td></tr><tr><td>gumbel_temp</td><td>2.5</td></tr><tr><td>kappa</td><td>0.09138</td></tr><tr><td>kappa_max</td><td>0.38178</td></tr><tr><td>lambda_sharing</td><td>0.05</td></tr><tr><td>lambda_sparsity</td><td>0.001</td></tr><tr><td>lambda_tasks</td><td>0.05</td></tr><tr><td>logloss</td><td>0.0</td></tr><tr><td>lr_0</td><td>0.001</td></tr><tr><td>lr_1</td><td>0.001</td></tr><tr><td>p_f1_max</td><td>0.40048</td></tr><tr><td>p_kappa_max</td><td>0.44566</td></tr><tr><td>policy_lr</td><td>0.01</td></tr><tr><td>roc_auc_score</td><td>0.65276</td></tr><tr><td>sc_loss</td><td>0.0005</td></tr><tr><td>train_layers</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0826_0848</strong>: <a href=\"https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task/runs/25ock6on\" target=\"_blank\">https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task/runs/25ock6on</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220826_084801-25ock6on/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ns.wandb_run.finish()\n",
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c03a5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Some data peeks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "146a7fde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T16:43:04.282818Z",
     "start_time": "2022-08-16T16:43:04.246814Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011841206578537822\n",
      "2.362737723160535e-05\n",
      "0.0012077480350853875\n",
      "{   'task1': 0.22806914488911734,\n",
      "    'task10': 0.07729441115807154,\n",
      "    'task2': 0.2615806116049444,\n",
      "    'task3': 0.6873060537261522,\n",
      "    'task4': 0.1177855923062318,\n",
      "    'task5': 0.352459824837004,\n",
      "    'task6': 0.08289676805336933,\n",
      "    'task7': 0.1123096017483592,\n",
      "    'task8': 0.17276770787165321,\n",
      "    'task9': 0.2891627654132546,\n",
      "    'total': 2.381632481608156}\n",
      "{   'policy': 0.0012077480350853875,\n",
      "    'task': 2.381632481608156,\n",
      "    'total': 2.3828402296432416,\n",
      "    'total_mean': nan}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(environ.val_metrics['sparsity']['total'])\n",
    "pp.pprint(environ.val_metrics['sharing']['total'])\n",
    "pp.pprint(environ.val_metrics['sharing']['total'] +environ.val_metrics['sparsity']['total'])\n",
    "pp.pprint(environ.val_metrics['task'])\n",
    "pp.pprint(environ.val_metrics['total'])\n",
    "pp.pprint(environ.val_metrics['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ffbb96d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T07:56:30.866019Z",
     "start_time": "2022-08-16T07:56:30.793987Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258.0\n",
      "[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "1          0.637037  0.778888        0.793752  0.789474  0.705071  0.000000   0.363636     0.752714  0.670283\n",
      "2          0.333333  0.381494        0.431970  0.685714  0.284085  0.000000   0.083333     0.284085  0.767408\n",
      "3          0.380952  0.093922        0.132289  0.240000  0.011812  0.000000   0.030303     0.030620  0.519829\n",
      "4          0.895785  0.940747        0.941210  0.911290  0.772889  0.473859   0.707979     0.772889  0.391612\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "619             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "620        0.826667  0.939015        0.940316  0.869565  0.742233  0.119171   0.603113     0.742233  0.439226\n",
      "621        0.913043  0.831354        0.841654  0.800000  0.472201  0.615094   0.686347     0.472201  0.456259\n",
      "622        0.763441  0.152862        0.239057  0.428571  0.045218  0.000000   0.336585     0.045218  0.305232\n",
      "623             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[624 rows x 9 columns]\n",
      "{'roc_auc_score': 0.7264691601690758, 'auc_pr': 0.63870543071269, 'avg_prec_score': 0.651959703396813, 'f1_max': 0.6954697552654789, 'p_f1_max': 0.368966169476639, 'kappa': 0.18080473130459035, 'kappa_max': 0.4420930648311257, 'p_kappa_max': 0.4361852161052038, 'bceloss': 0.5201728982316662, 'sc_loss': 0.00038752683200732503, 'logloss': 3.983986895807737e-06}\n",
      " wsum: 258.0   df.shape: (624, 9)   df2: (624, 9)  df2.sum(axis=0): \n",
      " roc_auc_score     258.0\n",
      "auc_pr            258.0\n",
      "avg_prec_score    258.0\n",
      "f1_max            258.0\n",
      "p_f1_max          258.0\n",
      "kappa             258.0\n",
      "kappa_max         258.0\n",
      "p_kappa_max       258.0\n",
      "bceloss           258.0\n",
      "dtype: float64\n",
      "\n",
      "  DIVISOR \n",
      "-----------\n",
      "roc_auc_score     0.003876\n",
      "auc_pr            0.003876\n",
      "avg_prec_score    0.003876\n",
      "f1_max            0.003876\n",
      "p_f1_max          0.003876\n",
      "kappa             0.003876\n",
      "kappa_max         0.003876\n",
      "p_kappa_max       0.003876\n",
      "bceloss           0.003876\n",
      "dtype: float64\n",
      "\n",
      "  DF \n",
      "------\n",
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "1          0.637037  0.778888        0.793752  0.789474  0.705071  0.000000   0.363636     0.752714  0.670283\n",
      "2          0.333333  0.381494        0.431970  0.685714  0.284085  0.000000   0.083333     0.284085  0.767408\n",
      "3          0.380952  0.093922        0.132289  0.240000  0.011812  0.000000   0.030303     0.030620  0.519829\n",
      "4          0.895785  0.940747        0.941210  0.911290  0.772889  0.473859   0.707979     0.772889  0.391612\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "619             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "620        0.826667  0.939015        0.940316  0.869565  0.742233  0.119171   0.603113     0.742233  0.439226\n",
      "621        0.913043  0.831354        0.841654  0.800000  0.472201  0.615094   0.686347     0.472201  0.456259\n",
      "622        0.763441  0.152862        0.239057  0.428571  0.045218  0.000000   0.336585     0.045218  0.305232\n",
      "623             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[624 rows x 9 columns]\n",
      "\n",
      "  DF2 \n",
      "-------\n",
      "      roc_auc_score  auc_pr  avg_prec_score  f1_max  p_f1_max  kappa  kappa_max  p_kappa_max  bceloss\n",
      "task                                                                                                 \n",
      "0               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "1               0.0     0.0             0.0     0.0       0.0    0.0        0.0          0.0      0.0\n",
      "2               0.0     0.0             0.0     0.0       0.0    0.0        0.0          0.0      0.0\n",
      "3               0.0     0.0             0.0     0.0       0.0    0.0        0.0          0.0      0.0\n",
      "4               1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "...             ...     ...             ...     ...       ...    ...        ...          ...      ...\n",
      "619             NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "620             1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "621             1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "622             0.0     0.0             0.0     0.0       0.0    0.0        0.0          0.0      0.0\n",
      "623             NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "\n",
      "[624 rows x 9 columns]\n",
      "\n",
      "  RESULT \n",
      "----------\n",
      "roc_auc_score     0.726469\n",
      "auc_pr            0.638705\n",
      "avg_prec_score    0.651960\n",
      "f1_max            0.695470\n",
      "p_f1_max          0.368966\n",
      "kappa             0.180805\n",
      "kappa_max         0.442093\n",
      "p_kappa_max       0.436185\n",
      "bceloss           0.520173\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from utils             import censored_mse_loss, censored_mae_loss, aggregate_results\n",
    "task_key = 'task2'\n",
    "print(environ.val_data[task_key]['yc_aggr_weights'].sum())\n",
    "print(environ.val_data[task_key]['yc_aggr_weights'])\n",
    "print(environ.val_metrics[task_key]['classification'])\n",
    "# print(environ.val_metrics[task_key]['classification'].sum())\n",
    "print(environ.val_metrics[task_key]['classification_agg'])\n",
    "# print(environ.val_data[task_key]['yc_aggr_weights'])\n",
    "# print((environ.batch_data[task_key]['yc_aggr_weights']==environ.val_data[task_key]['yc_aggr_weights']).all())\n",
    "\n",
    "\n",
    "tmp = aggregate_results(environ.val_metrics[task_key][\"classification\"], \n",
    "                      environ.val_data[task_key]['yc_aggr_weights'],\n",
    "                      verbose = True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ed7b40c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T07:17:18.629009Z",
     "start_time": "2022-08-16T07:17:18.396695Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'con' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_942638/1987916288.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# del all_tgs, all_tgs2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcon2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'con' is not defined"
     ]
    }
   ],
   "source": [
    "# del all_tgs, all_tgs2\n",
    "del con,con2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d52214fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T07:20:29.718039Z",
     "start_time": "2022-08-16T07:20:29.611094Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 task1  shape:  (472,) classifiaction: (472, 9)\n",
      "roc_auc_score     293.0\n",
      "auc_pr            293.0\n",
      "avg_prec_score    293.0\n",
      "f1_max            293.0\n",
      "p_f1_max          293.0\n",
      "kappa             293.0\n",
      "kappa_max         293.0\n",
      "p_kappa_max       293.0\n",
      "bceloss           293.0\n",
      "dtype: float64\n",
      "initialize (472,) (472, 9)\n",
      "2 task2  shape:  (624,) classifiaction: (624, 9)\n",
      "roc_auc_score     386.0\n",
      "auc_pr            386.0\n",
      "avg_prec_score    386.0\n",
      "f1_max            386.0\n",
      "p_f1_max          386.0\n",
      "kappa             386.0\n",
      "kappa_max         386.0\n",
      "p_kappa_max       386.0\n",
      "bceloss           386.0\n",
      "dtype: float64\n",
      "concatenate:  task2      (1096,) (1096, 9)\n",
      "3 task3  shape:  (688,) classifiaction: (688, 9)\n",
      "roc_auc_score     610.0\n",
      "auc_pr            610.0\n",
      "avg_prec_score    610.0\n",
      "f1_max            610.0\n",
      "p_f1_max          610.0\n",
      "kappa             610.0\n",
      "kappa_max         610.0\n",
      "p_kappa_max       610.0\n",
      "bceloss           610.0\n",
      "dtype: float64\n",
      "concatenate:  task3      (1784,) (1784, 9)\n",
      "4 task4  shape:  (192,) classifiaction: (192, 9)\n",
      "roc_auc_score     143.0\n",
      "auc_pr            143.0\n",
      "avg_prec_score    143.0\n",
      "f1_max            143.0\n",
      "p_f1_max          143.0\n",
      "kappa             143.0\n",
      "kappa_max         143.0\n",
      "p_kappa_max       143.0\n",
      "bceloss           143.0\n",
      "dtype: float64\n",
      "concatenate:  task4      (1976,) (1976, 9)\n",
      "5 task5  shape:  (620,) classifiaction: (620, 9)\n",
      "roc_auc_score     513.0\n",
      "auc_pr            513.0\n",
      "avg_prec_score    513.0\n",
      "f1_max            513.0\n",
      "p_f1_max          513.0\n",
      "kappa             513.0\n",
      "kappa_max         513.0\n",
      "p_kappa_max       513.0\n",
      "bceloss           513.0\n",
      "dtype: float64\n",
      "concatenate:  task5      (2596,) (2596, 9)\n",
      "6 task6  shape:  (184,) classifiaction: (184, 9)\n",
      "roc_auc_score     129.0\n",
      "auc_pr            129.0\n",
      "avg_prec_score    129.0\n",
      "f1_max            129.0\n",
      "p_f1_max          129.0\n",
      "kappa             129.0\n",
      "kappa_max         129.0\n",
      "p_kappa_max       129.0\n",
      "bceloss           129.0\n",
      "dtype: float64\n",
      "concatenate:  task6      (2780,) (2780, 9)\n",
      "7 task7  shape:  (224,) classifiaction: (224, 9)\n",
      "roc_auc_score     147.0\n",
      "auc_pr            147.0\n",
      "avg_prec_score    147.0\n",
      "f1_max            147.0\n",
      "p_f1_max          147.0\n",
      "kappa             147.0\n",
      "kappa_max         147.0\n",
      "p_kappa_max       147.0\n",
      "bceloss           147.0\n",
      "dtype: float64\n",
      "concatenate:  task7      (3004,) (3004, 9)\n",
      "8 task8  shape:  (148,) classifiaction: (148, 9)\n",
      "roc_auc_score     109.0\n",
      "auc_pr            109.0\n",
      "avg_prec_score    109.0\n",
      "f1_max            109.0\n",
      "p_f1_max          109.0\n",
      "kappa             109.0\n",
      "kappa_max         109.0\n",
      "p_kappa_max       109.0\n",
      "bceloss           109.0\n",
      "dtype: float64\n",
      "concatenate:  task8      (3152,) (3152, 9)\n",
      "9 task9  shape:  (344,) classifiaction: (344, 9)\n",
      "roc_auc_score     267.0\n",
      "auc_pr            267.0\n",
      "avg_prec_score    267.0\n",
      "f1_max            267.0\n",
      "p_f1_max          267.0\n",
      "kappa             267.0\n",
      "kappa_max         267.0\n",
      "p_kappa_max       267.0\n",
      "bceloss           267.0\n",
      "dtype: float64\n",
      "concatenate:  task9      (3496,) (3496, 9)\n",
      "10 task10  shape:  (72,) classifiaction: (72, 9)\n",
      "roc_auc_score     64.0\n",
      "auc_pr            64.0\n",
      "avg_prec_score    64.0\n",
      "f1_max            64.0\n",
      "p_f1_max          64.0\n",
      "kappa             64.0\n",
      "kappa_max         64.0\n",
      "p_kappa_max       64.0\n",
      "bceloss           64.0\n",
      "dtype: float64\n",
      "concatenate:  task10      (3568,) (3568, 9)\n",
      "ttl :  3568 con.shape: (3568,) all_tgs.shape (3568, 9)\n"
     ]
    }
   ],
   "source": [
    "# del con\n",
    "ttl = 0\n",
    "\n",
    "# con = np.ndarray()\n",
    "appd_df = []\n",
    "for i in range(1,11):\n",
    "    task_key = f\"task{i}\"\n",
    "    print(i, task_key, ' shape: ', environ.val_data[task_key]['yc_aggr_weights'].shape,  'classifiaction:', environ.val_metrics[task_key]['classification'].shape)\n",
    "    tmp_df = environ.val_metrics[task_key]['classification'].where(pd.isnull,1)\n",
    "    print(tmp_df.sum(axis=0))\n",
    "    \n",
    "    if i == 1:\n",
    "        con = np.copy(environ.val_data[task_key]['yc_aggr_weights'])\n",
    "        all_tgs = environ.val_metrics[task_key]['classification'].copy()\n",
    "        print(\"initialize\", con.shape, all_tgs.shape)\n",
    "    else:\n",
    "        con = np.hstack((con, environ.val_data[task_key]['yc_aggr_weights']))\n",
    "        all_tgs = all_tgs.append(environ.val_metrics[task_key]['classification'])\n",
    "        print(\"concatenate: \",task_key, \"    \", con.shape, all_tgs.shape)\n",
    "        \n",
    "    ttl += environ.val_data[task_key]['yc_aggr_weights'].shape[0]\n",
    "    \n",
    "print('ttl : ', ttl,  'con.shape:', con.shape, 'all_tgs.shape', all_tgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22870bf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-16T07:17:56.700Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_tgs2 = pd.concat(environ.val_metrics[f\"task{i}\"]['classification'] for i in range(1,11))\n",
    "\n",
    "all_tgs2.info()\n",
    "all_tgs2.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8bfb4137",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:53:27.145197Z",
     "start_time": "2022-08-02T08:53:27.076862Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3568,)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con2 = np.hstack([ environ.val_data[f\"task{i}\"]['yc_aggr_weights'] for i in range(1,11)])\n",
    "con2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9ecbee89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:51:56.737396Z",
     "start_time": "2022-08-02T08:51:56.667161Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# all_tgs.index = range(all_tgs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b8334f68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:52:05.606811Z",
     "start_time": "2022-08-02T08:52:05.540830Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(all_tgs2[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ac56e5a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:53:38.557041Z",
     "start_time": "2022-08-02T08:53:38.479724Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "roc_auc_score     448.0\n",
       "auc_pr            448.0\n",
       "avg_prec_score    448.0\n",
       "f1_max            448.0\n",
       "p_f1_max          448.0\n",
       "kappa             448.0\n",
       "kappa_max         448.0\n",
       "p_kappa_max       448.0\n",
       "bceloss           448.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tgs2_mod = all_tgs2.where(pd.isnull, 1) * con2[:,None]\n",
    "all_tgs2_mod.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "71ba25bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:40:54.050290Z",
     "start_time": "2022-08-02T08:40:53.982441Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# con3 = pd.concat([environ.val_metrics['task1']['classification'],environ.val_metrics['task2']['classification'] ])\n",
    "# print(con3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4e3cc76f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:53:46.438201Z",
     "start_time": "2022-08-02T08:53:46.318451Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wsum: 1314.0   df.shape: (3568, 9)   df2: (3568, 9)  df2.sum(axis=0): \n",
      " roc_auc_score     448.0\n",
      "auc_pr            448.0\n",
      "avg_prec_score    448.0\n",
      "f1_max            448.0\n",
      "p_f1_max          448.0\n",
      "kappa             448.0\n",
      "kappa_max         448.0\n",
      "p_kappa_max       448.0\n",
      "bceloss           448.0\n",
      "dtype: float64\n",
      "\n",
      "  DIVISOR \n",
      "-----------\n",
      "roc_auc_score     0.002232\n",
      "auc_pr            0.002232\n",
      "avg_prec_score    0.002232\n",
      "f1_max            0.002232\n",
      "p_f1_max          0.002232\n",
      "kappa             0.002232\n",
      "kappa_max         0.002232\n",
      "p_kappa_max       0.002232\n",
      "bceloss           0.002232\n",
      "dtype: float64\n",
      "\n",
      "  DF \n",
      "------\n",
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max  kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                      \n",
      "0               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "1          0.000000  0.250000        0.500000  0.666667  0.320208    0.0        0.0     0.587646  0.780148\n",
      "2               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "3               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "4          0.333333  0.166667        0.333333  0.500000  0.328739    0.0        0.2     0.328739  0.575516\n",
      "...             ...       ...             ...       ...       ...    ...        ...          ...       ...\n",
      "67              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "68              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "69              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "70              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "71              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "\n",
      "[3568 rows x 9 columns]\n",
      "\n",
      "  DF2 \n",
      "-------\n",
      "      roc_auc_score  auc_pr  avg_prec_score  f1_max  p_f1_max  kappa  kappa_max  p_kappa_max  bceloss\n",
      "task                                                                                                 \n",
      "0               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "1               1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "2               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "3               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "4               1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "...             ...     ...             ...     ...       ...    ...        ...          ...      ...\n",
      "67              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "68              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "69              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "70              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "71              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "\n",
      "[3568 rows x 9 columns]\n",
      "\n",
      "  RESULT \n",
      "----------\n",
      "roc_auc_score     0.685598\n",
      "auc_pr            0.681871\n",
      "avg_prec_score    0.744206\n",
      "f1_max            0.799004\n",
      "p_f1_max          0.484420\n",
      "kappa             0.080060\n",
      "kappa_max         0.582045\n",
      "p_kappa_max       0.532944\n",
      "bceloss           0.636030\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tmp2 = aggregate_results(all_tgs2, con2, verbose = True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f8aa6cb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T09:20:37.470235Z",
     "start_time": "2022-08-02T09:20:37.391995Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'auc_pr': 0.6818710653441948,\n",
      "    'avg_prec_score': 0.7442062851089334,\n",
      "    'bceloss': 0.6360303774875189,\n",
      "    'f1_max': 0.7990044449679128,\n",
      "    'kappa': 0.08006046274015079,\n",
      "    'kappa_max': 0.5820449674723311,\n",
      "    'logloss': 0.00032448763622636064,\n",
      "    'p_f1_max': 0.48441957962599447,\n",
      "    'p_kappa_max': 0.532944236640885,\n",
      "    'roc_auc_score': 0.6855984778924409,\n",
      "    'sc_loss': 0.24956344102169398}\n",
      "0.24956344102169398\n",
      "0.00032448763622636064\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(environ.val_metrics['aggregated'])\n",
    "print(environ.val_metrics['aggregated']['sc_loss'] )\n",
    "print(environ.val_metrics['aggregated'][\"logloss\"] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "46f21fac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T09:02:49.573973Z",
     "start_time": "2022-08-02T09:02:49.497930Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score     0.685598\n",
      "auc_pr            0.681871\n",
      "avg_prec_score    0.744206\n",
      "f1_max            0.799004\n",
      "p_f1_max          0.484420\n",
      "kappa             0.080060\n",
      "kappa_max         0.582045\n",
      "p_kappa_max       0.532944\n",
      "bceloss           0.636030\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(tmp2)\n",
    "pp.pprint(tmp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c58a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f0711df0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:53:56.393951Z",
     "start_time": "2022-08-02T08:53:56.231370Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 task1  shape:  (472,) classifiaction: (472, 9)\n",
      "roc_auc_score     60.0\n",
      "auc_pr            60.0\n",
      "avg_prec_score    60.0\n",
      "f1_max            60.0\n",
      "p_f1_max          60.0\n",
      "kappa             60.0\n",
      "kappa_max         60.0\n",
      "p_kappa_max       60.0\n",
      "bceloss           60.0\n",
      "dtype: float64\n",
      "2 task2  shape:  (624,) classifiaction: (624, 9)\n",
      "roc_auc_score     46.0\n",
      "auc_pr            46.0\n",
      "avg_prec_score    46.0\n",
      "f1_max            46.0\n",
      "p_f1_max          46.0\n",
      "kappa             46.0\n",
      "kappa_max         46.0\n",
      "p_kappa_max       46.0\n",
      "bceloss           46.0\n",
      "dtype: float64\n",
      "3 task3  shape:  (688,) classifiaction: (688, 9)\n",
      "roc_auc_score     126.0\n",
      "auc_pr            126.0\n",
      "avg_prec_score    126.0\n",
      "f1_max            126.0\n",
      "p_f1_max          126.0\n",
      "kappa             126.0\n",
      "kappa_max         126.0\n",
      "p_kappa_max       126.0\n",
      "bceloss           126.0\n",
      "dtype: float64\n",
      "4 task4  shape:  (192,) classifiaction: (192, 9)\n",
      "roc_auc_score     29.0\n",
      "auc_pr            29.0\n",
      "avg_prec_score    29.0\n",
      "f1_max            29.0\n",
      "p_f1_max          29.0\n",
      "kappa             29.0\n",
      "kappa_max         29.0\n",
      "p_kappa_max       29.0\n",
      "bceloss           29.0\n",
      "dtype: float64\n",
      "5 task5  shape:  (620,) classifiaction: (620, 9)\n",
      "roc_auc_score     107.0\n",
      "auc_pr            107.0\n",
      "avg_prec_score    107.0\n",
      "f1_max            107.0\n",
      "p_f1_max          107.0\n",
      "kappa             107.0\n",
      "kappa_max         107.0\n",
      "p_kappa_max       107.0\n",
      "bceloss           107.0\n",
      "dtype: float64\n",
      "6 task6  shape:  (184,) classifiaction: (184, 9)\n",
      "roc_auc_score     27.0\n",
      "auc_pr            27.0\n",
      "avg_prec_score    27.0\n",
      "f1_max            27.0\n",
      "p_f1_max          27.0\n",
      "kappa             27.0\n",
      "kappa_max         27.0\n",
      "p_kappa_max       27.0\n",
      "bceloss           27.0\n",
      "dtype: float64\n",
      "7 task7  shape:  (224,) classifiaction: (224, 9)\n",
      "roc_auc_score     27.0\n",
      "auc_pr            27.0\n",
      "avg_prec_score    27.0\n",
      "f1_max            27.0\n",
      "p_f1_max          27.0\n",
      "kappa             27.0\n",
      "kappa_max         27.0\n",
      "p_kappa_max       27.0\n",
      "bceloss           27.0\n",
      "dtype: float64\n",
      "8 task8  shape:  (148,) classifiaction: (148, 9)\n",
      "roc_auc_score     24.0\n",
      "auc_pr            24.0\n",
      "avg_prec_score    24.0\n",
      "f1_max            24.0\n",
      "p_f1_max          24.0\n",
      "kappa             24.0\n",
      "kappa_max         24.0\n",
      "p_kappa_max       24.0\n",
      "bceloss           24.0\n",
      "dtype: float64\n",
      "9 task9  shape:  (344,) classifiaction: (344, 9)\n",
      "roc_auc_score     57.0\n",
      "auc_pr            57.0\n",
      "avg_prec_score    57.0\n",
      "f1_max            57.0\n",
      "p_f1_max          57.0\n",
      "kappa             57.0\n",
      "kappa_max         57.0\n",
      "p_kappa_max       57.0\n",
      "bceloss           57.0\n",
      "dtype: float64\n",
      "10 task10  shape:  (72,) classifiaction: (72, 9)\n",
      "roc_auc_score     22.0\n",
      "auc_pr            22.0\n",
      "avg_prec_score    22.0\n",
      "f1_max            22.0\n",
      "p_f1_max          22.0\n",
      "kappa             22.0\n",
      "kappa_max         22.0\n",
      "p_kappa_max       22.0\n",
      "bceloss           22.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "all_tasks_classification_metrics = []\n",
    "all_tasks_aggregation_weights    = [] \n",
    "\n",
    "for i in range(1,11):\n",
    "    task_key = f\"task{i}\"\n",
    "    print(i, task_key, ' shape: ', environ.val_data[task_key]['yc_aggr_weights'].shape,  'classifiaction:', environ.val_metrics[task_key]['classification'].shape)\n",
    "    tmp_df = environ.val_metrics[task_key]['classification'].where(pd.isnull,1)\n",
    "    print(tmp_df.sum(axis=0))\n",
    "    \n",
    "    all_tasks_classification_metrics.append(environ.val_metrics[task_key]['classification'])\n",
    "    all_tasks_aggregation_weights.append(environ.val_data[task_key]['yc_aggr_weights'])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9616c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:50:55.310369Z",
     "start_time": "2022-08-02T08:50:55.205109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_tgs3 = pd.concat(all_tasks_classification_metrics)\n",
    "con3 = np.concatenate(all_tasks_aggregation_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e9cdf412",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:54:37.322219Z",
     "start_time": "2022-08-02T08:54:37.193928Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3568 entries, 0 to 71\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   roc_auc_score   525 non-null    float64\n",
      " 1   auc_pr          525 non-null    float64\n",
      " 2   avg_prec_score  525 non-null    float64\n",
      " 3   f1_max          525 non-null    float64\n",
      " 4   p_f1_max        525 non-null    float32\n",
      " 5   kappa           525 non-null    float64\n",
      " 6   kappa_max       525 non-null    float64\n",
      " 7   p_kappa_max     525 non-null    float32\n",
      " 8   bceloss         525 non-null    float64\n",
      "dtypes: float32(2), float64(7)\n",
      "memory usage: 250.9 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>avg_prec_score</th>\n",
       "      <th>f1_max</th>\n",
       "      <th>p_f1_max</th>\n",
       "      <th>kappa</th>\n",
       "      <th>kappa_max</th>\n",
       "      <th>p_kappa_max</th>\n",
       "      <th>bceloss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.320208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587646</td>\n",
       "      <td>0.780148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.328739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.328739</td>\n",
       "      <td>0.575516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max  kappa  kappa_max  p_kappa_max   bceloss\n",
       "task                                                                                                      \n",
       "0               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "1          0.000000  0.250000        0.500000  0.666667  0.320208    0.0        0.0     0.587646  0.780148\n",
       "2               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "3               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "4          0.333333  0.166667        0.333333  0.500000  0.328739    0.0        0.2     0.328739  0.575516\n",
       "5               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "6               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "7               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "8               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "9               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "10              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "11              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "12              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "13              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "14              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "15              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "16              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "17              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "18              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
       "19              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tgs3.info()\n",
    "all_tgs3.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9f29ee1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T09:02:16.745152Z",
     "start_time": "2022-08-02T09:02:16.608823Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wsum: 1314.0   df.shape: (3568, 9)   df2: (3568, 9)  df2.sum(axis=0): \n",
      " roc_auc_score     448.0\n",
      "auc_pr            448.0\n",
      "avg_prec_score    448.0\n",
      "f1_max            448.0\n",
      "p_f1_max          448.0\n",
      "kappa             448.0\n",
      "kappa_max         448.0\n",
      "p_kappa_max       448.0\n",
      "bceloss           448.0\n",
      "dtype: float64\n",
      "\n",
      "  DIVISOR \n",
      "-----------\n",
      "roc_auc_score     0.002232\n",
      "auc_pr            0.002232\n",
      "avg_prec_score    0.002232\n",
      "f1_max            0.002232\n",
      "p_f1_max          0.002232\n",
      "kappa             0.002232\n",
      "kappa_max         0.002232\n",
      "p_kappa_max       0.002232\n",
      "bceloss           0.002232\n",
      "dtype: float64\n",
      "\n",
      "  DF \n",
      "------\n",
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max  kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                      \n",
      "0               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "1          0.000000  0.250000        0.500000  0.666667  0.320208    0.0        0.0     0.587646  0.780148\n",
      "2               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "3               NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "4          0.333333  0.166667        0.333333  0.500000  0.328739    0.0        0.2     0.328739  0.575516\n",
      "...             ...       ...             ...       ...       ...    ...        ...          ...       ...\n",
      "67              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "68              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "69              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "70              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "71              NaN       NaN             NaN       NaN       NaN    NaN        NaN          NaN       NaN\n",
      "\n",
      "[3568 rows x 9 columns]\n",
      "\n",
      "  DF2 \n",
      "-------\n",
      "      roc_auc_score  auc_pr  avg_prec_score  f1_max  p_f1_max  kappa  kappa_max  p_kappa_max  bceloss\n",
      "task                                                                                                 \n",
      "0               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "1               1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "2               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "3               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "4               1.0     1.0             1.0     1.0       1.0    1.0        1.0          1.0      1.0\n",
      "...             ...     ...             ...     ...       ...    ...        ...          ...      ...\n",
      "67              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "68              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "69              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "70              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "71              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN      NaN\n",
      "\n",
      "[3568 rows x 9 columns]\n",
      "\n",
      "  RESULT \n",
      "----------\n",
      "roc_auc_score     0.685598\n",
      "auc_pr            0.681871\n",
      "avg_prec_score    0.744206\n",
      "f1_max            0.799004\n",
      "p_f1_max          0.484420\n",
      "kappa             0.080060\n",
      "kappa_max         0.582045\n",
      "p_kappa_max       0.532944\n",
      "bceloss           0.636030\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tmp3 = aggregate_results( all_tgs3, con3, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e5c12369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:59:51.408133Z",
     "start_time": "2022-08-02T08:59:51.294153Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task\n",
      "0   NaN\n",
      "Name: roc_auc_score, dtype: float64\n",
      "task\n",
      "0   NaN\n",
      "Name: roc_auc_score, dtype: float64\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_tgs2[0:1]['roc_auc_score'])\n",
    "print(all_tgs3[0:1]['roc_auc_score'])\n",
    "print((all_tgs2[0:1]['roc_auc_score'] == all_tgs3[0:1]['roc_auc_score']).all())\n",
    "all_tgs2.compare(all_tgs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "399eae39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T15:18:30.544168Z",
     "start_time": "2022-08-01T15:18:30.511229Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(344,) (344,)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(environ.val_data['task9']['yc_aggr_weights'].shape, con[3152:3496].shape)\n",
    "print((environ.val_data['task9']['yc_aggr_weights'] == con[3152:3496]).all())a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8183a98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T14:53:09.749812Z",
     "start_time": "2022-08-01T14:53:09.749793Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best ROC AUC   :   {ns.best_roc_auc:.5f}\\n\"\n",
    "      f\"Best Precision :   {ns.best_accuracy:.5f}\\n\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76406f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T13:56:23.922805Z",
     "start_time": "2022-07-08T13:56:23.891800Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch :       3\n",
      "Best Iteration :   7977 \n",
      "Best ROC AUC   :   0.73690\n",
      "Best Precision :   0.64175\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best ROC AUC   :   {ns.best_roc_auc:.5f}\\n\"\n",
    "      f\"Best Precision :   {ns.best_accuracy:.5f}\\n\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60564cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:50:02.608053Z",
     "start_time": "2022-07-07T13:50:02.553468Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch :       1\n",
      "Best Iteration :   2659 \n",
      "Best ROC AUC   :   0.71991\n",
      "Best Precision :   0.63031\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best ROC AUC   :   {ns.best_roc_auc:.5f}\\n\"\n",
    "      f\"Best Precision :   {ns.best_accuracy:.5f}\\n\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a8071",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bc9c724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T11:20:10.987625Z",
     "start_time": "2022-07-28T11:20:10.957009Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch :       2\n",
      "Best Iteration :   6258 \n",
      "Best ROC AUC   :   0.79359\n",
      "Best Precision :   0.72131\n",
      "\n",
      "\n",
      "roc_auc_score           0.7936\n",
      "auc_pr                  0.6974\n",
      "avg_prec_score          0.7213\n",
      "f1_max                  0.7534\n",
      "p_f1_max                0.4367\n",
      "kappa                   0.3055\n",
      "kappa_max               0.5732\n",
      "p_kappa_max             0.4947\n",
      "bceloss                 0.4300\n",
      "sc_loss                 0.0106\n",
      "logloss                 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best ROC AUC   :   {ns.best_roc_auc:.5f}\\n\"\n",
    "      f\"Best Precision :   {ns.best_accuracy:.5f}\\n\")\n",
    "print()\n",
    "for key in environ.val_metrics['aggregated']:\n",
    "    print(f\"{key:20s}    {environ.val_metrics['aggregated'][key]:0.4f}\")\n",
    "# pp.pprint(environ.val_metrics['aggregated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48528a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb49645c",
   "metadata": {},
   "source": [
    "# Weight & Policy Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aade16",
   "metadata": {},
   "source": [
    "### Weight/Policy Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f68f2e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-29T05:45:13.714706Z",
     "start_time": "2022-08-29T05:45:13.680806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone (Group 0) Initial LR  : 0.001000 \n",
      " Tasks    (Group 1) Initial LR  : 0.001000    \n",
      " Params : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.0005\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      "\n",
      "Parameter Group 1\n",
      "    dampening: 0\n",
      "    lr: 0.0005\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      ") \n",
      "\n",
      " Policy   Initial LR            : 0.010000  \n",
      " Params : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0.0005\n",
      ")  \n",
      "\n",
      "\n",
      " Backbone Initial LR            : 0.001000      Current LR : 0.0005 \n",
      " Tasks    Initial LR            : 0.001000      Current LR : 0.0005    \n",
      " Policy   Initial LR            : 0.010000      Current LR : 0.01  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone (Group 0) Initial LR  : {environ.opt['train']['backbone_lr']:4f} \\n\"\n",
    "       f\" Tasks    (Group 1) Initial LR  : {environ.opt['train']['task_lr']:4f}    \\n Params : {environ.optimizers['weights']} \\n\\n\"\n",
    "       f\" Policy   Initial LR            : {environ.opt['train']['policy_lr']:4f}  \\n Params : {environ.optimizers['alphas']}  \\n\\n\")\n",
    "\n",
    "print( f\" Backbone Initial LR            : {environ.opt['train']['backbone_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[0]['lr']} \\n\"\n",
    "       f\" Tasks    Initial LR            : {environ.opt['train']['task_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[1]['lr']}    \\n\"\n",
    "       f\" Policy   Initial LR            : {environ.opt['train']['policy_lr']:4f}      Current LR : {environ.optimizers['alphas'].param_groups[0]['lr']}  \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ccc02c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-29T05:45:19.218680Z",
     "start_time": "2022-08-29T05:45:19.173441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights Scheduler Parameters\n",
      "------------------------------\n",
      "    factor                   value: 0.5\n",
      "    min_lrs                  value: [0, 0]\n",
      "    patience                 value: 30\n",
      "    verbose                  value: True\n",
      "    cooldown                 value: 10\n",
      "    cooldown_counter         value: 0\n",
      "    mode                     value: min\n",
      "    threshold                value: 0.0001\n",
      "    threshold_mode           value: rel\n",
      "    best                     value: 2.1187280823000556\n",
      "    num_bad_epochs           value: 12\n",
      "    mode_worse               value: inf\n",
      "    eps                      value: 1e-08\n",
      "    last_epoch               value: 59\n",
      "    _last_lr                 value: [0.0005, 0.0005]\n",
      "\n",
      "Policy Scheduler Parameters\n",
      "-----------------------------\n",
      "    factor                   value: 0.5\n",
      "    min_lrs                  value: [0]\n",
      "    patience                 value: 30\n",
      "    verbose                  value: True\n",
      "    cooldown                 value: 10\n",
      "    cooldown_counter         value: 0\n",
      "    mode                     value: min\n",
      "    threshold                value: 0.0001\n",
      "    threshold_mode           value: rel\n",
      "    best                     value: 2.1135003430944006\n",
      "    num_bad_epochs           value: 6\n",
      "    mode_worse               value: inf\n",
      "    eps                      value: 1e-08\n",
      "    last_epoch               value: 59\n",
      "    _last_lr                 value: [0.01]\n"
     ]
    }
   ],
   "source": [
    "print_underline('Weights Scheduler Parameters', verbose = True) \n",
    "for k,i in environ.schedulers['weights'].state_dict().items():\n",
    "    print(f\"    {k:20s}     value: {i}\")\n",
    "\n",
    "print_underline('Policy Scheduler Parameters', verbose = True)\n",
    "for k,i in environ.schedulers['alphas'].state_dict().items():\n",
    "    print(f\"    {k:20s}     value: {i}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b284fe5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T05:55:00.234951Z",
     "start_time": "2022-08-27T05:55:00.184609Z"
    }
   },
   "outputs": [],
   "source": [
    "ns.flag = 'update_weights'\n",
    "model_initializations(ns, opt, environ, phase = ns.flag, policy_learning = True)\n",
    "# training_initializations(ns, opt, environ, dldrs, warmup = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6231ff38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T05:56:30.237991Z",
     "start_time": "2022-08-27T05:56:30.202367Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training preparation: - check for CUDA - cuda available as device id: [0]\n",
      "sparsechem_env.cuda()\n",
      " policy policy1 is None\n",
      " policy policy2 is None\n",
      " policy policy3 is None\n",
      " policy policy4 is None\n",
      " policy policy5 is None\n",
      " policy policy6 is None\n",
      " policy policy7 is None\n",
      " policy policy8 is None\n",
      " policy policy9 is None\n",
      " policy policy10 is None\n",
      " training preparation: - set print_freq to                                 : 1989 \n",
      " training preparation: - set number of batches per warmup training epoch to: 1000\n",
      " training preparation: - set number of batches per weight training epoch to: 750\n",
      " training preparation: - set number of batches per policy training epoch to: 250\n",
      " training preparation: - set number of batches per validation to           : 500\n",
      " training preparation complete . . .\n"
     ]
    }
   ],
   "source": [
    "# training_initializations(ns, opt, environ, dldrs, warmup_iterations = 200,  weight_iterations = 2, policy_iterations = 2, eval_iterations = 1, warmup = False)\n",
    "training_initializations(ns, opt, environ, dldrs, warmup_iterations = 1000, weight_iterations = 750, policy_iterations = 250, eval_iterations = 500, warmup = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8ed1774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-28T07:45:13.453282Z",
     "start_time": "2022-08-28T07:45:13.421740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone Initial LR            :      0.001000      Current LR : 0.001 \n",
      " Tasks    Initial LR            :      0.001000      Current LR : 0.001    \n",
      " Policy   Initial LR            :      0.010000      Current LR : 0.01  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone Initial LR            :      {environ.opt['train']['backbone_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[0]['lr']} \\n\"\n",
    "       f\" Tasks    Initial LR            :      {environ.opt['train']['task_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[1]['lr']}    \\n\"\n",
    "       f\" Policy   Initial LR            :      {environ.opt['train']['policy_lr']:4f}      Current LR : {environ.optimizers['alphas'].param_groups[0]['lr']}  \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90b1ace9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T05:56:46.873861Z",
     "start_time": "2022-08-27T05:56:46.840200Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "** 2022-08-27 07:56:46:869319 \n",
      "** Training epoch: 60 iter: 60000   flag: update_weights \n",
      "** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\n",
      "** Switch from Warm Up training to Alternate training Weights & Policy \n",
      "** Take checkpoint and block gradient flow through Policy net\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_heading( f\"** {timestring()} \\n\"\n",
    "               f\"** Training epoch: {ns.current_epoch} iter: {ns.current_iter}   flag: {ns.flag} \\n\"\n",
    "               f\"** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\\n\"\n",
    "               f\"** Switch from Warm Up training to Alternate training Weights & Policy \\n\"\n",
    "               f\"** Take checkpoint and block gradient flow through Policy net\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66affd0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-28T18:39:22.215240Z",
     "start_time": "2022-08-28T18:39:22.104634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "0.05\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(environ.opt['train']['lambda_sparsity'])\n",
    "print(environ.opt['train']['lambda_sharing'])\n",
    "print(environ.opt['train']['decay_temp_freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "653fc4a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-28T18:39:43.022824Z",
     "start_time": "2022-08-28T18:39:42.957992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "# environ.opt['is_curriculum'] = True\n",
    "# environ.opt['curriculum_speed'] = 4\n",
    "# ns.num_train_layers = None\n",
    "\n",
    "\n",
    "environ.opt['train']['lambda_sparsity'] = 0.01\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['decay_temp_freq'] = 6\n",
    "print(environ.opt['train']['lambda_sparsity'])\n",
    "# print(environ.opt['train']['lambda_sharing'])\n",
    "# print(environ.opt['train']['decay_temp_freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef3a11fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-28T18:39:46.293174Z",
     "start_time": "2022-08-28T18:39:46.214582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ns.flag                        :      update_weights\n",
      " num_train_layers               :      6\n",
      " environ.opt['is_curriculum']   :      False\n",
      " environ.opt['curriculum_speed']:      3\n",
      "\n",
      " Backbone Initial LR            :      0.001000      Current LR : 0.0005 \n",
      " Tasks    Initial LR            :      0.001000      Current LR : 0.0005    \n",
      " Policy   Initial LR            :      0.010000      Current LR : 0.01  \n",
      "\n",
      " Hard Sampling                  :      False\n",
      "\n",
      " Sparsity regularization        :      0.01\n",
      " Sharing  regularization        :      0.05 \n",
      " Tasks    regularization        :      1.0   \n",
      "\n",
      "\n",
      " Gumbel Temp                    :      0.0251         \n",
      " Gumbel Temp decay              :      3 \n",
      "\n",
      " ns.current_epoch               :      112\n",
      " ns.training_epochs             :      20 \n",
      "\n",
      " ns.current_iters               :      109884\n",
      " Batches in warmup epoch        :      1000\n",
      " Batches in weight epoch        :      750\n",
      " Batches in policy epoch        :      250\n",
      " Batches in validation          :      500\n",
      " num_train_layers               :      6 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( f\" ns.flag                        :      {ns.flag}\")\n",
    "print( f\" num_train_layers               :      {ns.num_train_layers}\")\n",
    "print( f\" environ.opt['is_curriculum']   :      {environ.opt['is_curriculum']}\")\n",
    "print( f\" environ.opt['curriculum_speed']:      {environ.opt['curriculum_speed']}\\n\")\n",
    "print( f\" Backbone Initial LR            :      {environ.opt['train']['backbone_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[0]['lr']} \\n\"\n",
    "       f\" Tasks    Initial LR            :      {environ.opt['train']['task_lr']:4f}      Current LR : {environ.optimizers['weights'].param_groups[1]['lr']}    \\n\"\n",
    "       f\" Policy   Initial LR            :      {environ.opt['train']['policy_lr']:4f}      Current LR : {environ.optimizers['alphas'].param_groups[0]['lr']}  \\n\")\n",
    "\n",
    "print( f\" Hard Sampling                  :      {environ.opt['train']['hard_sampling']}\\n\")\n",
    "\n",
    "print( f\" Sparsity regularization        :      {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization        :      {environ.opt['train']['lambda_sharing']} \\n\"\n",
    "       f\" Tasks    regularization        :      {environ.opt['train']['lambda_tasks']}   \\n\\n\")\n",
    "\n",
    "print( f\" Gumbel Temp                    :      {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay              :      {environ.opt['train']['decay_temp_freq']} \\n\") #\n",
    "\n",
    "print( f\" ns.current_epoch               :      {ns.current_epoch}\")\n",
    "print( f\" ns.training_epochs             :      {ns.training_epochs} \\n\") \n",
    "print( f\" ns.current_iters               :      {ns.current_iter}\")  \n",
    "print( f\" Batches in warmup epoch        :      {ns.trn_iters_warmup}\")\n",
    "print( f\" Batches in weight epoch        :      {ns.trn_iters_weights}\")\n",
    "print( f\" Batches in policy epoch        :      {ns.trn_iters_policy}\")\n",
    "print( f\" Batches in validation          :      {ns.eval_iters}\")\n",
    "print( f\" num_train_layers               :      {ns.num_train_layers} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a037fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-28T18:39:53.273275Z",
     "start_time": "2022-08-28T18:39:53.176180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[e] Last ep:112  it:109884  -  Losses:   \t Task: 2.1290   \t Sparsity: 8.74282e-05    \t Sharing: 1.40599e-03    \t Total: 2.1305 \n",
      "\n",
      "\n",
      " ep:  112    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.5842    0.4158  1    0.6929    0.3071  1    0.6500    0.3500  1    0.5901    0.4099  1    0.6034    0.3966  1    0.6060    0.3940  1    0.6332    0.3668  1    0.6210    0.3790  1    0.6164    0.3836  1    0.6103    0.3897  1\n",
      "  1    0.6889    0.3111  1    0.7872    0.2128  1    0.6184    0.3816  1    0.5517    0.4483  1    0.6047    0.3953  1    0.6282    0.3718  1    0.6472    0.3528  1    0.5081    0.4919  1    0.6213    0.3787  1    0.7084    0.2916  1\n",
      "  2    0.6984    0.3016  1    0.7828    0.2172  1    0.7033    0.2967  1    0.5897    0.4103  1    0.6454    0.3546  1    0.6464    0.3536  1    0.6739    0.3261  1    0.5070    0.4930  1    0.6035    0.3965  1    0.7217    0.2783  1\n",
      "  3    0.6327    0.3673  1    0.5949    0.4051  1    0.6400    0.3600  1    0.6354    0.3646  1    0.6513    0.3487  1    0.5942    0.4058  1    0.5948    0.4052  1    0.6335    0.3665  1    0.4876    0.5124  0    0.5966    0.4034  1\n",
      "  4    0.6452    0.3548  1    0.6647    0.3353  1    0.6927    0.3073  1    0.5945    0.4055  1    0.5486    0.4514  1    0.5701    0.4299  1    0.6139    0.3861  1    0.6283    0.3717  1    0.6262    0.3738  1    0.5975    0.4025  1\n",
      "  5    0.6431    0.3569  1    0.6366    0.3634  1    0.6657    0.3343  1    0.5728    0.4272  1    0.6643    0.3357  1    0.5482    0.4518  1    0.6103    0.3897  1    0.5824    0.4176  1    0.6522    0.3478  1    0.5512    0.4488  1\n",
      "\n",
      "\n",
      " ep:  112   logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         logits       s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.2610   -0.0791  1    0.2679   -0.5456  1    0.2504   -0.3686  1    0.2660   -0.0984  1    0.2611   -0.1585  1    0.2634   -0.1670  1    0.2602   -0.2859  1    0.2606   -0.2332  1    0.2636   -0.2108  1    0.2612   -0.1872  1\n",
      "  1    0.2980   -0.4968  1    0.3071   -1.0009  1    0.2989   -0.1838  1    0.2926    0.0851  1    0.3000   -0.1251  1    0.2974   -0.2270  1    0.3017   -0.3052  1    0.3294    0.2972  1    0.2940   -0.2010  1    0.2969   -0.5909  1\n",
      "  2    0.3727   -0.4670  1    0.3866   -0.8955  1    0.3774   -0.4855  1    0.3764    0.0135  1    0.3884   -0.2102  1    0.3680   -0.2352  1    0.3751   -0.3506  1    0.3505    0.3224  1    0.3181   -0.1018  1    0.4538   -0.4991  1\n",
      "  3    0.2140   -0.3296  1    0.2168   -0.1675  1    0.2184   -0.3571  1    0.2189   -0.3368  1    0.2185   -0.4061  1    0.2168   -0.1647  1    0.2143   -0.1696  1    0.2174   -0.3298  1    0.2166    0.2662  0    0.2161   -0.1752  1\n",
      "  4    0.2580   -0.3402  1    0.2585   -0.4256  1    0.2865   -0.5265  1    0.2605   -0.1220  1    0.2575    0.0626  1    0.2565   -0.0259  1    0.2558   -0.2081  1    0.2552   -0.2695  1    0.2539   -0.2621  1    0.2543   -0.1406  1\n",
      "  5    0.2270   -0.3617  1    0.2484   -0.3122  1    0.2305   -0.4584  1    0.2283   -0.0649  1    0.2422   -0.4403  1    0.2292    0.0359  1    0.2105   -0.2381  1    0.2277   -0.1050  1    0.2318   -0.3968  1    0.2276    0.0220  1\n",
      "\n",
      "\n",
      " ep:  112    softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s          softmax     s         \n",
      " ----- ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    ----------------- -    \n",
      "  0    0.5842    0.4158  1    0.6929    0.3071  1    0.6500    0.3500  1    0.5901    0.4099  0    0.6034    0.3966  0    0.6060    0.3940  1    0.6332    0.3668  0    0.6210    0.3790  0    0.6164    0.3836  1    0.6103    0.3897  1\n",
      "  1    0.6889    0.3111  0    0.7872    0.2128  0    0.6184    0.3816  0    0.5517    0.4483  0    0.6047    0.3953  0    0.6282    0.3718  1    0.6472    0.3528  1    0.5081    0.4919  1    0.6213    0.3787  1    0.7084    0.2916  1\n",
      "  2    0.6984    0.3016  1    0.7828    0.2172  1    0.7033    0.2967  0    0.5897    0.4103  1    0.6454    0.3546  0    0.6464    0.3536  0    0.6739    0.3261  1    0.5070    0.4930  1    0.6035    0.3965  0    0.7217    0.2783  1\n",
      "  3    0.6327    0.3673  1    0.5949    0.4051  1    0.6400    0.3600  1    0.6354    0.3646  0    0.6513    0.3487  1    0.5942    0.4058  0    0.5948    0.4052  1    0.6335    0.3665  1    0.4876    0.5124  0    0.5966    0.4034  1\n",
      "  4    0.6452    0.3548  1    0.6647    0.3353  1    0.6927    0.3073  0    0.5945    0.4055  1    0.5486    0.4514  0    0.5701    0.4299  1    0.6139    0.3861  1    0.6283    0.3717  0    0.6262    0.3738  1    0.5975    0.4025  1\n",
      "  5    0.6431    0.3569  1    0.6366    0.3634  0    0.6657    0.3343  0    0.5728    0.4272  1    0.6643    0.3357  1    0.5482    0.4518  0    0.6103    0.3897  1    0.5824    0.4176  1    0.6522    0.3478  1    0.5512    0.4488  0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed : 112       # of epochs to run:  20 -->  epochs 113 to 132\n",
      " policy_learning rate : 0.01 \n",
      " lambda_sparsity      : 0.01\n",
      " lambda_sharing       : 0.05\n",
      " curriculum training  : False     cirriculum speed: 3     num_training_layers : 6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_loss(ns.val_metrics, title = f\"[e] Last ep:{ns.current_epoch}  it:{ns.current_iter} \")\n",
    "print()\n",
    "environ.display_trained_policy(ns.current_epoch)\n",
    "environ.display_trained_logits(ns.current_epoch)\n",
    "environ.display_current_policy(ns.current_epoch)\n",
    "\n",
    "print_heading(f\" Last Epoch Completed : {ns.current_epoch}       # of epochs to run:  {ns.training_epochs} -->  epochs {ns.current_epoch+1} to {ns.training_epochs + ns.current_epoch}\"\n",
    "              f\"\\n policy_learning rate : {environ.opt['train']['policy_lr']} \"\n",
    "              f\"\\n lambda_sparsity      : {environ.opt['train']['lambda_sparsity']}\"\n",
    "              f\"\\n lambda_sharing       : {environ.opt['train']['lambda_sharing']}\"\n",
    "              f\"\\n curriculum training  : {opt['is_curriculum']}     cirriculum speed: {opt['curriculum_speed']}     num_training_layers : {ns.num_train_layers}\", \n",
    "              verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c71af",
   "metadata": {},
   "source": [
    "### Weight/Policy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ad7d8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-29T13:38:19.318Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed : 142       # of epochs to run:  4 -->  epochs 143 to 146\n",
      " Backbone Initial LR  : 0.001      Current LR : 0.00025 \n",
      " Heads    Initial LR  : 0.001      Current LR : 0.00025\n",
      " Policy   Initial LR  : 0.01      Current LR : 0.01\n",
      " Regularization tasks : 1.0          Sparsity: 0.01           sharing: 0.05\n",
      " curriculum training  : False      Cirriculum speed: 3     num_training_layers : 6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Ep: 143 [weights]:  12%|           | 87/750 [01:17<09:59,  1.11it/s, it=139971, Lss=1.2706, Spr=7.9436e-04, Shr=2.9583e-03, lyr=6]"
     ]
    }
   ],
   "source": [
    "weight_policy_training(ns, opt, environ, dldrs, display_policy = True, disable_tqdm = False, epochs = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f553102f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-29T13:36:56.303779Z",
     "start_time": "2022-08-29T13:36:55.905592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 142 | 2.50e-04  2.50e-04  1.00e-02  1.41e-03 |   1.5489   7.945e-04   2.919e-03    1.5526 |  5.549e-06   0.46255   0.67239   0.75861   0.65714   0.70673 |   2.1304   8.944e-04   3.331e-03    2.1346 |  -0.0 |\n",
      "\n",
      "[e] Last ep:142  it:139884  -  Losses:   \t Task: 2.1304   \t Sparsity: 8.94442e-04    \t Sharing: 3.33104e-03    \t Total: 2.1346 \n",
      "\n",
      "   best_epoch:    99   best iter: 96884   best_accuracy: 0.67959    best ROC auc: 0.76435\n"
     ]
    }
   ],
   "source": [
    "print_metrics_cr(ns.current_epoch,  time.time() - time.time() , ns.trn_losses, ns.val_metrics, 1, out=[sys.stdout]) \n",
    "print()\n",
    "print_loss(ns.val_metrics, title = f\"[e] Last ep:{ns.current_epoch}  it:{ns.current_iter} \")\n",
    "print()\n",
    "print(f'   best_epoch: {ns.best_epoch:5d}   best iter: {ns.best_iter:5d}'\n",
    "      f'   best_accuracy: {ns.best_accuracy:.5f}    best ROC auc: {ns.best_roc_auc:.5f}')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "747c5d13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-29T13:37:05.317815Z",
     "start_time": "2022-08-29T13:37:05.279261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights Scheduler Parameters\n",
      "------------------------------\n",
      "    factor                   value: 0.5\n",
      "    min_lrs                  value: [0, 0]\n",
      "    patience                 value: 30\n",
      "    verbose                  value: True\n",
      "    cooldown                 value: 10\n",
      "    cooldown_counter         value: 9\n",
      "    mode                     value: min\n",
      "    threshold                value: 0.0001\n",
      "    threshold_mode           value: rel\n",
      "    best                     value: 2.1187280823000556\n",
      "    num_bad_epochs           value: 0\n",
      "    mode_worse               value: inf\n",
      "    eps                      value: 1e-08\n",
      "    last_epoch               value: 79\n",
      "    _last_lr                 value: [0.00025, 0.00025]\n",
      "\n",
      "Policy Scheduler Parameters\n",
      "-----------------------------\n",
      "    factor                   value: 0.5\n",
      "    min_lrs                  value: [0]\n",
      "    patience                 value: 30\n",
      "    verbose                  value: True\n",
      "    cooldown                 value: 10\n",
      "    cooldown_counter         value: 0\n",
      "    mode                     value: min\n",
      "    threshold                value: 0.0001\n",
      "    threshold_mode           value: rel\n",
      "    best                     value: 2.1037495183310257\n",
      "    num_bad_epochs           value: 16\n",
      "    mode_worse               value: inf\n",
      "    eps                      value: 1e-08\n",
      "    last_epoch               value: 79\n",
      "    _last_lr                 value: [0.01]\n"
     ]
    }
   ],
   "source": [
    "print_underline('Weights Scheduler Parameters', verbose = True) \n",
    "for k,i in environ.schedulers['weights'].state_dict().items():\n",
    "    print(f\"    {k:20s}     value: {i}\")\n",
    "\n",
    "print_underline('Policy Scheduler Parameters', verbose = True)\n",
    "for k,i in environ.schedulers['alphas'].state_dict().items():\n",
    "    print(f\"    {k:20s}     value: {i}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3602d781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-29T13:38:02.096634Z",
     "start_time": "2022-08-29T13:38:02.065472Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.schedulers['alphas'].patience = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e42e43",
   "metadata": {},
   "source": [
    "### Close WandB run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f6b31da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T06:42:31.153044Z",
     "start_time": "2022-08-26T06:42:31.121193Z"
    }
   },
   "outputs": [],
   "source": [
    "ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b05db1",
   "metadata": {},
   "source": [
    "# Misc Code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f300a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Check values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58eeb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.253924Z",
     "start_time": "2022-03-28T05:13:32.221329Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ns.best_epoch = 0\n",
    "# from utils.notebook_modules import wrapup_phase\n",
    "# wrapup_phase(ns, opt, environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db994f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.307351Z",
     "start_time": "2022-03-28T05:13:32.262822Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['policy_lr']       = 0.002\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.05\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# # environ.opt['train']['decay_temp_freq'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01791944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:50.458223Z",
     "start_time": "2022-01-27T00:58:50.430889Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(opt['diff_sparsity_weights'])\n",
    "print(opt['is_sharing'])\n",
    "print(opt['diff_sparsity_weights'] and not opt['is_sharing'])\n",
    "print(environ.opt['train']['Lambda_sharing'])\n",
    "print(opt['train']['Lambda_sharing'])\n",
    "print(environ.opt['train']['Lambda_sparsity'])\n",
    "print(opt['train']['Lambda_sparsity'])\n",
    "print(environ.opt['train']['policy_lr'])\n",
    "print(opt['train']['policy_lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8a246",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-12T07:35:36.625Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" \n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\\n\") \n",
    "\n",
    "print( f\" current_iters               : {ns.current_iter}   \\n\"\n",
    "       f\" current_epochs              : {ns.current_epoch}  \\n\" \n",
    "       f\" train_total_epochs          : {ns.training_epochs}\\n\" \n",
    "       f\" stop_epoch_training         : {ns.stop_epoch_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67be2583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:20:45.610411Z",
     "start_time": "2022-08-18T12:20:45.568020Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eed489b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:24:06.014379Z",
     "start_time": "2022-08-18T12:24:05.974633Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " task1_logits                              torch.Size([6, 2]) \n",
      " task2_logits                              torch.Size([6, 2]) \n",
      " task3_logits                              torch.Size([6, 2]) \n",
      " task4_logits                              torch.Size([6, 2]) \n",
      " task5_logits                              torch.Size([6, 2]) \n",
      " task6_logits                              torch.Size([6, 2]) \n",
      " task7_logits                              torch.Size([6, 2]) \n",
      " task8_logits                              torch.Size([6, 2]) \n",
      " task9_logits                              torch.Size([6, 2]) \n",
      " task10_logits                             torch.Size([6, 2]) \n",
      " backbone.Input_Layer.linear.weight        torch.Size([32000, 4000]) \n",
      " backbone.Input_Layer.linear.bias          torch.Size([4000]) \n",
      " backbone.blocks.0.linear.weight           torch.Size([4000, 4000]) \n",
      " backbone.blocks.0.linear.bias             torch.Size([4000]) \n",
      " backbone.blocks.1.linear.weight           torch.Size([4000, 4000]) \n",
      " backbone.blocks.1.linear.bias             torch.Size([4000]) \n",
      " backbone.blocks.2.linear.weight           torch.Size([4000, 4000]) \n",
      " backbone.blocks.2.linear.bias             torch.Size([4000]) \n",
      " backbone.blocks.3.linear.weight           torch.Size([4000, 4000]) \n",
      " backbone.blocks.3.linear.bias             torch.Size([4000]) \n",
      " backbone.blocks.4.linear.weight           torch.Size([4000, 4000]) \n",
      " backbone.blocks.4.linear.bias             torch.Size([4000]) \n",
      " backbone.blocks.5.linear.weight           torch.Size([4000, 4000]) \n",
      " backbone.blocks.5.linear.bias             torch.Size([4000]) \n",
      " task1_fc1_c0.linear.weight                torch.Size([472, 4000]) \n",
      " task1_fc1_c0.linear.bias                  torch.Size([472]) \n",
      " task2_fc1_c0.linear.weight                torch.Size([624, 4000]) \n",
      " task2_fc1_c0.linear.bias                  torch.Size([624]) \n",
      " task3_fc1_c0.linear.weight                torch.Size([688, 4000]) \n",
      " task3_fc1_c0.linear.bias                  torch.Size([688]) \n",
      " task4_fc1_c0.linear.weight                torch.Size([192, 4000]) \n",
      " task4_fc1_c0.linear.bias                  torch.Size([192]) \n",
      " task5_fc1_c0.linear.weight                torch.Size([620, 4000]) \n",
      " task5_fc1_c0.linear.bias                  torch.Size([620]) \n",
      " task6_fc1_c0.linear.weight                torch.Size([184, 4000]) \n",
      " task6_fc1_c0.linear.bias                  torch.Size([184]) \n",
      " task7_fc1_c0.linear.weight                torch.Size([224, 4000]) \n",
      " task7_fc1_c0.linear.bias                  torch.Size([224]) \n",
      " task8_fc1_c0.linear.weight                torch.Size([148, 4000]) \n",
      " task8_fc1_c0.linear.bias                  torch.Size([148]) \n",
      " task9_fc1_c0.linear.weight                torch.Size([344, 4000]) \n",
      " task9_fc1_c0.linear.bias                  torch.Size([344]) \n",
      " task10_fc1_c0.linear.weight               torch.Size([72, 4000]) \n",
      " task10_fc1_c0.linear.bias                 torch.Size([72]) \n"
     ]
    }
   ],
   "source": [
    "for name, param in environ.networks['mtl-net'].named_parameters():\n",
    "    print(f\" {name:40s}  {param.shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33193377",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:25:02.887603Z",
     "start_time": "2022-08-18T12:25:02.846964Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input_Layer.linear.weight                 torch.Size([32000, 4000]) \n",
      " Input_Layer.linear.bias                   torch.Size([4000]) \n",
      " blocks.0.linear.weight                    torch.Size([4000, 4000]) \n",
      " blocks.0.linear.bias                      torch.Size([4000]) \n",
      " blocks.1.linear.weight                    torch.Size([4000, 4000]) \n",
      " blocks.1.linear.bias                      torch.Size([4000]) \n",
      " blocks.2.linear.weight                    torch.Size([4000, 4000]) \n",
      " blocks.2.linear.bias                      torch.Size([4000]) \n",
      " blocks.3.linear.weight                    torch.Size([4000, 4000]) \n",
      " blocks.3.linear.bias                      torch.Size([4000]) \n",
      " blocks.4.linear.weight                    torch.Size([4000, 4000]) \n",
      " blocks.4.linear.bias                      torch.Size([4000]) \n",
      " blocks.5.linear.weight                    torch.Size([4000, 4000]) \n",
      " blocks.5.linear.bias                      torch.Size([4000]) \n"
     ]
    }
   ],
   "source": [
    "for name, param in environ.networks['mtl-net'].backbone.named_parameters():\n",
    "        print(f\" {name:40s}  {param.shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95a6d417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T12:34:17.484632Z",
     "start_time": "2022-08-18T12:34:17.320204Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " task1_fc1_c0.linear.weight                torch.Size([472, 4000]) \n",
      " task1_fc1_c0.linear.bias                  torch.Size([472]) \n",
      " task2_fc1_c0.linear.weight                torch.Size([624, 4000]) \n",
      " task2_fc1_c0.linear.bias                  torch.Size([624]) \n",
      " task3_fc1_c0.linear.weight                torch.Size([688, 4000]) \n",
      " task3_fc1_c0.linear.bias                  torch.Size([688]) \n",
      " task4_fc1_c0.linear.weight                torch.Size([192, 4000]) \n",
      " task4_fc1_c0.linear.bias                  torch.Size([192]) \n",
      " task5_fc1_c0.linear.weight                torch.Size([620, 4000]) \n",
      " task5_fc1_c0.linear.bias                  torch.Size([620]) \n",
      " task6_fc1_c0.linear.weight                torch.Size([184, 4000]) \n",
      " task6_fc1_c0.linear.bias                  torch.Size([184]) \n",
      " task7_fc1_c0.linear.weight                torch.Size([224, 4000]) \n",
      " task7_fc1_c0.linear.bias                  torch.Size([224]) \n",
      " task8_fc1_c0.linear.weight                torch.Size([148, 4000]) \n",
      " task8_fc1_c0.linear.bias                  torch.Size([148]) \n",
      " task9_fc1_c0.linear.weight                torch.Size([344, 4000]) \n",
      " task9_fc1_c0.linear.bias                  torch.Size([344]) \n",
      " task10_fc1_c0.linear.weight               torch.Size([72, 4000]) \n",
      " task10_fc1_c0.linear.bias                 torch.Size([72]) \n"
     ]
    }
   ],
   "source": [
    "for name, param in environ.networks['mtl-net'].named_parameters():\n",
    "    if 'task' in name and 'fc' in name:    \n",
    "        print(f\" {name:40s}  {param.shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62568b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:30:31.940280Z",
     "start_time": "2022-01-26T19:30:31.910058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_blocks = 6\n",
    "num_policy_layers = 6\n",
    "gt =  torch.ones((num_blocks)).long()\n",
    "gt0 =  torch.zeros((num_blocks)).long()\n",
    "print(gt)\n",
    "print(gt0)\n",
    "\n",
    "loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "print(loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61487657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:42:31.300891Z",
     "start_time": "2022-01-26T19:42:31.257774Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if environ.opt['diff_sparsity_weights'] and not environ.opt['is_sharing']:\n",
    "    print(' cond 1')\n",
    "    ## Assign higher weights to higher layers \n",
    "    loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "    print(f\"{task_key} sparsity error:  {2 * (loss_weights[-num_blocks:] * environ.cross_entropy2(logits[-num_blocks:], gt)).mean()})\")\n",
    "    print_dbg(f\" loss_weights :  {loss_weights}\", verbose = True)\n",
    "    print_dbg(f\" cross_entropy:  {environ.cross_entropy2(logits[-num_blocks:], gt)}  \", verbose = True)\n",
    "    print_dbg(f\" loss[sparsity][{task_key}]: {self.losses['sparsity'][task_key] } \", verbose = True)\n",
    "\n",
    "else:\n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between \\n Logits   : \\n{logits[-num_blocks:]} \\n and gt: \\n{gt} \\n\", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-num_blocks:], gt)}\")\n",
    "    \n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt[-1:])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt0[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt0[-1:])} \\n\")\n",
    "    \n",
    "    print('\\n cond 3')    \n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt[0:1])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt0[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt0[0:1])} \\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12352a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T10:02:21.600933Z",
     "start_time": "2022-04-28T10:02:21.561452Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\" ns.check_for_improvment_wait:  {ns.check_for_improvment_wait}\")\n",
    "print(\" ns.curriculum_epochs:          {ns.curriculum_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dad034",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T11:09:14.782725Z",
     "start_time": "2022-04-28T11:09:14.692205Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.val_metrics)\n",
    "df = environ.val_metrics['task1']['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27ebed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T11:09:15.186827Z",
     "start_time": "2022-04-28T11:09:15.090906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df[pd.notna(df.roc_auc_score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4e2d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T11:09:44.692326Z",
     "start_time": "2022-04-28T11:09:44.611694Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[pd.notna(df.roc_auc_score)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a1a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:39:22.031664Z",
     "start_time": "2022-06-15T17:39:21.964660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.display_trained_policy(ns.current_epoch,out=[sys.stdout])\n",
    "# environ.num_tasks\n",
    "# print(environ.get_policy_prob().shape)\n",
    "# print(environ.val_data['task1'].keys())\n",
    "# print(environ.val_data['task1']['yc_ind'][0][:40])\n",
    "# print(environ.val_data['task1']['yc_ind'][1][:40])\n",
    "# print(environ.val_data['task1']['yc_data'][:40])\n",
    "# print(environ.val_data['task1']['yc_hat'][:40])\n",
    "# environ.display_trained_policy(ns.current_epoch,out=[sys.stdout])\n",
    "# environ.display_trained_logits(ns.current_epoch,out=[sys.stdout])\n",
    "batch = next(dldrs.warmup_trn_loader)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f163b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:39:22.757684Z",
     "start_time": "2022-06-15T17:39:22.679466Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99679c92",
   "metadata": {},
   "source": [
    "### Losses and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "99a79aa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-29T10:37:56.954474Z",
     "start_time": "2022-08-29T10:37:56.900806Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " val_metric keys               : dict_keys(['parms', 'task', 'task_mean', 'sparsity', 'sharing', 'total', 'task1', 'task2', 'task3', 'task4', 'task5', 'task6', 'task7', 'task8', 'task9', 'task10', 'aggregated', 'train_time', 'epoch'])\n",
      " aggreagted keys               : dict_keys(['roc_auc_score', 'auc_pr', 'avg_prec_score', 'f1_max', 'p_f1_max', 'kappa', 'kappa_max', 'p_kappa_max', 'bceloss', 'sc_loss', 'logloss'])\n",
      " task keys                     : dict_keys(['total', 'task1', 'task2', 'task3', 'task4', 'task5', 'task6', 'task7', 'task8', 'task9', 'task10'])\n",
      " task / task1 keys             : 0.18089021539345657\n",
      " sparsity keys                 : dict_keys(['total', 'task1', 'task2', 'task3', 'task4', 'task5', 'task6', 'task7', 'task8', 'task9', 'task10'])\n",
      " total keys                    : dict_keys(['total', 'total_mean', 'task', 'policy'])\n",
      " aggregated keys               : dict_keys(['roc_auc_score', 'auc_pr', 'avg_prec_score', 'f1_max', 'p_f1_max', 'kappa', 'kappa_max', 'p_kappa_max', 'bceloss', 'sc_loss', 'logloss'])\n",
      "\n",
      " task1 keys                    : dict_keys(['classification', 'classification_agg'])\n",
      " task1 classification keys     : Index(['roc_auc_score', 'auc_pr', 'avg_prec_score', 'f1_max', 'p_f1_max', 'kappa', 'kappa_max', 'p_kappa_max', 'bceloss'], dtype='object')\n",
      " task1 classification_agg keys : dict_keys(['roc_auc_score', 'auc_pr', 'avg_prec_score', 'f1_max', 'p_f1_max', 'kappa', 'kappa_max', 'p_kappa_max', 'bceloss', 'sc_loss', 'logloss'])\n",
      "\n",
      " task1 agg sc_loss             : 0.000362\n",
      " task1 agg bce_loss            : 0.442671\n",
      " task1 agg bce_loss            : 0.000005\n",
      " task-task1                    : 0.180890\n",
      " task-task1                    : \n",
      "        roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.853887  0.899257        0.900315  0.848921  0.469815  0.544061   0.586327     0.658563  0.475622\n",
      "1          0.801908  0.689046        0.695202  0.633333  0.362752  0.377013   0.500773     0.431153  0.477802\n",
      "2          0.835165  0.547687        0.579702  0.640000  0.229632  0.000000   0.594779     0.294500  0.253000\n",
      "3          0.905724  0.426530        0.449074  0.500000  0.088820  0.000000   0.492537     0.088820  0.107322\n",
      "4          0.875000  0.768320        0.788492  0.769231  0.438809  0.347826   0.640000     0.438809  0.506533\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "467             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "468             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "469             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "470             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "471             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[472 rows x 9 columns]\n",
      " task-task1                    : \n",
      "  {'roc_auc_score': 0.7464901774322181, 'auc_pr': 0.6354555421194535, 'avg_prec_score': 0.6483019231779099, 'f1_max': 0.6831994927675538, 'p_f1_max': 0.3578873760071803, 'kappa': 0.25132334306725945, 'kappa_max': 0.4657551444681675, 'p_kappa_max': 0.4457074444380184, 'bceloss': 0.4426710787594943, 'sc_loss': 0.0003617804307869131, 'logloss': 4.900049176331579e-06}\n",
      "\n",
      " task2                         : 0.000478\n",
      " task3                         : 0.001259\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3228063/3197962997.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" task2                         : {ns.val_metrics['task2']['classification_agg']['sc_loss']:5f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" task3                         : {ns.val_metrics['task3']['classification_agg']['sc_loss']:5f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" loss                          : {ns.val_metrics['loss']['total']:5f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" train_time                    : {ns.val_metrics['train_time']:2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" epoch                         : {ns.val_metrics['epoch']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "print(f\" val_metric keys               : {ns.val_metrics.keys()}\")\n",
    "print(f\" aggreagted keys               : {ns.val_metrics['aggregated'].keys()}\")\n",
    "print(f\" task keys                     : {ns.val_metrics['task'].keys()}\")\n",
    "print(f\" task / task1 keys             : {ns.val_metrics['task']['task1']}\")\n",
    "print(f\" sparsity keys                 : {ns.val_metrics['sparsity'].keys()}\")\n",
    "print(f\" total keys                    : {ns.val_metrics['total'].keys()}\")\n",
    "print(f\" aggregated keys               : {ns.val_metrics['aggregated'].keys()}\")\n",
    "print()\n",
    "print(f\" task1 keys                    : {ns.val_metrics['task1'].keys()}\")\n",
    "print(f\" task1 classification keys     : {ns.val_metrics['task1']['classification'].keys()}\")\n",
    "print(f\" task1 classification_agg keys : {ns.val_metrics['task1']['classification_agg'].keys()}\")\n",
    "\n",
    "print()\n",
    "print(f\" task1 agg sc_loss             : {ns.val_metrics['task1']['classification_agg']['sc_loss']:5f}\")\n",
    "print(f\" task1 agg bce_loss            : {ns.val_metrics['task1']['classification_agg']['bceloss']:5f}\")\n",
    "print(f\" task1 agg bce_loss            : {ns.val_metrics['task1']['classification_agg']['logloss']:5f}\")\n",
    "print(f\" task-task1                    : {ns.val_metrics['task']['task1']:5f}\")\n",
    "print(f\" task-task1                    : \\n  {ns.val_metrics['task1']['classification']}\")\n",
    "print(f\" task-task1                    : \\n  {ns.val_metrics['task1']['classification_agg']}\")\n",
    "\n",
    "print()\n",
    "print(f\" task2                         : {ns.val_metrics['task2']['classification_agg']['sc_loss']:5f}\")\n",
    "print(f\" task3                         : {ns.val_metrics['task3']['classification_agg']['sc_loss']:5f}\")\n",
    "print(f\" loss                          : {ns.val_metrics['loss']['total']:5f}\")\n",
    "print(f\" train_time                    : {ns.val_metrics['train_time']:2f}\")\n",
    "print(f\" epoch                         : {ns.val_metrics['epoch']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "993103ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-29T10:44:38.417573Z",
     "start_time": "2022-08-29T10:44:38.383420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([472])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.batch_data['task1']['yc_trn_weights'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5a722",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:19:43.683550Z",
     "start_time": "2022-01-08T01:19:43.571450Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = environ.get_loss_dict()\n",
    "print(tmp.keys())\n",
    "pp.pprint(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90151319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T09:12:32.452187Z",
     "start_time": "2022-04-13T09:12:32.420905Z"
    }
   },
   "outputs": [],
   "source": [
    "type(ns.val_metrics['aggregated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55c031eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-29T10:13:48.522436Z",
     "start_time": "2022-08-29T10:13:48.375346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'parms': {   'gumbel_temp': 0.004459516789125928,\n",
      "                 'lambda_sharing': 0.05,\n",
      "                 'lambda_sparsity': 0.01,\n",
      "                 'lambda_tasks': 1.0,\n",
      "                 'lr_0': 0.0005,\n",
      "                 'lr_1': 0.0005,\n",
      "                 'policy_lr': 0.01,\n",
      "                 'train_layers': 6},\n",
      "    'sharing': {   'total': tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)},\n",
      "    'sparsity': {   'task1': tensor(8.4396e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
      "                    'task10': tensor(6.8022e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
      "                    'task2': tensor(8.6199e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
      "                    'task3': tensor(9.3598e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
      "                    'task4': tensor(7.2445e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
      "                    'task5': tensor(8.7382e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
      "                    'task6': tensor(7.7664e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
      "                    'task7': tensor(7.6732e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
      "                    'task8': tensor(8.3907e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
      "                    'task9': tensor(8.2935e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
      "                    'total': tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)},\n",
      "    'task': {   'task1': tensor(0.0742, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                'task10': tensor(0.0869, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                'task2': tensor(0.1428, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                'task3': tensor(0.3934, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                'task4': tensor(0.0626, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                'task5': tensor(0.2389, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                'task6': tensor(0.0543, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                'task7': tensor(0.1708, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                'task8': tensor(0.0452, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                'task9': tensor(0.0753, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                'total': tensor(1.3443, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)},\n",
      "    'task_mean': {   'task1': tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                     'task10': tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                     'task2': tensor(0.0015, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                     'task3': tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                     'task4': tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                     'task5': tensor(0.0022, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                     'task6': tensor(0.0017, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                     'task7': tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                     'task8': tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                     'task9': tensor(0.0012, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                     'total': tensor(0.0163, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)},\n",
      "    'total': {   'backprop': tensor(1.3468, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>),\n",
      "                 'policy': tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>),\n",
      "                 'task': 0.0,\n",
      "                 'tasks': tensor(1.3443, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>),\n",
      "                 'total': tensor(1.3468, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>),\n",
      "                 'total_mean': tensor(0.0188, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)}}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(ns.trn_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a5a1d7fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-29T10:16:26.685693Z",
     "start_time": "2022-08-29T10:16:26.367212Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'aggregated': {   'auc_pr': 0.6615142171123191,\n",
      "                      'avg_prec_score': 0.6754890273504701,\n",
      "                      'bceloss': 0.4622365384594069,\n",
      "                      'f1_max': 0.7105706539493313,\n",
      "                      'kappa': 0.2440221960877036,\n",
      "                      'kappa_max': 0.4854695532094693,\n",
      "                      'logloss': 5.540098849245579e-06,\n",
      "                      'p_f1_max': 0.3768589172211572,\n",
      "                      'p_kappa_max': 0.4539545361340589,\n",
      "                      'roc_auc_score': 0.762805749290287,\n",
      "                      'sc_loss': 0.004264734853556151},\n",
      "    'epoch': 132,\n",
      "    'parms': {   'gumbel_temp': 0.004459516789125928,\n",
      "                 'lambda_sharing': 0.05,\n",
      "                 'lambda_sparsity': 0.01,\n",
      "                 'lambda_tasks': 1.0,\n",
      "                 'lr_0': 0.0005,\n",
      "                 'lr_1': 0.0005,\n",
      "                 'policy_lr': 0.01,\n",
      "                 'train_layers': 0},\n",
      "    'sharing': {'total': 0.0018787450389936566},\n",
      "    'sparsity': {   'task1': 9.49912573560141e-05,\n",
      "                    'task10': 7.656700472580269e-05,\n",
      "                    'task2': 9.732114267535508e-05,\n",
      "                    'task3': 0.00010539083450566977,\n",
      "                    'task4': 8.158758282661438e-05,\n",
      "                    'task5': 9.836835670284927e-05,\n",
      "                    'task6': 8.73836615937762e-05,\n",
      "                    'task7': 8.636888378532603e-05,\n",
      "                    'task8': 9.444767783861607e-05,\n",
      "                    'task9': 9.336104267276824e-05,\n",
      "                    'total': 0.0009157847380265594},\n",
      "    'task': {   'task1': 0.18089021539345657,\n",
      "                'task10': 0.0688062959639614,\n",
      "                'task2': 0.2389282872784762,\n",
      "                'task3': 0.6293609962560168,\n",
      "                'task4': 0.11680530165019642,\n",
      "                'task5': 0.3288104819869383,\n",
      "                'task6': 0.07341936589004872,\n",
      "                'task7': 0.10117653884384077,\n",
      "                'task8': 0.12286847512342328,\n",
      "                'task9': 0.2713014683917159,\n",
      "                'total': 2.1323674267780754},\n",
      "    'task1': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.853887  0.899257        0.900315  0.848921  0.469815  0.544061   0.586327     0.658563  0.475622\n",
      "1          0.801908  0.689046        0.695202  0.633333  0.362752  0.377013   0.500773     0.431153  0.477802\n",
      "2          0.835165  0.547687        0.579702  0.640000  0.229632  0.000000   0.594779     0.294500  0.253000\n",
      "3          0.905724  0.426530        0.449074  0.500000  0.088820  0.000000   0.492537     0.088820  0.107322\n",
      "4          0.875000  0.768320        0.788492  0.769231  0.438809  0.347826   0.640000     0.438809  0.506533\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "467             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "468             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "469             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "470             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "471             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[472 rows x 9 columns],\n",
      "                 'classification_agg': {   'auc_pr': 0.6354555421194535,\n",
      "                                           'avg_prec_score': 0.6483019231779099,\n",
      "                                           'bceloss': 0.4426710787594943,\n",
      "                                           'f1_max': 0.6831994927675538,\n",
      "                                           'kappa': 0.25132334306725945,\n",
      "                                           'kappa_max': 0.4657551444681675,\n",
      "                                           'logloss': 4.900049176331579e-06,\n",
      "                                           'p_f1_max': 0.3578873760071803,\n",
      "                                           'p_kappa_max': 0.4457074444380184,\n",
      "                                           'roc_auc_score': 0.7464901774322181,\n",
      "                                           'sc_loss': 0.0003617804307869131}},\n",
      "    'task10': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.798928  0.560097        0.563844  0.548523  0.129678  0.381241   0.438369     0.288543  0.450415\n",
      "1          0.870369  0.374116        0.393024  0.561798  0.142230  0.160378   0.513271     0.142230  0.212588\n",
      "2          0.776399  0.077448        0.092074  0.214286  0.044753  0.000000   0.189534     0.044753  0.103184\n",
      "3          0.182464  0.001445        0.002890  0.005764  0.000411  0.000000   0.001054     0.000411  0.021277\n",
      "4          0.827696  0.599044        0.600732  0.598837  0.380174  0.405438   0.480206     0.380174  0.400359\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "67              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "68         0.440000  0.371550        0.396138  0.421053  0.056355  0.000000   0.272727     0.133430  0.732861\n",
      "69         0.210526  0.031250        0.062500  0.117647  0.005213  0.000000   0.025974     0.005213  0.275880\n",
      "70              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "71              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[72 rows x 9 columns],\n",
      "                  'classification_agg': {   'auc_pr': 0.5131623052304266,\n",
      "                                            'avg_prec_score': 0.5205123246863766,\n",
      "                                            'bceloss': 0.36322074012759215,\n",
      "                                            'f1_max': 0.5509302973582861,\n",
      "                                            'kappa': 0.1546375267444553,\n",
      "                                            'kappa_max': 0.37400013382462693,\n",
      "                                            'logloss': 3.7044414753936364e-06,\n",
      "                                            'p_f1_max': 0.25671434737383747,\n",
      "                                            'p_kappa_max': 0.3145875982904377,\n",
      "                                            'roc_auc_score': 0.7245804717056619,\n",
      "                                            'sc_loss': 0.0001376125919279228}},\n",
      "    'task2': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "1          0.688889  0.853481        0.860593  0.818182  0.518815  0.243243   0.471698     0.739954  0.589381\n",
      "2          0.877551  0.897155        0.903834  0.857143  0.161031  0.000000   0.714286     0.161031  0.947720\n",
      "3          0.769231  0.125000        0.250000  0.400000  0.010642  0.000000   0.322581     0.010642  0.331901\n",
      "4          0.914245  0.962551        0.962771  0.896175  0.843580  0.517796   0.643076     0.843580  0.399714\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "619             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "620        0.857143  0.946689        0.948140  0.888889  0.675850  0.689655   0.709677     0.908967  0.429744\n",
      "621        1.000000  1.000000        1.000000  1.000000  0.556741  1.000000   1.000000     0.556741  0.306039\n",
      "622        0.814815  0.271429        0.365079  0.600000  0.047774  0.000000   0.500000     0.047774  0.444226\n",
      "623             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[624 rows x 9 columns],\n",
      "                 'classification_agg': {   'auc_pr': 0.6748042018059991,\n",
      "                                           'avg_prec_score': 0.6902116980490748,\n",
      "                                           'bceloss': 0.48071937915300117,\n",
      "                                           'f1_max': 0.7249462579954112,\n",
      "                                           'kappa': 0.2144165935465083,\n",
      "                                           'kappa_max': 0.5133971408051383,\n",
      "                                           'logloss': 4.931949371007869e-06,\n",
      "                                           'p_f1_max': 0.38456619052933927,\n",
      "                                           'p_kappa_max': 0.450523973587567,\n",
      "                                           'roc_auc_score': 0.7692313025617368,\n",
      "                                           'sc_loss': 0.0004778565745569524}},\n",
      "    'task3': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.896334  0.904223        0.904648  0.830645  0.471621  0.609159   0.627013     0.471621  0.399827\n",
      "1          0.920351  0.877204        0.877932  0.796875  0.533346  0.709121   0.718858     0.533346  0.322215\n",
      "2          0.952432  0.862720        0.864013  0.795181  0.297973  0.741565   0.755169     0.565231  0.207793\n",
      "3          0.954468  0.624552        0.643774  0.727273  0.152880  0.544381   0.705711     0.317494  0.137924\n",
      "4          0.896753  0.992876        0.992901  0.974684  0.638292  0.172646   0.442598     0.691578  0.168490\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "683             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "684        0.958042  0.950764        0.953063  0.909091  0.875153  0.000000   0.832168     0.875153  0.928082\n",
      "685        0.923077  0.729468        0.749923  0.777778  0.898021  0.535211   0.700000     0.898021  0.635099\n",
      "686        0.955556  0.461111        0.588889  0.750000  0.508621  0.717949   0.717949     0.508621  0.245687\n",
      "687             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[688 rows x 9 columns],\n",
      "                 'classification_agg': {   'auc_pr': 0.7158077225730475,\n",
      "                                           'avg_prec_score': 0.7265412333903059,\n",
      "                                           'bceloss': 0.45459871826191933,\n",
      "                                           'f1_max': 0.7483553717127268,\n",
      "                                           'kappa': 0.28259126449769917,\n",
      "                                           'kappa_max': 0.5090774697172191,\n",
      "                                           'logloss': 6.155300363394689e-06,\n",
      "                                           'p_f1_max': 0.40700511136092243,\n",
      "                                           'p_kappa_max': 0.4983405425643119,\n",
      "                                           'roc_auc_score': 0.7803981423910051,\n",
      "                                           'sc_loss': 0.0012587219925120337}},\n",
      "    'task4': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.715674  0.483994        0.488713  0.520548  0.320055  0.242424   0.269819     0.320055  0.520963\n",
      "1          0.650360  0.292461        0.296859  0.292135  0.171587  0.162240   0.218128     0.235847  0.320899\n",
      "2          0.717983  0.121998        0.140473  0.272727  0.065797  0.000000   0.238028     0.100656  0.133204\n",
      "3               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "4          0.644361  0.427545        0.431394  0.414634  0.130005  0.211286   0.279208     0.452133  0.525942\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "187        0.936047  0.750920        0.764286  0.666667  0.399549  0.549811   0.609495     0.566793  0.379314\n",
      "188        0.300000  0.767498        0.780960  0.869565  0.914721  0.000000   0.165138     0.967308  0.707544\n",
      "189        0.500000  0.768374        0.782263  0.857143  0.531777  0.000000   0.315789     0.531777  0.699541\n",
      "190        0.600000  0.240675        0.319444  0.545455  0.227540  0.000000   0.315789     0.227540  0.537061\n",
      "191             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[192 rows x 9 columns],\n",
      "                 'classification_agg': {   'auc_pr': 0.6395478227550249,\n",
      "                                           'avg_prec_score': 0.6506610849436976,\n",
      "                                           'bceloss': 0.45998318476277755,\n",
      "                                           'f1_max': 0.6907144078700322,\n",
      "                                           'kappa': 0.22881604956911195,\n",
      "                                           'kappa_max': 0.45691409358446006,\n",
      "                                           'logloss': 5.087117357702035e-06,\n",
      "                                           'p_f1_max': 0.3404774126712096,\n",
      "                                           'p_kappa_max': 0.4129430415694081,\n",
      "                                           'roc_auc_score': 0.7486289678365717,\n",
      "                                           'sc_loss': 0.00023361060330039286}},\n",
      "    'task5': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.893056  0.959562        0.959896  0.909091  0.780922  0.066667   0.683128     0.784120  0.470811\n",
      "1          0.864502  0.903580        0.904584  0.834951  0.427176  0.542104   0.588202     0.465606  0.495198\n",
      "2          0.862207  0.800060        0.803503  0.759494  0.272482  0.342256   0.565194     0.272482  0.496469\n",
      "3          0.905473  0.644011        0.662059  0.687500  0.213684  0.084864   0.616426     0.213684  0.405482\n",
      "4          0.750798  0.847329        0.848348  0.823529  0.542532  0.313374   0.422944     0.616245  0.579146\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "615             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "616             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "617        1.000000  1.000000        1.000000  1.000000  0.322837  0.000000   1.000000     0.322837  0.491196\n",
      "618             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "619             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[620 rows x 9 columns],\n",
      "                 'classification_agg': {   'auc_pr': 0.6684552187644772,\n",
      "                                           'avg_prec_score': 0.6829009197985176,\n",
      "                                           'bceloss': 0.49525732637204706,\n",
      "                                           'f1_max': 0.7203649109595711,\n",
      "                                           'kappa': 0.21777329260721695,\n",
      "                                           'kappa_max': 0.4721200586459189,\n",
      "                                           'logloss': 6.706312094369535e-06,\n",
      "                                           'p_f1_max': 0.37624364139318983,\n",
      "                                           'p_kappa_max': 0.4547409692177291,\n",
      "                                           'roc_auc_score': 0.7491650085973957,\n",
      "                                           'sc_loss': 0.0006576209639738766}},\n",
      "    'task6': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.781905  0.886630        0.887160  0.866142  0.862816  0.191872   0.509018     0.868526  0.592170\n",
      "1          0.778521  0.780895        0.782017  0.744337  0.489601  0.384615   0.423077     0.593511  0.601321\n",
      "2          0.829063  0.709736        0.711442  0.635514  0.622576  0.428199   0.543408     0.622576  0.436174\n",
      "3          0.809283  0.352573        0.392817  0.631579  0.392529  0.484342   0.616885     0.392529  0.157910\n",
      "4          0.753919  0.832176        0.833162  0.823881  0.506259  0.425643   0.436537     0.506259  0.560446\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "179        1.000000  1.000000        1.000000  1.000000  0.280476  0.000000   1.000000     0.280476  0.442326\n",
      "180        0.902857  0.895235        0.898657  0.904762  0.603249  0.824762   0.824762     0.603249  0.447060\n",
      "181        1.000000  1.000000        1.000000  1.000000  0.339044  0.000000   1.000000     0.339044  0.068640\n",
      "182        1.000000  1.000000        1.000000  1.000000  0.254907  0.000000   1.000000     0.254907  0.066957\n",
      "183        1.000000  1.000000        1.000000  1.000000  0.209361  0.000000   1.000000     0.209361  0.048276\n",
      "\n",
      "[184 rows x 9 columns],\n",
      "                 'classification_agg': {   'auc_pr': 0.6200309101317384,\n",
      "                                           'avg_prec_score': 0.6395234349424801,\n",
      "                                           'bceloss': 0.48474329482106604,\n",
      "                                           'f1_max': 0.6907939665916162,\n",
      "                                           'kappa': 0.21011523875112031,\n",
      "                                           'kappa_max': 0.4585411992097791,\n",
      "                                           'logloss': 5.300654529640367e-06,\n",
      "                                           'p_f1_max': 0.4006828726214521,\n",
      "                                           'p_kappa_max': 0.46870075210052375,\n",
      "                                           'roc_auc_score': 0.7309450365636571,\n",
      "                                           'sc_loss': 0.00014683873178009742}},\n",
      "    'task7': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.820409  0.893490        0.893791  0.853583  0.306561  0.457109   0.460579     0.431258  0.482618\n",
      "1          0.848226  0.793024        0.794003  0.742105  0.233669  0.512575   0.538224     0.233669  0.505176\n",
      "2          0.739671  0.381471        0.386715  0.416667  0.071951  0.083833   0.260880     0.071951  0.475347\n",
      "3          0.693182  0.043086        0.051077  0.133333  0.044780  0.000000   0.104099     0.044780  0.119415\n",
      "4          0.635545  0.417825        0.425318  0.524590  0.278885  0.143157   0.234323     0.278885  0.555326\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "219             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "220             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "221        0.854167  0.990275        0.990384  0.969697  0.878780  0.000000   0.291667     0.906615  0.206814\n",
      "222             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "223             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[224 rows x 9 columns],\n",
      "                 'classification_agg': {   'auc_pr': 0.6250442996567229,\n",
      "                                           'avg_prec_score': 0.6482903180466504,\n",
      "                                           'bceloss': 0.4353605499225004,\n",
      "                                           'f1_max': 0.705568660155091,\n",
      "                                           'kappa': 0.26704738487774704,\n",
      "                                           'kappa_max': 0.5306740955868674,\n",
      "                                           'logloss': 4.8877554997024525e-06,\n",
      "                                           'p_f1_max': 0.3483335578281964,\n",
      "                                           'p_kappa_max': 0.395927329388048,\n",
      "                                           'roc_auc_score': 0.7960202633125136,\n",
      "                                           'sc_loss': 0.00020235307768768154}},\n",
      "    'task8': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.702971  0.488650        0.489703  0.542056  0.183781  0.212193   0.273877     0.315472  0.571840\n",
      "1          0.732286  0.183177        0.185387  0.248804  0.065244  0.056784   0.163456     0.094551  0.265877\n",
      "2          0.807321  0.169142        0.178897  0.258065  0.602967  0.235126   0.251847     0.602967  0.068249\n",
      "3          0.931551  0.506992        0.508155  0.666667  0.081738  0.000000   0.666088     0.081738  0.013656\n",
      "4          0.910526  0.870649        0.875946  0.904762  0.172133  0.000000   0.795812     0.172133  0.791296\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "143             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "144        0.837662  0.893135        0.894885  0.810811  0.382552  0.000000   0.676692     0.382552  0.661339\n",
      "145             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "146             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "147             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[148 rows x 9 columns],\n",
      "                 'classification_agg': {   'auc_pr': 0.6177130120152883,\n",
      "                                           'avg_prec_score': 0.6306218480502103,\n",
      "                                           'bceloss': 0.47948727503277455,\n",
      "                                           'f1_max': 0.6788761010757343,\n",
      "                                           'kappa': 0.2229436839106381,\n",
      "                                           'kappa_max': 0.4531254951885111,\n",
      "                                           'logloss': 4.845544627654031e-06,\n",
      "                                           'p_f1_max': 0.42409406053020227,\n",
      "                                           'p_kappa_max': 0.4829567471589846,\n",
      "                                           'roc_auc_score': 0.7499659097292742,\n",
      "                                           'sc_loss': 0.0002457369502468466}},\n",
      "    'task9': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.746997  0.849361        0.850937  0.865854  0.460544  0.431113   0.510914     0.533225  0.515942\n",
      "1          0.621914  0.565738        0.574533  0.684211  0.233230  0.169302   0.215440     0.313893  0.684312\n",
      "2          0.819277  0.663291        0.669194  0.656716  0.270085  0.134959   0.514983     0.270085  0.479906\n",
      "3          0.728042  0.340233        0.351677  0.363636  0.265855  0.000000   0.344828     0.265855  0.244073\n",
      "4          0.823703  0.632875        0.634940  0.608187  0.503286  0.486953   0.493391     0.503286  0.444612\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "339             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "340             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "341             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "342             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "343             NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[344 rows x 9 columns],\n",
      "                 'classification_agg': {   'auc_pr': 0.623872755077307,\n",
      "                                           'avg_prec_score': 0.640792960158618,\n",
      "                                           'bceloss': 0.44189102663281,\n",
      "                                           'f1_max': 0.6807436020991257,\n",
      "                                           'kappa': 0.26412541547723506,\n",
      "                                           'kappa_max': 0.477982724653195,\n",
      "                                           'logloss': 5.795058706248204e-06,\n",
      "                                           'p_f1_max': 0.348254276338864,\n",
      "                                           'p_kappa_max': 0.42398162739905154,\n",
      "                                           'roc_auc_score': 0.7682730856411328,\n",
      "                                           'sc_loss': 0.0005426029367834319}},\n",
      "    'task_mean': {   'task1': nan,\n",
      "                     'task10': nan,\n",
      "                     'task2': nan,\n",
      "                     'task3': 0.0033536737942926834,\n",
      "                     'task4': nan,\n",
      "                     'task5': nan,\n",
      "                     'task6': nan,\n",
      "                     'task7': nan,\n",
      "                     'task8': nan,\n",
      "                     'task9': nan,\n",
      "                     'total': nan},\n",
      "    'total': {   'policy': 0.002794529777020216,\n",
      "                 'task': 2.1323674267780754,\n",
      "                 'total': 2.1351619565550957,\n",
      "                 'total_mean': nan},\n",
      "    'train_time': -2.384185791015625e-07}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5177f8a7",
   "metadata": {},
   "source": [
    "### val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "730506ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-29T10:46:04.669904Z",
     "start_time": "2022-08-29T10:46:04.636155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataloaders.chembl_dataloader.ClassRegrSparseDataset_v3 at 0x7fbad04449d0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dldrs.val_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "11f05e1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-29T10:51:15.390154Z",
     "start_time": "2022-08-29T10:51:15.214311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<86274x472 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 50791 stored elements in Compressed Sparse Row format>,\n",
       " <86274x624 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 65658 stored elements in Compressed Sparse Row format>,\n",
       " <86274x688 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 136843 stored elements in Compressed Sparse Row format>,\n",
       " <86274x192 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 30136 stored elements in Compressed Sparse Row format>,\n",
       " <86274x620 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 64840 stored elements in Compressed Sparse Row format>,\n",
       " <86274x184 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 19189 stored elements in Compressed Sparse Row format>,\n",
       " <86274x224 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 28096 stored elements in Compressed Sparse Row format>,\n",
       " <86274x148 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 34404 stored elements in Compressed Sparse Row format>,\n",
       " <86274x344 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 63732 stored elements in Compressed Sparse Row format>,\n",
       " <86274x72 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 25024 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dldrs.val_loader.dataset.y_class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb45fcf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:31:55.581510Z",
     "start_time": "2022-04-02T13:31:55.526855Z"
    }
   },
   "outputs": [],
   "source": [
    "(environ.val_data['task1']['yc_data'][0] == environ.val_data['task1']['yc_data']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02211ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:20:55.327255Z",
     "start_time": "2022-04-02T14:20:55.026238Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.sparsechem_utils import compute_metrics, aggregate_results\n",
    "import pandas\n",
    "cc = compute_metrics(cols   = environ.val_data['task1']['yc_ind'][1], \n",
    "                     y_true = environ.val_data['task1']['yc_data'], \n",
    "                     y_score= environ.val_data['task1']['yc_hat'] ,\n",
    "                     num_tasks=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0a5712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:34:57.196163Z",
     "start_time": "2022-04-02T13:34:57.130013Z"
    }
   },
   "outputs": [],
   "source": [
    " df   = pd.DataFrame({\"task\"   : environ.val_data['task1']['yc_ind'][1], \n",
    "                      \"y_true\" : environ.val_data['task1']['yc_data'],  \n",
    "                      \"y_score\": environ.val_data['task1']['yc_hat']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde23676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:44:52.754320Z",
     "start_time": "2022-04-02T13:44:52.611945Z"
    }
   },
   "outputs": [],
   "source": [
    "for task, frame in df.groupby(\"task\", sort=True):\n",
    "    print(f\" task {task}\")\n",
    "    print(frame.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b887a79b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:46:29.715440Z",
     "start_time": "2022-04-02T13:46:29.640674Z"
    }
   },
   "outputs": [],
   "source": [
    "# df\n",
    "df.groupby(\"task\", sort=True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5862488b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T11:10:20.301689Z",
     "start_time": "2022-04-28T11:10:20.151621Z"
    }
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e466147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:26:58.189057Z",
     "start_time": "2022-04-02T14:26:58.126134Z"
    }
   },
   "outputs": [],
   "source": [
    "print(environ.batch_data['task1']['yc_aggr_weights'])\n",
    "environ.batch['task1']['aggr_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007f28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = aggregate_results(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4570a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T17:11:11.578048Z",
     "start_time": "2022-04-02T17:11:11.535763Z"
    }
   },
   "outputs": [],
   "source": [
    "dldrs.trainset0.tasks_weights_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82a453",
   "metadata": {},
   "source": [
    "### Post Warm-up Training stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f0235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:37:10.158440Z",
     "start_time": "2022-01-28T16:37:09.742327Z"
    }
   },
   "outputs": [],
   "source": [
    "get_all_task_logits\n",
    "    \"p = environ.get_sample_policy(hard_sampling = False)\\n\"print(p)\n",
    "p = environ.get_policy_prob()\n",
    "print(p)\n",
    "p = environ.get_policy_logits()\n",
    "print(p)\n",
    "\n",
    "# p = environ.get_current_policy()\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bddd44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:40:37.799917Z",
     "start_time": "2022-01-28T16:40:37.773177Z"
    }
   },
   "outputs": [],
   "source": [
    "a = softmax([0.0, 1])\n",
    "print(a)\n",
    "sampled = np.random.choice((1, 0), p=a)\n",
    "print(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8f376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:13:16.205889Z",
     "start_time": "2022-01-28T16:13:16.179303Z"
    }
   },
   "outputs": [],
   "source": [
    "print(environ.optimizers['weights'])\n",
    "print(environ.schedulers['weights'].get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf9c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:50.411465Z",
     "start_time": "2022-02-01T12:46:50.020540Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('losses.keys      : ', environ.losses.keys())\n",
    "print('losses[task]keys : ', environ.losses['task1'].keys())\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20950069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T22:57:02.151169Z",
     "start_time": "2022-01-15T22:57:02.056562Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print( environ.val_metrics.keys())\n",
    "# pp.pprint(val_metrics)\n",
    "print(type(environ.val_metrics['aggregated']))\n",
    "print()\n",
    "print(type(environ.val_metrics['task1']['classification_agg']))\n",
    "print()\n",
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2d510",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Policy / Logit stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb628497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:35:14.041577Z",
     "start_time": "2022-02-08T20:35:14.018303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.special          import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eed454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:30.103364Z",
     "start_time": "2022-02-08T20:00:30.068021Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03b5cc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_task_logits(n)` Get logits for task group n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed8b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:56:35.652087Z",
     "start_time": "2022-02-08T20:56:35.327406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task_logits = environ.get_task_logits(1)\n",
    "print(task_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66fa5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_arch_parameters()`: Get last used logits from network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85521e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:31.101960Z",
     "start_time": "2022-02-08T20:00:30.757064Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b0bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:06.054699Z",
     "start_time": "2022-02-09T15:43:05.689327Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871ee38",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_logits()`:  Get Policy Logits - returns same as `get_arch_parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb40c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:24.972390Z",
     "start_time": "2022-02-09T15:43:24.636629Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs = environ.get_policy_logits()\n",
    "for i in logs:\n",
    "    print(i, '\\n')\n",
    "# probs = softmax(logs, axis= -1)\n",
    "# for i in probs:\n",
    "#     print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080a364",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_prob()` : Gets the softmax of the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c75af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:29.733732Z",
     "start_time": "2022-02-09T15:43:29.699600Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "for i in policy_softmaxs:\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3160d9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = False)` : Calls test_sample_policy of network with random choices based on softmax of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f411444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:21:15.636722Z",
     "start_time": "2022-02-08T22:21:15.165456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "policies,logits = environ.get_sample_policy(hard_sampling = False)\n",
    "\n",
    "for l, p, s in zip(logits, policies, policy_softmaxs) :\n",
    "    for  l_row, p_row, s_row in zip(l, p, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802664ec",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = True)` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea65bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:59:40.790899Z",
     "start_time": "2022-02-08T20:59:40.726657Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "hard_policies, logits = environ.get_sample_policy(hard_sampling = True)\n",
    "\n",
    "for p,l,s in zip(hard_policies, logits, policy_softmaxs) :\n",
    "    for  p_row, l_row, s_row in zip(p, l, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c39cf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fe096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:00:47.452220Z",
     "start_time": "2022-02-08T21:00:47.422902Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\" Layer    task 1      task 2      task 3\")\n",
    "print(f\" -----    ------      ------      ------\")\n",
    "for idx, (l1, l2, l3) in enumerate(zip(hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1}       {l2}       {l3}\")\n",
    "    \n",
    "\n",
    "    print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade0ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:39:39.936555Z",
     "start_time": "2022-02-08T22:39:39.911591Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_trained_policy(iter):\n",
    "\n",
    "    policy_softmaxs = environ.get_policy_prob()\n",
    "    policy_argmaxs = 1-np.argmax(policy_softmaxs, axis = -1)\n",
    "    print(f\"  Trained polcies at iteration: {iter} \")\n",
    "    print(f\"                   task 1                           task 2                         task 3        \")\n",
    "    print(f\" Layer       softmax        select          softmax        select          softmax        select   \")\n",
    "    print(f\" -----    ---------------   ------       ---------------   ------       ---------------   ------   \")\n",
    "    for idx, (l1,l2,l3,  p1,p2,p3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2], policy_argmaxs[0], policy_argmaxs[1], policy_argmaxs[2]),1):\n",
    "        print(f\"   {idx}      {l1[0]:.4f}   {l1[1]:.4f}   {p1:4d}    {l2[0]:11.4f}   {l2[1]:.4f}   {p2:4d}    {l3[0]:11.4f}   {l3[1]:.4f}   {p3:4d}\")\n",
    "\n",
    "    print()\n",
    "# print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec208dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:42:12.650813Z",
     "start_time": "2022-02-08T22:42:12.330169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display_trained_policy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec517e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:07:30.836214Z",
     "start_time": "2022-02-08T22:07:30.804575Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"                        POLICIES (SOFTMAX)                                       task 3          \")\n",
    "print(f\" Layer    task1              task2            task3 softmax         softmax         argmax         softmax         argmax   \")\n",
    "print(f\" -----    -------------     -------------     -------------   ------   \")\n",
    "for idx, (l1,l2,l3, h1,h2,h3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2],hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1[0]:.4f} {l1[1]:.4f}     {l2[0]:.4f} {l2[1]:.4f}     {l3[0]:.4f} {l3[1]:.4f}    {h3}\")\n",
    "    \n",
    "print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbeacb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:04:50.757406Z",
     "start_time": "2022-02-08T22:04:50.731736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(policy_softmaxs[2], np.argmax(1-policy_softmaxs[2], axis = -1))\n",
    "print(policy_softmaxs, np.argmax(policy_softmaxs, axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be0240",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_current_logits()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb7240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:19:06.155425Z",
     "start_time": "2022-02-08T21:19:06.118640Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits  = (environ.get_current_logits())\n",
    "for i in logits:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e84662",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_current_policy()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cfa24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:40:06.543376Z",
     "start_time": "2022-02-08T20:40:06.230711Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pols  = (environ.get_current_policy())\n",
    "\n",
    "for i in pols:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f556a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T18:27:33.593255Z",
     "start_time": "2022-01-27T18:27:33.553141Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792710e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `gumbel_softmax()`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265490e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:28:17.107529Z",
     "start_time": "2022-02-08T21:28:17.084910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', floatmode = 'maxprec_equal')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb0087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:35:11.617269Z",
     "start_time": "2022-02-08T21:35:11.569599Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.temp)\n",
    "# tau = environ.temp\n",
    "tau = 1\n",
    "for i in range(3): \n",
    "    logits_tensor = torch.tensor(logits[0])\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=tau, hard=False).cpu().numpy() \n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=tau, hard=True).cpu().numpy()\n",
    "    \n",
    "    for l, gs, gh in zip(lgts, gumbel_soft, gumbel_hard):\n",
    "        print(f\"   {l}   \\t {gs}            \\t {gh}\")\n",
    "#     print(lgts)\n",
    "#     print(gumbel_soft)\n",
    "#     print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5ef7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e0e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:21:35.524957Z",
     "start_time": "2022-02-08T21:21:35.488812Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for lgts in logits:\n",
    "    logits_tensor = torch.tensor(lgts)\n",
    "    print(lgts)\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=1, hard=False)\n",
    "    print(gumbel_soft)\n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=1, hard=True)\n",
    "    print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34a06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T20:49:37.643349Z",
     "start_time": "2022-02-03T20:49:37.580786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smax = scipy.special.softmax(logs, axis =1)\n",
    "# smax = np.array( \n",
    "# [[0.46973792, 0.530262  ],\n",
    "#  [0.45025694, 0.549743  ],\n",
    "#  [0.4443086 , 0.5556915 ],\n",
    "#  [0.4138397 , 0.58616036],\n",
    "#  [0.4140113 , 0.5859887 ],\n",
    "#  [0.42114905, 0.57885087]])\n",
    "\n",
    "print(smax.shape)\n",
    "print(smax)\n",
    "print(smax[0])\n",
    "print(smax[0].sum())\n",
    "print(np.random.choice((1,0), p =smax[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7de25c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:15:19.893888Z",
     "start_time": "2022-02-08T21:15:19.870899Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logs = np.array(\n",
    "[[0.33064184, 0.42053092],\n",
    " [0.3532089 , 0.52056104],\n",
    " [0.3888512 , 0.5680909 ],\n",
    " [0.42039296, 0.694217  ],\n",
    " [0.4519742 , 0.73311865],\n",
    " [0.48401102, 0.7522658 ]],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "399px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "888d4fda4588b3bfc9793c8a97c6f83877963bb7385ca7ca0c08738cf63adc49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
