{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23a61ee",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c54386fb",
   "execution_count": 1,
   "id": "c54386fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:28.927571Z",
     "start_time": "2022-09-05T20:12:28.891959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da64055f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-18T22:21:15.342994Z",
     "start_time": "2023-01-18T22:21:15.315352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kbardool/WSL-projs/AdaSparseChem/notebooks\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python39.zip\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/lib-dynload\n",
      "\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages\n",
      "/home/kbardool/WSL-projs/leader_follower\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'PYTHONPATH'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mpath:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPYTHONPATH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    676\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PYTHONPATH'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "for i in sys.path:\n",
    "    print(i)\n",
    "print(os.environ['PYTHONPATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8eae14a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:31.187083Z",
     "start_time": "2022-09-05T20:12:28.930025Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../src')\n",
    "# sys.path.insert(0, '/home/kbardool/kusanagi/AdaSparseChem/src') ; print(sys.path)\n",
    "import time\n",
    "import argparse\n",
    "import yaml\n",
    "import types, copy, pprint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "## Set visible GPU device \n",
    "##----------------------------------------------\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "# from pynvml import *\n",
    "from utils import (initialize, init_test_dataloader, init_environment, init_wandb, inference_initializations, model_initializations, \n",
    "                   check_for_resume_training, disp_dataloader_info, disp_info_1, warmup_phase, weight_policy_training, run_inference,\n",
    "                   display_gpu_info, print_separator, print_heading, print_underline, \n",
    "                   timestring, print_loss, get_command_line_args, load_from_pickle) \n",
    "import argparse\n",
    "import yaml\n",
    "import types, copy, pprint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "## Set visible GPU device \n",
    "##----------------------------------------------\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "# from pynvml import *\n",
    "from utils import (initialize, init_test_dataloader, init_environment, init_wandb, inference_initializations, model_initializations, \n",
    "                   check_for_resume_training, disp_dataloader_info, disp_info_1, warmup_phase, weight_policy_training, run_inference,\n",
    "                   display_gpu_info, print_separator, print_heading, print_underline, \n",
    "                   timestring, print_loss, get_command_line_args, load_from_pickle) \n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "pd.options.display.width = 132\n",
    "# torch.set_printoptions(precision=6, threshold=None, edgeitems=None, linewidth=132, profile=None, sci_mode=None)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "pd.options.display.width = 132\n",
    "# torch.set_printoptions(precision=6, threshold=None, edgeitems=None, linewidth=132, profile=None, sci_mode=None)\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Test.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "296df111",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:31.218126Z",
     "start_time": "2022-09-05T20:12:31.188866Z"
    }
   },
   "outputs": [],
   "source": [
    "# config_file      = \"../yamls/chembl_mini_train.yaml\"\n",
    "config_file      = \"../yamls/chembl_cb29_train.yaml\"\n",
    "config_file      = \"../yamls/chembl_cb29_test_10task.yaml\"\n",
    "batch_size=4098\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e994df7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:31.281097Z",
     "start_time": "2022-09-05T20:12:31.221230Z"
    }
   },
   "outputs": [],
   "source": [
    "test_input_args = f\" --config  {config_file} \" \\\n",
    "             \" --exp_desc     weight 105 bch/ep policy 105 bch/ep \" \\\n",
    "             \" --warmup_epochs        10 \"  \\\n",
    "             \" --hidden_size         4000 4000 4000 4000 4000 4000\"  \\\n",
    "             \" --tail_hidden_size    4000 \"  \\\n",
    "             \" --first_dropout       0.80 \"  \\\n",
    "             \" --middle_dropout      0.80\"  \\\n",
    "             \" --last_dropout        0.80 \"  \\\n",
    "             \" --seed_idx              0 \"  \\\n",
    "             f\" --batch_size        {batch_size} \"  \\\n",
    "             \" --task_lr           0.001 \"  \\\n",
    "             \" --backbone_lr       0.001 \"  \\\n",
    "             \" --decay_lr_rate       0.3 \"  \\\n",
    "             \" --decay_lr_freq        10 \"  \\\n",
    "             \" --policy_lr         0.001 \"  \\\n",
    "             \" --lambda_sparsity    0.02 \"  \\\n",
    "             \" --lambda_sharing     0.01 \"  \\\n",
    "             \" --skip_hidden       False \"  \\\n",
    "             \" --skip_residual     False \"  \\\n",
    "             \" --pytorch_threads       4 \"  \\\n",
    "             \" --cuda_devices          2\"   \\\n",
    "             \" --gpu_ids               0 \"  \\\n",
    "             \" --resume\"                    \\\n",
    "             \" --resume_path        ../../experiments/AdaSparseChem-cb29-10task/4000x6_0829_2050_lr0.001_do0.8/\" \\\n",
    "             \" --resume_ckpt        model_best\" \\\n",
    "             \" --resume_metrics     metrics_best.pickle\" \\\n",
    "             \" --exp_id             h05zsolg\" \\\n",
    "             \" --exp_name           0712_0950\" \\\n",
    "             \" --folder_sfx         RESUME4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd8299f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:31.346838Z",
     "start_time": "2022-09-05T20:12:31.283780Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_FROM_PATH  = '../../experiments/AdaSparseChem-cb29-10task/4000x6_0829_2050_lr0.001_do0.8/'\n",
    "TEST_MODEL_CKPT = 'model_best'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "execution_count": 3,
   "id": "296df111",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:31.218126Z",
     "start_time": "2022-09-05T20:12:31.188866Z"
    }
   },
   "outputs": [],
   "source": [
    "# config_file      = \"../yamls/chembl_mini_train.yaml\"\n",
    "config_file      = \"../yamls/chembl_cb29_train.yaml\"\n",
    "config_file      = \"../yamls/chembl_cb29_test_10task.yaml\"\n",
    "batch_size=4098\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e994df7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:31.281097Z",
     "start_time": "2022-09-05T20:12:31.221230Z"
    }
   },
   "outputs": [],
   "source": [
    "test_input_args = f\" --config  {config_file} \" \\\n",
    "             \" --exp_desc     weight 105 bch/ep policy 105 bch/ep \" \\\n",
    "             \" --warmup_epochs        10 \"  \\\n",
    "             \" --hidden_size         4000 4000 4000 4000 4000 4000\"  \\\n",
    "             \" --tail_hidden_size    4000 \"  \\\n",
    "             \" --first_dropout       0.80 \"  \\\n",
    "             \" --middle_dropout      0.80\"  \\\n",
    "             \" --last_dropout        0.80 \"  \\\n",
    "             \" --seed_idx              0 \"  \\\n",
    "             f\" --batch_size        {batch_size} \"  \\\n",
    "             \" --task_lr           0.001 \"  \\\n",
    "             \" --backbone_lr       0.001 \"  \\\n",
    "             \" --decay_lr_rate       0.3 \"  \\\n",
    "             \" --decay_lr_freq        10 \"  \\\n",
    "             \" --policy_lr         0.001 \"  \\\n",
    "             \" --lambda_sparsity    0.02 \"  \\\n",
    "             \" --lambda_sharing     0.01 \"  \\\n",
    "             \" --skip_hidden       False \"  \\\n",
    "             \" --skip_residual     False \"  \\\n",
    "             \" --pytorch_threads       4 \"  \\\n",
    "             \" --cuda_devices          2\"   \\\n",
    "             \" --gpu_ids               0 \"  \\\n",
    "             \" --resume\"                    \\\n",
    "             \" --resume_path        ../../experiments/AdaSparseChem-cb29-10task/4000x6_0829_2050_lr0.001_do0.8/\" \\\n",
    "             \" --resume_ckpt        model_best\" \\\n",
    "             \" --resume_metrics     metrics_best.pickle\" \\\n",
    "             \" --exp_id             h05zsolg\" \\\n",
    "             \" --exp_name           0712_0950\" \\\n",
    "             \" --folder_sfx         RESUME4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd8299f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:31.346838Z",
     "start_time": "2022-09-05T20:12:31.283780Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_FROM_PATH  = '../../experiments/AdaSparseChem-cb29-10task/4000x6_0829_2050_lr0.001_do0.8/'\n",
    "TEST_MODEL_CKPT = 'model_best'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5cd8ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:31.382346Z",
     "start_time": "2022-09-05T20:12:31.349576Z"
    }
   },
   "outputs": [],
   "source": [
    "input_args = f\" --config        {config_file} \" \\\n",
    "              \" --project_name  AdaSparseChem-cb29-10Task-Test \" \\\n",
    "              \" --folder_sfx    test_0\" \\\n",
    "              \" --exp_desc Test phase of 00225_1530 run - 0\" \\\n",
    "             f\" --batch_size {batch_size}\" \\\n",
    "              \" --cuda_devices 2 \" \\\n",
    "             \" --hidden_size         4000 4000 4000 4000 4000 4000\"  \\\n",
    "             \" --tail_hidden_size    4000 \"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e1631dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:31.508692Z",
     "start_time": "2022-09-05T20:12:31.384634Z"
     "end_time": "2022-09-05T20:12:31.382346Z",
     "start_time": "2022-09-05T20:12:31.349576Z"
    }
   },
   "outputs": [],
   "source": [
    "input_args = f\" --config        {config_file} \" \\\n",
    "              \" --project_name  AdaSparseChem-cb29-10Task-Test \" \\\n",
    "              \" --folder_sfx    test_0\" \\\n",
    "              \" --exp_desc Test phase of 00225_1530 run - 0\" \\\n",
    "             f\" --batch_size {batch_size}\" \\\n",
    "              \" --cuda_devices 2 \" \\\n",
    "             \" --hidden_size         4000 4000 4000 4000 4000 4000\"  \\\n",
    "             \" --tail_hidden_size    4000 \"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e1631dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:31.508692Z",
     "start_time": "2022-09-05T20:12:31.384634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " command line parms : \n",
      " command line parms : \n",
      "------------------------\n",
      " config...................  ../yamls/chembl_cb29_test_10task.yaml\n",
      " project_name.............  AdaSparseChem-cb29-10Task-Test\n",
      " exp_id...................  17n83toa\n",
      " exp_name.................  None\n",
      " config...................  ../yamls/chembl_cb29_test_10task.yaml\n",
      " project_name.............  AdaSparseChem-cb29-10Task-Test\n",
      " exp_id...................  17n83toa\n",
      " exp_name.................  None\n",
      " folder_sfx...............  test_0\n",
      " exp_desc.................  Test phase of 00225_1530 run - 0\n",
      " hidden_sizes.............  [4000, 4000, 4000, 4000, 4000, 4000]\n",
      " tail_hidden_size.........  [4000]\n",
      " warmup_epochs............  None\n",
      " training_epochs..........  None\n",
      " seed_idx.................  0\n",
      " batch_size...............  4098\n",
      " first_dropout............  None\n",
      " middle_dropout...........  None\n",
      " last_dropout.............  None\n",
      " hidden_sizes.............  [4000, 4000, 4000, 4000, 4000, 4000]\n",
      " tail_hidden_size.........  [4000]\n",
      " warmup_epochs............  None\n",
      " training_epochs..........  None\n",
      " seed_idx.................  0\n",
      " batch_size...............  4098\n",
      " first_dropout............  None\n",
      " middle_dropout...........  None\n",
      " last_dropout.............  None\n",
      " backbone_lr..............  None\n",
      " task_lr..................  None\n",
      " policy_lr................  None\n",
      " policy_lr................  None\n",
      " decay_lr_rate............  None\n",
      " decay_lr_freq............  None\n",
      " decay_lr_cooldown........  None\n",
      " policy_decay_lr_rate.....  None\n",
      " policy_decay_lr_freq.....  None\n",
      " policy_decay_lr_cooldown.  None\n",
      " lambda_tasks.............  None\n",
      " lambda_sparsity..........  None\n",
      " lambda_sharing...........  None\n",
      " cuda_devices.............  2\n",
      " gpu_ids..................  [0]\n",
      " pytorch_threads..........  2\n",
      " skip_residual............  False\n",
      " skip_hidden..............  False\n",
      " resume...................  False\n",
      " resume_path..............  None\n",
      " resume_ckpt..............  None\n",
      " resume_metrics...........  None\n",
      " cpu......................  False\n",
      " min_samples_class........  None\n",
      "\n",
      "\n",
      "\n"
      " decay_lr_cooldown........  None\n",
      " policy_decay_lr_rate.....  None\n",
      " policy_decay_lr_freq.....  None\n",
      " policy_decay_lr_cooldown.  None\n",
      " lambda_tasks.............  None\n",
      " lambda_sparsity..........  None\n",
      " lambda_sharing...........  None\n",
      " cuda_devices.............  2\n",
      " gpu_ids..................  [0]\n",
      " pytorch_threads..........  2\n",
      " skip_residual............  False\n",
      " skip_hidden..............  False\n",
      " resume...................  False\n",
      " resume_path..............  None\n",
      " resume_ckpt..............  None\n",
      " resume_metrics...........  None\n",
      " cpu......................  False\n",
      " min_samples_class........  None\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ns = types.SimpleNamespace()\n",
    "input_args = input_args.split() if input_args is not None else input_args\n",
    "# input_args = restart_input_args.split() \n",
    "ns.args = get_command_line_args(input_args, display = True)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=ns.args.cuda_devices"
    "ns = types.SimpleNamespace()\n",
    "input_args = input_args.split() if input_args is not None else input_args\n",
    "# input_args = restart_input_args.split() \n",
    "ns.args = get_command_line_args(input_args, display = True)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=ns.args.cuda_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "530bcb65",
   "execution_count": 8,
   "id": "530bcb65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:36.853632Z",
     "start_time": "2022-09-05T20:12:31.515839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "################### READ YAML ####################\n",
      "##################################################\n",
      " Pytorch thread count: 20\n",
      " Set Pytorch thread count to : 2\n",
      " Pytorch thread count set to : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkbardool\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kevin/WSL-projs/AdaSparseChem/notebooks/wandb/run-20220905_221232-17n83toa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task-Test/runs/17n83toa\" target=\"_blank\">0905_2212_test_0</a></strong> to <a href=\"https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task-Test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WandB Initialization -----------------------------------------------------------\n",
      " PROJECT NAME: AdaSparseChem-cb29-10Task-Test\n",
      " RUN ID      : 17n83toa \n",
      " RUN NAME    : 0905_2212_test_0\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " log_dir              create folder:  ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      " result_dir           folder exists:  ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      " checkpoint_dir       folder exists:  ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      " Pytorch thread count: 20\n",
      " Set Pytorch thread count to : 2\n",
      " Pytorch thread count set to : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkbardool\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kevin/WSL-projs/AdaSparseChem/notebooks/wandb/run-20220905_221232-17n83toa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task-Test/runs/17n83toa\" target=\"_blank\">0905_2212_test_0</a></strong> to <a href=\"https://wandb.ai/kbardool/AdaSparseChem-cb29-10Task-Test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WandB Initialization -----------------------------------------------------------\n",
      " PROJECT NAME: AdaSparseChem-cb29-10Task-Test\n",
      " RUN ID      : 17n83toa \n",
      " RUN NAME    : 0905_2212_test_0\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " log_dir              create folder:  ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      " result_dir           folder exists:  ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      " checkpoint_dir       folder exists:  ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " experiment name       : 0905_2212_test_0 \n",
      " experiment id         : 17n83toa \n",
      " folder_name           : 4000x6_0905_2212_lr0.001_do0.0_test_0 \n",
      " experiment name       : 0905_2212_test_0 \n",
      " experiment id         : 17n83toa \n",
      " folder_name           : 4000x6_0905_2212_lr0.001_do0.0_test_0 \n",
      " experiment description: Test phase of 00225_1530 run - 0\n",
      " Random seeds          : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      " Random  seed used     : 88 \n",
      " log folder            : ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      " checkpoint folder     : ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      " Gpu ids               : [0]\n",
      " Seed index            : 0\n",
      " policy_iter           : best\n",
      " Data Split ratios     : [0.725, 0.225, 0.05]\n",
      " Random seeds          : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      " Random  seed used     : 88 \n",
      " log folder            : ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      " checkpoint folder     : ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      " Gpu ids               : [0]\n",
      " Seed index            : 0\n",
      " policy_iter           : best\n",
      " Data Split ratios     : [0.725, 0.225, 0.05]\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "        project_name : AdaSparseChem-cb29-10Task-Test\n",
      "              exp_id : 17n83toa\n",
      "        exp_name_pfx : 0905_2212\n",
      "            exp_name : 0905_2212_test_0\n",
      "          exp_folder : 4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      "        project_name : AdaSparseChem-cb29-10Task-Test\n",
      "              exp_id : 17n83toa\n",
      "        exp_name_pfx : 0905_2212\n",
      "            exp_name : 0905_2212_test_0\n",
      "          exp_folder : 4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      "     exp_description : Test phase of 00225_1530 run - 0\n",
      "          folder_sfx : test_0\n",
      "         random_seed : 88\n",
      "           seed_list : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      "              config : ../yamls/chembl_cb29_test_10task.yaml\n",
      "                 cpu : None\n",
      "             gpu_ids : [0]\n",
      "          folder_sfx : test_0\n",
      "         random_seed : 88\n",
      "           seed_list : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      "              config : ../yamls/chembl_cb29_test_10task.yaml\n",
      "                 cpu : None\n",
      "             gpu_ids : [0]\n",
      "            backbone : SparseChem\n",
      "               tasks : ['class', 'class', 'class', 'class', 'class', 'class', 'class', 'class', 'class', 'class']\n",
      "     tasks_num_class : [472, 624, 688, 192, 620, 184, 224, 148, 344, 72]\n",
      "             lambdas : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "             verbose : False\n",
      "               tasks : ['class', 'class', 'class', 'class', 'class', 'class', 'class', 'class', 'class', 'class']\n",
      "     tasks_num_class : [472, 624, 688, 192, 620, 184, 224, 148, 344, 72]\n",
      "             lambdas : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "             verbose : False\n",
      "     input_size_freq : None\n",
      "          input_size : 32000\n",
      "        hidden_sizes : [4000, 4000, 4000, 4000, 4000, 4000]\n",
      "    tail_hidden_size : [4000]\n",
      "        hidden_sizes : [4000, 4000, 4000, 4000, 4000, 4000]\n",
      "    tail_hidden_size : [4000]\n",
      " first_non_linearity : relu\n",
      "middle_non_linearity : relu\n",
      "  last_non_linearity : relu\n",
      "       first_dropout : 0.0\n",
      "      middle_dropout : 0.0\n",
      "        last_dropout : 0.0\n",
      "   class_output_size : None\n",
      "    regr_output_size : None\n",
      "       first_dropout : 0.0\n",
      "      middle_dropout : 0.0\n",
      "        last_dropout : 0.0\n",
      "   class_output_size : None\n",
      "    regr_output_size : None\n",
      "              policy : True\n",
      "        policy_model : task-specific\n",
      "       skip_residual : False\n",
      "         skip_hidden : False\n",
      "        policy_model : task-specific\n",
      "       skip_residual : False\n",
      "         skip_hidden : False\n",
      "           is_sparse : True\n",
      "diff_sparsity_weights : False\n",
      "          is_sharing : True\n",
      "diff_sharing_weights : False\n",
      "          is_sharing : True\n",
      "diff_sharing_weights : False\n",
      "          skip_layer : 0\n",
      "       is_curriculum : False\n",
      "       is_curriculum : False\n",
      "    curriculum_speed : 3\n",
      "              fix_BN : False\n",
      "     retrain_from_pl : False\n",
      "\n",
      "train\n",
      "-----\n",
      "             task_lr : 0.001\n",
      "         backbone_lr : 0.001\n",
      "    weight_optimizer : adam\n",
      "    policy_optimizer : adam\n",
      "       decay_lr_rate : 0.75\n",
      "       decay_lr_freq : 40\n",
      "   decay_lr_cooldown : 0\n",
      "           policy_lr : 0.001\n",
      "policy_decay_lr_rate : 0.75\n",
      "policy_decay_lr_freq : 40\n",
      "policy_decay_lr_cooldown : 0\n",
      "     lambda_sparsity : 0.02\n",
      "      lambda_sharing : 0.01\n",
      "        lambda_tasks : 1\n",
      "         init_method : random\n",
      "           init_temp : 2.5\n",
      "          decay_temp : 0.75\n",
      "     decay_temp_freq : 3\n",
      "     init_neg_logits : None\n",
      "       hard_sampling : False\n",
      "            val_freq : 500\n",
      "          print_freq : -1\n",
      "warmup_iter_alternate : -1\n",
      "weight_iter_alternate : -1\n",
      "alpha_iter_alternate : -1\n",
      "           val_iters : -1\n",
      "              resume : False\n",
      "      retrain_resume : False\n",
      "         policy_iter : best\n",
      "          which_iter : warmup\n",
      "\n",
      "train\n",
      "-----\n",
      "             task_lr : 0.001\n",
      "         backbone_lr : 0.001\n",
      "    weight_optimizer : adam\n",
      "    policy_optimizer : adam\n",
      "       decay_lr_rate : 0.75\n",
      "       decay_lr_freq : 40\n",
      "   decay_lr_cooldown : 0\n",
      "           policy_lr : 0.001\n",
      "policy_decay_lr_rate : 0.75\n",
      "policy_decay_lr_freq : 40\n",
      "policy_decay_lr_cooldown : 0\n",
      "     lambda_sparsity : 0.02\n",
      "      lambda_sharing : 0.01\n",
      "        lambda_tasks : 1\n",
      "         init_method : random\n",
      "           init_temp : 2.5\n",
      "          decay_temp : 0.75\n",
      "     decay_temp_freq : 3\n",
      "     init_neg_logits : None\n",
      "       hard_sampling : False\n",
      "            val_freq : 500\n",
      "          print_freq : -1\n",
      "warmup_iter_alternate : -1\n",
      "weight_iter_alternate : -1\n",
      "alpha_iter_alternate : -1\n",
      "           val_iters : -1\n",
      "              resume : False\n",
      "      retrain_resume : False\n",
      "         policy_iter : best\n",
      "          which_iter : warmup\n",
      "\n",
      "paths\n",
      "-----\n",
      "             log_dir : ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      "          result_dir : ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      "      checkpoint_dir : ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      "             log_dir : ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      "          result_dir : ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      "      checkpoint_dir : ../../experiments/AdaSparseChem-cb29-10task-test/4000x6_0905_2212_lr0.001_do0.0_test_0\n",
      "\n",
      "dataload\n",
      "--------\n",
      "             dataset : Chembl29\n",
      "            dataroot : ../../MLDatasets/chembl29_10task\n",
      "                   x : chembl_29_X.npy\n",
      "             dataset : Chembl29\n",
      "            dataroot : ../../MLDatasets/chembl29_10task\n",
      "                   x : chembl_29_X.npy\n",
      "      x_split_ratios : [0.725, 0.225, 0.05]\n",
      "             folding : chembl_29_folding.npy\n",
      "             y_tasks : ['chembl_29_Y_tg_0_cols_472.npy', 'chembl_29_Y_tg_1_cols_624.npy', 'chembl_29_Y_tg_6_cols_688.npy', 'chembl_29_Y_tg_10_cols_192.npy', 'chembl_29_Y_tg_11_cols_620.npy', 'chembl_29_Y_tg_643_cols_184.npy', 'chembl_29_Y_tg_836_cols_224.npy', 'chembl_29_Y_tg_1005_cols_148.npy', 'chembl_29_Y_tg_1028_cols_344.npy', 'chembl_29_Y_tg_1031_cols_72.npy']\n",
      "            y_censor : None\n",
      "             folding : chembl_29_folding.npy\n",
      "             y_tasks : ['chembl_29_Y_tg_0_cols_472.npy', 'chembl_29_Y_tg_1_cols_624.npy', 'chembl_29_Y_tg_6_cols_688.npy', 'chembl_29_Y_tg_10_cols_192.npy', 'chembl_29_Y_tg_11_cols_620.npy', 'chembl_29_Y_tg_643_cols_184.npy', 'chembl_29_Y_tg_836_cols_224.npy', 'chembl_29_Y_tg_1005_cols_148.npy', 'chembl_29_Y_tg_1028_cols_344.npy', 'chembl_29_Y_tg_1031_cols_72.npy']\n",
      "            y_censor : None\n",
      "         fold_inputs : 32000\n",
      "     input_transform : None\n",
      "       weights_class : None\n",
      "   min_samples_class : 1\n",
      "           fold_test : [0]\n",
      "             fold_va : [1]\n",
      "         fold_warmup : [2, 3, 4]\n",
      "        fold_weights : [2, 3]\n",
      "         fold_policy : [4]\n",
      "   min_samples_class : 1\n",
      "           fold_test : [0]\n",
      "             fold_va : [1]\n",
      "         fold_warmup : [2, 3, 4]\n",
      "        fold_weights : [2, 3]\n",
      "         fold_policy : [4]\n",
      "\n",
      "SC\n",
      "--\n",
      "      normalize_loss : None\n",
      "\n",
      "test\n",
      "----\n",
      "          test_iters : -1\n",
      "     pytorch_threads : 2\n",
      "            seed_idx : 0\n",
      "          batch_size : 4098\n",
      "         resume_path : None\n",
      "         resume_ckpt : None\n",
      "      resume_metrics : None\n"
      "          test_iters : -1\n",
      "     pytorch_threads : 2\n",
      "            seed_idx : 0\n",
      "          batch_size : 4098\n",
      "         resume_path : None\n",
      "         resume_ckpt : None\n",
      "      resume_metrics : None\n"
     ]
    }
   ],
   "source": [
    "opt = initialize(ns, build_folders = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58caea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T07:40:24.684944Z",
     "start_time": "2022-07-04T07:40:24.654093Z"
    }
   },
   "source": [
    "### Setup Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a2edeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:39.205926Z",
     "start_time": "2022-09-05T20:12:36.855968Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test folds    : [0]\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      " Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      " Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 472  Y rows with populated labels: 5642  non zero cols: 14461\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      " Task 2 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      " Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 624  Y rows with populated labels: 6650  non zero cols: 15454\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      " Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      " Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 688  Y rows with populated labels: 19594  non zero cols: 72093\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      " Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n",
      "\n",
      " Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 192  Y rows with populated labels: 3986  non zero cols: 8406\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n",
      "\n",
      " Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n",
      "\n",
      " Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 620  Y rows with populated labels: 10009  non zero cols: 28257\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      " Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n",
      "\n",
      " Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 184  Y rows with populated labels: 3206  non zero cols: 8576\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n",
      "\n",
      " Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n",
      "\n",
      " Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 224  Y rows with populated labels: 2320  non zero cols: 7597\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      " Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 148  Y rows with populated labels: 3434  non zero cols: 6827\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n",
      "\n",
      " Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      " Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 344  Y rows with populated labels: 7852  non zero cols: 25179\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      " Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n",
      "\n",
      " Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 72  Y rows with populated labels: 1444  non zero cols: 3563\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "\n",
      "Training dataset :\n",
      "--------------------\n",
      "  Nnumber of batches per test epoch to: -1\n",
      "  Size of test set              :  82933 \n",
      "  Number of batches in testset  :  21 \n",
      "  test set num of positive      :  18631 \n",
      "  test set num of negative      :  107922 \n",
      "  task_weights_list[0].aggregation_weight sum        :  199.0\n",
      "\n",
      "\n",
      " testset.y_class                                   :  [(82933, 472), (82933, 624), (82933, 688), (82933, 192), (82933, 620), (82933, 184), (82933, 224), (82933, 148), (82933, 344), (82933, 72)]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "dldrs = init_test_dataloader(opt, verbose = False)\n"
    "opt = initialize(ns, build_folders = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58caea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T07:40:24.684944Z",
     "start_time": "2022-07-04T07:40:24.654093Z"
    }
   ],
   "source": [
    " \n",
    "dldrs = init_test_dataloader(opt, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e531702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:43.560570Z",
     "start_time": "2022-09-05T20:12:39.211850Z"
    },
    "scrolled": false
   },
   "source": [
    "### Setup Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a2edeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:39.205926Z",
     "start_time": "2022-09-05T20:12:36.855968Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test folds    : [0]\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 1 - task group chembl_29_Y_tg_0_cols_472.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 1 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      81937 \n",
      "    Total   -1  Labels :     188511 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     270448\n",
      "\n",
      " Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 472  Y rows with populated labels: 32866  non zero cols: 81937\n",
      "\n",
      " Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 472  Y rows with populated labels: 5642  non zero cols: 14461\n",
      "\n",
      "Using 199 of 472 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 2 - task group chembl_29_Y_tg_1_cols_624.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 2 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      90665 \n",
      "    Total   -1  Labels :     219244 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     309909\n",
      "\n",
      " Task 2 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 624  Y rows with populated labels: 38131  non zero cols: 90665\n",
      "\n",
      " Task 2 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 624  Y rows with populated labels: 6650  non zero cols: 15454\n",
      "\n",
      "Using 258 of 624 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "---------------------------------------------------------------------------\n",
      "Load label/Y file for task 3 - task group chembl_29_Y_tg_6_cols_688.npy\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 3 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     320094 \n",
      "    Total   -1  Labels :     382164 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     702258\n",
      "\n",
      " Task 3 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 688  Y rows with populated labels: 91425  non zero cols: 320094\n",
      "\n",
      " Task 3 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 688  Y rows with populated labels: 19594  non zero cols: 72093\n",
      "\n",
      "Using 524 of 688 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 4 - task group chembl_29_Y_tg_10_cols_192.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 4 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      44576 \n",
      "    Total   -1  Labels :     110611 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     155187\n",
      "\n",
      " Task 4 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 192  Y rows with populated labels: 20024  non zero cols: 44576\n",
      "\n",
      " Task 4 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 192  Y rows with populated labels: 3986  non zero cols: 8406\n",
      "\n",
      "Using 111 of 192 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "----------------------------------------------------------------------------\n",
      "Load label/Y file for task 5 - task group chembl_29_Y_tg_11_cols_620.npy\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 5 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     142158 \n",
      "    Total   -1  Labels :     193933 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     336091\n",
      "\n",
      " Task 5 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 620  Y rows with populated labels: 51001  non zero cols: 142158\n",
      "\n",
      " Task 5 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 620  Y rows with populated labels: 10009  non zero cols: 28257\n",
      "\n",
      "Using 389 of 620 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 6 - task group chembl_29_Y_tg_643_cols_184.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 6 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      41813 \n",
      "    Total   -1  Labels :      69820 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     111633\n",
      "\n",
      " Task 6 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 184  Y rows with populated labels: 15543  non zero cols: 41813\n",
      "\n",
      " Task 6 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 184  Y rows with populated labels: 3206  non zero cols: 8576\n",
      "\n",
      "Using 92 of 184 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "-----------------------------------------------------------------------------\n",
      "Load label/Y file for task 7 - task group chembl_29_Y_tg_836_cols_224.npy\n",
      "----------------------------------------------------------------------------- \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 7 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      38227 \n",
      "    Total   -1  Labels :      91904 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     130131\n",
      "\n",
      " Task 7 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 224  Y rows with populated labels: 11789  non zero cols: 38227\n",
      "\n",
      " Task 7 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 224  Y rows with populated labels: 2320  non zero cols: 7597\n",
      "\n",
      "Using 109 of 224 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 8 - task group chembl_29_Y_tg_1005_cols_148.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 8 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      45065 \n",
      "    Total   -1  Labels :     104361 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     149426\n",
      "\n",
      " Task 8 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 148  Y rows with populated labels: 21460  non zero cols: 45065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Task 8 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 148  Y rows with populated labels: 3434  non zero cols: 6827\n",
      "\n",
      "Using 80 of 148 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 9 - task group chembl_29_Y_tg_1028_cols_344.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 9 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :     110249 \n",
      "    Total   -1  Labels :     213195 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     323444\n",
      "\n",
      " Task 9 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 344  Y rows with populated labels: 35996  non zero cols: 110249\n",
      "\n",
      " Task 9 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 344  Y rows with populated labels: 7852  non zero cols: 25179\n",
      "\n",
      "Using 226 of 344 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "------------------------------------------------------------------------------\n",
      "Load label/Y file for task 10 - task group chembl_29_Y_tg_1031_cols_72.npy\n",
      "------------------------------------------------------------------------------ \n",
      "\n",
      " Number of non-zero features in ecfp[0]:79\n",
      "\n",
      " Task 10 label file: \n",
      "    Total > +1  Labels :          0 \n",
      "    Total   +1  Labels :      18631 \n",
      "    Total   -1  Labels :     107922 \n",
      "    Total < -1  Labels :          0 \n",
      "    Total != 0  Labels :     126553\n",
      "\n",
      " Task 10 files pre-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  423736     # Features per Sample: 32000   \n",
      "Y file : # Samples :  423736     # Labels per Sample  : 72  Y rows with populated labels: 7835  non zero cols: 18631\n",
      "\n",
      " Task 10 files post-filtering : \n",
      "----------------------------------\n",
      "X file : # Samples :  82933     # Features per Sample: 32000 \n",
      "Y file : # Samples :  82933     # Labels per Sample  : 72  Y rows with populated labels: 1444  non zero cols: 3563\n",
      "\n",
      "Using 52 of 72 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "\n",
      "Training dataset :\n",
      "--------------------\n",
      "  Nnumber of batches per test epoch to: -1\n",
      "  Size of test set              :  82933 \n",
      "  Number of batches in testset  :  21 \n",
      "  test set num of positive      :  18631 \n",
      "  test set num of negative      :  107922 \n",
      "  task_weights_list[0].aggregation_weight sum        :  199.0\n",
      "\n",
      "\n",
      " testset.y_class                                   :  [(82933, 472), (82933, 624), (82933, 688), (82933, 192), (82933, 620), (82933, 184), (82933, 224), (82933, 148), (82933, 344), (82933, 72)]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "dldrs = init_test_dataloader(opt, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e531702",
   "execution_count": 10,
   "id": "0e531702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:43.560570Z",
     "start_time": "2022-09-05T20:12:39.211850Z"
    }
   ],
   "source": [
    " \n",
    "dldrs = init_test_dataloader(opt, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e531702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:43.560570Z",
     "start_time": "2022-09-05T20:12:39.211850Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      " device is  cuda:0\n",
      "--------------------------------------------------\n",
      " SparseChem_Backbone  Ver: 1.0 Init() Start \n",
      "-------------------------------------------------- \n",
      " device is  cuda:0\n",
      "--------------------------------------------------\n",
      " SparseChem_Backbone  Ver: 1.0 Init() Start \n",
      "-------------------------------------------------- \n",
      "\n",
      " layer config        : [1, 1, 1, 1, 1, 1] \n",
      " skip residual layers: False   skip hidden layers  : False\n",
      " SparseChem_BackBone() Input Layer  - Input: 32000  output: 4000  non-linearity:<class 'torch.nn.modules.activation.ReLU'>\n",
      " Hidden layer 0 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.0 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.0 bias: True\n",
      " Hidden layer 1 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.0 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.0 bias: True\n",
      " Hidden layer 2 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.0 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.0 bias: True\n",
      " Hidden layer 3 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.0 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.0 bias: True\n",
      " Hidden layer 4 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.0 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.0 bias: True\n",
      " Final Hidden layer 4 : Input size: 4000   output size:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.0 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.0 bias: True\n",
      " Module List \n",
      " layer config        : [1, 1, 1, 1, 1, 1] \n",
      " skip residual layers: False   skip hidden layers  : False\n",
      " SparseChem_BackBone() Input Layer  - Input: 32000  output: 4000  non-linearity:<class 'torch.nn.modules.activation.ReLU'>\n",
      " Hidden layer 0 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.0 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.0 bias: True\n",
      " Hidden layer 1 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.0 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.0 bias: True\n",
      " Hidden layer 2 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.0 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.0 bias: True\n",
      " Hidden layer 3 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.0 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.0 bias: True\n",
      " Hidden layer 4 - Input: 4000   output:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.0 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.0 bias: True\n",
      " Final Hidden layer 4 : Input size: 4000   output size:4000\n",
      "    _make_layer() using block: <class 'models.sparsechem_backbone.SparseChemBlock'>\n",
      "           input_size: 4000 output_sz: 4000  non_linearity: ReLU() dropout: 0.0 bias: True\n",
      "           SparseChemBlock.init(): input_size: 4000 output_sz: 4000   non_linearity: ReLU() dropout: 0.0 bias: True\n",
      " Module List \n",
      "--------------------------------------------------\n",
      " Initialize weights \n",
      " Initialize weights \n",
      "-------------------------------------------------- \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " SparseChem Backbone -- Final configuration(2) : \n",
      "                     self.blocks: <class 'torch.nn.modules.container.ModuleList'>  len:6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "\n",
      " Input_Layer  type:<class 'torch.nn.modules.container.Sequential'>  \n",
      "----------------------------------------------------------------------\n",
      "self.Input_layer\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Layers/Blocks    : <class 'torch.nn.modules.container.ModuleList'>   len:6 \n",
      "Resdiual layers  : <class 'torch.nn.modules.container.ModuleList'>   len:6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 1  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 1  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 2  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 2  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 3  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 3  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 4  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 4  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 5  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 5  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 6  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 6  type:<class 'NoneType'> \n",
      " None\n",
      "\n",
      "\n",
      "\n",
      " SparseChem_Backbone Init() End \n",
      "----------------------------------------------------\n",
      "* SparseChemEnv environment successfully created\n",
      "---------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      " SparseChem Backbone -- Final configuration(2) : \n",
      "                     self.blocks: <class 'torch.nn.modules.container.ModuleList'>  len:6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "\n",
      " Input_Layer  type:<class 'torch.nn.modules.container.Sequential'>  \n",
      "----------------------------------------------------------------------\n",
      "self.Input_layer\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Layers/Blocks    : <class 'torch.nn.modules.container.ModuleList'>   len:6 \n",
      "Resdiual layers  : <class 'torch.nn.modules.container.ModuleList'>   len:6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 1  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 1  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 2  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 2  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 3  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 3  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 4  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 4  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 5  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 5  type:<class 'NoneType'> \n",
      " None\n",
      "---------------------------------------------------------------------------\n",
      " Layer #: 6  type:<class 'models.sparsechem_backbone.SparseChemBlock'> \n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      " SparseChemBlock(\n",
      "  (linear): Linear(in_features=4000, out_features=4000, bias=True)\n",
      "  (non_linear): ReLU()\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ") \n",
      "\n",
      " Residual Layer #: 6  type:<class 'NoneType'> \n",
      " None\n",
      "\n",
      "\n",
      "\n",
      " SparseChem_Backbone Init() End \n",
      "----------------------------------------------------\n",
      "* SparseChemEnv environment successfully created\n",
      "---------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ********************************************************************\n",
    "# ********************Create the environment *************************\n",
    "# ********************************************************************\n",
    "# create the model and the pretrain model\n",
    "print_separator('CREATE THE ENVIRONMENT')\n",
    "environ = init_environment(ns, opt, \n",
    "                            is_train = False,\n",
    "                            verbose  = True)"
    "environ = init_environment(ns, opt, \n",
    "                            is_train = False,\n",
    "                            verbose  = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a52b1c35",
   "execution_count": 11,
   "id": "a52b1c35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:45.590339Z",
     "start_time": "2022-09-05T20:12:43.562506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 1. load checkpoint : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0829_2050_lr0.001_do0.8/ - model_best\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "=> loading snapshot from ../../experiments/AdaSparseChem-cb29-10task/4000x6_0829_2050_lr0.001_do0.8/model_best.tar\n",
      "=> loading snapshot to   cuda:0\n",
      "   Loading to GPU cuda:0\n",
      "\n",
      " 1. load checkpoint : ../../experiments/AdaSparseChem-cb29-10task/4000x6_0829_2050_lr0.001_do0.8/ - model_best\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "=> loading snapshot from ../../experiments/AdaSparseChem-cb29-10task/4000x6_0829_2050_lr0.001_do0.8/model_best.tar\n",
      "=> loading snapshot to   cuda:0\n",
      "   Loading to GPU cuda:0\n",
      "  networks -  network:  mtl-net\n",
      "  load snapshot - network:  mtl-net\n",
      "    network mtl-net - item task1_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task2_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task3_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task4_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task5_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task6_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task7_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task8_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task9_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task10_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item backbone.Input_Layer.linear.weight - shape: torch.Size([32000, 4000])\n",
      "    network mtl-net - item backbone.Input_Layer.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.0.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.0.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.1.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.1.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.2.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.2.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.3.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.3.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.4.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.4.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.5.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.5.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item task1_fc1_c0.linear.weight - shape: torch.Size([472, 4000])\n",
      "    network mtl-net - item task1_fc1_c0.linear.bias - shape: torch.Size([472])\n",
      "    network mtl-net - item task2_fc1_c0.linear.weight - shape: torch.Size([624, 4000])\n",
      "    network mtl-net - item task2_fc1_c0.linear.bias - shape: torch.Size([624])\n",
      "    network mtl-net - item task3_fc1_c0.linear.weight - shape: torch.Size([688, 4000])\n",
      "    network mtl-net - item task3_fc1_c0.linear.bias - shape: torch.Size([688])\n",
      "    network mtl-net - item task4_fc1_c0.linear.weight - shape: torch.Size([192, 4000])\n",
      "    network mtl-net - item task4_fc1_c0.linear.bias - shape: torch.Size([192])\n",
      "    network mtl-net - item task5_fc1_c0.linear.weight - shape: torch.Size([620, 4000])\n",
      "    network mtl-net - item task5_fc1_c0.linear.bias - shape: torch.Size([620])\n",
      "    network mtl-net - item task6_fc1_c0.linear.weight - shape: torch.Size([184, 4000])\n",
      "    network mtl-net - item task6_fc1_c0.linear.bias - shape: torch.Size([184])\n",
      "    network mtl-net - item task7_fc1_c0.linear.weight - shape: torch.Size([224, 4000])\n",
      "    network mtl-net - item task7_fc1_c0.linear.bias - shape: torch.Size([224])\n",
      "    network mtl-net - item task8_fc1_c0.linear.weight - shape: torch.Size([148, 4000])\n",
      "    network mtl-net - item task8_fc1_c0.linear.bias - shape: torch.Size([148])\n",
      "    network mtl-net - item task9_fc1_c0.linear.weight - shape: torch.Size([344, 4000])\n",
      "    network mtl-net - item task9_fc1_c0.linear.bias - shape: torch.Size([344])\n",
      "    network mtl-net - item task10_fc1_c0.linear.weight - shape: torch.Size([72, 4000])\n",
      "    network mtl-net - item task10_fc1_c0.linear.bias - shape: torch.Size([72])\n",
      "self.gumbel_temperature: 0.0014110189840593756\n",
      "snapshot[iter]         : 456799\n",
      "snapshot[iter]         : 230\n",
      " keys : dict_keys(['mtl-net', 'weights', 'alphas', 'iter', 'epoch', 'temp'])\n",
      " data is :  (456799, 230)\n",
      "----------------------------------------------------------------------------------\n",
      " Evaluating the snapshot saved at - loaded epoch:230   loaded iteration:456799\n",
      "---------------------------------------------------------------------------------- \n",
      "\n"
      "    network mtl-net - item task1_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task2_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task3_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task4_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task5_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task6_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task7_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task8_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task9_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item task10_logits - shape: torch.Size([6, 2])\n",
      "    network mtl-net - item backbone.Input_Layer.linear.weight - shape: torch.Size([32000, 4000])\n",
      "    network mtl-net - item backbone.Input_Layer.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.0.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.0.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.1.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.1.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.2.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.2.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.3.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.3.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.4.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.4.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item backbone.blocks.5.linear.weight - shape: torch.Size([4000, 4000])\n",
      "    network mtl-net - item backbone.blocks.5.linear.bias - shape: torch.Size([4000])\n",
      "    network mtl-net - item task1_fc1_c0.linear.weight - shape: torch.Size([472, 4000])\n",
      "    network mtl-net - item task1_fc1_c0.linear.bias - shape: torch.Size([472])\n",
      "    network mtl-net - item task2_fc1_c0.linear.weight - shape: torch.Size([624, 4000])\n",
      "    network mtl-net - item task2_fc1_c0.linear.bias - shape: torch.Size([624])\n",
      "    network mtl-net - item task3_fc1_c0.linear.weight - shape: torch.Size([688, 4000])\n",
      "    network mtl-net - item task3_fc1_c0.linear.bias - shape: torch.Size([688])\n",
      "    network mtl-net - item task4_fc1_c0.linear.weight - shape: torch.Size([192, 4000])\n",
      "    network mtl-net - item task4_fc1_c0.linear.bias - shape: torch.Size([192])\n",
      "    network mtl-net - item task5_fc1_c0.linear.weight - shape: torch.Size([620, 4000])\n",
      "    network mtl-net - item task5_fc1_c0.linear.bias - shape: torch.Size([620])\n",
      "    network mtl-net - item task6_fc1_c0.linear.weight - shape: torch.Size([184, 4000])\n",
      "    network mtl-net - item task6_fc1_c0.linear.bias - shape: torch.Size([184])\n",
      "    network mtl-net - item task7_fc1_c0.linear.weight - shape: torch.Size([224, 4000])\n",
      "    network mtl-net - item task7_fc1_c0.linear.bias - shape: torch.Size([224])\n",
      "    network mtl-net - item task8_fc1_c0.linear.weight - shape: torch.Size([148, 4000])\n",
      "    network mtl-net - item task8_fc1_c0.linear.bias - shape: torch.Size([148])\n",
      "    network mtl-net - item task9_fc1_c0.linear.weight - shape: torch.Size([344, 4000])\n",
      "    network mtl-net - item task9_fc1_c0.linear.bias - shape: torch.Size([344])\n",
      "    network mtl-net - item task10_fc1_c0.linear.weight - shape: torch.Size([72, 4000])\n",
      "    network mtl-net - item task10_fc1_c0.linear.bias - shape: torch.Size([72])\n",
      "self.gumbel_temperature: 0.0014110189840593756\n",
      "snapshot[iter]         : 456799\n",
      "snapshot[iter]         : 230\n",
      " keys : dict_keys(['mtl-net', 'weights', 'alphas', 'iter', 'epoch', 'temp'])\n",
      " data is :  (456799, 230)\n",
      "----------------------------------------------------------------------------------\n",
      " Evaluating the snapshot saved at - loaded epoch:230   loaded iteration:456799\n",
      "---------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Load Model and Policy snapshots\n",
    "##\n",
    "# current_iter = environ.load_checkpoint('retrain%03d_policyIter%s_best' % (exp_ids[0], opt['train']['policy_iter']))\n",
    "\n",
    "print_underline(f\"\\n 1. load checkpoint : {TEST_FROM_PATH} - {TEST_MODEL_CKPT}\", verbose = True)\n",
    "ns.loaded_iter, ns.loaded_epoch = environ.load_checkpoint(TEST_MODEL_CKPT, path=TEST_FROM_PATH, verbose = True)\n",
    "print_heading(f\" Evaluating the snapshot saved at - loaded epoch:{ns.loaded_epoch}   loaded iteration:{ns.loaded_iter}\", verbose = True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bfeb7c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:45.622840Z",
     "start_time": "2022-09-05T20:12:45.592898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " A. load existing POLICY: Iter_best_expid_17n83toa\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ns.loaded_iter, ns.loaded_epoch = environ.load_checkpoint(TEST_MODEL_CKPT, path=TEST_FROM_PATH, verbose = True)\n",
    "print_heading(f\" Evaluating the snapshot saved at - loaded epoch:{ns.loaded_epoch}   loaded iteration:{ns.loaded_iter}\", verbose = True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bfeb7c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:45.622840Z",
     "start_time": "2022-09-05T20:12:45.592898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " A. load existing POLICY: Iter_best_expid_17n83toa\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# policy_label = 'Iter%s_rs%04d' % (opt['train']['policy_iter'], opt['seed'][exp_ids[0]])\n",
    "policy_label = f\"Iter_{opt['train']['policy_iter']:s}_expid_{opt['exp_id']:s}\"\n",
    "print_underline(f\"\\n A. load existing POLICY: {policy_label}\", verbose = True)"
    "policy_label = f\"Iter_{opt['train']['policy_iter']:s}_expid_{opt['exp_id']:s}\"\n",
    "print_underline(f\"\\n A. load existing POLICY: {policy_label}\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b628e718",
   "execution_count": 13,
   "id": "b628e718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:12:45.876646Z",
     "start_time": "2022-09-05T20:12:45.624746Z"
     "end_time": "2022-09-05T20:12:45.876646Z",
     "start_time": "2022-09-05T20:12:45.624746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " inference preparation: - check for CUDA - cuda available as device id: [0]\n",
      "sparsechem_env.cuda()\n",
      " inference preparation complete . . .\n"
      " inference preparation: - check for CUDA - cuda available as device id: [0]\n",
      "sparsechem_env.cuda()\n",
      " inference preparation complete . . .\n"
     ]
    }
   ],
   "source": [
    "inference_initializations(ns, opt, environ, dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ae05153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T17:57:02.056047Z",
     "start_time": "2022-09-05T17:57:02.014570Z"
    }
   },
   "outputs": [],
   "source": [
    "# if environ.check_exist_policy(policy_label,path = TEST_FROM_PATH):\n",
    "#     environ.load_policy(policy_label, path = TEST_FROM_PATH, verbose = True)\n",
    "# else:\n",
    "#     print(f\"{policy_label} not found \")\n",
    "\n",
    "# policys = environ.get_current_policy()\n",
    "# overall_policy = np.concatenate(policys, axis=-1)\n",
    "# print_underline('loaded policy ', verbose = True)\n",
    "# print(overall_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1c3e26c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T18:00:48.146036Z",
     "start_time": "2022-09-05T18:00:48.054785Z"
    },
    "scrolled": true
   },
   "outputs": [
    }
   ],
   "source": [
    "inference_initializations(ns, opt, environ, dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ae05153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T17:57:02.056047Z",
     "start_time": "2022-09-05T17:57:02.014570Z"
    }
   },
   "outputs": [],
   "source": [
    "# if environ.check_exist_policy(policy_label,path = TEST_FROM_PATH):\n",
    "#     environ.load_policy(policy_label, path = TEST_FROM_PATH, verbose = True)\n",
    "# else:\n",
    "#     print(f\"{policy_label} not found \")\n",
    "\n",
    "# policys = environ.get_current_policy()\n",
    "# overall_policy = np.concatenate(policys, axis=-1)\n",
    "# print_underline('loaded policy ', verbose = True)\n",
    "# print(overall_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1c3e26c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T18:00:48.146036Z",
     "start_time": "2022-09-05T18:00:48.054785Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval iters set to :  21\n",
      "                                                                                                                                                               \r"
      "eval iters set to :  21\n",
      "                                                                                                                                                               \r"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3099100/4172450540.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menviron\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdldrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard_sampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/WSL-projs/AdaSparseChem/notebooks/../src/utils/notebook_modules.py\u001b[0m in \u001b[0;36mrun_inference\u001b[0;34m(ns, opt, environ, dldrs, hard_sampling, verbose)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;31m#     val_metrics = eval_fix_policy(environ, val_loader, opt['tasks'], num_seg_cls=num_seg_class, eval_iter=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     val_metrics = environ.evaluate(dldrs.test_loader, \n\u001b[0m\u001b[1;32m    428\u001b[0m                                    \u001b[0mis_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                                    \u001b[0mpolicy_sampling_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fix_policy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WSL-projs/AdaSparseChem/notebooks/../src/envs/sparsechem_env.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataloader, is_policy, num_train_layers, hard_sampling, policy_sampling_mode, device, disable_tqdm, eval_iters, leave, verbose)\u001b[0m\n\u001b[1;32m    749\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     self.validate(is_policy, \n\u001b[0m\u001b[1;32m    752\u001b[0m                                   \u001b[0mnum_train_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                                   \u001b[0mhard_sampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhard_sampling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WSL-projs/AdaSparseChem/notebooks/../src/envs/sparsechem_env.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, is_policy, num_train_layers, policy_sampling_mode, hard_sampling, verbose)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_loss_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         self.forward(is_policy = is_policy, \n\u001b[0m\u001b[1;32m    542\u001b[0m                     \u001b[0mpolicy_sampling_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_sampling_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                     \u001b[0mnum_train_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_train_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WSL-projs/AdaSparseChem/notebooks/../src/envs/sparsechem_env.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, is_policy, num_train_layers, policy_sampling_mode, hard_sampling, verbose)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;31m#               f\"policy_sampling_mode: {policy_sampling_mode}    hard_sampling: {hard_sampling}\", verbose = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         self.outputs, self.policys, self.logits = self.networks['mtl-net'](input            = self.input, \n\u001b[0m\u001b[1;32m    564\u001b[0m                                                             \u001b[0mtemperature\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgumbel_temperature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                                                             \u001b[0mis_policy\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mis_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WSL-projs/AdaSparseChem/notebooks/../src/models/MTL3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, temperature, is_policy, num_train_layers, hard_sampling, policy_sampling_mode, verbose)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mpolicy_sampling_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fix_policy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"policy_sampling_mode [{policy_sampling_mode}] is not implemented\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_metrics = run_inference(ns, opt, environ, dldrs, hard_sampling = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "019585aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T17:44:11.747932Z",
     "start_time": "2022-09-05T17:44:11.703844Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3059729/2657858382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# ********************************************************************\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# ******************************  Test  ******************************\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3099100/4172450540.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menviron\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdldrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard_sampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/WSL-projs/AdaSparseChem/notebooks/../src/utils/notebook_modules.py\u001b[0m in \u001b[0;36mrun_inference\u001b[0;34m(ns, opt, environ, dldrs, hard_sampling, verbose)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;31m#     val_metrics = eval_fix_policy(environ, val_loader, opt['tasks'], num_seg_cls=num_seg_class, eval_iter=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     val_metrics = environ.evaluate(dldrs.test_loader, \n\u001b[0m\u001b[1;32m    428\u001b[0m                                    \u001b[0mis_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                                    \u001b[0mpolicy_sampling_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fix_policy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WSL-projs/AdaSparseChem/notebooks/../src/envs/sparsechem_env.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataloader, is_policy, num_train_layers, hard_sampling, policy_sampling_mode, device, disable_tqdm, eval_iters, leave, verbose)\u001b[0m\n\u001b[1;32m    749\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     self.validate(is_policy, \n\u001b[0m\u001b[1;32m    752\u001b[0m                                   \u001b[0mnum_train_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                                   \u001b[0mhard_sampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhard_sampling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WSL-projs/AdaSparseChem/notebooks/../src/envs/sparsechem_env.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, is_policy, num_train_layers, policy_sampling_mode, hard_sampling, verbose)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_loss_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         self.forward(is_policy = is_policy, \n\u001b[0m\u001b[1;32m    542\u001b[0m                     \u001b[0mpolicy_sampling_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_sampling_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                     \u001b[0mnum_train_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_train_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WSL-projs/AdaSparseChem/notebooks/../src/envs/sparsechem_env.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, is_policy, num_train_layers, policy_sampling_mode, hard_sampling, verbose)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;31m#               f\"policy_sampling_mode: {policy_sampling_mode}    hard_sampling: {hard_sampling}\", verbose = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         self.outputs, self.policys, self.logits = self.networks['mtl-net'](input            = self.input, \n\u001b[0m\u001b[1;32m    564\u001b[0m                                                             \u001b[0mtemperature\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgumbel_temperature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                                                             \u001b[0mis_policy\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mis_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WSL-projs/AdaSparseChem/notebooks/../src/models/MTL3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, temperature, is_policy, num_train_layers, hard_sampling, policy_sampling_mode, verbose)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mpolicy_sampling_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fix_policy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"policy_sampling_mode [{policy_sampling_mode}] is not implemented\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_metrics = run_inference(ns, opt, environ, dldrs, hard_sampling = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "019585aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T17:44:11.747932Z",
     "start_time": "2022-09-05T17:44:11.703844Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3059729/2657858382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# ********************************************************************\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# ******************************  Test  ******************************\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    environ.cuda(gpu_ids)\n",
    "\n",
    "    # ********************************************************************\n",
    "    # ******************************  Test  ******************************\n",
    "    # ********************************************************************\n",
    "#     num_seg_class = opt['tasks_num_class'][opt['tasks'].index('seg')] if 'seg' in opt['tasks'] else -1\n",
    "    environ.eval()\n",
    "    \n",
    "    \n",
    "#     val_metrics = eval_fix_policy(environ, val_loader, opt['tasks'], num_seg_cls=num_seg_class, eval_iter=-1)\n",
    "    val_metrics = run_inference(test_loader, \n",
    "    val_metrics = run_inference(test_loader, \n",
    "                                   is_policy=True,\n",
    "                                   policy_sampling_mode = 'fix_policy')\n",
    "#                                    hard_sampling=None,  ## hard_sampling=opt['train']['hard_sampling'],\n",
    "#                                    eval_iters = -1, \n",
    "#                                    progress = True, \n",
    "#                                    leave = False, \n",
    "#                                    verbose = False)    \n",
    "    print(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9703129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T23:56:53.010530Z",
     "start_time": "2022-03-02T23:56:52.948667Z"
    },
    "scrolled": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.809947  0.870241        0.870419  0.809683  0.234723  0.454949   \n",
      "1          0.702792  0.668633        0.669218  0.645374  0.201933  0.319945   \n",
      "2          0.790758  0.759362        0.760180  0.773430  0.032953  0.435676   \n",
      "3          0.790516  0.740017        0.740502  0.678700  0.482500  0.411142   \n",
      "4          0.700168  0.759219        0.759621  0.719298  0.000054  0.291268   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.472036     0.745512  0.776153  \n",
      "1      0.349626     0.645575  1.607327  \n",
      "2      0.490710     0.146744  1.025560  \n",
      "3      0.458359     0.818019  0.916853  \n",
      "4      0.330854     0.896638  1.467913  \n",
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.770925  0.853607        0.853787  0.814872  0.167403  0.393060   \n",
      "1          0.808843  0.804886        0.805242  0.739356  0.516177  0.450856   \n",
      "2          0.782245  0.768615        0.769201  0.748527  0.172160  0.446186   \n",
      "3          0.780946  0.760152        0.760824  0.707373  0.114713  0.460210   \n",
      "4          0.872058  0.862533        0.862737  0.777302  0.142900  0.577004   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.430515     0.705141  1.027356  \n",
      "1      0.477075     0.843245  0.833418  \n",
      "2      0.457611     0.544157  0.976801  \n",
      "3      0.464405     0.514307  1.184837  \n",
      "4      0.594856     0.750179  0.735722  \n",
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.839879  0.797614        0.798060  0.769527  0.115009  0.530321   \n",
      "1          0.739206  0.790114        0.790543  0.768178  0.037533  0.358766   \n",
      "2          0.815088  0.815198        0.815437  0.735263  0.236443  0.439317   \n",
      "3          0.776969  0.792596        0.793156  0.767559  0.130948  0.419725   \n",
      "4          0.715192  0.716736        0.717286  0.712007  0.007196  0.271767   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.541681     0.600133  0.784565  \n",
      "1      0.396078     0.091330  1.342083  \n",
      "2      0.471812     0.273693  0.919688  \n",
      "3      0.436612     0.554105  0.873690  \n",
      "4      0.308437     0.230116  1.250910  \n"
     ]
    }
   ],
   "source": [
    "print(environ.val_metrics['task1']['classification'])\n",
    "print(environ.val_metrics['task2']['classification'])\n",
    "print(environ.val_metrics['task3']['classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "831a87a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T23:57:08.184290Z",
     "start_time": "2022-03-02T23:57:08.060255Z"
    },
    "scrolled": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'aggregated': {   'auc_pr': 0.7839680874062291,\n",
      "                      'avg_prec_score': 0.7844142007773247,\n",
      "                      'bceloss': 1.0481916864713035,\n",
      "                      'f1_max': 0.7444299731015749,\n",
      "                      'kappa': 0.4173461494995934,\n",
      "                      'kappa_max': 0.4453778160823674,\n",
      "                      'logloss': 0.001139338805300659,\n",
      "                      'p_f1_max': 0.1728429940039253,\n",
      "                      'p_kappa_max': 0.5572595953941344,\n",
      "                      'roc_auc_score': 0.7797019318818047,\n",
      "                      'sc_loss': 0.017090082079509884},\n",
      "    'losses': {   'task1': 5.793805089180847,\n",
      "                  'task2': 4.7581341425005,\n",
      "                  'task3': 5.170936281467743,\n",
      "                  'total': 15.722875513149093},\n",
      "    'losses_mean': {   'task1': 1.1587610178361685,\n",
      "                       'task2': 0.9516268285000998,\n",
      "                       'task3': 1.0341872562935486,\n",
      "                       'total': 3.144575102629818},\n",
      "    'parms': {'gumbel_temp': 0.23133697843771778, 'train_layers': 0},\n",
      "    'sharing': {'total': 0.05962842330336571},\n",
      "    'sparsity': {   'task1': 0.6706137615701426,\n",
      "                    'task2': 0.604851366126019,\n",
      "                    'task3': 0.7153697138247282,\n",
      "                    'total': 1.9908376932144165},\n",
      "    'task1': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.809947  0.870241        0.870419  0.809683  0.234723  0.454949   \n",
      "1          0.702792  0.668633        0.669218  0.645374  0.201933  0.319945   \n",
      "2          0.790758  0.759362        0.760180  0.773430  0.032953  0.435676   \n",
      "3          0.790516  0.740017        0.740502  0.678700  0.482500  0.411142   \n",
      "4          0.700168  0.759219        0.759621  0.719298  0.000054  0.291268   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.472036     0.745512  0.776153  \n",
      "1      0.349626     0.645575  1.607327  \n",
      "2      0.490710     0.146744  1.025560  \n",
      "3      0.458359     0.818019  0.916853  \n",
      "4      0.330854     0.896638  1.467913  ,\n",
      "                 'classification_agg': {   'auc_pr': 0.7594942816244834,\n",
      "                                           'avg_prec_score': 0.7599881043071657,\n",
      "                                           'bceloss': 1.1587610244750977,\n",
      "                                           'f1_max': 0.7252972503806633,\n",
      "                                           'kappa': 0.3825959219302103,\n",
      "                                           'kappa_max': 0.42031705943172193,\n",
      "                                           'logloss': 1.1587610178361694,\n",
      "                                           'p_f1_max': 0.19043253272975563,\n",
      "                                           'p_kappa_max': 0.6504974097013474,\n",
      "                                           'roc_auc_score': 0.7588358603273964,\n",
      "                                           'sc_loss': 5.793805089180847}},\n",
      "    'task2': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.770925  0.853607        0.853787  0.814872  0.167403  0.393060   \n",
      "1          0.808843  0.804886        0.805242  0.739356  0.516177  0.450856   \n",
      "2          0.782245  0.768615        0.769201  0.748527  0.172160  0.446186   \n",
      "3          0.780946  0.760152        0.760824  0.707373  0.114713  0.460210   \n",
      "4          0.872058  0.862533        0.862737  0.777302  0.142900  0.577004   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.430515     0.705141  1.027356  \n",
      "1      0.477075     0.843245  0.833418  \n",
      "2      0.457611     0.544157  0.976801  \n",
      "3      0.464405     0.514307  1.184837  \n",
      "4      0.594856     0.750179  0.735722  ,\n",
      "                 'classification_agg': {   'auc_pr': 0.8099583743716137,\n",
      "                                           'avg_prec_score': 0.8103582395958632,\n",
      "                                           'bceloss': 0.9516267895698547,\n",
      "                                           'f1_max': 0.7574860184770491,\n",
      "                                           'kappa': 0.4654633542197265,\n",
      "                                           'kappa_max': 0.4848923527992579,\n",
      "                                           'logloss': 0.9516268285001,\n",
      "                                           'p_f1_max': 0.22267068773508072,\n",
      "                                           'p_kappa_max': 0.6714058160781861,\n",
      "                                           'roc_auc_score': 0.8030032032580486,\n",
      "                                           'sc_loss': 4.7581341425005}},\n",
      "    'task3': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.839879  0.797614        0.798060  0.769527  0.115009  0.530321   \n",
      "1          0.739206  0.790114        0.790543  0.768178  0.037533  0.358766   \n",
      "2          0.815088  0.815198        0.815437  0.735263  0.236443  0.439317   \n",
      "3          0.776969  0.792596        0.793156  0.767559  0.130948  0.419725   \n",
      "4          0.715192  0.716736        0.717286  0.712007  0.007196  0.271767   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.541681     0.600133  0.784565  \n",
      "1      0.396078     0.091330  1.342083  \n",
      "2      0.471812     0.273693  0.919688  \n",
      "3      0.436612     0.554105  0.873690  \n",
      "4      0.308437     0.230116  1.250910  ,\n",
      "                 'classification_agg': {   'auc_pr': 0.7824516062225904,\n",
      "                                           'avg_prec_score': 0.7828962584289456,\n",
      "                                           'bceloss': 1.0341872453689576,\n",
      "                                           'f1_max': 0.7505066504470125,\n",
      "                                           'kappa': 0.40397917234884345,\n",
      "                                           'kappa_max': 0.43092403601612256,\n",
      "                                           'logloss': 1.0341872562935486,\n",
      "                                           'p_f1_max': 0.10542576154693963,\n",
      "                                           'p_kappa_max': 0.3498755604028702,\n",
      "                                           'roc_auc_score': 0.7772667320599693,\n",
      "                                           'sc_loss': 5.170936281467743}},\n",
      "    'total': {'total': 17.773341629666874, 'total_mean': 5.1950412191476}}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(environ.val_metrics)\n",
    "# pp.pprint(environ.val_metrics)\n",
    "# print(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23bfe929",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T00:02:33.476946Z",
     "start_time": "2022-03-03T00:02:33.444088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " save_policy(): save metrics to ../experiments/AdaSparseChem/50x6_0225_1530_test_0/metrics_Iter_best_expid_00_seed_0088.pickle\n"
     ]
    }
   ],
   "source": [
    "environ.save_metrics(policy_label, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "execution_count": 15,
   "id": "b0f73d2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:15:01.924518Z",
     "start_time": "2022-09-05T20:15:01.865558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4890, -0.4892],\n",
       "        [ 0.6206, -0.5527],\n",
       "        [ 0.6392, -0.1628],\n",
       "        [ 0.4834, -0.3636],\n",
       "        [ 0.3115, -0.5288],\n",
       "        [ 0.4814, -0.4269]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.networks['mtl-net'].task1_logits"
   ]
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:15:01.924518Z",
     "start_time": "2022-09-05T20:15:01.865558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4890, -0.4892],\n",
       "        [ 0.6206, -0.5527],\n",
       "        [ 0.6392, -0.1628],\n",
       "        [ 0.4834, -0.3636],\n",
       "        [ 0.3115, -0.5288],\n",
       "        [ 0.4814, -0.4269]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.networks['mtl-net'].task1_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7dc0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "execution_count": 14,
   "id": "a273a6ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:14:40.056242Z",
     "start_time": "2022-09-05T20:14:40.019709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.networks['mtl-net'].policys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db605013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:26:52.305282Z",
     "start_time": "2022-09-05T20:26:52.272206Z"
    }
   },
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:14:40.056242Z",
     "start_time": "2022-09-05T20:14:40.019709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.networks['mtl-net'].policys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db605013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:26:52.305282Z",
     "start_time": "2022-09-05T20:26:52.272206Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special          import softmax"
   ]
   "source": [
    "from scipy.special          import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afdf1d34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:23:27.820549Z",
     "start_time": "2022-09-05T20:23:27.787451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00141\n"
     ]
    }
   ],
   "source": [
    "print(f\"{environ.gumbel_temperature:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "execution_count": 22,
   "id": "afdf1d34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:23:27.820549Z",
     "start_time": "2022-09-05T20:23:27.787451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00141\n"
     ]
    }
   ],
   "source": [
    "print(f\"{environ.gumbel_temperature:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e01e9f0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:30:47.021308Z",
     "start_time": "2022-09-05T20:30:46.981292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48896503 -0.48924568]\n",
      " [ 0.6205768  -0.552715  ]\n",
      " [ 0.63918984 -0.16280036]\n",
      " [ 0.4834445  -0.36361492]\n",
      " [ 0.3115304  -0.52878916]\n",
      " [ 0.48136818 -0.42690638]] \n",
      "\n",
      " [[0.72675306 0.27324694]\n",
      " [0.7637395  0.23626049]\n",
      " [0.6904001  0.3096    ]\n",
      " [0.69994986 0.30005005]\n",
      " [0.6985326  0.30146748]\n",
      " [0.71264696 0.2873531 ]] \n",
      "\n",
      "\n",
      "\n",
      "[[ 0.48895213 -0.43660605]\n",
      " [ 0.603317   -0.69223595]\n",
      " [ 0.6392036  -0.6845882 ]\n",
      " [ 0.52562886 -0.74845964]\n",
      " [ 0.3114557  -0.706185  ]\n",
      " [ 0.4813958  -0.4292571 ]] \n",
      "\n",
      " [[0.71617323 0.28382674]\n",
      " [0.7850855  0.2149144 ]\n",
      " [0.78981185 0.21018815]\n",
      " [0.7814418  0.21855816]\n",
      " [0.7345128  0.26548722]\n",
      " [0.7131337  0.28686622]] \n",
      "\n",
      "\n",
      "\n",
      "[[ 0.488867   -0.90275866]\n",
      " [ 0.6687285  -0.64754575]\n",
      " [ 0.6391611  -0.575725  ]\n",
      " [ 0.52565235 -0.89058083]\n",
      " [ 0.31142807 -0.63682896]\n",
      " [ 0.48141176 -0.51926106]] \n",
      "\n",
      " [[0.8008517  0.19914836]\n",
      " [0.7885612  0.21143883]\n",
      " [0.77116233 0.22883767]\n",
      " [0.8047472  0.19525276]\n",
      " [0.72076446 0.27923548]\n",
      " [0.73119074 0.26880914]] \n",
      "\n",
      "\n",
      "\n",
      "[[ 0.48890802 -0.33195516]\n",
      " [ 0.60330254 -0.88435936]\n",
      " [ 0.6391694  -0.4603544 ]\n",
      " [ 0.52040595 -0.17959097]\n",
      " [ 0.32173148 -0.4430691 ]\n",
      " [ 0.48138922 -0.41956025]] \n",
      "\n",
      " [[0.6944195  0.30558044]\n",
      " [0.815727   0.18427292]\n",
      " [0.7501708  0.24982911]\n",
      " [0.6681871  0.33181292]\n",
      " [0.68239504 0.3176049 ]\n",
      " [0.71114457 0.2888554 ]] \n",
      "\n",
      "\n",
      "\n",
      "[[ 0.48888287 -0.4916184 ]\n",
      " [ 0.6033102  -0.36034486]\n",
      " [ 0.66033834 -0.5874939 ]\n",
      " [ 0.5256392  -0.3045775 ]\n",
      " [ 0.3114787  -0.10587034]\n",
      " [ 0.48139653 -0.5031237 ]] \n",
      "\n",
      " [[0.72720766 0.2727923 ]\n",
      " [0.723853   0.27614698]\n",
      " [0.77692443 0.22307561]\n",
      " [0.6964007  0.30359927]\n",
      " [0.6028487  0.39715126]\n",
      " [0.7280041  0.27199575]] \n",
      "\n",
      "\n",
      "\n",
      "[[ 0.48895526 -0.2773913 ]\n",
      " [ 0.6034851  -0.4313855 ]\n",
      " [ 0.63926196 -0.06015459]\n",
      " [ 0.5256856  -0.36442396]\n",
      " [ 0.3113086  -0.0158772 ]\n",
      " [ 0.4813902  -0.06321865]] \n",
      "\n",
      " [[0.6827301  0.31726995]\n",
      " [0.73785913 0.26214093]\n",
      " [0.6680584  0.33194163]\n",
      " [0.70891273 0.2910872 ]\n",
      " [0.5810745  0.4189255 ]\n",
      " [0.6328839  0.3671161 ]] \n",
      "\n",
      "\n",
      "\n",
      "[[ 0.4889178  -0.15715386]\n",
      " [ 0.60329664 -0.0409422 ]\n",
      " [ 0.63922155 -0.37472653]\n",
      " [ 0.5256387  -0.04207312]\n",
      " [ 0.3114468  -0.16228794]\n",
      " [ 0.4814286  -0.4903575 ]] \n",
      "\n",
      " [[0.6561247  0.3438753 ]\n",
      " [0.65571105 0.34428898]\n",
      " [0.7337921  0.26620796]\n",
      " [0.6382351  0.36176497]\n",
      " [0.6162674  0.3837327 ]\n",
      " [0.7254754  0.27452466]] \n",
      "\n",
      "\n",
      "\n",
      "[[ 0.4890115   0.11046085]\n",
      " [ 0.6033009   0.00097789]\n",
      " [ 0.63917434 -0.51779795]\n",
      " [ 0.52563715 -0.25382566]\n",
      " [ 0.310421   -0.24171518]\n",
      " [ 0.48199174 -0.2644784 ]] \n",
      "\n",
      " [[0.5935235  0.40647653]\n",
      " [0.6461876  0.3538124 ]\n",
      " [0.7607821  0.23921785]\n",
      " [0.6855643  0.3144357 ]\n",
      " [0.6346311  0.36536893]\n",
      " [0.67840904 0.32159093]] \n",
      "\n",
      "\n",
      "\n",
      "[[ 0.4889828  -0.610774  ]\n",
      " [ 0.6033404  -0.68587166]\n",
      " [ 0.6495294  -0.82801753]\n",
      " [ 0.52566785 -0.31121156]\n",
      " [ 0.31146637 -0.0364964 ]\n",
      " [ 0.48148617 -0.3959859 ]] \n",
      "\n",
      " [[0.7502145  0.24978545]\n",
      " [0.7840138  0.2159862 ]\n",
      " [0.8142017  0.18579821]\n",
      " [0.69780755 0.30219245]\n",
      " [0.5861234  0.41387653]\n",
      " [0.70629805 0.29370192]] \n",
      "\n",
      "\n",
      "\n",
      "[[ 0.48893    -0.06902971]\n",
      " [ 0.60302913 -0.23066354]\n",
      " [ 0.6393874  -0.21302229]\n",
      " [ 0.5549794  -0.35968143]\n",
      " [ 0.3114171  -0.00235975]\n",
      " [ 0.48113638 -0.04400484]] \n",
      "\n",
      " [[0.6359803  0.36401966]\n",
      " [0.6971352  0.30286485]\n",
      " [0.7010724  0.2989276 ]\n",
      " [0.71395296 0.286047  ]\n",
      " [0.5778069  0.4221931 ]\n",
      " [0.6283491  0.3716508 ]] \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgts = environ.get_all_task_logits_numpy() \n",
    "# plcy = environ.networks['mtl-net'].train_sample_policy(temperature=2, hard_sampling = False )\n",
    "for l in lgts:\n",
    "    print(l, '\\n\\n', softmax(l, axis = -1), '\\n\\n\\n')\n",
    "# print('\\n\\n\\n')\n",
    "# for p in plcy:\n",
    "#     print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e381299f",
   "cell_type": "code",
   "execution_count": 82,
   "id": "e381299f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T20:30:58.408795Z",
     "start_time": "2022-09-05T20:30:58.347756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4890, -0.4892],\n",
      "        [ 0.6206, -0.5527],\n",
      "        [ 0.6392, -0.1628],\n",
      "        [ 0.4834, -0.3636],\n",
      "        [ 0.3115, -0.5288],\n",
      "        [ 0.4814, -0.4269]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4890, -0.4366],\n",
      "        [ 0.6033, -0.6922],\n",
      "        [ 0.6392, -0.6846],\n",
      "        [ 0.5256, -0.7485],\n",
      "        [ 0.3115, -0.7062],\n",
      "        [ 0.4814, -0.4293]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4889, -0.9028],\n",
      "        [ 0.6687, -0.6475],\n",
      "        [ 0.6392, -0.5757],\n",
      "        [ 0.5257, -0.8906],\n",
      "        [ 0.3114, -0.6368],\n",
      "        [ 0.4814, -0.5193]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4889, -0.3320],\n",
      "        [ 0.6033, -0.8844],\n",
      "        [ 0.6392, -0.4604],\n",
      "        [ 0.5204, -0.1796],\n",
      "        [ 0.3217, -0.4431],\n",
      "        [ 0.4814, -0.4196]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4889, -0.4916],\n",
      "        [ 0.6033, -0.3603],\n",
      "        [ 0.6603, -0.5875],\n",
      "        [ 0.5256, -0.3046],\n",
      "        [ 0.3115, -0.1059],\n",
      "        [ 0.4814, -0.5031]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4890, -0.2774],\n",
      "        [ 0.6035, -0.4314],\n",
      "        [ 0.6393, -0.0602],\n",
      "        [ 0.5257, -0.3644],\n",
      "        [ 0.3113, -0.0159],\n",
      "        [ 0.4814, -0.0632]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4889, -0.1572],\n",
      "        [ 0.6033, -0.0409],\n",
      "        [ 0.6392, -0.3747],\n",
      "        [ 0.5256, -0.0421],\n",
      "        [ 0.3114, -0.1623],\n",
      "        [ 0.4814, -0.4904]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4890,  0.1105],\n",
      "        [ 0.6033,  0.0010],\n",
      "        [ 0.6392, -0.5178],\n",
      "        [ 0.5256, -0.2538],\n",
      "        [ 0.3104, -0.2417],\n",
      "        [ 0.4820, -0.2645]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4890, -0.6108],\n",
      "        [ 0.6033, -0.6859],\n",
      "        [ 0.6495, -0.8280],\n",
      "        [ 0.5257, -0.3112],\n",
      "        [ 0.3115, -0.0365],\n",
      "        [ 0.4815, -0.3960]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4889, -0.0690],\n",
      "        [ 0.6030, -0.2307],\n",
      "        [ 0.6394, -0.2130],\n",
      "        [ 0.5550, -0.3597],\n",
      "        [ 0.3114, -0.0024],\n",
      "        [ 0.4811, -0.0440]], device='cuda:0', requires_grad=True)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[9.9998e-01, 1.9884e-05],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 1.8387e-20],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [4.2435e-33, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [4.3861e-43, 1.0000e+00],\n",
      "        [1.0000e+00, 2.1476e-11],\n",
      "        [1.0000e+00, 4.5727e-35],\n",
      "        [0.0000e+00, 1.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 4.1836e-30],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "plcy, lgts = environ.networks['mtl-net'].train_sample_policy(temperature=environ.gumbel_temperature, hard_sampling = False )\n",
    "for l in lgts:\n",
    "    print(l)\n",
    "print('\\n\\n\\n')\n",
    "for p in plcy:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d076f6",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a63119",
   "metadata": {},
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.util import init_records, populate_records, populate_validation_metrics\n",
    "\n",
    "def eval_fix_policy(environ, dataloader, tasks, num_seg_cls=-1, eval_iter=10):\n",
    "    batch_size = []\n",
    "    records = {}\n",
    "    val_metrics = {}\n",
    "\n",
    "    records = init_records(tasks, num_seg_cls)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(dataloader)):\n",
    "            if eval_iter != -1:\n",
    "                if batch_idx > eval_iter:\n",
    "                    break\n",
    "            environ.set_inputs(batch)\n",
    "            \n",
    "            metrics = environ.val_fix_policy()\n",
    "            \n",
    "            populate_records(records, metrics, tasks)\n",
    "\n",
    "            batch_size.append(len(batch['img']))\n",
    "\n",
    "    ##  Populate Validation Metrics \n",
    "    val_metrics = populate_validation_metrics(records, tasks, num_seg_cls)\n",
    "\n",
    "    return val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933695c",
   "metadata": {},
   "source": [
    "###  Old code cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "733566d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T21:39:51.999310Z",
     "start_time": "2022-09-04T21:39:51.974104Z"
    }
   },
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# from utils.sparsechem_utils import load_sparse, load_task_weights, class_fold_counts, fold_and_transform_inputs, print_metrics_cr\n",
    "\n",
    "# from dataloaders.chembl_dataloader_dev import ClassRegrSparseDataset_v3, ClassRegrSparseDataset, InfiniteDataLoader\n",
    "\n",
    "# from utils.util import ( makedir, print_separator, create_path, print_yaml, print_yaml2, print_loss, should, \n",
    "#                          fix_random_seed, read_yaml, timestring, print_heading, print_dbg, \n",
    "#                          print_underline, write_config_report, display_config, get_command_line_args, is_notebook) \n",
    "### Read Configuration File### Initialization\n",
    "# pp = pprint.PrettyPrinter(indent=4)\n",
    "# os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Test.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1561e90e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T21:49:56.495940Z",
     "start_time": "2022-09-04T21:49:56.463279Z"
    }
   },
   "outputs": [],
   "source": [
    "# ********************************************************************\n",
    "# ****************** create folders and print options ****************\n",
    "# ********************************************************************\n",
    "# print_separator('READ YAML')\n",
    "\n",
    "# opt, gpu_ids, exp_ids = read_yaml(args)\n",
    "\n",
    "# exp_id = exp_ids[0]\n",
    "# fix_random_seed(opt[\"seed\"][exp_id])\n",
    "    \n",
    "# create_path(opt)    \n",
    "# print()\n",
    "# print_heading(f\" experiment name       : {opt['exp_name']} \\n\"\n",
    "#               f\" experiment instance   : {opt['exp_instance']} \\n\"\n",
    "#               f\" folder_name           : {opt['exp_folder']} \\n\"\n",
    "#               f\" folder_sfx            : {opt['folder_sfx']} \\n\"\n",
    "#               f\" experiment description: {opt['exp_description']}\\n\"\n",
    "#               f\" log folder            : {opt['paths']['log_dir']}\\n\"\n",
    "#               f\" checkpoint folder     : {opt['paths']['checkpoint_dir']}\", verbose = True)\n",
    "# print(f\" Gpu ids: {gpu_ids}     exp_ids: {exp_ids}         seed: {opt['seed']}\")        \n",
    "\n",
    "# write_config_report(opt, filename = 'run_params.txt')    \n",
    "# display_config(opt)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33a54ef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T03:26:41.777153Z",
     "start_time": "2022-03-03T03:26:41.461855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############### CREATE DATALOADERS ###############\n",
      "##################################################\n",
      "[0.725, 0.225, 0.05]\n",
      "size of test set  :  920\n",
      "size of test set:  920\n",
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      "-------------------------------------------------------\n",
      "* SparseChemEnv_Dev  Initializtion - verbose: False\n",
      "------------------------------------------------------- \n",
      "\n",
      "------------------------------------------------------------\n",
      "SparseChemEnv_Dev.super() init()  Start - verbose: False\n",
      "------------------------------------------------------------ \n",
      "\n",
      " log_dir        :  ../experiments/AdaSparseChem/50x6_0225_1530_test_0 \n",
      " checkpoint_dir :  ../experiments/AdaSparseChem/50x6_0225_1530_test_0 \n",
      " exp_name       :  SparseChem \n",
      " tasks_num_class:  [5, 5, 5] \n",
      " device         :  cuda:0 \n",
      " device id      :  0 \n",
      " dataset        :  Chembl_23_mini \n",
      " tasks          :  ['class', 'class', 'class'] \n",
      "\n",
      "--------------------------------------------------\n",
      "SparseChemEnv_Dev.super() init()  end\n",
      "-------------------------------------------------- \n",
      "\n",
      " is_train       :  False \n",
      " init_neg_logits:  -10 \n",
      " init temp      :  5.0 \n",
      " decay temp     :  0.965 \n",
      " input_size     :  32000 \n",
      " normalize loss :  None \n",
      " num_tasks      :  3 \n",
      " policys        :  [None, None, None]\n",
      "--------------------------------------------------------\n",
      "* SparseChemEnv_Dev environment successfully created\n",
      "-------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ********************************************************************\n",
    "# ******************** Prepare the dataloaders ***********************\n",
    "# ********************************************************************\n",
    "# load the dataloader\n",
    "print_separator('CREATE DATALOADERS')\n",
    "print(opt['dataload']['x_split_ratios'])\n",
    "\n",
    "if opt['dataload']['dataset'] == 'Chembl_23_mini':\n",
    "    testset  = ClassRegrSparseDataset_v3(opt, split_ratios = opt['dataload']['x_split_ratios'], ratio_index = 2, verbose = False)\n",
    "    print('size of test set  : ', len(testset))\n",
    "else:\n",
    "    raise NotImplementedError('Dataset %s is not implemented' % opt['dataload']['dataset'])\n",
    "\n",
    "print('size of test set: ', len(testset))\n",
    "\n",
    "# test_loader = DataLoader(testset, batch_size=opt['test']['batch_size'], drop_last=True, num_workers=2, shuffle=True)\n",
    "#     val_loader = DataLoader(valset, batch_size=1, drop_last=True, num_workers=2, shuffle=False)\n",
    "\n",
    "# test_loader = DataLoader(testset, batch_size=1, drop_last=True, num_workers=2, shuffle=True)\n",
    "test_loader   = InfiniteDataLoader(testset, batch_size=1, num_workers = 1, pin_memory=True, collate_fn=testset.collate  , shuffle=False)\n",
    "\n",
    "\n",
    "# ********************************************************************\n",
    "# ********************Create the environment *************************\n",
    "# ********************************************************************\n",
    "# create the model and the pretrain model\n",
    "print_separator('CREATE THE ENVIRONMENT')\n",
    "environ = SparseChemEnv_Dev(log_dir          = opt['paths']['log_dir'], \n",
    "                            checkpoint_dir   = opt['paths']['checkpoint_dir'], \n",
    "                            exp_name         = opt['exp_name'],\n",
    "                            tasks_num_class  = opt['tasks_num_class'], \n",
    "#                                 init_neg_logits  = opt['train']['init_neg_logits'], \n",
    "                            device           = gpu_ids[0],\n",
    "#                                 init_temperature = opt['train']['init_temp'], \n",
    "#                                 temperature_decay= opt['train']['decay_temp'], \n",
    "                            is_train         = False,\n",
    "                            opt              = opt, \n",
    "                            verbose          = False)\n",
    "\n",
    "cfg = environ.print_configuration()\n",
    "# print(cfg)\n",
    "write_config_report(opt, cfg, filename = 'run_params.txt', mode = 'a')    \n",
    "\n",
    "    \n",
    "    # create the model and the pretrain model\n",
    "#     print_separator('CREATE THE ENVIRONMENT')\n",
    "#     environ = BlockDropEnv(opt['paths']['log_dir'], \n",
    "#                            opt['paths']['checkpoint_dir'], \n",
    "#                            opt['exp_name'],\n",
    "#                            opt['tasks_num_class'],\n",
    "#                            device=gpu_ids[0], \n",
    "#                            is_train=False, \n",
    "#                            opt=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c4491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d933695c",
   "metadata": {},
   "source": [
    "###  Old code cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "733566d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T21:39:51.999310Z",
     "start_time": "2022-09-04T21:39:51.974104Z"
    }
   },
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# from utils.sparsechem_utils import load_sparse, load_task_weights, class_fold_counts, fold_and_transform_inputs, print_metrics_cr\n",
    "\n",
    "# from dataloaders.chembl_dataloader_dev import ClassRegrSparseDataset_v3, ClassRegrSparseDataset, InfiniteDataLoader\n",
    "\n",
    "# from utils.util import ( makedir, print_separator, create_path, print_yaml, print_yaml2, print_loss, should, \n",
    "#                          fix_random_seed, read_yaml, timestring, print_heading, print_dbg, \n",
    "#                          print_underline, write_config_report, display_config, get_command_line_args, is_notebook) \n",
    "### Read Configuration File### Initialization\n",
    "# pp = pprint.PrettyPrinter(indent=4)\n",
    "# os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Test.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1561e90e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T21:49:56.495940Z",
     "start_time": "2022-09-04T21:49:56.463279Z"
    }
   },
   "outputs": [],
   "source": [
    "# ********************************************************************\n",
    "# ****************** create folders and print options ****************\n",
    "# ********************************************************************\n",
    "# print_separator('READ YAML')\n",
    "\n",
    "# opt, gpu_ids, exp_ids = read_yaml(args)\n",
    "\n",
    "# exp_id = exp_ids[0]\n",
    "# fix_random_seed(opt[\"seed\"][exp_id])\n",
    "    \n",
    "# create_path(opt)    \n",
    "# print()\n",
    "# print_heading(f\" experiment name       : {opt['exp_name']} \\n\"\n",
    "#               f\" experiment instance   : {opt['exp_instance']} \\n\"\n",
    "#               f\" folder_name           : {opt['exp_folder']} \\n\"\n",
    "#               f\" folder_sfx            : {opt['folder_sfx']} \\n\"\n",
    "#               f\" experiment description: {opt['exp_description']}\\n\"\n",
    "#               f\" log folder            : {opt['paths']['log_dir']}\\n\"\n",
    "#               f\" checkpoint folder     : {opt['paths']['checkpoint_dir']}\", verbose = True)\n",
    "# print(f\" Gpu ids: {gpu_ids}     exp_ids: {exp_ids}         seed: {opt['seed']}\")        \n",
    "\n",
    "# write_config_report(opt, filename = 'run_params.txt')    \n",
    "# display_config(opt)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33a54ef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T03:26:41.777153Z",
     "start_time": "2022-03-03T03:26:41.461855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############### CREATE DATALOADERS ###############\n",
      "##################################################\n",
      "[0.725, 0.225, 0.05]\n",
      "size of test set  :  920\n",
      "size of test set:  920\n",
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      "-------------------------------------------------------\n",
      "* SparseChemEnv_Dev  Initializtion - verbose: False\n",
      "------------------------------------------------------- \n",
      "\n",
      "------------------------------------------------------------\n",
      "SparseChemEnv_Dev.super() init()  Start - verbose: False\n",
      "------------------------------------------------------------ \n",
      "\n",
      " log_dir        :  ../experiments/AdaSparseChem/50x6_0225_1530_test_0 \n",
      " checkpoint_dir :  ../experiments/AdaSparseChem/50x6_0225_1530_test_0 \n",
      " exp_name       :  SparseChem \n",
      " tasks_num_class:  [5, 5, 5] \n",
      " device         :  cuda:0 \n",
      " device id      :  0 \n",
      " dataset        :  Chembl_23_mini \n",
      " tasks          :  ['class', 'class', 'class'] \n",
      "\n",
      "--------------------------------------------------\n",
      "SparseChemEnv_Dev.super() init()  end\n",
      "-------------------------------------------------- \n",
      "\n",
      " is_train       :  False \n",
      " init_neg_logits:  -10 \n",
      " init temp      :  5.0 \n",
      " decay temp     :  0.965 \n",
      " input_size     :  32000 \n",
      " normalize loss :  None \n",
      " num_tasks      :  3 \n",
      " policys        :  [None, None, None]\n",
      "--------------------------------------------------------\n",
      "* SparseChemEnv_Dev environment successfully created\n",
      "-------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ********************************************************************\n",
    "# ******************** Prepare the dataloaders ***********************\n",
    "# ********************************************************************\n",
    "# load the dataloader\n",
    "print_separator('CREATE DATALOADERS')\n",
    "print(opt['dataload']['x_split_ratios'])\n",
    "\n",
    "if opt['dataload']['dataset'] == 'Chembl_23_mini':\n",
    "    testset  = ClassRegrSparseDataset_v3(opt, split_ratios = opt['dataload']['x_split_ratios'], ratio_index = 2, verbose = False)\n",
    "    print('size of test set  : ', len(testset))\n",
    "else:\n",
    "    raise NotImplementedError('Dataset %s is not implemented' % opt['dataload']['dataset'])\n",
    "\n",
    "print('size of test set: ', len(testset))\n",
    "\n",
    "# test_loader = DataLoader(testset, batch_size=opt['test']['batch_size'], drop_last=True, num_workers=2, shuffle=True)\n",
    "#     val_loader = DataLoader(valset, batch_size=1, drop_last=True, num_workers=2, shuffle=False)\n",
    "\n",
    "# test_loader = DataLoader(testset, batch_size=1, drop_last=True, num_workers=2, shuffle=True)\n",
    "test_loader   = InfiniteDataLoader(testset, batch_size=1, num_workers = 1, pin_memory=True, collate_fn=testset.collate  , shuffle=False)\n",
    "\n",
    "\n",
    "# ********************************************************************\n",
    "# ********************Create the environment *************************\n",
    "# ********************************************************************\n",
    "# create the model and the pretrain model\n",
    "print_separator('CREATE THE ENVIRONMENT')\n",
    "environ = SparseChemEnv_Dev(log_dir          = opt['paths']['log_dir'], \n",
    "                            checkpoint_dir   = opt['paths']['checkpoint_dir'], \n",
    "                            exp_name         = opt['exp_name'],\n",
    "                            tasks_num_class  = opt['tasks_num_class'], \n",
    "#                                 init_neg_logits  = opt['train']['init_neg_logits'], \n",
    "                            device           = gpu_ids[0],\n",
    "#                                 init_temperature = opt['train']['init_temp'], \n",
    "#                                 temperature_decay= opt['train']['decay_temp'], \n",
    "                            is_train         = False,\n",
    "                            opt              = opt, \n",
    "                            verbose          = False)\n",
    "\n",
    "cfg = environ.print_configuration()\n",
    "# print(cfg)\n",
    "write_config_report(opt, cfg, filename = 'run_params.txt', mode = 'a')    \n",
    "\n",
    "    \n",
    "    # create the model and the pretrain model\n",
    "#     print_separator('CREATE THE ENVIRONMENT')\n",
    "#     environ = BlockDropEnv(opt['paths']['log_dir'], \n",
    "#                            opt['paths']['checkpoint_dir'], \n",
    "#                            opt['exp_name'],\n",
    "#                            opt['tasks_num_class'],\n",
    "#                            device=gpu_ids[0], \n",
    "#                            is_train=False, \n",
    "#                            opt=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c4491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
