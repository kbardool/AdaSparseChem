{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408f1261",
   "metadata": {},
   "source": [
    "## Initialization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d574cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T18:09:35.305697Z",
     "start_time": "2022-04-02T18:09:35.166297Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:08.233990Z",
     "iopub.status.busy": "2022-01-07T22:44:08.233053Z",
     "iopub.status.idle": "2022-01-07T22:44:08.273284Z",
     "shell.execute_reply": "2022-01-07T22:44:08.271908Z",
     "shell.execute_reply.started": "2022-01-07T22:44:08.233943Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import time\n",
    "import argparse\n",
    "import yaml\n",
    "import types\n",
    "import copy, pprint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import numpy  as np\n",
    "import torch  \n",
    "import wandb\n",
    "import pandas as pd\n",
    "from utils.notebook_modules import initialize, init_dataloaders, init_environment, init_wandb, \\\n",
    "                                   training_prep, disp_dataloader_info,disp_info_1, \\\n",
    "                                   warmup_phase, weight_policy_training, disp_gpu_info\n",
    "\n",
    "from utils import print_separator, print_heading, timestring, print_loss, load_from_pickle\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=6, linewidth=132)\n",
    "pd.options.display.width = 132\n",
    "# torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
    "# sys.path.insert(0, '/home/kbardool/kusanagi/AdaSparseChem/src')\n",
    "# print(sys.path)\n",
    "# disp_gpu_info() \n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Training.ipynb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33ac6e",
   "metadata": {},
   "source": [
    "## Create Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee652c57",
   "metadata": {},
   "source": [
    "### Parse Input Args  - Read YAML config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a42bb98b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T18:09:36.506138Z",
     "start_time": "2022-04-02T18:09:36.474044Z"
    }
   },
   "outputs": [],
   "source": [
    "# RESUME_MODEL_CKPT = 'model_train_ep_25_seed_0088'\n",
    "\n",
    "## For RESTARTING\n",
    "##\n",
    "# input_args = \" --config yamls/chembl_3task_train.yaml \" \\\n",
    "#              \" --resume \" \\\n",
    "#              \" --exp_id      330i85cg\" \\\n",
    "#              \" --exp_name    0308_1204\" \\\n",
    "#              \" --exp_desc    Train with dropout 0.5\" \\\n",
    "#              \" --seed_idx    0 \"\\\n",
    "#              \" --batch_size  128\" \\\n",
    "#              \" --lambda_sparsity  0.01\"\\\n",
    "#              \" --lambda_sharing   0.01\" \n",
    "## get command line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3a7f00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T18:09:36.714094Z",
     "start_time": "2022-04-02T18:09:36.684654Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [],
   "source": [
    "##  For Initiating \n",
    "##\n",
    "input_args = \" --config ../yamls/chembl_synt_train.yaml \" \\\n",
    "             \" --exp_desc            dropout 0.5, weight 105 bch/ep policy 105 bch/ep \" \\\n",
    "             \" --warmup_epochs       150 \" \\\n",
    "             \" --hidden_size         40 40 40 40 \" \\\n",
    "             \" --tail_hidden_size    40\" \\\n",
    "             \" --seed_idx             0\" \\\n",
    "             \" --batch_size         128\" \\\n",
    "             \" --task_lr          0.001\" \\\n",
    "             \" --backbone_lr      0.001\" \\\n",
    "             \" --policy_lr        0.001\" \\\n",
    "             \" --lambda_sparsity   0.02\" \\\n",
    "             \" --lambda_sharing    0.01\" \\\n",
    "               \" --folder_sfx    noplcy\"                       \n",
    "#              \" --hidden_size   100 100 100 100 100 100\" \\\n",
    "#              \" --tail_hidden_size  100 \" \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbc14177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T18:09:38.066972Z",
     "start_time": "2022-04-02T18:09:37.974612Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  command line parms : \n",
      "------------------------\n",
      " config...................  ../yamls/chembl_synt_train.yaml\n",
      " exp_id...................  None\n",
      " exp_name.................  None\n",
      " folder_sfx...............  noplcy\n",
      " exp_desc.................  dropout 0.5, weight 105 bch/ep policy 105 bch/ep\n",
      " hidden_sizes.............  [40, 40, 40, 40]\n",
      " tail_hidden_size.........  40\n",
      " warmup_epochs............  150\n",
      " training_epochs..........  None\n",
      " seed_idx.................  0\n",
      " batch_size...............  128\n",
      " backbone_lr..............  0.001\n",
      " task_lr..................  0.001\n",
      " policy_lr................  0.001\n",
      " decay_lr_rate............  None\n",
      " decay_lr_freq............  None\n",
      " lambda_sparsity..........  0.02\n",
      " lambda_sharing...........  0.01\n",
      " gpu_ids..................  [0]\n",
      " resume...................  False\n",
      " cpu......................  False\n",
      "\n",
      "\n",
      "\n",
      "##################################################\n",
      "################### READ YAML ####################\n",
      "##################################################\n",
      "\n",
      "\n",
      " log_dir              create folder:  ../../experiments/AdaSparseChem/40x4_0402_2009_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      " result_dir           folder exists:  ../../experiments/AdaSparseChem/40x4_0402_2009_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      " checkpoint_dir       folder exists:  ../../experiments/AdaSparseChem/40x4_0402_2009_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " experiment name       : 0402_2009_noplcy \n",
      " experiment id         : 3jxtrd3e \n",
      " folder_name           : 40x4_0402_2009_plr0.001_sp0.02_sh0.01_lr0.001_noplcy \n",
      " experiment description: dropout 0.5, weight 105 bch/ep policy 105 bch/ep\n",
      " Random seeds          : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      " Random  seed used     : 88 \n",
      " log folder            : ../../experiments/AdaSparseChem/40x4_0402_2009_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      " checkpoint folder     : ../../experiments/AdaSparseChem/40x4_0402_2009_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      " Gpu ids               : [0]\n",
      " Seed index            : 0\n",
      " policy_iter           : best\n",
      " Data Split ratios     : [0.725, 0.225, 0.05]\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "        project_name : AdaSparseChem\n",
      "              exp_id : 3jxtrd3e\n",
      "            exp_name : 0402_2009_noplcy\n",
      "          exp_folder : 40x4_0402_2009_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      "     exp_description : dropout 0.5, weight 105 bch/ep policy 105 bch/ep\n",
      "          folder_sfx : noplcy\n",
      "         random_seed : 88\n",
      "           seed_list : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      "                 cpu : False\n",
      "             gpu_ids : [0]\n",
      "            backbone : SparseChem\n",
      "               tasks : ['class', 'class', 'class']\n",
      "     tasks_num_class : [5, 5, 5]\n",
      "             lambdas : [1, 1, 1]\n",
      "        policy_model : task-specific\n",
      "             verbose : False\n",
      "       backbone_orig : ResNet18\n",
      "          tasks_orig : ['seg', 'sn']\n",
      "     input_size_freq : None\n",
      "          input_size : 32000\n",
      " first_non_linearity : relu\n",
      "middle_non_linearity : relu\n",
      "  last_non_linearity : relu\n",
      "      middle_dropout : 0.5\n",
      "        last_dropout : 0.5\n",
      "   class_output_size : None\n",
      "    regr_output_size : None\n",
      "              policy : True\n",
      "           is_sparse : True\n",
      "          is_sharing : True\n",
      "diff_sparsity_weights : False\n",
      "          skip_layer : 0\n",
      "       is_curriculum : False\n",
      "    curriculum_speed : 3\n",
      "              fix_BN : False\n",
      "     retrain_from_pl : False\n",
      "\n",
      "train\n",
      "-----\n",
      "          batch_size : 128\n",
      "       warmup_epochs : 150\n",
      "     training_epochs : 250\n",
      "         total_iters : 25000\n",
      "       warm_up_iters : None\n",
      "             task_lr : 0.001\n",
      "         backbone_lr : 0.001\n",
      "       decay_lr_rate : 0.75\n",
      "       decay_lr_freq : 40\n",
      "policy_decay_lr_rate : 0.75\n",
      "policy_decay_lr_freq : 50\n",
      "           policy_lr : 0.001\n",
      "     lambda_sparsity : 0.02\n",
      "      lambda_sharing : 0.01\n",
      "        lambda_tasks : 1\n",
      "         init_method : random\n",
      "           init_temp : 4\n",
      "          decay_temp : 0.965\n",
      "     decay_temp_freq : 16\n",
      "     init_neg_logits : None\n",
      "       hard_sampling : False\n",
      "            val_freq : 500\n",
      "          print_freq : -1\n",
      "           val_iters : -1\n",
      "              resume : False\n",
      "      retrain_resume : False\n",
      "         policy_iter : best\n",
      "          which_iter : warmup\n",
      "\n",
      "paths\n",
      "-----\n",
      "             log_dir : ../../experiments/AdaSparseChem/40x4_0402_2009_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      "          result_dir : ../../experiments/AdaSparseChem/40x4_0402_2009_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      "      checkpoint_dir : ../../experiments/AdaSparseChem/40x4_0402_2009_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      "\n",
      "dataload\n",
      "--------\n",
      "             dataset : Chembl23_mini\n",
      "            dataroot : /home/kbardool/WSL-projs/MLDatasets/chembl23_synthetic\n",
      "                   x : chembl_23mini_x.npy\n",
      "      x_split_ratios : [0.725, 0.225, 0.05]\n",
      "             folding : chembl_23mini_folds.npy\n",
      "         fold_inputs : 32000\n",
      "     input_transform : None\n",
      "             y_tasks : ['chembl_23mini_adashare_y1_bin_sparse.npy', 'chembl_23mini_adashare_y2_bin_sparse.npy', 'chembl_23mini_adashare_y3_bin_sparse.npy']\n",
      "            y_censor : None\n",
      "       weights_class : None\n",
      "              crop_h : 321\n",
      "              crop_w : 321\n",
      "   min_samples_class : 5\n",
      "             fold_va : 0\n",
      "             fold_te : None\n",
      "\n",
      "SC\n",
      "--\n",
      "      normalize_loss : None\n",
      "        hidden_sizes : [40, 40, 40, 40]\n",
      "    tail_hidden_size : 40\n",
      "        exp_name_pfx : 0402_2009\n"
     ]
    }
   ],
   "source": [
    "opt, ns = initialize(input_args, build_folders = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bfa8d",
   "metadata": {},
   "source": [
    "### Setup Dataloader and Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c631eb67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T17:37:20.493344Z",
     "start_time": "2022-04-02T17:37:19.572242Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############### CREATE DATALOADERS ###############\n",
      "##################################################\n",
      "----------------------------------------------------------------\n",
      " 2022-04-02 19:37:19:692302  Create new  Chembl_23 instance \n",
      "---------------------------------------------------------------- \n",
      "\n",
      " verbose        : True\n",
      "\n",
      "* load y_task1 file : chembl_23mini_adashare_y1_bin_sparse.npy . . .\n",
      "\t y_task[1]  All y values are 0, 1, or -1.\n",
      "\t load_task_weights - filename: None label: y_task1\n",
      "\t load_task_weights - no weights file provided for y_task1, training_weights for all  5 classes set to 1 \n",
      "\t tasks_class.aggregation_weight WAS NOT passed \n",
      "\t min_samples_class: 5\n",
      "\t Class fold counts: \n",
      "  fold_pos:\n",
      "[[1382 1417 1493 1346 1435]\n",
      " [1463 1492 1350 1516 1291]\n",
      " [1498 1306 1366 1428 1333]\n",
      " [1331 1264 1205 1312 1356]\n",
      " [1375 1370 1359 1362 1339]]  \n",
      "\n",
      "  fold_neg:\n",
      "[[1363 1328 1252 1399 1310]\n",
      " [1424 1395 1537 1371 1596]\n",
      " [1129 1321 1261 1199 1294]\n",
      " [1154 1221 1280 1173 1129]\n",
      " [1212 1217 1228 1225 1248]]\n",
      "\t tasks_class.aggregation_weight set to [1. 1. 1. 1. 1.] \n",
      "\t task_weights.aggregation_weight.shape: (5,) - [1. 1. 1. 1. 1.]\n",
      "\n",
      "* load y_task2 file : chembl_23mini_adashare_y2_bin_sparse.npy . . .\n",
      "\t y_task[2]  All y values are 0, 1, or -1.\n",
      "\t load_task_weights - filename: None label: y_task2\n",
      "\t load_task_weights - no weights file provided for y_task2, training_weights for all  5 classes set to 1 \n",
      "\t tasks_class.aggregation_weight WAS NOT passed \n",
      "\t min_samples_class: 5\n",
      "\t Class fold counts: \n",
      "  fold_pos:\n",
      "[[1385 1285 1310 1409 1220]\n",
      " [1393 1301 1562 1305 1440]\n",
      " [1272 1408 1279 1244 1267]\n",
      " [1292 1350 1285 1276 1280]\n",
      " [1311 1281 1396 1266 1295]]  \n",
      "\n",
      "  fold_neg:\n",
      "[[1360 1460 1435 1336 1525]\n",
      " [1494 1586 1325 1582 1447]\n",
      " [1355 1219 1348 1383 1360]\n",
      " [1193 1135 1200 1209 1205]\n",
      " [1276 1306 1191 1321 1292]]\n",
      "\t tasks_class.aggregation_weight set to [1. 1. 1. 1. 1.] \n",
      "\t task_weights.aggregation_weight.shape: (5,) - [1. 1. 1. 1. 1.]\n",
      "\n",
      "* load y_task3 file : chembl_23mini_adashare_y3_bin_sparse.npy . . .\n",
      "\t y_task[3]  All y values are 0, 1, or -1.\n",
      "\t load_task_weights - filename: None label: y_task3\n",
      "\t load_task_weights - no weights file provided for y_task3, training_weights for all  5 classes set to 1 \n",
      "\t tasks_class.aggregation_weight WAS NOT passed \n",
      "\t min_samples_class: 5\n",
      "\t Class fold counts: \n",
      "  fold_pos:\n",
      "[[1498 1384 1471 1322 1372]\n",
      " [1324 1462 1404 1508 1456]\n",
      " [1341 1232 1262 1390 1347]\n",
      " [1187 1324 1245 1156 1140]\n",
      " [1202 1167 1413 1321 1355]]  \n",
      "\n",
      "  fold_neg:\n",
      "[[1247 1361 1274 1423 1373]\n",
      " [1563 1425 1483 1379 1431]\n",
      " [1286 1395 1365 1237 1280]\n",
      " [1298 1161 1240 1329 1345]\n",
      " [1385 1420 1174 1266 1232]]\n",
      "\t tasks_class.aggregation_weight set to [1. 1. 1. 1. 1.] \n",
      "\t task_weights.aggregation_weight.shape: (5,) - [1. 1. 1. 1. 1.]\n",
      "--------------------------------------------------\n",
      "Chembl_23 Create complete\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      " trainset.y_class                                   :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " trainset1.y_class                                  :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " trainset2.y_class                                  :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " valset.y_class                                     :  [(4137, 5), (4137, 5), (4137, 5)]  \n",
      " testset.y_class                                    :  [(920, 5), (920, 5), (920, 5)]  \n",
      "                                 \n",
      " size of training set 0 (warm up)                   :  13331 \n",
      " size of training set 1 (network parms)             :  13331 \n",
      " size of training set 2 (policy weights)            :  13331 \n",
      " size of validation set                             :  4137 \n",
      " size of test set                                   :  920 \n",
      "                               Total                :  45050 \n",
      "                                 \n",
      " lenght (# batches) in training 0 (warm up)         :  105 \n",
      " lenght (# batches) in training 1 (network parms)   :  105 \n",
      " lenght (# batches) in training 2 (policy weights)  :  105 \n",
      " lenght (# batches) in validation dataset           :  33 \n",
      " lenght (# batches) in test dataset                 :  29 \n",
      "                                \n",
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      " device is  cuda:0\n",
      "----------------------------------------------------\n",
      "* SparseChemEnv environment successfully created\n",
      "---------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dldrs = init_dataloaders(opt, verbose = True)\n",
    "disp_dataloader_info(dldrs)\n",
    "\n",
    "environ = init_environment(ns, opt, is_train = True, policy_learning = False, display_cfg = False)\n",
    "\n",
    "# ********************************************************************\n",
    "# **************** define optimizer and schedulers *******************\n",
    "# ********************************************************************                                \n",
    "environ.define_optimizer(policy_learning=False)\n",
    "environ.define_scheduler(policy_learning=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "677fa3f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:58:24.556949Z",
     "start_time": "2022-04-02T14:58:24.404607Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.optimizers['weights'].param_groups[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320fdeee",
   "metadata": {},
   "source": [
    "###  Weights and Biases Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03c2469c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:58:33.094615Z",
     "start_time": "2022-04-02T14:58:27.118315Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkbardool\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1o46td06 0402_1658_noplcy AdaSparseChem\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kbardool/WSL-projs/AdaSparseChem/notebooks/wandb/run-20220402_165827-1o46td06</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"http://localhost:8080/kbardool/AdaSparseChem/runs/1o46td06\" target=\"_blank\">0402_1658_noplcy</a></strong> to <a href=\"http://localhost:8080/kbardool/AdaSparseChem\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PROJECT NAME: AdaSparseChem\n",
      " RUN ID      : 1o46td06 \n",
      " RUN NAME    : 0402_1658_noplcy\n",
      " PROJECT NAME: AdaSparseChem\n",
      " RUN ID      : 1o46td06 \n",
      " RUN NAME    : 0402_1658_noplcy\n"
     ]
    }
   ],
   "source": [
    "init_wandb(ns, opt, environment = environ)\n",
    "\n",
    "print(f\" PROJECT NAME: {ns.wandb_run.project}\\n\"\n",
    "      f\" RUN ID      : {ns.wandb_run.id} \\n\"\n",
    "      f\" RUN NAME    : {ns.wandb_run.name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d949180d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T15:19:43.607726Z",
     "start_time": "2022-04-02T15:19:43.363650Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'types.SimpleNamespace' object has no attribute 'wandb_run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3296/1968508735.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'types.SimpleNamespace' object has no attribute 'wandb_run'"
     ]
    }
   ],
   "source": [
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d738062",
   "metadata": {},
   "source": [
    "### Initiate / Resume Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd2a36e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:58:36.569650Z",
     "start_time": "2022-04-02T14:58:36.489926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############### Initiate Training  ###############\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "if opt['train']['resume']:\n",
    "    RESUME_MODEL_CKPT = \"\"\n",
    "    RESUME_METRICS_CKPT = \"\"    \n",
    "    print(opt['train']['which_iter'])\n",
    "    print(opt['paths']['checkpoint_dir'])\n",
    "    print(RESUME_MODEL_CKPT)\n",
    "    # opt['train']['resume'] = True\n",
    "    # opt['train']['which_iter'] = 'warmup_ep_40_seed_0088'\n",
    "    print_separator('Resume training')\n",
    "    loaded_iter, loaded_epoch = environ.load_checkpoint(RESUME_MODEL_CKPT, path = opt['paths']['checkpoint_dir'], verbose = True)\n",
    "    print(loaded_iter, loaded_epoch)    \n",
    "#     current_iter = environ.load_checkpoint(opt['train']['which_iter'])\n",
    "    environ.networks['mtl-net'].reset_logits()\n",
    "    val_metrics = load_from_pickle(opt['paths']['checkpoint_dir'], RESUME_METRICS_CKPT)\n",
    "    # training_prep(ns, opt, environ, dldrs, epoch = loaded_epoch, iter = loaded_iter )\n",
    "\n",
    "else:\n",
    "    print_separator('Initiate Training ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7774f",
   "metadata": {},
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8b6afdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:58:42.757696Z",
     "start_time": "2022-04-02T14:58:42.406436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cuda available [0]\n",
      " set print_freq to length of train loader: 105\n",
      " set eval_iters to length of val loader  : 33\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Num_blocks                : 4                                \n",
      "\n",
      " batch size                : 128 \n",
      " batches/ Weight trn epoch : 105 \n",
      " batches/ Policy trn epoch : 105                                 \n",
      "\n",
      " Print Frequency           : -1 \n",
      " Config Val Frequency      : 500 \n",
      " Config Val Iterations     : -1 \n",
      " Val iterations            : 33 \n",
      " which_iter                : warmup \n",
      " train_resume              : False                                 \n",
      " \n",
      " fix BN parms              : False \n",
      " Task LR                   : 0.001 \n",
      " Backbone LR               : 0.001                                 \n",
      "\n",
      " Sharing  regularization   : 0.01 \n",
      " Sparsity regularization   : 0.02 \n",
      " Task     regularization   : 1                                 \n",
      "\n",
      " Current epoch             : 0  \n",
      " Warm-up epochs            : 150 \n",
      " Training epochs           : 250\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    folder: 40x4_0402_1658_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      "    layers: 4 [40, 40, 40, 40] \n",
      "    \n",
      "    middle dropout         : 0.5\n",
      "    last dropout           : 0.5\n",
      "    diff_sparsity_weights  : False\n",
      "    skip_layer             : 0\n",
      "    is_curriculum          : False\n",
      "    curriculum_speed       : 3\n",
      "    \n",
      "    task_lr                : 0.001\n",
      "    backbone_lr            : 0.001\n",
      "    decay_lr_rate          : 0.75\n",
      "    decay_lr_freq          : 40\n",
      "    \n",
      "    policy_lr              : 0.001\n",
      "    policy_decay_lr_rate   : 0.75\n",
      "    policy_decay_lr_freq   : 50\n",
      "    lambda_sparsity        : 0.02\n",
      "    lambda_sharing         : 0.01\n",
      "    lambda_tasks           : 1\n",
      "    \n",
      "    Gumbel init_temp       : 4\n",
      "    Gumbel decay_temp      : 0.965\n",
      "    Gumbel decay_temp_freq : 16\n",
      "    Logit init_method      : random\n",
      "    Logit init_neg_logits  : None\n",
      "    Logit hard_sampling    : False\n",
      "    Warm-up epochs         : 150\n",
      "    training epochs        : 250\n",
      "    Data split ratios      : [0.725, 0.225, 0.05]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_prep(ns, opt, environ, dldrs)\n",
    "print('-'*80)\n",
    "disp_info_1(ns, opt, environ)\n",
    "print('-'*80)\n",
    "print(environ.disp_for_excel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278d6d1",
   "metadata": {},
   "source": [
    "## Warmup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92380a48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:58:45.235089Z",
     "start_time": "2022-04-02T14:58:45.179147Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n",
      "----------------------------------------------------------------------\n",
      " Last Epoch: 0   # of warm-up epochs to do:  2 - Run epochs 1 to 2\n",
      "---------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# environ.display_trained_policy(ns.current_epoch,out=sys.stdout)\n",
    "# ns.stop_epoch_warmup = 10\n",
    "ns.warmup_epochs = 2\n",
    "# ns.check_for_improvment_wait = 0\n",
    "print(ns.warmup_epochs, ns.current_epoch)\n",
    "print_heading(f\" Last Epoch: {ns.current_epoch}   # of warm-up epochs to do:  {ns.warmup_epochs} - Run epochs {ns.current_epoch+1} to {ns.current_epoch + ns.warmup_epochs}\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8be9d65b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:02:01.838745Z",
     "start_time": "2022-04-02T13:01:53.794358Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      " Last Epoch: 150   # of warm-up epochs to do:  2 - Run epochs 151 to 152\n",
      "---------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      " + Validation Loop Start - batch_idx:1  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:1  eval_iters: 33\n",
      "    loss[task1]     : 0.3179    sum(err)               : 0.3179    sum(err)/batch_id      : 0.3179 \n",
      "    loss_mean[task1]: 0.2949    sum(err_mean)          : 0.2949    avg(err_mean)          : 0.2949\n",
      "    self.metrics[task_key][yc_wghts_sum] 138.0    task_weights[task_key] : 138.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:1  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 0.3179     avg(all_tasks_loss_sum)     : 0.3179 \n",
      "    all tasks_loss_sum_mean     : 0.2949    avg(all_tasks_loss_sum_mean): 0.2949\n",
      "\n",
      " + Validation Loop Start - batch_idx:2  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:2  eval_iters: 33\n",
      "    loss[task1]     : 0.1831    sum(err)               : 0.5010    sum(err)/batch_id      : 0.2505 \n",
      "    loss_mean[task1]: 0.1699    sum(err_mean)          : 0.4647    avg(err_mean)          : 0.2324\n",
      "    self.metrics[task_key][yc_wghts_sum] 138.0    task_weights[task_key] : 276.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:2  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 0.5010     avg(all_tasks_loss_sum)     : 0.2505 \n",
      "    all tasks_loss_sum_mean     : 0.4647    avg(all_tasks_loss_sum_mean): 0.2324\n",
      "\n",
      " + Validation Loop Start - batch_idx:3  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:3  eval_iters: 33\n",
      "    loss[task1]     : 0.2294    sum(err)               : 0.7304    sum(err)/batch_id      : 0.2435 \n",
      "    loss_mean[task1]: 0.2127    sum(err_mean)          : 0.6775    avg(err_mean)          : 0.2258\n",
      "    self.metrics[task_key][yc_wghts_sum] 138.0    task_weights[task_key] : 414.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:3  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 0.7304     avg(all_tasks_loss_sum)     : 0.2435 \n",
      "    all tasks_loss_sum_mean     : 0.6775    avg(all_tasks_loss_sum_mean): 0.2258\n",
      "\n",
      " + Validation Loop Start - batch_idx:4  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:4  eval_iters: 33\n",
      "    loss[task1]     : 0.2493    sum(err)               : 0.9797    sum(err)/batch_id      : 0.2449 \n",
      "    loss_mean[task1]: 0.2279    sum(err_mean)          : 0.9054    avg(err_mean)          : 0.2263\n",
      "    self.metrics[task_key][yc_wghts_sum] 140.0    task_weights[task_key] : 554.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:4  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 0.9797     avg(all_tasks_loss_sum)     : 0.2449 \n",
      "    all tasks_loss_sum_mean     : 0.9054    avg(all_tasks_loss_sum_mean): 0.2263\n",
      "\n",
      " + Validation Loop Start - batch_idx:5  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:5  eval_iters: 33\n",
      "    loss[task1]     : 0.3704    sum(err)               : 1.3500    sum(err)/batch_id      : 0.2700 \n",
      "    loss_mean[task1]: 0.3338    sum(err_mean)          : 1.2392    avg(err_mean)          : 0.2478\n",
      "    self.metrics[task_key][yc_wghts_sum] 142.0    task_weights[task_key] : 696.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:5  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 1.3500     avg(all_tasks_loss_sum)     : 0.2700 \n",
      "    all tasks_loss_sum_mean     : 1.2392    avg(all_tasks_loss_sum_mean): 0.2478\n",
      "\n",
      " + Validation Loop Start - batch_idx:6  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:6  eval_iters: 33\n",
      "    loss[task1]     : 0.1508    sum(err)               : 1.5008    sum(err)/batch_id      : 0.2501 \n",
      "    loss_mean[task1]: 0.1398    sum(err_mean)          : 1.3791    avg(err_mean)          : 0.2298\n",
      "    self.metrics[task_key][yc_wghts_sum] 138.0    task_weights[task_key] : 834.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:6  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 1.5008     avg(all_tasks_loss_sum)     : 0.2501 \n",
      "    all tasks_loss_sum_mean     : 1.3791    avg(all_tasks_loss_sum_mean): 0.2298\n",
      "\n",
      " + Validation Loop Start - batch_idx:7  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:7  eval_iters: 33\n",
      "    loss[task1]     : 0.4292    sum(err)               : 1.9300    sum(err)/batch_id      : 0.2757 \n",
      "    loss_mean[task1]: 0.3953    sum(err_mean)          : 1.7743    avg(err_mean)          : 0.2535\n",
      "    self.metrics[task_key][yc_wghts_sum] 139.0    task_weights[task_key] : 973.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:7  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 1.9300     avg(all_tasks_loss_sum)     : 0.2757 \n",
      "    all tasks_loss_sum_mean     : 1.7743    avg(all_tasks_loss_sum_mean): 0.2535\n",
      "\n",
      " + Validation Loop Start - batch_idx:8  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:8  eval_iters: 33\n",
      "    loss[task1]     : 0.2908    sum(err)               : 2.2209    sum(err)/batch_id      : 0.2776 \n",
      "    loss_mean[task1]: 0.2737    sum(err_mean)          : 2.0481    avg(err_mean)          : 0.2560\n",
      "    self.metrics[task_key][yc_wghts_sum] 136.0    task_weights[task_key] : 1109.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:8  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 2.2209     avg(all_tasks_loss_sum)     : 0.2776 \n",
      "    all tasks_loss_sum_mean     : 2.0481    avg(all_tasks_loss_sum_mean): 0.2560\n",
      "\n",
      " + Validation Loop Start - batch_idx:9  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:9  eval_iters: 33\n",
      "    loss[task1]     : 0.2692    sum(err)               : 2.4901    sum(err)/batch_id      : 0.2767 \n",
      "    loss_mean[task1]: 0.2462    sum(err_mean)          : 2.2942    avg(err_mean)          : 0.2549\n",
      "    self.metrics[task_key][yc_wghts_sum] 140.0    task_weights[task_key] : 1249.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:9  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 2.4901     avg(all_tasks_loss_sum)     : 0.2767 \n",
      "    all tasks_loss_sum_mean     : 2.2942    avg(all_tasks_loss_sum_mean): 0.2549\n",
      "\n",
      " + Validation Loop Start - batch_idx:10  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:10  eval_iters: 33\n",
      "    loss[task1]     : 0.2210    sum(err)               : 2.7111    sum(err)/batch_id      : 0.2711 \n",
      "    loss_mean[task1]: 0.1978    sum(err_mean)          : 2.4920    avg(err_mean)          : 0.2492\n",
      "    self.metrics[task_key][yc_wghts_sum] 143.0    task_weights[task_key] : 1392.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:10  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 2.7111     avg(all_tasks_loss_sum)     : 0.2711 \n",
      "    all tasks_loss_sum_mean     : 2.4920    avg(all_tasks_loss_sum_mean): 0.2492\n",
      "\n",
      " + Validation Loop Start - batch_idx:11  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:11  eval_iters: 33\n",
      "    loss[task1]     : 0.1731    sum(err)               : 2.8842    sum(err)/batch_id      : 0.2622 \n",
      "    loss_mean[task1]: 0.1594    sum(err_mean)          : 2.6514    avg(err_mean)          : 0.2410\n",
      "    self.metrics[task_key][yc_wghts_sum] 139.0    task_weights[task_key] : 1531.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:11  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 2.8842     avg(all_tasks_loss_sum)     : 0.2622 \n",
      "    all tasks_loss_sum_mean     : 2.6514    avg(all_tasks_loss_sum_mean): 0.2410\n",
      "\n",
      " + Validation Loop Start - batch_idx:12  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:12  eval_iters: 33\n",
      "    loss[task1]     : 0.2567    sum(err)               : 3.1409    sum(err)/batch_id      : 0.2617 \n",
      "    loss_mean[task1]: 0.2330    sum(err_mean)          : 2.8845    avg(err_mean)          : 0.2404\n",
      "    self.metrics[task_key][yc_wghts_sum] 141.0    task_weights[task_key] : 1672.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:12  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 3.1409     avg(all_tasks_loss_sum)     : 0.2617 \n",
      "    all tasks_loss_sum_mean     : 2.8845    avg(all_tasks_loss_sum_mean): 0.2404\n",
      "\n",
      " + Validation Loop Start - batch_idx:13  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:13  eval_iters: 33\n",
      "    loss[task1]     : 0.3094    sum(err)               : 3.4503    sum(err)/batch_id      : 0.2654 \n",
      "    loss_mean[task1]: 0.2829    sum(err_mean)          : 3.1673    avg(err_mean)          : 0.2436\n",
      "    self.metrics[task_key][yc_wghts_sum] 140.0    task_weights[task_key] : 1812.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:13  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 3.4503     avg(all_tasks_loss_sum)     : 0.2654 \n",
      "    all tasks_loss_sum_mean     : 3.1673    avg(all_tasks_loss_sum_mean): 0.2436\n",
      "\n",
      " + Validation Loop Start - batch_idx:14  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:14  eval_iters: 33\n",
      "    loss[task1]     : 0.4081    sum(err)               : 3.8584    sum(err)/batch_id      : 0.2756 \n",
      "    loss_mean[task1]: 0.3627    sum(err_mean)          : 3.5301    avg(err_mean)          : 0.2521\n",
      "    self.metrics[task_key][yc_wghts_sum] 144.0    task_weights[task_key] : 1956.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:14  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 3.8584     avg(all_tasks_loss_sum)     : 0.2756 \n",
      "    all tasks_loss_sum_mean     : 3.5301    avg(all_tasks_loss_sum_mean): 0.2521\n",
      "\n",
      " + Validation Loop Start - batch_idx:15  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:15  eval_iters: 33\n",
      "    loss[task1]     : 0.3305    sum(err)               : 4.1889    sum(err)/batch_id      : 0.2793 \n",
      "    loss_mean[task1]: 0.3044    sum(err_mean)          : 3.8344    avg(err_mean)          : 0.2556\n",
      "    self.metrics[task_key][yc_wghts_sum] 139.0    task_weights[task_key] : 2095.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:15  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 4.1889     avg(all_tasks_loss_sum)     : 0.2793 \n",
      "    all tasks_loss_sum_mean     : 3.8344    avg(all_tasks_loss_sum_mean): 0.2556\n",
      "\n",
      " + Validation Loop Start - batch_idx:16  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:16  eval_iters: 33\n",
      "    loss[task1]     : 0.1239    sum(err)               : 4.3128    sum(err)/batch_id      : 0.2695 \n",
      "    loss_mean[task1]: 0.1132    sum(err_mean)          : 3.9477    avg(err_mean)          : 0.2467\n",
      "    self.metrics[task_key][yc_wghts_sum] 140.0    task_weights[task_key] : 2235.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:16  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 4.3128     avg(all_tasks_loss_sum)     : 0.2695 \n",
      "    all tasks_loss_sum_mean     : 3.9477    avg(all_tasks_loss_sum_mean): 0.2467\n",
      "\n",
      " + Validation Loop Start - batch_idx:17  eval_iters: 33  t_validation: 33 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " + Validation Loop - batch_idx:17  eval_iters: 33\n",
      "    loss[task1]     : 0.5093    sum(err)               : 4.8220    sum(err)/batch_id      : 0.2836 \n",
      "    loss_mean[task1]: 0.4724    sum(err_mean)          : 4.4201    avg(err_mean)          : 0.2600\n",
      "    self.metrics[task_key][yc_wghts_sum] 138.0    task_weights[task_key] : 2373.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:17  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 4.8220     avg(all_tasks_loss_sum)     : 0.2836 \n",
      "    all tasks_loss_sum_mean     : 4.4201    avg(all_tasks_loss_sum_mean): 0.2600\n",
      "\n",
      " + Validation Loop Start - batch_idx:18  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:18  eval_iters: 33\n",
      "    loss[task1]     : 0.3115    sum(err)               : 5.1335    sum(err)/batch_id      : 0.2852 \n",
      "    loss_mean[task1]: 0.2712    sum(err_mean)          : 4.6913    avg(err_mean)          : 0.2606\n",
      "    self.metrics[task_key][yc_wghts_sum] 147.0    task_weights[task_key] : 2520.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:18  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 5.1335     avg(all_tasks_loss_sum)     : 0.2852 \n",
      "    all tasks_loss_sum_mean     : 4.6913    avg(all_tasks_loss_sum_mean): 0.2606\n",
      "\n",
      " + Validation Loop Start - batch_idx:19  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:19  eval_iters: 33\n",
      "    loss[task1]     : 0.2358    sum(err)               : 5.3694    sum(err)/batch_id      : 0.2826 \n",
      "    loss_mean[task1]: 0.2172    sum(err_mean)          : 4.9085    avg(err_mean)          : 0.2583\n",
      "    self.metrics[task_key][yc_wghts_sum] 139.0    task_weights[task_key] : 2659.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:19  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 5.3694     avg(all_tasks_loss_sum)     : 0.2826 \n",
      "    all tasks_loss_sum_mean     : 4.9085    avg(all_tasks_loss_sum_mean): 0.2583\n",
      "\n",
      " + Validation Loop Start - batch_idx:20  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:20  eval_iters: 33\n",
      "    loss[task1]     : 0.1810    sum(err)               : 5.5503    sum(err)/batch_id      : 0.2775 \n",
      "    loss_mean[task1]: 0.1643    sum(err_mean)          : 5.0728    avg(err_mean)          : 0.2536\n",
      "    self.metrics[task_key][yc_wghts_sum] 141.0    task_weights[task_key] : 2800.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:20  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 5.5503     avg(all_tasks_loss_sum)     : 0.2775 \n",
      "    all tasks_loss_sum_mean     : 5.0728    avg(all_tasks_loss_sum_mean): 0.2536\n",
      "\n",
      " + Validation Loop Start - batch_idx:21  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:21  eval_iters: 33\n",
      "    loss[task1]     : 0.3265    sum(err)               : 5.8769    sum(err)/batch_id      : 0.2799 \n",
      "    loss_mean[task1]: 0.2985    sum(err_mean)          : 5.3713    avg(err_mean)          : 0.2558\n",
      "    self.metrics[task_key][yc_wghts_sum] 140.0    task_weights[task_key] : 2940.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:21  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 5.8769     avg(all_tasks_loss_sum)     : 0.2799 \n",
      "    all tasks_loss_sum_mean     : 5.3713    avg(all_tasks_loss_sum_mean): 0.2558\n",
      "\n",
      " + Validation Loop Start - batch_idx:22  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:22  eval_iters: 33\n",
      "    loss[task1]     : 0.2403    sum(err)               : 6.1171    sum(err)/batch_id      : 0.2781 \n",
      "    loss_mean[task1]: 0.2229    sum(err_mean)          : 5.5942    avg(err_mean)          : 0.2543\n",
      "    self.metrics[task_key][yc_wghts_sum] 138.0    task_weights[task_key] : 3078.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:22  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 6.1171     avg(all_tasks_loss_sum)     : 0.2781 \n",
      "    all tasks_loss_sum_mean     : 5.5942    avg(all_tasks_loss_sum_mean): 0.2543\n",
      "\n",
      " + Validation Loop Start - batch_idx:23  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:23  eval_iters: 33\n",
      "    loss[task1]     : 0.4053    sum(err)               : 6.5224    sum(err)/batch_id      : 0.2836 \n",
      "    loss_mean[task1]: 0.3843    sum(err_mean)          : 5.9784    avg(err_mean)          : 0.2599\n",
      "    self.metrics[task_key][yc_wghts_sum] 135.0    task_weights[task_key] : 3213.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:23  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 6.5224     avg(all_tasks_loss_sum)     : 0.2836 \n",
      "    all tasks_loss_sum_mean     : 5.9784    avg(all_tasks_loss_sum_mean): 0.2599\n",
      "\n",
      " + Validation Loop Start - batch_idx:24  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:24  eval_iters: 33\n",
      "    loss[task1]     : 0.1866    sum(err)               : 6.7090    sum(err)/batch_id      : 0.2795 \n",
      "    loss_mean[task1]: 0.1782    sum(err_mean)          : 6.1567    avg(err_mean)          : 0.2565\n",
      "    self.metrics[task_key][yc_wghts_sum] 134.0    task_weights[task_key] : 3347.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:24  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 6.7090     avg(all_tasks_loss_sum)     : 0.2795 \n",
      "    all tasks_loss_sum_mean     : 6.1567    avg(all_tasks_loss_sum_mean): 0.2565\n",
      "\n",
      " + Validation Loop Start - batch_idx:25  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:25  eval_iters: 33\n",
      "    loss[task1]     : 0.2614    sum(err)               : 6.9704    sum(err)/batch_id      : 0.2788 \n",
      "    loss_mean[task1]: 0.2356    sum(err_mean)          : 6.3923    avg(err_mean)          : 0.2557\n",
      "    self.metrics[task_key][yc_wghts_sum] 142.0    task_weights[task_key] : 3489.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:25  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 6.9704     avg(all_tasks_loss_sum)     : 0.2788 \n",
      "    all tasks_loss_sum_mean     : 6.3923    avg(all_tasks_loss_sum_mean): 0.2557\n",
      "\n",
      " + Validation Loop Start - batch_idx:26  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:26  eval_iters: 33\n",
      "    loss[task1]     : 0.4011    sum(err)               : 7.3715    sum(err)/batch_id      : 0.2835 \n",
      "    loss_mean[task1]: 0.3693    sum(err_mean)          : 6.7617    avg(err_mean)          : 0.2601\n",
      "    self.metrics[task_key][yc_wghts_sum] 139.0    task_weights[task_key] : 3628.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:26  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 7.3715     avg(all_tasks_loss_sum)     : 0.2835 \n",
      "    all tasks_loss_sum_mean     : 6.7617    avg(all_tasks_loss_sum_mean): 0.2601\n",
      "\n",
      " + Validation Loop Start - batch_idx:27  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:27  eval_iters: 33\n",
      "    loss[task1]     : 0.2456    sum(err)               : 7.6171    sum(err)/batch_id      : 0.2821 \n",
      "    loss_mean[task1]: 0.2230    sum(err_mean)          : 6.9846    avg(err_mean)          : 0.2587\n",
      "    self.metrics[task_key][yc_wghts_sum] 141.0    task_weights[task_key] : 3769.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:27  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 7.6171     avg(all_tasks_loss_sum)     : 0.2821 \n",
      "    all tasks_loss_sum_mean     : 6.9846    avg(all_tasks_loss_sum_mean): 0.2587\n",
      "\n",
      " + Validation Loop Start - batch_idx:28  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:28  eval_iters: 33\n",
      "    loss[task1]     : 0.2475    sum(err)               : 7.8647    sum(err)/batch_id      : 0.2809 \n",
      "    loss_mean[task1]: 0.2279    sum(err_mean)          : 7.2126    avg(err_mean)          : 0.2576\n",
      "    self.metrics[task_key][yc_wghts_sum] 139.0    task_weights[task_key] : 3908.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:28  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 7.8647     avg(all_tasks_loss_sum)     : 0.2809 \n",
      "    all tasks_loss_sum_mean     : 7.2126    avg(all_tasks_loss_sum_mean): 0.2576\n",
      "\n",
      " + Validation Loop Start - batch_idx:29  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:29  eval_iters: 33\n",
      "    loss[task1]     : 0.1414    sum(err)               : 8.0060    sum(err)/batch_id      : 0.2761 \n",
      "    loss_mean[task1]: 0.1302    sum(err_mean)          : 7.3427    avg(err_mean)          : 0.2532\n",
      "    self.metrics[task_key][yc_wghts_sum] 139.0    task_weights[task_key] : 4047.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:29  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 8.0060     avg(all_tasks_loss_sum)     : 0.2761 \n",
      "    all tasks_loss_sum_mean     : 7.3427    avg(all_tasks_loss_sum_mean): 0.2532\n",
      "\n",
      " + Validation Loop Start - batch_idx:30  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:30  eval_iters: 33\n",
      "    loss[task1]     : 0.3215    sum(err)               : 8.3275    sum(err)/batch_id      : 0.2776 \n",
      "    loss_mean[task1]: 0.2982    sum(err_mean)          : 7.6410    avg(err_mean)          : 0.2547\n",
      "    self.metrics[task_key][yc_wghts_sum] 138.0    task_weights[task_key] : 4185.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:30  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 8.3275     avg(all_tasks_loss_sum)     : 0.2776 \n",
      "    all tasks_loss_sum_mean     : 7.6410    avg(all_tasks_loss_sum_mean): 0.2547\n",
      "\n",
      " + Validation Loop Start - batch_idx:31  eval_iters: 33  t_validation: 33 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " + Validation Loop - batch_idx:31  eval_iters: 33\n",
      "    loss[task1]     : 0.1707    sum(err)               : 8.4983    sum(err)/batch_id      : 0.2741 \n",
      "    loss_mean[task1]: 0.1572    sum(err_mean)          : 7.7982    avg(err_mean)          : 0.2516\n",
      "    self.metrics[task_key][yc_wghts_sum] 139.0    task_weights[task_key] : 4324.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:31  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 8.4983     avg(all_tasks_loss_sum)     : 0.2741 \n",
      "    all tasks_loss_sum_mean     : 7.7982    avg(all_tasks_loss_sum_mean): 0.2516\n",
      "\n",
      " + Validation Loop Start - batch_idx:32  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:32  eval_iters: 33\n",
      "    loss[task1]     : 0.2065    sum(err)               : 8.7048    sum(err)/batch_id      : 0.2720 \n",
      "    loss_mean[task1]: 0.1930    sum(err_mean)          : 7.9911    avg(err_mean)          : 0.2497\n",
      "    self.metrics[task_key][yc_wghts_sum] 137.0    task_weights[task_key] : 4461.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:32  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 8.7048     avg(all_tasks_loss_sum)     : 0.2720 \n",
      "    all tasks_loss_sum_mean     : 7.9911    avg(all_tasks_loss_sum_mean): 0.2497\n",
      "\n",
      " + Validation Loop Start - batch_idx:33  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:33  eval_iters: 33\n",
      "    loss[task1]     : 0.0895    sum(err)               : 8.7943    sum(err)/batch_id      : 0.2665 \n",
      "    loss_mean[task1]: 0.0798    sum(err_mean)          : 8.0709    avg(err_mean)          : 0.2446\n",
      "    self.metrics[task_key][yc_wghts_sum] 46.0    task_weights[task_key] : 4507.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:33  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 8.7943     avg(all_tasks_loss_sum)     : 0.2665 \n",
      "    all tasks_loss_sum_mean     : 8.0709    avg(all_tasks_loss_sum_mean): 0.2446\n",
      "--------------------------------------------------------------\n",
      " + Validation Loops complete- batch_idx:33  eval_iters: 33\n",
      "-------------------------------------------------------------- \n",
      "\n",
      "    task:   1     batch_idx       : <class 'int'> \n",
      "    sum(err)                              : 8.7943 \n",
      "    avg(err)=sum(err)/batch_idx           : 0.2665\n",
      "    task   1: sum(err_mean)       : 8.0709 \n",
      "    avg(err_mean)=sum(err_mean)/batch_idx : 8.0709 \n",
      "    self.metrics[task_key][yc_wghts_sum]  : 46.0    task_weights[task_key]                : 4507.0 \n",
      "    all_tasks_sharing_loss                : 0.0139     all_tasks_class_weights               : <class 'float'>\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  151 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.0337   1.3859e-02   0.0000e+00    0.0475 |       nan       nan       nan       nan |    0.2665   1.3859e-02   0.0000e+00     0.2804 |   3.7 |\n",
      "\n",
      " + Validation Loop Start - batch_idx:1  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:1  eval_iters: 33\n",
      "    loss[task1]     : 0.3126    sum(err)               : 0.3126    sum(err)/batch_id      : 0.3126 \n",
      "    loss_mean[task1]: 0.2838    sum(err_mean)          : 0.2838    avg(err_mean)          : 0.2838\n",
      "    self.metrics[task_key][yc_wghts_sum] 141.0    task_weights[task_key] : 141.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:1  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 0.3126     avg(all_tasks_loss_sum)     : 0.3126 \n",
      "    all tasks_loss_sum_mean     : 0.2838    avg(all_tasks_loss_sum_mean): 0.2838\n",
      "\n",
      " + Validation Loop Start - batch_idx:2  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:2  eval_iters: 33\n",
      "    loss[task1]     : 0.2813    sum(err)               : 0.5939    sum(err)/batch_id      : 0.2969 \n",
      "    loss_mean[task1]: 0.2628    sum(err_mean)          : 0.5466    avg(err_mean)          : 0.2733\n",
      "    self.metrics[task_key][yc_wghts_sum] 137.0    task_weights[task_key] : 278.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:2  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 0.5939     avg(all_tasks_loss_sum)     : 0.2969 \n",
      "    all tasks_loss_sum_mean     : 0.5466    avg(all_tasks_loss_sum_mean): 0.2733\n",
      "\n",
      " + Validation Loop Start - batch_idx:3  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:3  eval_iters: 33\n",
      "    loss[task1]     : 0.2074    sum(err)               : 0.8013    sum(err)/batch_id      : 0.2671 \n",
      "    loss_mean[task1]: 0.1870    sum(err_mean)          : 0.7335    avg(err_mean)          : 0.2445\n",
      "    self.metrics[task_key][yc_wghts_sum] 142.0    task_weights[task_key] : 420.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:3  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 0.8013     avg(all_tasks_loss_sum)     : 0.2671 \n",
      "    all tasks_loss_sum_mean     : 0.7335    avg(all_tasks_loss_sum_mean): 0.2445\n",
      "\n",
      " + Validation Loop Start - batch_idx:4  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:4  eval_iters: 33\n",
      "    loss[task1]     : 0.1115    sum(err)               : 0.9127    sum(err)/batch_id      : 0.2282 \n",
      "    loss_mean[task1]: 0.1065    sum(err_mean)          : 0.8400    avg(err_mean)          : 0.2100\n",
      "    self.metrics[task_key][yc_wghts_sum] 134.0    task_weights[task_key] : 554.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:4  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 0.9127     avg(all_tasks_loss_sum)     : 0.2282 \n",
      "    all tasks_loss_sum_mean     : 0.8400    avg(all_tasks_loss_sum_mean): 0.2100\n",
      "\n",
      " + Validation Loop Start - batch_idx:5  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:5  eval_iters: 33\n",
      "    loss[task1]     : 0.2220    sum(err)               : 1.1347    sum(err)/batch_id      : 0.2269 \n",
      "    loss_mean[task1]: 0.2030    sum(err_mean)          : 1.0430    avg(err_mean)          : 0.2086\n",
      "    self.metrics[task_key][yc_wghts_sum] 140.0    task_weights[task_key] : 694.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:5  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 1.1347     avg(all_tasks_loss_sum)     : 0.2269 \n",
      "    all tasks_loss_sum_mean     : 1.0430    avg(all_tasks_loss_sum_mean): 0.2086\n",
      "\n",
      " + Validation Loop Start - batch_idx:6  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:6  eval_iters: 33\n",
      "    loss[task1]     : 0.2899    sum(err)               : 1.4247    sum(err)/batch_id      : 0.2374 \n",
      "    loss_mean[task1]: 0.2729    sum(err_mean)          : 1.3158    avg(err_mean)          : 0.2193\n",
      "    self.metrics[task_key][yc_wghts_sum] 136.0    task_weights[task_key] : 830.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:6  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 1.4247     avg(all_tasks_loss_sum)     : 0.2374 \n",
      "    all tasks_loss_sum_mean     : 1.3158    avg(all_tasks_loss_sum_mean): 0.2193\n",
      "\n",
      " + Validation Loop Start - batch_idx:7  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:7  eval_iters: 33\n",
      "    loss[task1]     : 0.2578    sum(err)               : 1.6824    sum(err)/batch_id      : 0.2403 \n",
      "    loss_mean[task1]: 0.2357    sum(err_mean)          : 1.5515    avg(err_mean)          : 0.2216\n",
      "    self.metrics[task_key][yc_wghts_sum] 140.0    task_weights[task_key] : 970.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:7  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 1.6824     avg(all_tasks_loss_sum)     : 0.2403 \n",
      "    all tasks_loss_sum_mean     : 1.5515    avg(all_tasks_loss_sum_mean): 0.2216\n",
      "\n",
      " + Validation Loop Start - batch_idx:8  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:8  eval_iters: 33\n",
      "    loss[task1]     : 0.1543    sum(err)               : 1.8368    sum(err)/batch_id      : 0.2296 \n",
      "    loss_mean[task1]: 0.1474    sum(err_mean)          : 1.6990    avg(err_mean)          : 0.2124\n",
      "    self.metrics[task_key][yc_wghts_sum] 134.0    task_weights[task_key] : 1104.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:8  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 1.8368     avg(all_tasks_loss_sum)     : 0.2296 \n",
      "    all tasks_loss_sum_mean     : 1.6990    avg(all_tasks_loss_sum_mean): 0.2124\n",
      "\n",
      " + Validation Loop Start - batch_idx:9  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:9  eval_iters: 33\n",
      "    loss[task1]     : 0.2408    sum(err)               : 2.0775    sum(err)/batch_id      : 0.2308 \n",
      "    loss_mean[task1]: 0.2217    sum(err_mean)          : 1.9207    avg(err_mean)          : 0.2134\n",
      "    self.metrics[task_key][yc_wghts_sum] 139.0    task_weights[task_key] : 1243.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:9  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 2.0775     avg(all_tasks_loss_sum)     : 0.2308 \n",
      "    all tasks_loss_sum_mean     : 1.9207    avg(all_tasks_loss_sum_mean): 0.2134\n",
      "\n",
      " + Validation Loop Start - batch_idx:10  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:10  eval_iters: 33\n",
      "    loss[task1]     : 0.4167    sum(err)               : 2.4943    sum(err)/batch_id      : 0.2494 \n",
      "    loss_mean[task1]: 0.3653    sum(err_mean)          : 2.2860    avg(err_mean)          : 0.2286\n",
      "    self.metrics[task_key][yc_wghts_sum] 146.0    task_weights[task_key] : 1389.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:10  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 2.4943     avg(all_tasks_loss_sum)     : 0.2494 \n",
      "    all tasks_loss_sum_mean     : 2.2860    avg(all_tasks_loss_sum_mean): 0.2286\n",
      "\n",
      " + Validation Loop Start - batch_idx:11  eval_iters: 33  t_validation: 33 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " + Validation Loop - batch_idx:11  eval_iters: 33\n",
      "    loss[task1]     : 0.2600    sum(err)               : 2.7542    sum(err)/batch_id      : 0.2504 \n",
      "    loss_mean[task1]: 0.2483    sum(err_mean)          : 2.5343    avg(err_mean)          : 0.2304\n",
      "    self.metrics[task_key][yc_wghts_sum] 134.0    task_weights[task_key] : 1523.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:11  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 2.7542     avg(all_tasks_loss_sum)     : 0.2504 \n",
      "    all tasks_loss_sum_mean     : 2.5343    avg(all_tasks_loss_sum_mean): 0.2304\n",
      "\n",
      " + Validation Loop Start - batch_idx:12  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:12  eval_iters: 33\n",
      "    loss[task1]     : 0.3024    sum(err)               : 3.0566    sum(err)/batch_id      : 0.2547 \n",
      "    loss_mean[task1]: 0.2707    sum(err_mean)          : 2.8050    avg(err_mean)          : 0.2337\n",
      "    self.metrics[task_key][yc_wghts_sum] 143.0    task_weights[task_key] : 1666.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:12  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 3.0566     avg(all_tasks_loss_sum)     : 0.2547 \n",
      "    all tasks_loss_sum_mean     : 2.8050    avg(all_tasks_loss_sum_mean): 0.2337\n",
      "\n",
      " + Validation Loop Start - batch_idx:13  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:13  eval_iters: 33\n",
      "    loss[task1]     : 0.6202    sum(err)               : 3.6768    sum(err)/batch_id      : 0.2828 \n",
      "    loss_mean[task1]: 0.5590    sum(err_mean)          : 3.3640    avg(err_mean)          : 0.2588\n",
      "    self.metrics[task_key][yc_wghts_sum] 142.0    task_weights[task_key] : 1808.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:13  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 3.6768     avg(all_tasks_loss_sum)     : 0.2828 \n",
      "    all tasks_loss_sum_mean     : 3.3640    avg(all_tasks_loss_sum_mean): 0.2588\n",
      "\n",
      " + Validation Loop Start - batch_idx:14  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:14  eval_iters: 33\n",
      "    loss[task1]     : 0.2295    sum(err)               : 3.9063    sum(err)/batch_id      : 0.2790 \n",
      "    loss_mean[task1]: 0.2040    sum(err_mean)          : 3.5680    avg(err_mean)          : 0.2549\n",
      "    self.metrics[task_key][yc_wghts_sum] 144.0    task_weights[task_key] : 1952.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:14  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 3.9063     avg(all_tasks_loss_sum)     : 0.2790 \n",
      "    all tasks_loss_sum_mean     : 3.5680    avg(all_tasks_loss_sum_mean): 0.2549\n",
      "\n",
      " + Validation Loop Start - batch_idx:15  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:15  eval_iters: 33\n",
      "    loss[task1]     : 0.2344    sum(err)               : 4.1407    sum(err)/batch_id      : 0.2760 \n",
      "    loss_mean[task1]: 0.2098    sum(err_mean)          : 3.7779    avg(err_mean)          : 0.2519\n",
      "    self.metrics[task_key][yc_wghts_sum] 143.0    task_weights[task_key] : 2095.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:15  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 4.1407     avg(all_tasks_loss_sum)     : 0.2760 \n",
      "    all tasks_loss_sum_mean     : 3.7779    avg(all_tasks_loss_sum_mean): 0.2519\n",
      "\n",
      " + Validation Loop Start - batch_idx:16  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:16  eval_iters: 33\n",
      "    loss[task1]     : 0.3604    sum(err)               : 4.5011    sum(err)/batch_id      : 0.2813 \n",
      "    loss_mean[task1]: 0.3343    sum(err_mean)          : 4.1121    avg(err_mean)          : 0.2570\n",
      "    self.metrics[task_key][yc_wghts_sum] 138.0    task_weights[task_key] : 2233.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:16  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 4.5011     avg(all_tasks_loss_sum)     : 0.2813 \n",
      "    all tasks_loss_sum_mean     : 4.1121    avg(all_tasks_loss_sum_mean): 0.2570\n",
      "\n",
      " + Validation Loop Start - batch_idx:17  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:17  eval_iters: 33\n",
      "    loss[task1]     : 0.2099    sum(err)               : 4.7110    sum(err)/batch_id      : 0.2771 \n",
      "    loss_mean[task1]: 0.1919    sum(err_mean)          : 4.3040    avg(err_mean)          : 0.2532\n",
      "    self.metrics[task_key][yc_wghts_sum] 140.0    task_weights[task_key] : 2373.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:17  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 4.7110     avg(all_tasks_loss_sum)     : 0.2771 \n",
      "    all tasks_loss_sum_mean     : 4.3040    avg(all_tasks_loss_sum_mean): 0.2532\n",
      "\n",
      " + Validation Loop Start - batch_idx:18  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:18  eval_iters: 33\n",
      "    loss[task1]     : 0.2886    sum(err)               : 4.9996    sum(err)/batch_id      : 0.2778 \n",
      "    loss_mean[task1]: 0.2639    sum(err_mean)          : 4.5679    avg(err_mean)          : 0.2538\n",
      "    self.metrics[task_key][yc_wghts_sum] 140.0    task_weights[task_key] : 2513.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:18  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 4.9996     avg(all_tasks_loss_sum)     : 0.2778 \n",
      "    all tasks_loss_sum_mean     : 4.5679    avg(all_tasks_loss_sum_mean): 0.2538\n",
      "\n",
      " + Validation Loop Start - batch_idx:19  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:19  eval_iters: 33\n",
      "    loss[task1]     : 0.1943    sum(err)               : 5.1939    sum(err)/batch_id      : 0.2734 \n",
      "    loss_mean[task1]: 0.1727    sum(err_mean)          : 4.7406    avg(err_mean)          : 0.2495\n",
      "    self.metrics[task_key][yc_wghts_sum] 144.0    task_weights[task_key] : 2657.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:19  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 5.1939     avg(all_tasks_loss_sum)     : 0.2734 \n",
      "    all tasks_loss_sum_mean     : 4.7406    avg(all_tasks_loss_sum_mean): 0.2495\n",
      "\n",
      " + Validation Loop Start - batch_idx:20  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:20  eval_iters: 33\n",
      "    loss[task1]     : 0.3036    sum(err)               : 5.4975    sum(err)/batch_id      : 0.2749 \n",
      "    loss_mean[task1]: 0.2837    sum(err_mean)          : 5.0243    avg(err_mean)          : 0.2512\n",
      "    self.metrics[task_key][yc_wghts_sum] 137.0    task_weights[task_key] : 2794.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:20  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 5.4975     avg(all_tasks_loss_sum)     : 0.2749 \n",
      "    all tasks_loss_sum_mean     : 5.0243    avg(all_tasks_loss_sum_mean): 0.2512\n",
      "\n",
      " + Validation Loop Start - batch_idx:21  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:21  eval_iters: 33\n",
      "    loss[task1]     : 0.2777    sum(err)               : 5.7752    sum(err)/batch_id      : 0.2750 \n",
      "    loss_mean[task1]: 0.2673    sum(err_mean)          : 5.2916    avg(err_mean)          : 0.2520\n",
      "    self.metrics[task_key][yc_wghts_sum] 133.0    task_weights[task_key] : 2927.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:21  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 5.7752     avg(all_tasks_loss_sum)     : 0.2750 \n",
      "    all tasks_loss_sum_mean     : 5.2916    avg(all_tasks_loss_sum_mean): 0.2520\n",
      "\n",
      " + Validation Loop Start - batch_idx:22  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:22  eval_iters: 33\n",
      "    loss[task1]     : 0.1628    sum(err)               : 5.9380    sum(err)/batch_id      : 0.2699 \n",
      "    loss_mean[task1]: 0.1543    sum(err_mean)          : 5.4459    avg(err_mean)          : 0.2475\n",
      "    self.metrics[task_key][yc_wghts_sum] 135.0    task_weights[task_key] : 3062.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:22  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 5.9380     avg(all_tasks_loss_sum)     : 0.2699 \n",
      "    all tasks_loss_sum_mean     : 5.4459    avg(all_tasks_loss_sum_mean): 0.2475\n",
      "\n",
      " + Validation Loop Start - batch_idx:23  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:23  eval_iters: 33\n",
      "    loss[task1]     : 0.1400    sum(err)               : 6.0780    sum(err)/batch_id      : 0.2643 \n",
      "    loss_mean[task1]: 0.1262    sum(err_mean)          : 5.5721    avg(err_mean)          : 0.2423\n",
      "    self.metrics[task_key][yc_wghts_sum] 142.0    task_weights[task_key] : 3204.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:23  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 6.0780     avg(all_tasks_loss_sum)     : 0.2643 \n",
      "    all tasks_loss_sum_mean     : 5.5721    avg(all_tasks_loss_sum_mean): 0.2423\n",
      "\n",
      " + Validation Loop Start - batch_idx:24  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:24  eval_iters: 33\n",
      "    loss[task1]     : 0.3351    sum(err)               : 6.4131    sum(err)/batch_id      : 0.2672 \n",
      "    loss_mean[task1]: 0.2938    sum(err_mean)          : 5.8659    avg(err_mean)          : 0.2444\n",
      "    self.metrics[task_key][yc_wghts_sum] 146.0    task_weights[task_key] : 3350.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:24  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 6.4131     avg(all_tasks_loss_sum)     : 0.2672 \n",
      "    all tasks_loss_sum_mean     : 5.8659    avg(all_tasks_loss_sum_mean): 0.2444\n",
      "\n",
      " + Validation Loop Start - batch_idx:25  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:25  eval_iters: 33\n",
      "    loss[task1]     : 0.2232    sum(err)               : 6.6363    sum(err)/batch_id      : 0.2655 \n",
      "    loss_mean[task1]: 0.2086    sum(err_mean)          : 6.0744    avg(err_mean)          : 0.2430\n",
      "    self.metrics[task_key][yc_wghts_sum] 137.0    task_weights[task_key] : 3487.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:25  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 6.6363     avg(all_tasks_loss_sum)     : 0.2655 \n",
      "    all tasks_loss_sum_mean     : 6.0744    avg(all_tasks_loss_sum_mean): 0.2430\n",
      "\n",
      " + Validation Loop Start - batch_idx:26  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:26  eval_iters: 33\n",
      "    loss[task1]     : 0.2955    sum(err)               : 6.9318    sum(err)/batch_id      : 0.2666 \n",
      "    loss_mean[task1]: 0.2721    sum(err_mean)          : 6.3465    avg(err_mean)          : 0.2441\n",
      "    self.metrics[task_key][yc_wghts_sum] 139.0    task_weights[task_key] : 3626.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:26  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 6.9318     avg(all_tasks_loss_sum)     : 0.2666 \n",
      "    all tasks_loss_sum_mean     : 6.3465    avg(all_tasks_loss_sum_mean): 0.2441\n",
      "\n",
      " + Validation Loop Start - batch_idx:27  eval_iters: 33  t_validation: 33 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " + Validation Loop - batch_idx:27  eval_iters: 33\n",
      "    loss[task1]     : 0.3472    sum(err)               : 7.2791    sum(err)/batch_id      : 0.2696 \n",
      "    loss_mean[task1]: 0.3108    sum(err_mean)          : 6.6574    avg(err_mean)          : 0.2466\n",
      "    self.metrics[task_key][yc_wghts_sum] 143.0    task_weights[task_key] : 3769.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:27  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 7.2791     avg(all_tasks_loss_sum)     : 0.2696 \n",
      "    all tasks_loss_sum_mean     : 6.6574    avg(all_tasks_loss_sum_mean): 0.2466\n",
      "\n",
      " + Validation Loop Start - batch_idx:28  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:28  eval_iters: 33\n",
      "    loss[task1]     : 0.3173    sum(err)               : 7.5963    sum(err)/batch_id      : 0.2713 \n",
      "    loss_mean[task1]: 0.2901    sum(err_mean)          : 6.9474    avg(err_mean)          : 0.2481\n",
      "    self.metrics[task_key][yc_wghts_sum] 140.0    task_weights[task_key] : 3909.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:28  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 7.5963     avg(all_tasks_loss_sum)     : 0.2713 \n",
      "    all tasks_loss_sum_mean     : 6.9474    avg(all_tasks_loss_sum_mean): 0.2481\n",
      "\n",
      " + Validation Loop Start - batch_idx:29  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:29  eval_iters: 33\n",
      "    loss[task1]     : 0.3250    sum(err)               : 7.9214    sum(err)/batch_id      : 0.2732 \n",
      "    loss_mean[task1]: 0.3037    sum(err_mean)          : 7.2511    avg(err_mean)          : 0.2500\n",
      "    self.metrics[task_key][yc_wghts_sum] 137.0    task_weights[task_key] : 4046.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:29  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 7.9214     avg(all_tasks_loss_sum)     : 0.2732 \n",
      "    all tasks_loss_sum_mean     : 7.2511    avg(all_tasks_loss_sum_mean): 0.2500\n",
      "\n",
      " + Validation Loop Start - batch_idx:30  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:30  eval_iters: 33\n",
      "    loss[task1]     : 0.2077    sum(err)               : 8.1291    sum(err)/batch_id      : 0.2710 \n",
      "    loss_mean[task1]: 0.1927    sum(err_mean)          : 7.4438    avg(err_mean)          : 0.2481\n",
      "    self.metrics[task_key][yc_wghts_sum] 138.0    task_weights[task_key] : 4184.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:30  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 8.1291     avg(all_tasks_loss_sum)     : 0.2710 \n",
      "    all tasks_loss_sum_mean     : 7.4438    avg(all_tasks_loss_sum_mean): 0.2481\n",
      "\n",
      " + Validation Loop Start - batch_idx:31  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:31  eval_iters: 33\n",
      "    loss[task1]     : 0.3438    sum(err)               : 8.4729    sum(err)/batch_id      : 0.2733 \n",
      "    loss_mean[task1]: 0.3236    sum(err_mean)          : 7.7674    avg(err_mean)          : 0.2506\n",
      "    self.metrics[task_key][yc_wghts_sum] 136.0    task_weights[task_key] : 4320.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:31  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 8.4729     avg(all_tasks_loss_sum)     : 0.2733 \n",
      "    all tasks_loss_sum_mean     : 7.7674    avg(all_tasks_loss_sum_mean): 0.2506\n",
      "\n",
      " + Validation Loop Start - batch_idx:32  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:32  eval_iters: 33\n",
      "    loss[task1]     : 0.2159    sum(err)               : 8.6888    sum(err)/batch_id      : 0.2715 \n",
      "    loss_mean[task1]: 0.1988    sum(err_mean)          : 7.9662    avg(err_mean)          : 0.2489\n",
      "    self.metrics[task_key][yc_wghts_sum] 139.0    task_weights[task_key] : 4459.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:32  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 8.6888     avg(all_tasks_loss_sum)     : 0.2715 \n",
      "    all tasks_loss_sum_mean     : 7.9662    avg(all_tasks_loss_sum_mean): 0.2489\n",
      "\n",
      " + Validation Loop Start - batch_idx:33  eval_iters: 33  t_validation: 33 \n",
      "\n",
      " + Validation Loop - batch_idx:33  eval_iters: 33\n",
      "    loss[task1]     : 0.2738    sum(err)               : 8.9626    sum(err)/batch_id      : 0.2716 \n",
      "    loss_mean[task1]: 0.2338    sum(err_mean)          : 8.2000    avg(err_mean)          : 0.2485\n",
      "    self.metrics[task_key][yc_wghts_sum] 48.0    task_weights[task_key] : 4507.0  \n",
      "\n",
      " + Validation Loop end - batch_idx:33  eval_iters: 33 \n",
      "    all tasks_loss_sum          : 8.9626     avg(all_tasks_loss_sum)     : 0.2716 \n",
      "    all tasks_loss_sum_mean     : 8.2000    avg(all_tasks_loss_sum_mean): 0.2485\n",
      "--------------------------------------------------------------\n",
      " + Validation Loops complete- batch_idx:33  eval_iters: 33\n",
      "-------------------------------------------------------------- \n",
      "\n",
      "    task:   1     batch_idx       : <class 'int'> \n",
      "    sum(err)                              : 8.9626 \n",
      "    avg(err)=sum(err)/batch_idx           : 0.2716\n",
      "    task   1: sum(err_mean)       : 8.2000 \n",
      "    avg(err_mean)=sum(err_mean)/batch_idx : 8.2000 \n",
      "    self.metrics[task_key][yc_wghts_sum]  : 48.0    task_weights[task_key]                : 4507.0 \n",
      "    all_tasks_sharing_loss                : 0.0139     all_tasks_class_weights               : <class 'float'>\n",
      "  152 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.0178   1.3859e-02   0.0000e+00    0.0317 |       nan       nan       nan       nan |    0.2716   1.3859e-02   0.0000e+00     0.2855 |   4.0 |\n",
      "[Final] ep:152  it:15960 -  Total Loss: 0.2855     \n",
      "Task: 0.2716   Sparsity: 1.38588e-02    Sharing: 0.00000e+00 \n",
      "\n",
      " ep:  152   softmax      s        \n",
      " ----- ----------------- -    \n",
      "  0    0.4999    0.5001  0\n",
      "  1    0.5002    0.4998  1\n",
      "  2    0.4996    0.5004  0\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17066/1941024487.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# warmup_phase(ns,opt, environ, dldrs, epochs = 25)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwarmup_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menviron\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdldrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/WSL-projs/AdaSparseChem/notebooks/../src/utils/notebook_modules.py\u001b[0m in \u001b[0;36mwarmup_phase\u001b[0;34m(ns, opt, environ, dldrs, disable_tqdm, epochs)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mcheck_for_improvement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0mwrapup_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menviron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WSL-projs/AdaSparseChem/notebooks/../src/utils/notebook_modules.py\u001b[0m in \u001b[0;36mwrapup_phase\u001b[0;34m(ns, opt, environ, label)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0mprint_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"[Final] ep:{ns.current_epoch}  it:{ns.current_iter}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_trained_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_trained_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m     \u001b[0mprint_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" save {label} val_metrics to :  {ns.model_label}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0mprint_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" save {label} checkpoint  to :  {ns.model_label}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WSL-projs/AdaSparseChem/notebooks/../src/envs/base_env.py\u001b[0m in \u001b[0;36mdisplay_trained_logits\u001b[0;34m(self, epoch, out)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mln\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\" epch: {epoch:3d}   logits       s          logits      s         logits       s\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mln\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\" -----  ----------------- -    ----------------  -    ----------------  - \\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         for idx, (l1,l2,l3,  p1,p2,p3) in enumerate(zip(logits[0], logits[1], logits[2], \n\u001b[0m\u001b[1;32m    293\u001b[0m                                                         logits_argmaxs[0], logits_argmaxs[1], logits_argmaxs[2]),1):\n\u001b[1;32m    294\u001b[0m             \u001b[0mln\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"{idx:4d}  {l1[0]:8.4f}  {l1[1]:8.4f}  {p1:1d}  {l2[0]:8.4f}  {l2[1]:8.4f}  {p2:1d}  {l3[0]:8.4f}  {l3[1]:8.4f}  {p3:1d}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# warmup_phase(ns,opt, environ, dldrs, epochs = 25)\n",
    "warmup_phase(ns,opt, environ, dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "21d94990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:45:27.230363Z",
     "start_time": "2022-04-02T13:45:27.161652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['yc_ind', 'yc_data', 'yc_hat', 'yc_aggr_weights'])\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 11 12 13 14 15 16 17 18 19 20 20 21 22 23 23 24 25 26 27 28 29 30 31 32 33 34 35 36]\n",
      "[50 28  6 50 62 28 50 50  6 50 50 53 76 50  0 50 50  6  0  6 50 53 76  0 10 45 52 28 10 50 28 50 71 55  0 71  6 50 38 38]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[ 5.70437     4.990391    4.3287272   5.445829    2.4678407   5.8073773   6.275769    6.7793107   2.1642404   5.247794    5.058744   -2.703812\n",
      "  2.0684931   5.310354    5.5971427   6.154443    5.8311005   0.01745471  5.625531    3.347758    5.379189   -3.6483507   1.9944686  12.822014\n",
      "  3.6128433   1.616868    1.422966    4.418747    3.780817    6.8150287   5.8084474   6.3284893   3.542095   -4.6277356  14.590454    2.8610904\n",
      "  1.4714723   5.6356153   3.6492748   5.145975  ]\n"
     ]
    }
   ],
   "source": [
    "# environ.display_trained_policy(ns.current_epoch,out=[sys.stdout])\n",
    "# environ.num_tasks\n",
    "# print(environ.get_policy_prob().shape)\n",
    "print(environ.val_data['task1'].keys())\n",
    "print(environ.val_data['task1']['yc_ind'][0][:40])\n",
    "print(environ.val_data['task1']['yc_ind'][1][:40])\n",
    "print(environ.val_data['task1']['yc_data'][:40])\n",
    "print(environ.val_data['task1']['yc_hat'][:40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8d282759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:31:53.440981Z",
     "start_time": "2022-04-02T13:31:53.291595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classification': {'_type': 'table-file', 'path': 'media/table/classification_303_06f949eef1c3e2770223.table.json', 'sha256': '06f949eef1c3e2770223ac877bb7bbf4138285b078998733776f70df690c26b7', 'size': 5492, 'artifact_path': 'wandb-client-artifact://it72gol71w4zwp58zxle9snz98k2ywxtf4qndvd2bxwxzkjcfdkssn3nfc1g1uj7sxv1my7vndse2cmmugf9qywm4gq9go3d9t22hhx8fqprfjbca0854vzrjelq6rz9/classification.table.json', '_latest_artifact_path': 'wandb-client-artifact://xfq7c1c8syngcvo0o8w9th5qieyu6fgvajvmb5ra9ug3svw3c08yd17k48o0hazadypv7zncp071os8qeenbvy9ntm0qlwmmtb7c7ittqt0dqbydnk4dt19unzon6uto:latest/classification.table.json', 'ncols': 9, 'nrows': 100}, 'classification_agg': {'roc_auc_score': nan, 'auc_pr': nan, 'avg_prec_score': nan, 'f1_max': nan, 'p_f1_max': nan, 'kappa': nan, 'kappa_max': nan, 'p_kappa_max': nan, 'bceloss': nan, 'sc_loss': 0.00823010015592516, 'logloss': 6.0260329519753785e-05}}\n",
      "4170.0\n",
      "4507\n",
      "4507\n",
      "4507\n"
     ]
    }
   ],
   "source": [
    "print(environ.val_metrics['task1'])\n",
    "print((environ.val_data['task1']['yc_data']).sum())\n",
    "print(len(environ.val_data['task1']['yc_ind'][1]))\n",
    "print(len(environ.val_data['task1']['yc_data']))\n",
    "print(len(environ.val_data['task1']['yc_hat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "23a55df5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:31:55.581510Z",
     "start_time": "2022-04-02T13:31:55.526855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(environ.val_data['task1']['yc_data'][0] == environ.val_data['task1']['yc_data']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "75b168d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:20:55.327255Z",
     "start_time": "2022-04-02T14:20:55.026238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [task is       task  y_true    y_score\n",
      "14       0     1.0   5.597143\n",
      "18       0     1.0   5.625531\n",
      "23       0     1.0  12.822014\n",
      "34       0     1.0  14.590454\n",
      "48       0     1.0   6.488068\n",
      "...    ...     ...        ...\n",
      "4470     0     1.0  10.922712\n",
      "4473     0     1.0  13.666399\n",
      "4475     0     1.0  12.766981\n",
      "4483     0     1.0  12.470244\n",
      "4502     0     1.0  13.195760\n",
      "\n",
      "[318 rows x 3 columns]]\n",
      " [task is       task  y_true   y_score\n",
      "893      3     1.0  5.705761\n",
      "1315     3     1.0  6.690732\n",
      "1382     3     1.0  7.397319\n",
      "2311     3     1.0  9.090773\n",
      "2364     3     1.0  4.605497\n",
      "2441     3     1.0  6.213061\n",
      "2458     3     1.0  6.602612\n",
      "2548     3     1.0  6.541490\n",
      "2625     3     1.0  6.570337\n",
      "2952     3     1.0  8.752759\n",
      "3413     3     1.0  5.917402\n",
      "3463     3     1.0  5.819000\n",
      "3705     3     1.0  4.716419\n",
      "3730     3     1.0  7.974041\n",
      "3768     3     1.0  9.193141\n",
      "4284     3     1.0  8.716344]\n",
      " [task is       task  y_true   y_score\n",
      "2        6     1.0  4.328727\n",
      "8        6     1.0  2.164240\n",
      "17       6     1.0  0.017455\n",
      "19       6     1.0  3.347758\n",
      "36       6     1.0  1.471472\n",
      "...    ...     ...       ...\n",
      "4484     6     1.0  3.097137\n",
      "4485     6     1.0  0.730731\n",
      "4490     6     1.0 -0.336954\n",
      "4491     6     1.0  3.395676\n",
      "4498     6     1.0 -0.164987\n",
      "\n",
      "[656 rows x 3 columns]]\n",
      " [task is       task  y_true   y_score\n",
      "24      10     1.0  3.612843\n",
      "28      10     1.0  3.780817\n",
      "43      10     1.0  2.525036\n",
      "54      10     1.0  4.478582\n",
      "55      10     1.0  3.253286\n",
      "...    ...     ...       ...\n",
      "4446    10     1.0  3.604181\n",
      "4449    10     1.0  3.249227\n",
      "4489    10     1.0  2.853686\n",
      "4495    10     1.0  3.210963\n",
      "4496    10     1.0  3.637440\n",
      "\n",
      "[401 rows x 3 columns]]\n",
      " [task is       task  y_true   y_score\n",
      "207     22     1.0 -1.913030\n",
      "834     22     1.0 -1.415941\n",
      "867     22     1.0 -1.857236\n",
      "1168    22     1.0 -3.875910\n",
      "1268    22     1.0 -2.437869\n",
      "1643    22     1.0 -3.082006\n",
      "1822    22     1.0 -1.518179\n",
      "2000    22     1.0 -3.752945\n",
      "2144    22     1.0 -2.319946\n",
      "2227    22     1.0 -3.376478\n",
      "2274    22     1.0 -1.795733\n",
      "2371    22     1.0 -3.403508\n",
      "2626    22     1.0 -2.038337\n",
      "3439    22     1.0 -2.586216\n",
      "3567    22     1.0 -2.023433\n",
      "4226    22     1.0 -3.138940]\n",
      " [task is       task  y_true    y_score\n",
      "1       28     1.0   4.990391\n",
      "5       28     1.0   5.807377\n",
      "27      28     1.0   4.418747\n",
      "30      28     1.0   5.808447\n",
      "42      28     1.0   5.785405\n",
      "...    ...     ...        ...\n",
      "4486    28     1.0   5.120580\n",
      "4492    28     1.0  10.621143\n",
      "4499    28     1.0   9.247607\n",
      "4500    28     1.0   5.780535\n",
      "4501    28     1.0   7.176177\n",
      "\n",
      "[569 rows x 3 columns]]\n",
      " [task is       task  y_true   y_score\n",
      "38      38     1.0  3.649275\n",
      "39      38     1.0  5.145975\n",
      "41      38     1.0  5.309868\n",
      "56      38     1.0  4.734281\n",
      "82      38     1.0  5.628111\n",
      "...    ...     ...       ...\n",
      "4452    38     1.0  4.493577\n",
      "4454    38     1.0  5.434719\n",
      "4459    38     1.0  3.070567\n",
      "4474    38     1.0  4.343500\n",
      "4497    38     1.0  5.337717\n",
      "\n",
      "[392 rows x 3 columns]]\n",
      " [task is       task  y_true   y_score\n",
      "25      45     1.0  1.616868\n",
      "106     45     1.0  1.976464\n",
      "391     45     1.0  1.821831\n",
      "411     45     1.0  1.642702\n",
      "569     45     1.0  1.537865\n",
      "...    ...     ...       ...\n",
      "4175    45     1.0  1.790347\n",
      "4212    45     1.0  2.201289\n",
      "4221    45     1.0  1.792394\n",
      "4481    45     1.0  1.846876\n",
      "4505    45     1.0  2.198826\n",
      "\n",
      "[66 rows x 3 columns]]\n",
      " [task is       task  y_true   y_score\n",
      "64      47     1.0 -0.064374\n",
      "292     47     1.0  1.959596\n",
      "329     47     1.0  0.038840\n",
      "340     47     1.0  0.665554\n",
      "344     47     1.0  0.239510\n",
      "645     47     1.0  1.457622\n",
      "948     47     1.0  0.392184\n",
      "956     47     1.0  0.231047\n",
      "992     47     1.0 -0.370126\n",
      "1270    47     1.0 -0.064374\n",
      "1324    47     1.0  1.692844\n",
      "1426    47     1.0  0.731340\n",
      "1539    47     1.0 -0.150518\n",
      "1592    47     1.0  0.577222\n",
      "1678    47     1.0  0.315438\n",
      "1828    47     1.0 -0.031724\n",
      "1840    47     1.0  0.829619\n",
      "1899    47     1.0  1.552252\n",
      "2111    47     1.0 -0.050204\n",
      "2164    47     1.0 -0.350070\n",
      "2321    47     1.0  0.455003\n",
      "2439    47     1.0  0.215053\n",
      "2550    47     1.0 -0.443491\n",
      "2921    47     1.0  0.201255\n",
      "2986    47     1.0  0.228516\n",
      "3178    47     1.0  0.275073\n",
      "3180    47     1.0  1.037046\n",
      "3282    47     1.0 -0.285253\n",
      "3412    47     1.0  0.146528\n",
      "3445    47     1.0 -0.089862\n",
      "3564    47     1.0 -0.381970\n",
      "3781    47     1.0  0.136376\n",
      "3845    47     1.0  0.044166\n",
      "3915    47     1.0  0.373618\n",
      "3923    47     1.0  1.124196\n",
      "4392    47     1.0 -0.843895]\n",
      " [task is       task  y_true   y_score\n",
      "0       50     1.0  5.704370\n",
      "3       50     1.0  5.445829\n",
      "6       50     1.0  6.275769\n",
      "7       50     1.0  6.779311\n",
      "9       50     1.0  5.247794\n",
      "...    ...     ...       ...\n",
      "4464    50     1.0  4.786297\n",
      "4467    50     1.0  6.089084\n",
      "4488    50     1.0  5.729190\n",
      "4493    50     1.0  6.106776\n",
      "4504    50     1.0  7.440650\n",
      "\n",
      "[943 rows x 3 columns]]\n",
      " [task is       task  y_true   y_score\n",
      "26      52     0.0  1.422966\n",
      "107     52     1.0  1.443249\n",
      "392     52     0.0  0.328956\n",
      "412     52     0.0  1.140198\n",
      "570     52     0.0  0.666191\n",
      "...    ...     ...       ...\n",
      "4176    52     0.0  0.528904\n",
      "4213    52     1.0 -0.096205\n",
      "4222    52     0.0  0.111998\n",
      "4482    52     0.0  2.010538\n",
      "4506    52     0.0  0.025763\n",
      "\n",
      "[66 rows x 3 columns]]\n",
      " [task is       task  y_true   y_score\n",
      "11      53     0.0 -2.703812\n",
      "21      53     0.0 -3.648351\n",
      "50      53     1.0 -3.760930\n",
      "72      53     0.0 -3.349384\n",
      "89      53     0.0 -4.108949\n",
      "...    ...     ...       ...\n",
      "4461    53     0.0 -4.266840\n",
      "4465    53     0.0 -5.050652\n",
      "4471    53     0.0 -4.555850\n",
      "4477    53     0.0 -4.582585\n",
      "4479    53     0.0 -4.022981\n",
      "\n",
      "[222 rows x 3 columns]]\n",
      " [task is       task  y_true   y_score\n",
      "33      55     1.0 -4.627736\n",
      "63      55     1.0 -4.063807\n",
      "83      55     0.0 -3.334249\n",
      "85      55     0.0 -3.533749\n",
      "93      55     0.0 -3.768533\n",
      "...    ...     ...       ...\n",
      "4430    55     0.0 -2.905076\n",
      "4445    55     1.0 -3.090491\n",
      "4447    55     1.0 -3.271445\n",
      "4455    55     0.0 -3.055339\n",
      "4476    55     1.0 -3.653259\n",
      "\n",
      "[208 rows x 3 columns]]\n",
      " [task is       task  y_true   y_score\n",
      "4       62     1.0  2.467841\n",
      "149     62     1.0  2.547959\n",
      "160     62     1.0  2.184751\n",
      "169     62     1.0  2.489848\n",
      "245     62     1.0  2.754905\n",
      "290     62     1.0  2.742797\n",
      "416     62     1.0  2.269622\n",
      "428     62     1.0  2.986905\n",
      "447     62     1.0  2.523392\n",
      "469     62     1.0  2.048451\n",
      "543     62     1.0  3.723209\n",
      "792     62     1.0  2.349208\n",
      "826     62     1.0  2.239576\n",
      "873     62     1.0  2.746202\n",
      "918     62     1.0  2.084995\n",
      "974     62     1.0  2.322423\n",
      "997     62     1.0  2.802052\n",
      "1002    62     1.0  2.339142\n",
      "1042    62     1.0  2.446967\n",
      "1175    62     1.0  3.062562\n",
      "1242    62     1.0  2.510443\n",
      "1512    62     1.0  2.607582\n",
      "1523    62     1.0  2.692894\n",
      "1902    62     1.0  2.961499\n",
      "2043    62     1.0  2.223506\n",
      "2056    62     1.0  3.229435\n",
      "2614    62     1.0  2.643672\n",
      "2748    62     1.0  2.961633\n",
      "2908    62     1.0  2.369488\n",
      "2909    62     1.0  2.282293\n",
      "2917    62     1.0  2.330168\n",
      "2951    62     1.0  1.957431\n",
      "2974    62     1.0  2.229758\n",
      "3048    62     1.0  2.277138\n",
      "3083    62     1.0  2.668720\n",
      "3106    62     1.0  2.646745\n",
      "3116    62     1.0  2.614855\n",
      "3130    62     1.0  2.721765\n",
      "3133    62     1.0  2.561265\n",
      "3146    62     1.0  1.957424\n",
      "3294    62     1.0  2.580565\n",
      "3451    62     1.0  1.942935\n",
      "3543    62     1.0  1.691319\n",
      "3760    62     1.0  2.704839\n",
      "3791    62     1.0  2.514860\n",
      "3835    62     1.0  2.021663\n",
      "3901    62     1.0  2.789785\n",
      "3920    62     1.0  2.843198\n",
      "3945    62     1.0  2.722281\n",
      "4128    62     1.0  3.234183\n",
      "4195    62     1.0  2.873601\n",
      "4211    62     1.0  2.462086\n",
      "4306    62     1.0  2.584171\n",
      "4494    62     1.0  2.578659]\n",
      " [task is       task  y_true   y_score\n",
      "474     68     1.0  6.894630\n",
      "517     68     1.0  4.909050\n",
      "1309    68     1.0  7.747762\n",
      "1365    68     1.0  6.770548\n",
      "1435    68     1.0  6.719142\n",
      "1635    68     1.0  6.491697\n",
      "2653    68     1.0  3.373842\n",
      "2836    68     1.0  6.150122\n",
      "2914    68     1.0  7.326953\n",
      "3111    68     1.0  6.970116\n",
      "3526    68     1.0  8.508581\n",
      "4042    68     1.0  7.055281]\n",
      " [task is       task  y_true   y_score\n",
      "32      71     1.0  3.542095\n",
      "35      71     1.0  2.861090\n",
      "60      71     1.0  4.334939\n",
      "61      71     1.0  3.936629\n",
      "75      71     1.0  3.913762\n",
      "...    ...     ...       ...\n",
      "4366    71     1.0  4.540621\n",
      "4404    71     1.0  4.696834\n",
      "4439    71     1.0  4.622665\n",
      "4487    71     1.0  2.581047\n",
      "4503    71     1.0  4.803043\n",
      "\n",
      "[267 rows x 3 columns]]\n",
      " [task is       task  y_true   y_score\n",
      "1549    72     0.0 -4.761949]\n",
      " len(y_true) : 1 <= 1 or   (y_true[0] == y_true).all() = True\n",
      " [task is       task  y_true   y_score\n",
      "12      76     1.0  2.068493\n",
      "22      76     1.0  1.994469\n",
      "51      76     1.0  2.804951\n",
      "73      76     1.0  2.098541\n",
      "90      76     1.0  2.344858\n",
      "...    ...     ...       ...\n",
      "4462    76     1.0  2.710233\n",
      "4466    76     1.0  3.430464\n",
      "4472    76     1.0  3.264653\n",
      "4478    76     1.0  3.086493\n",
      "4480    76     1.0  2.494192\n",
      "\n",
      "[222 rows x 3 columns]]\n",
      " [task is       task  y_true   y_score\n",
      "2940    82     0.0 -1.321465]\n",
      " len(y_true) : 1 <= 1 or   (y_true[0] == y_true).all() = True\n",
      " [task is       task  y_true   y_score\n",
      "165     84     1.0  2.155682\n",
      "212     84     1.0  2.407773\n",
      "364     84     1.0  2.577271\n",
      "952     84     1.0  2.392301\n",
      "1199    84     1.0  1.641989\n",
      "1255    84     1.0  2.499376\n",
      "1264    84     1.0  2.160800\n",
      "1421    84     1.0  1.054517\n",
      "1477    84     1.0  1.208343\n",
      "1481    84     1.0  2.286361\n",
      "1577    84     1.0  1.154782\n",
      "1807    84     1.0  2.337575\n",
      "2109    84     1.0  1.310973\n",
      "2384    84     1.0  2.403760\n",
      "2566    84     1.0  2.040709\n",
      "2762    84     1.0  3.191659\n",
      "2805    84     1.0  1.208554\n",
      "2853    84     1.0  2.349583\n",
      "2987    84     1.0  2.478069\n",
      "2991    84     1.0  1.115319\n",
      "3027    84     1.0  1.043471\n",
      "3149    84     1.0  1.269087\n",
      "3706    84     1.0  1.287372\n",
      "3946    84     1.0  2.619840\n",
      "4340    84     1.0  0.906477]\n",
      " [task is       task  y_true   y_score\n",
      "208     96     1.0  1.247626\n",
      "318     96     1.0  1.869833\n",
      "614     96     1.0  1.604757\n",
      "909     96     1.0  1.421189\n",
      "1889    96     1.0  1.564591\n",
      "2101    96     1.0  1.034542\n",
      "2127    96     1.0  1.497459\n",
      "2673    96     1.0  1.273252\n",
      "2686    96     1.0  1.105160\n",
      "2938    96     1.0  1.545542\n",
      "3368    96     1.0  1.344751\n",
      "3909    96     1.0  1.564739\n",
      "4232    96     1.0  1.622726\n",
      "4436    96     1.0  1.489715]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [task is      task  y_true   y_score\n",
      "373    99     0.0 -2.167241\n",
      "712    99     0.0 -2.095917]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    }
   ],
   "source": [
    "from utils.sparsechem_utils import compute_metrics, aggregate_results\n",
    "import pandas\n",
    "cc = compute_metrics(cols   = environ.val_data['task1']['yc_ind'][1], \n",
    "                     y_true = environ.val_data['task1']['yc_data'], \n",
    "                     y_score= environ.val_data['task1']['yc_hat'] ,\n",
    "                     num_tasks=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8590312d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:34:57.196163Z",
     "start_time": "2022-04-02T13:34:57.130013Z"
    }
   },
   "outputs": [],
   "source": [
    " df   = pd.DataFrame({\"task\"   : environ.val_data['task1']['yc_ind'][1], \n",
    "                      \"y_true\" : environ.val_data['task1']['yc_data'],  \n",
    "                      \"y_score\": environ.val_data['task1']['yc_hat']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e3874b30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:44:52.754320Z",
     "start_time": "2022-04-02T13:44:52.611945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " task 0\n",
      "    task  y_true    y_score\n",
      "14     0     1.0   5.597143\n",
      "18     0     1.0   5.625531\n",
      "23     0     1.0  12.822014\n",
      "34     0     1.0  14.590454\n",
      "48     0     1.0   6.488068\n",
      "62     0     1.0  13.065102\n",
      "67     0     1.0   3.847331\n",
      "68     0     1.0   6.939640\n",
      "69     0     1.0  13.071250\n",
      "77     0     1.0  13.010993\n",
      " task 3\n",
      "      task  y_true   y_score\n",
      "893      3     1.0  5.705761\n",
      "1315     3     1.0  6.690732\n",
      "1382     3     1.0  7.397319\n",
      "2311     3     1.0  9.090773\n",
      "2364     3     1.0  4.605497\n",
      "2441     3     1.0  6.213061\n",
      "2458     3     1.0  6.602612\n",
      "2548     3     1.0  6.541490\n",
      "2625     3     1.0  6.570337\n",
      "2952     3     1.0  8.752759\n",
      " task 6\n",
      "    task  y_true   y_score\n",
      "2      6     1.0  4.328727\n",
      "8      6     1.0  2.164240\n",
      "17     6     1.0  0.017455\n",
      "19     6     1.0  3.347758\n",
      "36     6     1.0  1.471472\n",
      "40     6     1.0  3.464773\n",
      "47     6     1.0  4.258944\n",
      "49     6     1.0  3.673662\n",
      "52     6     1.0  0.113874\n",
      "57     6     1.0 -0.642786\n",
      " task 10\n",
      "     task  y_true   y_score\n",
      "24     10     1.0  3.612843\n",
      "28     10     1.0  3.780817\n",
      "43     10     1.0  2.525036\n",
      "54     10     1.0  4.478582\n",
      "55     10     1.0  3.253286\n",
      "70     10     1.0  4.204772\n",
      "102    10     1.0  2.871986\n",
      "105    10     1.0  2.148204\n",
      "110    10     1.0  3.400303\n",
      "119    10     1.0  3.451682\n",
      " task 22\n",
      "      task  y_true   y_score\n",
      "207     22     1.0 -1.913030\n",
      "834     22     1.0 -1.415941\n",
      "867     22     1.0 -1.857236\n",
      "1168    22     1.0 -3.875910\n",
      "1268    22     1.0 -2.437869\n",
      "1643    22     1.0 -3.082006\n",
      "1822    22     1.0 -1.518179\n",
      "2000    22     1.0 -3.752945\n",
      "2144    22     1.0 -2.319946\n",
      "2227    22     1.0 -3.376478\n",
      " task 28\n",
      "    task  y_true   y_score\n",
      "1     28     1.0  4.990391\n",
      "5     28     1.0  5.807377\n",
      "27    28     1.0  4.418747\n",
      "30    28     1.0  5.808447\n",
      "42    28     1.0  5.785405\n",
      "44    28     1.0  7.395255\n",
      "53    28     1.0  9.902944\n",
      "58    28     1.0  6.185909\n",
      "65    28     1.0  4.932642\n",
      "74    28     1.0  4.690283\n",
      " task 38\n",
      "     task  y_true   y_score\n",
      "38     38     1.0  3.649275\n",
      "39     38     1.0  5.145975\n",
      "41     38     1.0  5.309868\n",
      "56     38     1.0  4.734281\n",
      "82     38     1.0  5.628111\n",
      "84     38     1.0  6.432337\n",
      "92     38     1.0  6.089152\n",
      "114    38     0.0  7.593419\n",
      "120    38     1.0  8.033896\n",
      "125    38     1.0  3.119194\n",
      " task 45\n",
      "     task  y_true   y_score\n",
      "25     45     1.0  1.616868\n",
      "106    45     1.0  1.976464\n",
      "391    45     1.0  1.821831\n",
      "411    45     1.0  1.642702\n",
      "569    45     1.0  1.537865\n",
      "590    45     1.0  2.486867\n",
      "683    45     1.0  2.167043\n",
      "779    45     1.0  2.133227\n",
      "819    45     1.0  1.069390\n",
      "933    45     1.0  1.709337\n",
      " task 47\n",
      "      task  y_true   y_score\n",
      "64      47     1.0 -0.064374\n",
      "292     47     1.0  1.959596\n",
      "329     47     1.0  0.038840\n",
      "340     47     1.0  0.665554\n",
      "344     47     1.0  0.239510\n",
      "645     47     1.0  1.457622\n",
      "948     47     1.0  0.392184\n",
      "956     47     1.0  0.231047\n",
      "992     47     1.0 -0.370126\n",
      "1270    47     1.0 -0.064374\n",
      " task 50\n",
      "    task  y_true   y_score\n",
      "0     50     1.0  5.704370\n",
      "3     50     1.0  5.445829\n",
      "6     50     1.0  6.275769\n",
      "7     50     1.0  6.779311\n",
      "9     50     1.0  5.247794\n",
      "10    50     1.0  5.058744\n",
      "13    50     1.0  5.310354\n",
      "15    50     1.0  6.154443\n",
      "16    50     1.0  5.831100\n",
      "20    50     1.0  5.379189\n",
      " task 52\n",
      "     task  y_true   y_score\n",
      "26     52     0.0  1.422966\n",
      "107    52     1.0  1.443249\n",
      "392    52     0.0  0.328956\n",
      "412    52     0.0  1.140198\n",
      "570    52     0.0  0.666191\n",
      "591    52     0.0 -0.060250\n",
      "684    52     1.0  0.332110\n",
      "780    52     0.0  0.761510\n",
      "820    52     0.0  1.044076\n",
      "934    52     1.0  0.564946\n",
      " task 53\n",
      "     task  y_true   y_score\n",
      "11     53     0.0 -2.703812\n",
      "21     53     0.0 -3.648351\n",
      "50     53     1.0 -3.760930\n",
      "72     53     0.0 -3.349384\n",
      "89     53     0.0 -4.108949\n",
      "97     53     0.0 -3.741627\n",
      "150    53     0.0 -2.679311\n",
      "209    53     0.0 -3.344077\n",
      "227    53     0.0 -4.618840\n",
      "235    53     0.0 -3.009869\n",
      " task 55\n",
      "     task  y_true   y_score\n",
      "33     55     1.0 -4.627736\n",
      "63     55     1.0 -4.063807\n",
      "83     55     0.0 -3.334249\n",
      "85     55     0.0 -3.533749\n",
      "93     55     0.0 -3.768533\n",
      "99     55     1.0 -5.661200\n",
      "115    55     1.0 -3.948116\n",
      "136    55     0.0 -3.595448\n",
      "164    55     1.0 -4.561674\n",
      "167    55     0.0 -2.425200\n",
      " task 62\n",
      "     task  y_true   y_score\n",
      "4      62     1.0  2.467841\n",
      "149    62     1.0  2.547959\n",
      "160    62     1.0  2.184751\n",
      "169    62     1.0  2.489848\n",
      "245    62     1.0  2.754905\n",
      "290    62     1.0  2.742797\n",
      "416    62     1.0  2.269622\n",
      "428    62     1.0  2.986905\n",
      "447    62     1.0  2.523392\n",
      "469    62     1.0  2.048451\n",
      " task 68\n",
      "      task  y_true   y_score\n",
      "474     68     1.0  6.894630\n",
      "517     68     1.0  4.909050\n",
      "1309    68     1.0  7.747762\n",
      "1365    68     1.0  6.770548\n",
      "1435    68     1.0  6.719142\n",
      "1635    68     1.0  6.491697\n",
      "2653    68     1.0  3.373842\n",
      "2836    68     1.0  6.150122\n",
      "2914    68     1.0  7.326953\n",
      "3111    68     1.0  6.970116\n",
      " task 71\n",
      "     task  y_true   y_score\n",
      "32     71     1.0  3.542095\n",
      "35     71     1.0  2.861090\n",
      "60     71     1.0  4.334939\n",
      "61     71     1.0  3.936629\n",
      "75     71     1.0  3.913762\n",
      "91     71     1.0  3.628667\n",
      "94     71     1.0  4.878995\n",
      "101    71     1.0  3.613529\n",
      "124    71     1.0  4.571155\n",
      "131    71     1.0  3.504508\n",
      " task 72\n",
      "      task  y_true   y_score\n",
      "1549    72     0.0 -4.761949\n",
      " task 76\n",
      "     task  y_true   y_score\n",
      "12     76     1.0  2.068493\n",
      "22     76     1.0  1.994469\n",
      "51     76     1.0  2.804951\n",
      "73     76     1.0  2.098541\n",
      "90     76     1.0  2.344858\n",
      "98     76     1.0  2.421362\n",
      "151    76     1.0  1.912609\n",
      "210    76     1.0  2.058251\n",
      "228    76     1.0  3.255492\n",
      "236    76     1.0  2.100544\n",
      " task 82\n",
      "      task  y_true   y_score\n",
      "2940    82     0.0 -1.321465\n",
      " task 84\n",
      "      task  y_true   y_score\n",
      "165     84     1.0  2.155682\n",
      "212     84     1.0  2.407773\n",
      "364     84     1.0  2.577271\n",
      "952     84     1.0  2.392301\n",
      "1199    84     1.0  1.641989\n",
      "1255    84     1.0  2.499376\n",
      "1264    84     1.0  2.160800\n",
      "1421    84     1.0  1.054517\n",
      "1477    84     1.0  1.208343\n",
      "1481    84     1.0  2.286361\n",
      " task 96\n",
      "      task  y_true   y_score\n",
      "208     96     1.0  1.247626\n",
      "318     96     1.0  1.869833\n",
      "614     96     1.0  1.604757\n",
      "909     96     1.0  1.421189\n",
      "1889    96     1.0  1.564591\n",
      "2101    96     1.0  1.034542\n",
      "2127    96     1.0  1.497459\n",
      "2673    96     1.0  1.273252\n",
      "2686    96     1.0  1.105160\n",
      "2938    96     1.0  1.545542\n",
      " task 99\n",
      "     task  y_true   y_score\n",
      "373    99     0.0 -2.167241\n",
      "712    99     0.0 -2.095917\n"
     ]
    }
   ],
   "source": [
    "for task, frame in df.groupby(\"task\", sort=True):\n",
    "    print(f\" task {task}\")\n",
    "    print(frame.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "768dcd39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:46:29.715440Z",
     "start_time": "2022-04-02T13:46:29.640674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>656</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>401</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>569</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>943</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>267</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_true  y_score\n",
       "task                 \n",
       "0        318      318\n",
       "3         16       16\n",
       "6        656      656\n",
       "10       401      401\n",
       "22        16       16\n",
       "28       569      569\n",
       "38       392      392\n",
       "45        66       66\n",
       "47        36       36\n",
       "50       943      943\n",
       "52        66       66\n",
       "53       222      222\n",
       "55       208      208\n",
       "62        54       54\n",
       "68        12       12\n",
       "71       267      267\n",
       "72         1        1\n",
       "76       222      222\n",
       "82         1        1\n",
       "84        25       25\n",
       "96        14       14\n",
       "99         2        2"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df\n",
    "df.groupby(\"task\", sort=True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4eeed797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:57:12.585754Z",
     "start_time": "2022-04-02T13:57:12.502583Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>avg_prec_score</th>\n",
       "      <th>f1_max</th>\n",
       "      <th>p_f1_max</th>\n",
       "      <th>kappa</th>\n",
       "      <th>kappa_max</th>\n",
       "      <th>p_kappa_max</th>\n",
       "      <th>bceloss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.002298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.737796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.946335</td>\n",
       "      <td>0.215865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250506</td>\n",
       "      <td>0.112183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      roc_auc_score  auc_pr  avg_prec_score  f1_max  p_f1_max  kappa  kappa_max  p_kappa_max   bceloss\n",
       "task                                                                                                  \n",
       "0               NaN     1.0             1.0     1.0  0.962070    NaN        0.0     1.000000  0.001196\n",
       "1               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN       NaN\n",
       "2               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN       NaN\n",
       "3               NaN     1.0             1.0     1.0  0.990102    NaN        0.0     0.999963  0.002298\n",
       "4               NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN       NaN\n",
       "...             ...     ...             ...     ...       ...    ...        ...          ...       ...\n",
       "95              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN       NaN\n",
       "96              NaN     1.0             1.0     1.0  0.737796    NaN        0.0     0.946335  0.215865\n",
       "97              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN       NaN\n",
       "98              NaN     NaN             NaN     NaN       NaN    NaN        NaN          NaN       NaN\n",
       "99              NaN     NaN             NaN     0.0  0.109494    NaN        0.0     0.250506  0.112183\n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "51eb01b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:26:58.189057Z",
     "start_time": "2022-04-02T14:26:58.126134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(environ.batch_data['task1']['yc_aggr_weights'])\n",
    "environ.batch['task1']['aggr_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = aggregate_results(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9589f8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T15:00:56.621023Z",
     "start_time": "2022-04-02T15:00:56.539683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[namespace(training_weight=tensor([1., 1., 1., 1., 1.]),\n",
       "           aggregation_weight=array([1., 1., 1., 1., 1.]),\n",
       "           task_type=None,\n",
       "           censored_weight=tensor([])),\n",
       " namespace(training_weight=tensor([1., 1., 1., 1., 1.]),\n",
       "           aggregation_weight=array([1., 1., 1., 1., 1.]),\n",
       "           task_type=None,\n",
       "           censored_weight=tensor([])),\n",
       " namespace(training_weight=tensor([1., 1., 1., 1., 1.]),\n",
       "           aggregation_weight=array([1., 1., 1., 1., 1.]),\n",
       "           task_type=None,\n",
       "           censored_weight=tensor([]))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dldrs.trainset0.tasks_weights_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05b99542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T12:40:01.166081Z",
     "start_time": "2022-04-02T12:40:01.048231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warmup_phase(ns,opt, environ, dldrs, epochs = 25)\n",
    "ns.best_epoch, ns.best_iter, ns.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a3dc43cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:32:00.484067Z",
     "start_time": "2022-04-02T14:31:56.371878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a2d2087f0a4bf0ac59b23f25501ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='7.795 MB of 7.795 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_time</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>152</td></tr><tr><td>train_time</td><td>4.03822</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0402_1417_noplcy</strong>: <a href=\"http://localhost:8080/kbardool/AdaSparseChem/runs/zsuu90b0\" target=\"_blank\">http://localhost:8080/kbardool/AdaSparseChem/runs/zsuu90b0</a><br/>Synced 7 W&B file(s), 152 media file(s), 189 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220402_141721-zsuu90b0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Upgrade to the 0.9.50 version of W&B Local to get the latest features. Learn more: <a href=\"https://wandb.me/local-upgrade\" target=\"_blank\">https://wandb.me/local-upgrade</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ns.wandb_run.finish()\n",
    "\n",
    "ns.wandb_run.finish()\n",
    "\n",
    "# environ.losses\n",
    "\n",
    "# environ.val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea84c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04d238e8",
   "metadata": {},
   "source": [
    "#### display parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e75ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:47.732297Z",
     "start_time": "2022-03-28T04:02:47.639607Z"
    }
   },
   "outputs": [],
   "source": [
    "print( f\" Backbone Initial LR         : {environ.opt['train']['backbone_lr']:4f}      current LR : {environ.optimizers['alphas'].param_groups[0]['lr']} \\n\"\n",
    "       f\" Tasks    Initial LR         : {environ.opt['train']['task_lr']:4f}      current LR : {environ.optimizers['weights'].param_groups[0]['lr']}    \\n\"\n",
    "       f\" Policy   Initial LR         : {environ.opt['train']['policy_lr']:4f}      current LR : {environ.optimizers['weights'].param_groups[1]['lr']}  \\n\")\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db34fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:47.803657Z",
     "start_time": "2022-03-28T04:02:47.736497Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['policy_lr'] = 0.01\n",
    "# opt['train']['policy_lr']         = 0.01\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.1\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# environ.opt['train']['decay_temp_freq'] = 2\n",
    "# print(environ.optimizers['alphas'].param_groups)\n",
    "# print(environ.optimizers['weights'].param_groups)\n",
    "# print('current lr: ', environ.optimizers['alphas'].param_groups[0]['lr'],)\n",
    "# print('current lr: ', environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "# print('current lr: ', environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49645c",
   "metadata": {},
   "source": [
    "## Weight & Policy Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aade16",
   "metadata": {},
   "source": [
    "### Weight/Policy Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe24a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:47.867009Z",
     "start_time": "2022-03-28T04:02:47.807720Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.flag_warmup = True\n",
    "# num_train_layers = None \n",
    "# environ.opt['is_curriculum'] = True\n",
    "# environ.opt['curriculum_speed'] = 4\n",
    "# ns.num_train_layers = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365996be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:47.944530Z",
     "start_time": "2022-03-28T04:02:47.871259Z"
    }
   },
   "outputs": [],
   "source": [
    "if ns.flag_warmup:\n",
    "    print_heading( f\"** {timestring()} \\n\"\n",
    "                   f\"** Training epoch: {ns.current_epoch} iter: {ns.current_iter}   flag: {ns.flag} \\n\"\n",
    "                   f\"** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\\n\"\n",
    "                   f\"** Switch from Warm Up training to Alternate training Weights & Policy \\n\"\n",
    "                   f\"** Take checkpoint and block gradient flow through Policy net\", verbose=True)\n",
    "#     environ.define_optimizer(policy_learning=True)\n",
    "#     environ.define_scheduler(policy_learning=True)\n",
    "    ns.flag_warmup = False\n",
    "    ns.flag = 'update_weights'\n",
    "    environ.fix_alpha()\n",
    "    environ.free_weights(opt['fix_BN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc79e10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:48.024063Z",
     "start_time": "2022-03-28T04:02:47.950823Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.training_epochs = 250\n",
    "# environ.display_trained_policy(ns.current_epoch)\n",
    "# environ.display_trained_logits(ns.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d84a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:48.115175Z",
     "start_time": "2022-03-28T04:02:48.028324Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"ns.current_epoch           : {ns.current_epoch}\")\n",
    "print(f\"ns.training_epochs         : {ns.training_epochs} \\n\") \n",
    "print(f\"ns.current_iters           : {ns.current_iter}\")  \n",
    "print(f\"Batches in weight epoch    : {ns.stop_iter_w}\")\n",
    "print(f\"Batches in policy epoch    : {ns.stop_iter_a}\")\n",
    "print(f\"num_train_layers           : {ns.num_train_layers}\")\n",
    "print()\n",
    "print_loss(environ.val_metrics, title = f\"[e] Last ep:{ns.current_epoch}  it:{ns.current_iter}\")\n",
    "print()\n",
    "\n",
    "print_heading(f\" Last Epoch Completed : {ns.current_epoch}       # of epochs to run:  {ns.training_epochs} -->  epochs {ns.current_epoch+1} to {ns.training_epochs + ns.current_epoch}\"\n",
    "              f\"\\n policy_learning rate : {environ.opt['train']['policy_lr']} \"\n",
    "              f\"\\n lambda_sparsity      : {environ.opt['train']['lambda_sparsity']}\"\n",
    "              f\"\\n lambda_sharing       : {environ.opt['train']['lambda_sharing']}\"\n",
    "              f\"\\n curriculum training  : {opt['is_curriculum']}     cirriculum speed: {opt['curriculum_speed']}     num_training_layers : {ns.num_train_layers}\", \n",
    "              verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c71af",
   "metadata": {},
   "source": [
    "### Weight/Policy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ad7d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:27.891351Z",
     "start_time": "2022-03-28T04:02:48.119371Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# weight_policy_training(ns, opt, environ, dldrs, epochs = 100)\n",
    "weight_policy_training(ns, opt, environ, dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27779c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:28.065212Z",
     "start_time": "2022-03-28T05:13:27.897193Z"
    }
   },
   "outputs": [],
   "source": [
    "ns.best_epoch, ns.best_iter, ns.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be1060",
   "metadata": {},
   "source": [
    "### Close WandB run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f6dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.216421Z",
     "start_time": "2022-03-28T05:13:28.068834Z"
    }
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49cc3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.253924Z",
     "start_time": "2022-03-28T05:13:32.221329Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.best_epoch = 0\n",
    "# from utils.notebook_modules import wrapup_phase\n",
    "# wrapup_phase(ns, opt, environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570db82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.307351Z",
     "start_time": "2022-03-28T05:13:32.262822Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['policy_lr']       = 0.002\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.05\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# # environ.opt['train']['decay_temp_freq'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26efa07b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.344678Z",
     "start_time": "2022-03-28T05:13:32.310706Z"
    }
   },
   "outputs": [],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" \n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\\n\") \n",
    "\n",
    "print( f\" current_iters               : {ns.current_iter}   \\n\"\n",
    "       f\" current_epochs              : {ns.current_epoch}  \\n\" \n",
    "       f\" train_total_epochs          : {ns.training_epochs}\\n\" \n",
    "       f\" stop_epoch_training         : {ns.stop_epoch_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3dcb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86ac6b6a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Post Training Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de4040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T22:17:44.833671Z",
     "start_time": "2022-03-13T22:17:44.799394Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "# pp.pprint(environ.val_metrics)\n",
    "environ.num_layers, environ.networks['mtl-net'].num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ca92e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T23:23:43.744498Z",
     "start_time": "2022-03-10T23:23:43.696990Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.val_metrics['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e5cec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T17:44:36.218784Z",
     "start_time": "2022-02-21T17:44:36.063411Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "# environ.display_trained_policy(current_epoch)\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c1c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:32:52.580865Z",
     "start_time": "2022-03-06T00:32:52.554112Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_label   = 'model_train_ep_%d_seed_%04d' % (current_epoch, opt['random_seed'])\n",
    "# metrics_label = 'metrics_train_ep_%d_seed_%04d.pickle' % (current_epoch, opt['random_seed'])\n",
    "# environ.save_checkpoint(model_label, current_iter, current_epoch) \n",
    "# save_to_pickle(environ.val_metrics, environ.opt['paths']['checkpoint_dir'], metrics_label)\n",
    "# print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "# environ.display_trained_policy(current_epoch,out=[sys.stdout, environ.log_file])\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad3a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T22:48:27.014120Z",
     "start_time": "2022-02-20T22:48:26.982535Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_loss(current_iter, environ.losses, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")\n",
    "# print()\n",
    "# print_loss(current_iter, trn_losses, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")\n",
    "# print()\n",
    "# print_loss(current_iter, environ.val_metrics, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d5db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T20:31:45.254334Z",
     "start_time": "2022-03-01T20:31:45.116895Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.losses\n",
    "# environ.val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4dd81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T20:47:29.582501Z",
     "start_time": "2022-03-01T20:47:29.492581Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.batch_data\n",
    "# print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics, 0, out=[sys.stdout])\n",
    "# environ.display_parameters()\n",
    "\n",
    "# with np.printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', precision=7, formatter={'float': lambda x: f\"{x:12.5e}\"}):\n",
    "#     environ.print_logit_grads('gradients')\n",
    "\n",
    "# environ_params = environ.get_task_specific_parameters()\n",
    "# environ_params = environ.get_arch_parameters()\n",
    "# environ_params = environ.get_backbone_parameters()\n",
    "# print(environ_params)\n",
    "# for param in environ_params:\n",
    "#     print(param.grad.shape, '\\n', param.grad)\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c80c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:12:46.806056Z",
     "start_time": "2022-03-11T21:12:46.471801Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.display_trained_logits(ns.current_epoch)\n",
    "environ.display_trained_policy(ns.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d47dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:13:19.578964Z",
     "start_time": "2022-03-11T21:13:19.242252Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.display_test_sample_policy(ns.current_epoch, hard_sampling = True)\n",
    "environ.display_train_sample_policy(ns.current_epoch, hard_sampling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754b317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:33:19.474125Z",
     "start_time": "2022-03-06T00:33:19.447847Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.define_optimizer(policy_learning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e89541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T00:07:08.097708Z",
     "start_time": "2022-03-09T00:07:08.070721Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.optimizers['alphas'])\n",
    "print(environ.optimizers['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ecc91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T00:07:50.026992Z",
     "start_time": "2022-03-09T00:07:49.986101Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Policy  initial_lr : ', environ.optimizers['alphas'].param_groups[0]['initial_lr'], 'lr : ',environ.optimizers['alphas'].param_groups[0]['lr'])\n",
    "print('Weights initial_lr : ', environ.optimizers['weights'].param_groups[0]['initial_lr'], 'lr : ',environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "print('Weights initial_lr : ', environ.optimizers['weights'].param_groups[1]['initial_lr'], 'lr : ',environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1306e8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T22:31:50.425696Z",
     "start_time": "2022-03-10T22:31:50.396531Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wandb.run is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b8e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:10:03.751132Z",
     "start_time": "2022-03-05T23:10:03.724538Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# opt['exp_instance'] = '0218_1358'     \n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\"\n",
    "# print()\n",
    "# opt['exp_instance'] = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "# opt['exp_description'] = f\"No Alternating Weight/Policy - training all done with both weights and policy\"\n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2affee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:12:20.322227Z",
     "start_time": "2022-03-11T21:12:20.285961Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527bd00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:25:11.319751Z",
     "start_time": "2022-02-20T21:25:11.210062Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "p = environ.get_current_state(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919068f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:25:26.324030Z",
     "start_time": "2022-02-20T21:25:26.112782Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82a453",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Post Warm-up Training stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb74c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:45:43.999959Z",
     "start_time": "2022-02-01T12:45:43.862475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b47da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:36.700361Z",
     "start_time": "2022-02-01T12:46:36.367037Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].arch_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f0235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:37:10.158440Z",
     "start_time": "2022-01-28T16:37:09.742327Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p = environ.get_sample_policy(hard_sampling = False)\n",
    "print(p)\n",
    "p = environ.get_policy_prob()\n",
    "print(p)\n",
    "p = environ.get_policy_logits()\n",
    "print(p)\n",
    "\n",
    "# p = environ.get_current_policy()\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bddd44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:40:37.799917Z",
     "start_time": "2022-01-28T16:40:37.773177Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = softmax([0.0, 1])\n",
    "print(a)\n",
    "sampled = np.random.choice((1, 0), p=a)\n",
    "print(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8f376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:13:16.205889Z",
     "start_time": "2022-01-28T16:13:16.179303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.optimizers['weights'])\n",
    "print(environ.schedulers['weights'].get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf9c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:50.411465Z",
     "start_time": "2022-02-01T12:46:50.020540Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('losses.keys      : ', environ.losses.keys())\n",
    "print('losses[task]keys : ', environ.losses['task1'].keys())\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20950069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T22:57:02.151169Z",
     "start_time": "2022-01-15T22:57:02.056562Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print( environ.val_metrics.keys())\n",
    "# pp.pprint(val_metrics)\n",
    "print(type(environ.val_metrics['aggregated']))\n",
    "print()\n",
    "print(type(environ.val_metrics['task1']['classification_agg']))\n",
    "print()\n",
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6e311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.266303Z",
     "start_time": "2022-01-14T18:57:26.166878Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"val_metrics.pkl\", mode= 'wb') as f:\n",
    "#         pickle.dump(val_metrics, f)\n",
    "    \n",
    "# with open('val_metrics.pkl', 'rb') as f:    \n",
    "#     tst_val_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00a8aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.297444Z",
     "start_time": "2022-01-14T18:57:26.269323Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(environ.input.shape) \n",
    "# a = getattr(environ, 'task1_pred')\n",
    "# yc_data = environ.batch['task1_data']\n",
    "# print(yc_data.shape)\n",
    "# yc_ind = environ.batch['task1_ind']\n",
    "# print(yc_ind.shape)\n",
    "# yc_hat_all = getattr(environ, 'task1_pred')\n",
    "# print(yc_hat_all.shape)\n",
    "# yc_hat  = yc_hat_all[yc_ind[0], yc_ind[1]]\n",
    "# print(yc_hat_all.shape, yc_hat.shape)\n",
    "\n",
    "# \n",
    "# environ.losses\n",
    "# loss = {}\n",
    "# for key in environ.losses.keys():\n",
    "#     loss[key] = {}\n",
    "#     for subkey, v in environ.losses[key].items():\n",
    "#         print(f\" key:  {key}   subkey: {subkey} \")\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             loss[key][subkey] = v.data\n",
    "#             print(f\" Tensor  -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "#         else:\n",
    "#             loss[key][subkey] = v\n",
    "#             print(f\" integer -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "# pp.pprint(tst_val_metrics)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987f89f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.340792Z",
     "start_time": "2022-01-14T18:57:26.302528Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print('metrics.keys: ', environ.metrics.keys())\n",
    "# print('metrics[task].keys: ', environ.metrics['task1'].keys())\n",
    "# pp.pprint(environ.metrics['task1'])\n",
    "# pp.pprint(environ.losses['task1']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ae417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.373399Z",
     "start_time": "2022-01-14T18:57:26.345065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# title='Iteration'\n",
    "# for t_id, _ in enumerate(environ.tasks):\n",
    "#     task_key = f\"task{t_id+1}\"\n",
    "# #     print_heading(f\"{title}  {current_iter}  {task_key} : {val_metrics[task_key]['classification_agg']}\", verbose = True)\n",
    "\n",
    "#     for key, _  in val_metrics[task_key]['classification_agg'].items():\n",
    "#         print('%s/%-20s'%(task_key, key), val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print(f\"{task_key:s}/{key:20s}\", val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print()\n",
    "#             # print_current_errors(os.path.join(self.log_dir, 'loss.txt'), current_iter,key, loss[key], time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b73b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:48.162261Z",
     "start_time": "2022-01-07T22:52:48.140423Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.print_loss(current_iter, start_time, metrics = val_metrics['loss'], verbose=True)\n",
    "# print(opt['lambdas'])\n",
    "# p = (opt['lambdas'][0] * environ.losses['tasks']['task1'])\n",
    "# print(p)\n",
    "\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics , title='validation', verbose=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850378b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:47.661019Z",
     "start_time": "2022-01-07T22:52:47.639094Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(current_iter)\n",
    "# print_metrics_cr(current_iter, t1 - t0, None, val_metrics , True)\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics, title='validation', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a80b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:14:58.034384Z",
     "start_time": "2022-01-07T23:14:58.004850Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\" val_metric keys               : {val_metrics.keys()}\")\n",
    "print(f\" loss keys                     : {val_metrics['loss'].keys()}\")\n",
    "print(f\" task1 keys                    : {val_metrics['task1'].keys()}\")\n",
    "print(f\" task1 classification keys     : {val_metrics['task1']['classification'].keys()}\")\n",
    "print(f\" task1 classification_agg keys : {val_metrics['task1']['classification_agg'].keys()}\")\n",
    "print()\n",
    "print(f\" task1                       : {val_metrics['task1']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task2                       : {val_metrics['task2']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task3                       : {val_metrics['task3']['classification_agg']['loss']:5f}\")\n",
    "print(f\" loss                        : {val_metrics['loss']['total']:5f}\")\n",
    "print(f\" train_time                  : {val_metrics['train_time']:2f}\")\n",
    "print(f\" epoch                       : {val_metrics['epoch']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc43a6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Post Weight + Policy Training Stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65640cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:22:20.634818Z",
     "start_time": "2022-01-27T00:22:20.444566Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].backbone.layer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4374287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:30:31.940280Z",
     "start_time": "2022-01-26T19:30:31.910058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_blocks = 6\n",
    "num_policy_layers = 6\n",
    "gt =  torch.ones((num_blocks)).long()\n",
    "gt0 =  torch.zeros((num_blocks)).long()\n",
    "print(gt)\n",
    "print(gt0)\n",
    "\n",
    "loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "print(loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651bc43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:42:31.300891Z",
     "start_time": "2022-01-26T19:42:31.257774Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if environ.opt['diff_sparsity_weights'] and not environ.opt['is_sharing']:\n",
    "    print(' cond 1')\n",
    "    ## Assign higher weights to higher layers \n",
    "    loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "    print(f\"{task_key} sparsity error:  {2 * (loss_weights[-num_blocks:] * environ.cross_entropy2(logits[-num_blocks:], gt)).mean()})\")\n",
    "    print_dbg(f\" loss_weights :  {loss_weights}\", verbose = True)\n",
    "    print_dbg(f\" cross_entropy:  {environ.cross_entropy2(logits[-num_blocks:], gt)}  \", verbose = True)\n",
    "    print_dbg(f\" loss[sparsity][{task_key}]: {self.losses['sparsity'][task_key] } \", verbose = True)\n",
    "\n",
    "else:\n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between \\n Logits   : \\n{logits[-num_blocks:]} \\n and gt: \\n{gt} \\n\", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-num_blocks:], gt)}\")\n",
    "    \n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt[-1:])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt0[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt0[-1:])} \\n\")\n",
    "    \n",
    "    print('\\n cond 3')    \n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt[0:1])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt0[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt0[0:1])} \\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686cd05",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ee1b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:30.155045Z",
     "start_time": "2022-01-26T00:14:30.107095Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# flag = 'update_w'\n",
    "# environ.fix_alpha\n",
    "# environ.free_w(opt['fix_BN'])\n",
    "\n",
    "flag = 'update_alpha'\n",
    "environ.fix_weights()\n",
    "environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7996b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:31.184285Z",
     "start_time": "2022-01-25T23:43:31.159229Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f436ee6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:34.993711Z",
     "start_time": "2022-01-26T00:14:34.968623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") \n",
    "\n",
    "train_total_epochs += 5\n",
    "\n",
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334a0b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T17:15:02.216665Z",
     "start_time": "2022-01-25T17:15:01.848081Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - t0, None, environ.val_metrics , num_prints)      \n",
    "\n",
    "# num_prints += 1\n",
    "# t0 = time.time()\n",
    "\n",
    "# # Take check point\n",
    "# environ.save_checkpoint('latest', current_iter)\n",
    "# environ.train()\n",
    "# #-------------------------------------------------------\n",
    "# # END validation process\n",
    "# #-------------------------------------------------------       \n",
    "# flag = 'update_alpha'\n",
    "# environ.fix_w()\n",
    "# environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c4f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:08:57.366231Z",
     "start_time": "2022-01-08T01:08:57.295445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dilation = 2\n",
    "# kernel_size = np.asarray((3, 3))\n",
    "# upsampled_kernel_size = (kernel_size - 1) * (dilation - 1) + kernel_size\n",
    "# print(upsampled_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500c390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:39.763599Z",
     "start_time": "2022-01-25T23:43:39.728402Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.optimizers['weights'].param_groups[0]\n",
    "# for param_group in optimizer.param_groups:\n",
    "#     return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb71bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:41.628847Z",
     "start_time": "2022-01-25T23:43:41.602238Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.schedulers['weights'].get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7934862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:36:17.129535Z",
     "start_time": "2022-01-08T01:36:16.006144Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.optimizers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    current_state[k] = v.state_dict()\n",
    "pp.pprint(current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5faf7f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:40:22.032247Z",
     "start_time": "2022-01-08T01:40:22.006953Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.schedulers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    print(v.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd497e72",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Losses and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66169a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T16:34:44.555617Z",
     "start_time": "2022-02-09T16:34:44.507417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_losses = environ.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb8234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:35:11.758429Z",
     "start_time": "2022-02-10T03:35:11.278211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0301f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:21:49.107793Z",
     "start_time": "2022-02-10T03:21:49.084484Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498b6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:20:32.866010Z",
     "start_time": "2022-02-10T03:20:32.442919Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "pp.pprint(trn_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe30724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:34:21.945701Z",
     "start_time": "2022-02-10T03:34:21.411234Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d81167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:49.364883Z",
     "start_time": "2022-01-27T00:58:49.342931Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['Lambda_sharing'] = 0.5\n",
    "# opt['train']['Lambda_sharing'] = 0.5\n",
    "\n",
    "# environ.opt['train']['policy_lr'] = 0.001\n",
    "# opt['train']['policy_lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73aa06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T01:00:41.996410Z",
     "start_time": "2022-01-26T01:00:41.559006Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.losses.keys()\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ece74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:19:43.683550Z",
     "start_time": "2022-01-08T01:19:43.571450Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = environ.get_loss_dict()\n",
    "print(tmp.keys())\n",
    "pp.pprint(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac0256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:50.458223Z",
     "start_time": "2022-01-27T00:58:50.430889Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(opt['diff_sparsity_weights'])\n",
    "print(opt['is_sharing'])\n",
    "print(opt['diff_sparsity_weights'] and not opt['is_sharing'])\n",
    "print(environ.opt['train']['Lambda_sharing'])\n",
    "print(opt['train']['Lambda_sharing'])\n",
    "print(environ.opt['train']['Lambda_sparsity'])\n",
    "print(opt['train']['Lambda_sparsity'])\n",
    "print(environ.opt['train']['policy_lr'])\n",
    "print(opt['train']['policy_lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2d510",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Policy / Logit stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb628497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:35:14.041577Z",
     "start_time": "2022-02-08T20:35:14.018303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.special          import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eed454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:30.103364Z",
     "start_time": "2022-02-08T20:00:30.068021Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03b5cc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_task_logits(n)` Get logits for task group n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed8b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:56:35.652087Z",
     "start_time": "2022-02-08T20:56:35.327406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task_logits = environ.get_task_logits(1)\n",
    "print(task_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66fa5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_arch_parameters()`: Get last used logits from network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85521e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:31.101960Z",
     "start_time": "2022-02-08T20:00:30.757064Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b0bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:06.054699Z",
     "start_time": "2022-02-09T15:43:05.689327Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea1743",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_logits()`:  Get Policy Logits - returns same as `get_arch_parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb40c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:24.972390Z",
     "start_time": "2022-02-09T15:43:24.636629Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs = environ.get_policy_logits()\n",
    "for i in logs:\n",
    "    print(i, '\\n')\n",
    "# probs = softmax(logs, axis= -1)\n",
    "# for i in probs:\n",
    "#     print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080a364",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_prob()` : Gets the softmax of the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c75af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:29.733732Z",
     "start_time": "2022-02-09T15:43:29.699600Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "for i in policy_softmaxs:\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3160d9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = False)` : Calls test_sample_policy of network with random choices based on softmax of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f411444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:21:15.636722Z",
     "start_time": "2022-02-08T22:21:15.165456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "policies,logits = environ.get_sample_policy(hard_sampling = False)\n",
    "\n",
    "for l, p, s in zip(logits, policies, policy_softmaxs) :\n",
    "    for  l_row, p_row, s_row in zip(l, p, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802664ec",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = True)` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea65bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:59:40.790899Z",
     "start_time": "2022-02-08T20:59:40.726657Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "hard_policies, logits = environ.get_sample_policy(hard_sampling = True)\n",
    "\n",
    "for p,l,s in zip(hard_policies, logits, policy_softmaxs) :\n",
    "    for  p_row, l_row, s_row in zip(p, l, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c39cf",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fe096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:00:47.452220Z",
     "start_time": "2022-02-08T21:00:47.422902Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\" Layer    task 1      task 2      task 3\")\n",
    "print(f\" -----    ------      ------      ------\")\n",
    "for idx, (l1, l2, l3) in enumerate(zip(hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1}       {l2}       {l3}\")\n",
    "    \n",
    "\n",
    "    print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade0ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:39:39.936555Z",
     "start_time": "2022-02-08T22:39:39.911591Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_trained_policy(iter):\n",
    "\n",
    "    policy_softmaxs = environ.get_policy_prob()\n",
    "    policy_argmaxs = 1-np.argmax(policy_softmaxs, axis = -1)\n",
    "    print(f\"  Trained polcies at iteration: {iter} \")\n",
    "    print(f\"                   task 1                           task 2                         task 3        \")\n",
    "    print(f\" Layer       softmax        select          softmax        select          softmax        select   \")\n",
    "    print(f\" -----    ---------------   ------       ---------------   ------       ---------------   ------   \")\n",
    "    for idx, (l1,l2,l3,  p1,p2,p3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2], policy_argmaxs[0], policy_argmaxs[1], policy_argmaxs[2]),1):\n",
    "        print(f\"   {idx}      {l1[0]:.4f}   {l1[1]:.4f}   {p1:4d}    {l2[0]:11.4f}   {l2[1]:.4f}   {p2:4d}    {l3[0]:11.4f}   {l3[1]:.4f}   {p3:4d}\")\n",
    "\n",
    "    print()\n",
    "# print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec208dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:42:12.650813Z",
     "start_time": "2022-02-08T22:42:12.330169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display_trained_policy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec517e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:07:30.836214Z",
     "start_time": "2022-02-08T22:07:30.804575Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"                        POLICIES (SOFTMAX)                                       task 3          \")\n",
    "print(f\" Layer    task1              task2            task3 softmax         softmax         argmax         softmax         argmax   \")\n",
    "print(f\" -----    -------------     -------------     -------------   ------   \")\n",
    "for idx, (l1,l2,l3, h1,h2,h3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2],hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1[0]:.4f} {l1[1]:.4f}     {l2[0]:.4f} {l2[1]:.4f}     {l3[0]:.4f} {l3[1]:.4f}    {h3}\")\n",
    "    \n",
    "print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbeacb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:04:50.757406Z",
     "start_time": "2022-02-08T22:04:50.731736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(policy_softmaxs[2], np.argmax(1-policy_softmaxs[2], axis = -1))\n",
    "print(policy_softmaxs, np.argmax(policy_softmaxs, axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be0240",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_logits()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb7240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:19:06.155425Z",
     "start_time": "2022-02-08T21:19:06.118640Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits  = (environ.get_current_logits())\n",
    "for i in logits:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e84662",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_policy()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cfa24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:40:06.543376Z",
     "start_time": "2022-02-08T20:40:06.230711Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pols  = (environ.get_current_policy())\n",
    "\n",
    "for i in pols:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f556a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T18:27:33.593255Z",
     "start_time": "2022-01-27T18:27:33.553141Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792710e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `gumbel_softmax()`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265490e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:28:17.107529Z",
     "start_time": "2022-02-08T21:28:17.084910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', floatmode = 'maxprec_equal')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb0087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:35:11.617269Z",
     "start_time": "2022-02-08T21:35:11.569599Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.temp)\n",
    "# tau = environ.temp\n",
    "tau = 1\n",
    "for i in range(3): \n",
    "    logits_tensor = torch.tensor(logits[0])\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=tau, hard=False).cpu().numpy() \n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=tau, hard=True).cpu().numpy()\n",
    "    \n",
    "    for l, gs, gh in zip(lgts, gumbel_soft, gumbel_hard):\n",
    "        print(f\"   {l}   \\t {gs}            \\t {gh}\")\n",
    "#     print(lgts)\n",
    "#     print(gumbel_soft)\n",
    "#     print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5ef7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e0e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:21:35.524957Z",
     "start_time": "2022-02-08T21:21:35.488812Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for lgts in logits:\n",
    "    logits_tensor = torch.tensor(lgts)\n",
    "    print(lgts)\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=1, hard=False)\n",
    "    print(gumbel_soft)\n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=1, hard=True)\n",
    "    print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34a06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T20:49:37.643349Z",
     "start_time": "2022-02-03T20:49:37.580786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smax = scipy.special.softmax(logs, axis =1)\n",
    "# smax = np.array( \n",
    "# [[0.46973792, 0.530262  ],\n",
    "#  [0.45025694, 0.549743  ],\n",
    "#  [0.4443086 , 0.5556915 ],\n",
    "#  [0.4138397 , 0.58616036],\n",
    "#  [0.4140113 , 0.5859887 ],\n",
    "#  [0.42114905, 0.57885087]])\n",
    "\n",
    "print(smax.shape)\n",
    "print(smax)\n",
    "print(smax[0])\n",
    "print(smax[0].sum())\n",
    "print(np.random.choice((1,0), p =smax[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7de25c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:15:19.893888Z",
     "start_time": "2022-02-08T21:15:19.870899Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logs = np.array(\n",
    "[[0.33064184, 0.42053092],\n",
    " [0.3532089 , 0.52056104],\n",
    " [0.3888512 , 0.5680909 ],\n",
    " [0.42039296, 0.694217  ],\n",
    " [0.4519742 , 0.73311865],\n",
    " [0.48401102, 0.7522658 ]],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "399px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
