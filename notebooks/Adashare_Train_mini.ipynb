{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408f1261",
   "metadata": {},
   "source": [
    "## Initialization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55604c43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:14:21.397969Z",
     "start_time": "2022-06-15T17:14:21.382098Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d574cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:35:10.681016Z",
     "start_time": "2022-06-15T17:35:08.026857Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:08.233990Z",
     "iopub.status.busy": "2022-01-07T22:44:08.233053Z",
     "iopub.status.idle": "2022-01-07T22:44:08.273284Z",
     "shell.execute_reply": "2022-01-07T22:44:08.271908Z",
     "shell.execute_reply.started": "2022-01-07T22:44:08.233943Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n",
      " CUDA device count  :  1\n",
      " CUDA current device:  0\n",
      " GPU Processes      : \n",
      " GPU:0\n",
      "process          4 uses        0.000 MB GPU memory\n",
      " Device : cuda:0\n",
      "   name:        NVIDIA GeForce GTX 970M\n",
      "   capability:  (5, 2)\n",
      "   properties:  _CudaDeviceProperties(name='NVIDIA GeForce GTX 970M', major=5, minor=2, total_memory=3071MB, multi_processor_count=10)\n",
      "   Allocated :  0\n",
      "   Reserved  :  0\n",
      "\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | nan% | 18% |\n",
      "cuda:0\n",
      "0\n",
      "nvml_gpu_id:  0\n",
      "<pynvml.nvml.LP_struct_c_nvmlDevice_t object at 0x7fcb3bbed840>\n",
      "c_nvmlMemory_t(total: 3221225472 B, free: 2655805440 B, used: 565420032 B)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreloa\n",
    "%autoreload 2\n",
    "import os \n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import time\n",
    "import argparse\n",
    "import yaml\n",
    "import types\n",
    "import copy, pprint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import numpy  as np\n",
    "import torch  \n",
    "import wandb\n",
    "from pynvml import *\n",
    "import pandas as pd\n",
    "from utils.notebook_modules import (initialize, init_dataloaders, init_environment, init_wandb, \n",
    "                                   training_prep, disp_dataloader_info,disp_info_1, \n",
    "                                   warmup_phase, weight_policy_training, display_gpu_info,\n",
    "                                   init_dataloaders_by_fold_id)\n",
    "                                    \n",
    "from utils import (print_separator, print_heading, timestring, print_loss, load_from_pickle) #, print_underline, \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=6, linewidth=132)\n",
    "pd.options.display.width = 132\n",
    "# torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
    "# sys.path.insert(0, '/home/kbardool/kusanagi/AdaSparseChem/src')\n",
    "# print(sys.path)\n",
    "# disp_gpu_info() \n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Train_mini.ipynb\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "display_gpu_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33ac6e",
   "metadata": {},
   "source": [
    "## Create Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee652c57",
   "metadata": {},
   "source": [
    "### Parse Input Args  - Read YAML config file - wandb initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42bb98b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:35:10.721250Z",
     "start_time": "2022-06-15T17:35:10.689146Z"
    }
   },
   "outputs": [],
   "source": [
    "# RESUME_MODEL_CKPT = 'model_train_ep_25_seed_0088'\n",
    "\n",
    "## For RESTARTING\n",
    "##\n",
    "# input_args = \" --config yamls/chembl_3task_train.yaml \" \\\n",
    "#              \" --resume \" \\\n",
    "#              \" --exp_id      330i85cg\" \\\n",
    "#              \" --exp_name    0308_1204\" \\\n",
    "#              \" --exp_desc    Train with dropout 0.5\" \\\n",
    "#              \" --seed_idx    0 \"\\\n",
    "#              \" --batch_size  128\" \\\n",
    "#              \" --lambda_sparsity  0.01\"\\\n",
    "#              \" --lambda_sharing   0.01\" \n",
    "## get command line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd3a7f00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:35:10.756396Z",
     "start_time": "2022-06-15T17:35:10.724902Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_1task_config = \"../yamls/chembl_synt_train_1task.yaml\"\n",
    "synthetic_3task_config = \"../yamls/chembl_synt_train_3task.yaml\"\n",
    "synthetic_5task_config = \"../yamls/chembl_synt_train_5task.yaml\"\n",
    "synthetic_config_file  = \"../yamls/chembl_synt_train.yaml\"\n",
    "# config_file      = \"../yamls/chembl_mini_train.yaml\"\n",
    "config_file      = \"../yamls/chembl_cb29_train.yaml\"\n",
    "batch_size=16\n",
    "\n",
    "##  For Initiating \n",
    "##\n",
    "input_args = f\" --config  {config_file} \" \\\n",
    "             \" --exp_desc     weight 105 bch/ep policy 105 bch/ep \" \\\n",
    "             \" --warmup_epochs        10 \"  \\\n",
    "             \" --hidden_size          1000 \"  \\\n",
    "             \" --tail_hidden_size     1000 \"  \\\n",
    "             \" --first_dropout       0.45 \"  \\\n",
    "             \" --middle_dropout      0.45\"  \\\n",
    "             \" --last_dropout        0.45 \"  \\\n",
    "             \" --seed_idx              0 \"  \\\n",
    "             f\" --batch_size        {batch_size} \"  \\\n",
    "             \" --task_lr           0.001 \"  \\\n",
    "             \" --backbone_lr       0.001 \"  \\\n",
    "             \" --decay_lr_rate       0.3 \"  \\\n",
    "             \" --decay_lr_freq        10 \"  \\\n",
    "             \" --policy_lr         0.001 \"  \\\n",
    "             \" --lambda_sparsity    0.02 \"  \\\n",
    "             \" --lambda_sharing     0.01 \"  \\\n",
    "             \" --skip_hidden \" \\\n",
    "             \" --cpu \" \n",
    "\n",
    "#              \" --no_residual \"\n",
    "#              \" --exp_name       0410_1934 \" \\\n",
    "#              \" --hidden_size   100 100 100 100 100 100\" \\\n",
    "#              \" --tail_hidden_size  100 \" \\\n",
    "#              \" --decay_lr_rate      0.75\"  \\\n",
    "#              \" --decay_lr_freq       20\"  \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ddaf625",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:35:17.138158Z",
     "start_time": "2022-06-15T17:35:10.763018Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkbardool\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  command line parms : \n",
      "------------------------\n",
      " config...................  ../yamls/chembl_mini_train.yaml\n",
      " exp_id...................  1ui7go1a\n",
      " exp_name.................  None\n",
      " folder_sfx...............  None\n",
      " exp_desc.................  weight 105 bch/ep policy 105 bch/ep\n",
      " hidden_sizes.............  [1000]\n",
      " tail_hidden_size.........  [1000]\n",
      " warmup_epochs............  10\n",
      " training_epochs..........  None\n",
      " seed_idx.................  0\n",
      " batch_size...............  128\n",
      " first_dropout............  0.45\n",
      " middle_dropout...........  0.45\n",
      " last_dropout.............  0.45\n",
      " backbone_lr..............  0.001\n",
      " task_lr..................  0.001\n",
      " policy_lr................  0.001\n",
      " decay_lr_rate............  0.3\n",
      " decay_lr_freq............  10.0\n",
      " lambda_sparsity..........  0.02\n",
      " lambda_sharing...........  0.01\n",
      " gpu_ids..................  [0]\n",
      " skip_residual............  False\n",
      " skip_hidden..............  True\n",
      " resume...................  False\n",
      " cpu......................  True\n",
      " min_samples_class........  None\n",
      "\n",
      "\n",
      "\n",
      "##################################################\n",
      "################### READ YAML ####################\n",
      "##################################################\n",
      "1ui7go1a 0615_1935_skip_hdn AdaSparseChem-Mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: cannot run ipynb_drop_output: No such file or directory\n",
      "error: cannot fork to run external filter 'ipynb_drop_output'\n",
      "error: external filter 'ipynb_drop_output' failed\n",
      "error: cannot run ipynb_drop_output: No such file or directory\n",
      "error: cannot fork to run external filter 'ipynb_drop_output'\n",
      "error: external filter 'ipynb_drop_output' failed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kbardool/WSL-projs/AdaSparseChem/notebooks/wandb/run-20220615_193510-1ui7go1a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"http://localhost:8080/kbardool/AdaSparseChem-Mini/runs/1ui7go1a\" target=\"_blank\">0615_1935_skip_hdn</a></strong> to <a href=\"http://localhost:8080/kbardool/AdaSparseChem-Mini\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PROJECT NAME: AdaSparseChem-Mini\n",
      " RUN ID      : 1ui7go1a \n",
      " RUN NAME    : 0615_1935_skip_hdn\n",
      " PROJECT NAME: AdaSparseChem-Mini\n",
      " RUN ID      : 1ui7go1a \n",
      " RUN NAME    : 0615_1935_skip_hdn\n",
      "\n",
      "\n",
      " log_dir              create folder:  ../../experiments/mini-AdaSparseChem/1000x1_0615_1935_lr0.001_do0.45_skip_hdn\n",
      " result_dir           folder exists:  ../../experiments/mini-AdaSparseChem/1000x1_0615_1935_lr0.001_do0.45_skip_hdn\n",
      " checkpoint_dir       folder exists:  ../../experiments/mini-AdaSparseChem/1000x1_0615_1935_lr0.001_do0.45_skip_hdn\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " experiment name       : 0615_1935_skip_hdn \n",
      " experiment id         : 1ui7go1a \n",
      " folder_name           : 1000x1_0615_1935_lr0.001_do0.45_skip_hdn \n",
      " experiment description: weight 105 bch/ep policy 105 bch/ep\n",
      " Random seeds          : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      " Random  seed used     : 88 \n",
      " log folder            : ../../experiments/mini-AdaSparseChem/1000x1_0615_1935_lr0.001_do0.45_skip_hdn\n",
      " checkpoint folder     : ../../experiments/mini-AdaSparseChem/1000x1_0615_1935_lr0.001_do0.45_skip_hdn\n",
      " Gpu ids               : [0]\n",
      " Seed index            : 0\n",
      " policy_iter           : best\n",
      " Data Split ratios     : [0.725, 0.225, 0.05]\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "        project_name : AdaSparseChem-Mini\n",
      "              exp_id : 1ui7go1a\n",
      "        exp_name_pfx : 0615_1935\n",
      "            exp_name : 0615_1935_skip_hdn\n",
      "          exp_folder : 1000x1_0615_1935_lr0.001_do0.45_skip_hdn\n",
      "     exp_description : weight 105 bch/ep policy 105 bch/ep\n",
      "          folder_sfx : skip_hdn\n",
      "         random_seed : 88\n",
      "           seed_list : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      "              config : ../yamls/chembl_mini_train.yaml\n",
      "                 cpu : True\n",
      "             gpu_ids : [0]\n",
      "            backbone : SparseChem\n",
      "               tasks : ['class']\n",
      "     tasks_num_class : [100]\n",
      "             lambdas : [1]\n",
      "             verbose : False\n",
      "     input_size_freq : None\n",
      "          input_size : 32000\n",
      "        hidden_sizes : [1000]\n",
      "    tail_hidden_size : [1000]\n",
      " first_non_linearity : relu\n",
      "middle_non_linearity : relu\n",
      "  last_non_linearity : relu\n",
      "       first_dropout : 0.45\n",
      "      middle_dropout : 0.45\n",
      "        last_dropout : 0.45\n",
      "   class_output_size : None\n",
      "    regr_output_size : None\n",
      "              policy : True\n",
      "        policy_model : task-specific\n",
      "       skip_residual : False\n",
      "         skip_hidden : True\n",
      "           is_sparse : True\n",
      "          is_sharing : True\n",
      "diff_sparsity_weights : False\n",
      "          skip_layer : 0\n",
      "       is_curriculum : False\n",
      "    curriculum_speed : 3\n",
      "              fix_BN : False\n",
      "     retrain_from_pl : False\n",
      "\n",
      "train\n",
      "-----\n",
      "          batch_size : 128\n",
      "       warmup_epochs : 10\n",
      "     training_epochs : 250\n",
      "         total_iters : 25000\n",
      "       warm_up_iters : None\n",
      "             task_lr : 0.001\n",
      "         backbone_lr : 0.001\n",
      "    weight_optimizer : adam\n",
      "    policy_optimizer : adam\n",
      "       decay_lr_rate : 0.3\n",
      "       decay_lr_freq : 10.0\n",
      "   decay_lr_cooldown : 0\n",
      "policy_decay_lr_rate : 0.75\n",
      "policy_decay_lr_freq : 50\n",
      "policy_decay_lr_cooldown : 0\n",
      "           policy_lr : 0.001\n",
      "     lambda_sparsity : 0.02\n",
      "      lambda_sharing : 0.01\n",
      "        lambda_tasks : 1\n",
      "         init_method : random\n",
      "           init_temp : 4\n",
      "          decay_temp : 0.965\n",
      "     decay_temp_freq : 16\n",
      "     init_neg_logits : None\n",
      "       hard_sampling : False\n",
      "            val_freq : 500\n",
      "          print_freq : -1\n",
      "           val_iters : -1\n",
      "              resume : False\n",
      "      retrain_resume : False\n",
      "         policy_iter : best\n",
      "          which_iter : warmup\n",
      "\n",
      "paths\n",
      "-----\n",
      "             log_dir : ../../experiments/mini-AdaSparseChem/1000x1_0615_1935_lr0.001_do0.45_skip_hdn\n",
      "          result_dir : ../../experiments/mini-AdaSparseChem/1000x1_0615_1935_lr0.001_do0.45_skip_hdn\n",
      "      checkpoint_dir : ../../experiments/mini-AdaSparseChem/1000x1_0615_1935_lr0.001_do0.45_skip_hdn\n",
      "\n",
      "dataload\n",
      "--------\n",
      "             dataset : Chembl23_mini\n",
      "            dataroot : ../../MLDatasets/chembl23_mini\n",
      "                   x : chembl_23mini_x.npy\n",
      "      x_split_ratios : [0.725, 0.225, 0.05]\n",
      "             y_tasks : ['chembl_23mini_y.npy']\n",
      "            y_censor : None\n",
      "             folding : chembl_23mini_folds.npy\n",
      "         fold_inputs : 32000\n",
      "     input_transform : None\n",
      "       weights_class : None\n",
      "   min_samples_class : 1\n",
      "             fold_va : 0\n",
      "             fold_te : None\n",
      "\n",
      "SC\n",
      "--\n",
      "      normalize_loss : None\n"
     ]
    }
   ],
   "source": [
    "opt, ns = initialize(input_args, build_folders = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a5e80e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:35:17.560744Z",
     "start_time": "2022-06-15T17:35:17.143685Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3a2edeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:35:24.252984Z",
     "start_time": "2022-06-15T17:35:17.566643Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      " 2022-06-15 19:35:17:618534  Create new  Chembl_23 instance \n",
      "---------------------------------------------------------------- \n",
      "\n",
      " verbose        : True\n",
      "\n",
      " FOLDS param provided - folds: [1, 2, 3, 4] \n",
      "\n",
      " X (ecfp[0]) file count non zero (post fold & transform) :80 \n",
      "\n",
      "\n",
      " Load label/Y file for task 1 filename : chembl_23mini_y.npy . . .\n",
      "-------------------------------------------------------------------\n",
      " load_task_weights() - filename: None label: y_task1\n",
      " load_task_weights() - no weights file provided for y_task1, training_weights for all  100 classes set to 1 \n",
      " Number of non-zero features in ecfp[0]:80\n",
      "\n",
      " Task 1 label file: \n",
      "    Total Positive Labels :     18704 \n",
      "    Total Negative Labels :      2445 \n",
      "    Total Non-Zero Labels :     21149\n",
      " All y values are 0, 1, or -1.\n",
      "\n",
      " tasks_class.aggregation_weight WAS NOT passed \n",
      " min_samples_class: 1\n",
      "\n",
      " Class fold counts: \n",
      "---------------------\n",
      " fold_pos - total: 18704 - .sum(axis=0):\n",
      "[ 884   59   59  284   55   43  749   14  292  342  423   13  119    1  281  213    0   11  190   27   46   36   16   43    9   70    7  163 1399\n",
      "   35  447    1    0  675  327  142    6   31  552   52   27  325    1  350  535   72   94   36   55  259 1366    3   24    9 1408  148  971  113\n",
      "   31   55   70   74   63    0   86   58    2    0  465  273    9  317   91  146  199    0  251  232   62   14  230   79   30   41   32 1610   74\n",
      "   16   22    0    0    0  102    1    0   32   14    0   10    1] \n",
      "\n",
      " fold_pos: \n",
      " [[115  31  17  54   7  18 203   3  55  76  63   1  42   0  75  36   0   1  43   2   7   7   0   3   0  21   1  37 330  11  86   0   0 142  27  25\n",
      "    4   7 111  12   7  79   0  97 129  15  10   9   9  38 272   1   2   0 285  63 185   1   0   4  19  21  13   0  18  12   0   0  93  55   1  73\n",
      "   29  41  18   0  46  37  14   0  40  18   6   8  10 330   6   4   1   0   0   0   8   0   0   0   3   0   1   0]\n",
      " [179   1  13  70   8   8 124   3  57  65  10   3  28   0  62  75   0   5  21   3  11  13   4   0   1  11   0  32 300   8 118   0   0 153  57  25\n",
      "    2   5 111  12   2  59   1  47 110  15  21   1   6  43 276   1   4   4 329   7 185 108   1  11  34  14   7   0  20  19   1   0 101  75   1  68\n",
      "   14  21  29   0  83  61   9   0  50   2   5   6   2 359  24   1   4   0   0   0   5   0   0   6   0   0   1   0]\n",
      " [237   0  10  63  15   6 144   3  59  64  67   2  14   0  48  34   0   4  25   6   3   8  12   4   4   6   1  35 250   3  66   0   0 119 133  24\n",
      "    0   8 117  12  18  31   0  78  78   9  26  12  10  38 296   0   4   3 280  45 172   1   5  14   5  11  20   0  16  24   0   0  85  65   0  73\n",
      "   25  20  16   0  51  42  13   0  58  22  10   8  10 347  20   3   9   0   0   0  23   0   0  12   3   0   0   1]\n",
      " [171   0  12  37  19   6 121   2  77  46 221   1  18   0  58  35   0   0  53   5  12   6   0  27   2  17   0  20 200   4  63   1   0 132  55  28\n",
      "    0   3 101  10   0 125   0  66 138  26  20  14  20  73 268   0  10   2 237  11 188   1  11  16   8  17  20   0  14   2   0   0  91  38   4  61\n",
      "   14  27 125   0  21  45   4  14  35  22   9   9   4 248  12   3   1   0   0   0  45   1   0  10   6   0   3   0]\n",
      " [182  27   7  60   6   5 157   3  44  91  62   6  17   1  38  33   0   1  48  11  13   2   0   9   2  15   5  39 319   9 114   0   0 129  55  40\n",
      "    0   8 112   6   0  31   0  62  80   7  17   0  10  67 254   1   4   0 277  22 241   2  14  10   4  11   3   0  18   1   1   0  95  40   3  42\n",
      "    9  37  11   0  50  47  22   0  47  15   0  10   6 326  12   5   7   0   0   0  21   0   0   4   2   0   5   0]] \n",
      "\n",
      "\n",
      "\n",
      " fold_neg - total: 2445 - .sum(axis=0):\n",
      "[ 83   0   0   0   0   3  29   7   9  11   0   0   0  12   3   0   0   0   0   9   0  13  21   0   0   0   0   0  45   0   0 143   0   9   0  56   9\n",
      "  18  17   0   0   1   1   1  72   0  10   0 280   2   0   2  48 245  17  77   4   0   0   9   0   5   3   2  57   1   0   1   5   2  44   2  64  11\n",
      "   1  24   3   0 101  21  38   0  19   0   1 220  16  13 400  32   0  27   1  17   0   0   2   0  32  14] \n",
      "\n",
      " fold_neg: \n",
      " [[ 17   0   0   0   0   1   3   4   2   2   0   0   0   1   2   0   0   0   0   2   0   0  13   0   0   0   0   0   6   0   0  30   0   0   0   3\n",
      "    3   3   2   0   0   1   1   1  18   0   2   0  85   0   0   2  13  47   1  11   0   0   0   2   0   1   1   1   3   0   0   0   0   0  18   0\n",
      "    9   3   0   4   1   0  23  11   6   0   5   0   0  46   4   4  73   2   0   7   1   0   0   0   0   0   4   0]\n",
      " [ 27   0   0   0   0   0   2   2   5   4   0   0   0   3   0   0   0   0   0   2   0   5   0   0   0   0   0   0  11   0   0  34   0   4   0  17\n",
      "    0   3   1   0   0   0   0   0   6   0   0   0  37   2   0   0  11  79   4  28   0   0   0   1   0   2   0   1  13   0   0   0   1   1   2   1\n",
      "    2   2   0   7   0   0  23   4   9   0   4   0   0  35   1   3 115   1   0   2   0   5   0   0   1   0  13   4]\n",
      " [ 18   0   0   0   0   1  15   0   0   2   0   0   0   2   0   0   0   0   0   2   0   2   2   0   0   0   0   0   9   0   0  33   0   2   0  17\n",
      "    1   5   5   0   0   0   0   0  11   0   0   0  51   0   0   0   5  48   3  23   2   0   0   1   0   0   0   0   5   1   0   0   1   0   5   1\n",
      "   16   2   0   6   0   0  22   2   6   0   2   0   0  42   1   4  52   5   0  18   0   5   0   0   0   0   9   4]\n",
      " [  5   0   0   0   0   1   7   1   0   3   0   0   0   1   1   0   0   0   0   3   0   3   1   0   0   0   0   0  16   0   0  19   0   0   0  15\n",
      "    2   3   3   0   0   0   0   0  11   0   3   0  56   0   0   0  16  19   5   6   0   0   0   3   0   0   2   0  18   0   0   1   3   0  15   0\n",
      "   22   4   1   4   0   0  16   1   9   0   3   0   0  61   5   1  86   2   0   0   0   4   0   0   1   0   3   2]\n",
      " [ 16   0   0   0   0   0   2   0   2   0   0   0   0   5   0   0   0   0   0   0   0   3   5   0   0   0   0   0   3   0   0  27   0   3   0   4\n",
      "    3   4   6   0   0   0   0   0  26   0   5   0  51   0   0   0   3  52   4   9   2   0   0   2   0   2   0   0  18   0   0   0   0   1   4   0\n",
      "   15   0   0   3   2   0  17   3   8   0   5   0   1  36   5   1  74  22   0   0   0   3   0   0   0   0   3   4]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  task_weights.aggregation_weight: \n",
      "------------------------------------\n",
      " fold_pos >= 1 and  fold_neg >= 1\n",
      " shape: (100,) sum: 20.0\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "\n",
      "  task_weights.training_weight: \n",
      "---------------------------------\n",
      " shape    : (100,) sum: 100.0\n",
      " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "  Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  18388       # Features per Sample: 32000   \n",
      "Y file : # Samples :  18388     # Labels per Sample: 100 \n",
      "\n",
      "  Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  14633     # Features: 32000   \n",
      "Y file : # Samples :  100     # Subtasks: 100 \n",
      "Using 20 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "--------------------------------------------------\n",
      "Chembl_23 Create complete\n",
      "-------------------------------------------------- \n",
      "\n",
      "----------------------------------------------------------------\n",
      " 2022-06-15 19:35:19:893104  Create new  Chembl_23 instance \n",
      "---------------------------------------------------------------- \n",
      "\n",
      " verbose        : True\n",
      "\n",
      " FOLDS param provided - folds: [0] \n",
      "\n",
      " X (ecfp[0]) file count non zero (post fold & transform) :80 \n",
      "\n",
      "\n",
      " Load label/Y file for task 1 filename : chembl_23mini_y.npy . . .\n",
      "-------------------------------------------------------------------\n",
      " load_task_weights() - filename: None label: y_task1\n",
      " load_task_weights() - no weights file provided for y_task1, training_weights for all  100 classes set to 1 \n",
      " Number of non-zero features in ecfp[0]:80\n",
      "\n",
      " Task 1 label file: \n",
      "    Total Positive Labels :     18704 \n",
      "    Total Negative Labels :      2445 \n",
      "    Total Non-Zero Labels :     21149\n",
      " All y values are 0, 1, or -1.\n",
      "\n",
      " tasks_class.aggregation_weight WAS NOT passed \n",
      " min_samples_class: 1\n",
      "\n",
      " Class fold counts: \n",
      "---------------------\n",
      " fold_pos - total: 18704 - .sum(axis=0):\n",
      "[ 884   59   59  284   55   43  749   14  292  342  423   13  119    1  281  213    0   11  190   27   46   36   16   43    9   70    7  163 1399\n",
      "   35  447    1    0  675  327  142    6   31  552   52   27  325    1  350  535   72   94   36   55  259 1366    3   24    9 1408  148  971  113\n",
      "   31   55   70   74   63    0   86   58    2    0  465  273    9  317   91  146  199    0  251  232   62   14  230   79   30   41   32 1610   74\n",
      "   16   22    0    0    0  102    1    0   32   14    0   10    1] \n",
      "\n",
      " fold_pos: \n",
      " [[115  31  17  54   7  18 203   3  55  76  63   1  42   0  75  36   0   1  43   2   7   7   0   3   0  21   1  37 330  11  86   0   0 142  27  25\n",
      "    4   7 111  12   7  79   0  97 129  15  10   9   9  38 272   1   2   0 285  63 185   1   0   4  19  21  13   0  18  12   0   0  93  55   1  73\n",
      "   29  41  18   0  46  37  14   0  40  18   6   8  10 330   6   4   1   0   0   0   8   0   0   0   3   0   1   0]\n",
      " [179   1  13  70   8   8 124   3  57  65  10   3  28   0  62  75   0   5  21   3  11  13   4   0   1  11   0  32 300   8 118   0   0 153  57  25\n",
      "    2   5 111  12   2  59   1  47 110  15  21   1   6  43 276   1   4   4 329   7 185 108   1  11  34  14   7   0  20  19   1   0 101  75   1  68\n",
      "   14  21  29   0  83  61   9   0  50   2   5   6   2 359  24   1   4   0   0   0   5   0   0   6   0   0   1   0]\n",
      " [237   0  10  63  15   6 144   3  59  64  67   2  14   0  48  34   0   4  25   6   3   8  12   4   4   6   1  35 250   3  66   0   0 119 133  24\n",
      "    0   8 117  12  18  31   0  78  78   9  26  12  10  38 296   0   4   3 280  45 172   1   5  14   5  11  20   0  16  24   0   0  85  65   0  73\n",
      "   25  20  16   0  51  42  13   0  58  22  10   8  10 347  20   3   9   0   0   0  23   0   0  12   3   0   0   1]\n",
      " [171   0  12  37  19   6 121   2  77  46 221   1  18   0  58  35   0   0  53   5  12   6   0  27   2  17   0  20 200   4  63   1   0 132  55  28\n",
      "    0   3 101  10   0 125   0  66 138  26  20  14  20  73 268   0  10   2 237  11 188   1  11  16   8  17  20   0  14   2   0   0  91  38   4  61\n",
      "   14  27 125   0  21  45   4  14  35  22   9   9   4 248  12   3   1   0   0   0  45   1   0  10   6   0   3   0]\n",
      " [182  27   7  60   6   5 157   3  44  91  62   6  17   1  38  33   0   1  48  11  13   2   0   9   2  15   5  39 319   9 114   0   0 129  55  40\n",
      "    0   8 112   6   0  31   0  62  80   7  17   0  10  67 254   1   4   0 277  22 241   2  14  10   4  11   3   0  18   1   1   0  95  40   3  42\n",
      "    9  37  11   0  50  47  22   0  47  15   0  10   6 326  12   5   7   0   0   0  21   0   0   4   2   0   5   0]] \n",
      "\n",
      "\n",
      "\n",
      " fold_neg - total: 2445 - .sum(axis=0):\n",
      "[ 83   0   0   0   0   3  29   7   9  11   0   0   0  12   3   0   0   0   0   9   0  13  21   0   0   0   0   0  45   0   0 143   0   9   0  56   9\n",
      "  18  17   0   0   1   1   1  72   0  10   0 280   2   0   2  48 245  17  77   4   0   0   9   0   5   3   2  57   1   0   1   5   2  44   2  64  11\n",
      "   1  24   3   0 101  21  38   0  19   0   1 220  16  13 400  32   0  27   1  17   0   0   2   0  32  14] \n",
      "\n",
      " fold_neg: \n",
      " [[ 17   0   0   0   0   1   3   4   2   2   0   0   0   1   2   0   0   0   0   2   0   0  13   0   0   0   0   0   6   0   0  30   0   0   0   3\n",
      "    3   3   2   0   0   1   1   1  18   0   2   0  85   0   0   2  13  47   1  11   0   0   0   2   0   1   1   1   3   0   0   0   0   0  18   0\n",
      "    9   3   0   4   1   0  23  11   6   0   5   0   0  46   4   4  73   2   0   7   1   0   0   0   0   0   4   0]\n",
      " [ 27   0   0   0   0   0   2   2   5   4   0   0   0   3   0   0   0   0   0   2   0   5   0   0   0   0   0   0  11   0   0  34   0   4   0  17\n",
      "    0   3   1   0   0   0   0   0   6   0   0   0  37   2   0   0  11  79   4  28   0   0   0   1   0   2   0   1  13   0   0   0   1   1   2   1\n",
      "    2   2   0   7   0   0  23   4   9   0   4   0   0  35   1   3 115   1   0   2   0   5   0   0   1   0  13   4]\n",
      " [ 18   0   0   0   0   1  15   0   0   2   0   0   0   2   0   0   0   0   0   2   0   2   2   0   0   0   0   0   9   0   0  33   0   2   0  17\n",
      "    1   5   5   0   0   0   0   0  11   0   0   0  51   0   0   0   5  48   3  23   2   0   0   1   0   0   0   0   5   1   0   0   1   0   5   1\n",
      "   16   2   0   6   0   0  22   2   6   0   2   0   0  42   1   4  52   5   0  18   0   5   0   0   0   0   9   4]\n",
      " [  5   0   0   0   0   1   7   1   0   3   0   0   0   1   1   0   0   0   0   3   0   3   1   0   0   0   0   0  16   0   0  19   0   0   0  15\n",
      "    2   3   3   0   0   0   0   0  11   0   3   0  56   0   0   0  16  19   5   6   0   0   0   3   0   0   2   0  18   0   0   1   3   0  15   0\n",
      "   22   4   1   4   0   0  16   1   9   0   3   0   0  61   5   1  86   2   0   0   0   4   0   0   1   0   3   2]\n",
      " [ 16   0   0   0   0   0   2   0   2   0   0   0   0   5   0   0   0   0   0   0   0   3   5   0   0   0   0   0   3   0   0  27   0   3   0   4\n",
      "    3   4   6   0   0   0   0   0  26   0   5   0  51   0   0   0   3  52   4   9   2   0   0   2   0   2   0   0  18   0   0   0   0   1   4   0\n",
      "   15   0   0   3   2   0  17   3   8   0   5   0   1  36   5   1  74  22   0   0   0   3   0   0   0   0   3   4]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  task_weights.aggregation_weight: \n",
      "------------------------------------\n",
      " fold_pos >= 1 and  fold_neg >= 1\n",
      " shape: (100,) sum: 20.0\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "\n",
      "  task_weights.training_weight: \n",
      "---------------------------------\n",
      " shape    : (100,) sum: 100.0\n",
      " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "  Task 1 files pre-filtering : \n",
      "--------------------------------\n",
      "X file : # Samples :  18388       # Features per Sample: 32000   \n",
      "Y file : # Samples :  18388     # Labels per Sample: 100 \n",
      "\n",
      "  Task 1 files post-filtering : \n",
      "---------------------------------\n",
      "X file : # Samples :  3755     # Features: 32000   \n",
      "Y file : # Samples :  100     # Subtasks: 100 \n",
      "Using 20 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "--------------------------------------------------\n",
      "Chembl_23 Create complete\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dldrs = init_dataloaders(opt, verbose = False)\n",
    "dldrs = init_dataloaders_by_fold_id(opt, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbc14177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:35:31.350017Z",
     "start_time": "2022-06-15T17:35:24.260093Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " trainset.y_class                                   :  [(14633, 100)] \n",
      " trainset1.y_class                                  :  [(14633, 100)] \n",
      " trainset2.y_class                                  :  [(14633, 100)] \n",
      " valset.y_class                                     :  [(3755, 100)]  \n",
      "                                 \n",
      " size of training set 0 (warm up)                   :  14633 \n",
      " size of training set 1 (network parms)             :  14633 \n",
      " size of training set 2 (policy weights)            :  14633 \n",
      " size of validation set                             :  3755 \n",
      "                               Total                :  47654 \n",
      "                                 \n",
      " Number of batches in training 0 (warm up)          :  115 \n",
      " Number of batches in training 1 (network parms)    :  115 \n",
      " Number of batches in training 2 (policy weights)   :  115 \n",
      " Number of batches in validation dataset            :  30 \n",
      "                                \n"
     ]
    }
   ],
   "source": [
    "disp_dataloader_info(dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6729bc64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:35:32.302884Z",
     "start_time": "2022-06-15T17:35:31.357411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set  2445\n",
      "validation set  18704\n",
      "training set  2445\n",
      "training set  18704\n"
     ]
    }
   ],
   "source": [
    "print(\"validation set num of negative: \", dldrs.valset.num_neg.sum())\n",
    "print(\"validation set num of positive: \", dldrs.valset.num_pos.sum())\n",
    "print(\"training set num of negative  : \", dldrs.trainset0.num_neg.sum())\n",
    "print(\"training set num of positive  : \", dldrs.trainset0.num_pos.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5c9fcc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:35:32.402717Z",
     "start_time": "2022-06-15T17:35:32.308670Z"
    }
   },
   "outputs": [],
   "source": [
    "# folding  = np.load(os.path.join('/mnt/f/Chembl29', opt['dataload']['folding']))\n",
    "# print(folding.shape)\n",
    "# print(folding.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ceb061d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:35:33.392240Z",
     "start_time": "2022-06-15T17:35:32.408024Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in zip(dldrs.valset.num_pos, dldrs.valset.num_neg, dldrs.trainset0.num_pos, dldrs.trainset0.num_neg):\n",
    "#     print(f\" {i[0]:4d}  {i[1]:4d}    trianing: {i[2]:4d}   {i[3]:4d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efb80735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:35:33.718902Z",
     "start_time": "2022-06-15T17:35:33.402201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "print(dldrs.trainset0.tasks_weights_list[0].aggregation_weight.sum())\n",
    "print(dldrs.valset.tasks_weights_list[0].aggregation_weight.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bfa8d",
   "metadata": {},
   "source": [
    "### Setup Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c631eb67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:47:30.329067Z",
     "start_time": "2022-06-15T17:47:29.715195Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      " device is  cuda:0\n",
      "--------------------------------------------------\n",
      " SparseChem_Backbone  Ver: 1.0 Init() Start \n",
      "-------------------------------------------------- \n",
      "\n",
      " layer config        : [1] \n",
      " skip residual layers: False   skip hidden layers  : True\n",
      " SparseChem_BackBone() Input Layer  - Input: 32000  output: 1000  non-linearity:<class 'torch.nn.modules.activation.ReLU'>\n",
      " Module List \n",
      "--------------------------------------------------\n",
      " Initialize weights \n",
      "-------------------------------------------------- \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " SparseChem Backbone -- Final configuration(2) : \n",
      "                     self.blocks: <class 'torch.nn.modules.container.ModuleList'>  len:0\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "\n",
      "  Input_Layer  type:<class 'torch.nn.modules.container.Sequential'>  \n",
      "----------------------------------------------------------------------\n",
      "self.Input_layer\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Layers/Blocks    : <class 'torch.nn.modules.container.ModuleList'>   len:0 \n",
      "Resdiual layers  : <class 'torch.nn.modules.container.ModuleList'>   len:0\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " SparseChem_Backbone Init() End \n",
      "----------------------------------------------------\n",
      "* SparseChemEnv environment successfully created\n",
      "---------------------------------------------------- \n",
      "\n",
      " \n",
      "\n",
      "SparseChemEnv  Configuration       \n",
      "---------------------------------------- \n",
      "\n",
      "----------------\n",
      "networks       :\n",
      "----------------\n",
      " {'mtl-net': MTL3(\n",
      "  (backbone): SparseChem_Backbone(\n",
      "    (Input_Layer): Sequential(\n",
      "      (linear): SparseLinear(in_features=32000, out_features=1000, bias=True)\n",
      "      (non_linear): ReLU()\n",
      "      (dropout): Dropout(p=0.45, inplace=False)\n",
      "    )\n",
      "    (blocks): ModuleList()\n",
      "    (residuals): ModuleList()\n",
      "  )\n",
      "  (task1_fc1_c0): SparseChem_Classification_Module(\n",
      "    (linear): Linear(in_features=1000, out_features=100, bias=True)\n",
      "  )\n",
      ")}\n",
      "\n",
      "----------------\n",
      "optimizers     :\n",
      "----------------\n",
      " {'weights': Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      "), 'alphas': Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0005\n",
      ")}\n",
      "\n",
      "----------------\n",
      "schedulers     :\n",
      "----------------\n",
      "factor                        : 0.75 \n",
      "optimizer                     : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0005\n",
      ") \n",
      "min_lrs                       : [0] \n",
      "patience                      : 50 \n",
      "verbose                       : True \n",
      "cooldown                      : 0 \n",
      "cooldown_counter              : 0 \n",
      "mode                          : min \n",
      "threshold                     : 0.0001 \n",
      "threshold_mode                : rel \n",
      "best                          : inf \n",
      "num_bad_epochs                : 0 \n",
      "mode_worse                    : inf \n",
      "eps                           : 1e-08 \n",
      "last_epoch                    : 0 \n",
      "factor                        : 0.3 \n",
      "optimizer                     : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ") \n",
      "min_lrs                       : [0, 0] \n",
      "patience                      : 10.0 \n",
      "verbose                       : True \n",
      "cooldown                      : 0 \n",
      "cooldown_counter              : 0 \n",
      "mode                          : min \n",
      "threshold                     : 0.0001 \n",
      "threshold_mode                : rel \n",
      "best                          : inf \n",
      "num_bad_epochs                : 0 \n",
      "mode_worse                    : inf \n",
      "eps                           : 1e-08 \n",
      "last_epoch                    : 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "environ = init_environment(ns, opt, is_train = True, policy_learning = False, display_cfg = True)\n",
    "# environ.define_optimizer(policy_learning=False)\n",
    "# environ.define_scheduler(policy_learning=False)\n",
    "\n",
    "# environ.optimizers['weights'].param_groups[0]\n",
    "# print(environ.print_configuration())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84dff3ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:14:33.627253Z",
     "start_time": "2022-06-15T17:14:33.532641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.000447, -0.000642]], requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(environ.networks['mtl-net']._arch_parameters)\n",
    "print()\n",
    "pp.pprint(environ.networks['mtl-net'].__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7feeb05a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:47:33.437614Z",
     "start_time": "2022-06-15T17:47:33.366119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict([('task1_logits',\n",
       "               Parameter containing:\n",
       "               tensor([[-0.000447, -0.000642]], requires_grad=True))]),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict([(0,\n",
       "               <function wandb.wandb_torch.TorchHistory.add_log_hooks_to_pytorch_module.<locals>.<lambda>(mod, inp, outp)>)]),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('backbone',\n",
       "               SparseChem_Backbone(\n",
       "                 (Input_Layer): Sequential(\n",
       "                   (linear): SparseLinear(in_features=32000, out_features=1000, bias=True)\n",
       "                   (non_linear): ReLU()\n",
       "                   (dropout): Dropout(p=0.45, inplace=False)\n",
       "                 )\n",
       "                 (blocks): ModuleList()\n",
       "                 (residuals): ModuleList()\n",
       "               )),\n",
       "              ('task1_fc1_c0',\n",
       "               SparseChem_Classification_Module(\n",
       "                 (linear): Linear(in_features=1000, out_features=100, bias=True)\n",
       "               ))]),\n",
       " 'num_tasks': 1,\n",
       " 'verbose': False,\n",
       " 'layers': [1],\n",
       " 'num_layers': 1,\n",
       " 'skip_layer': 0,\n",
       " 'init_method': 'random',\n",
       " 'init_neg_logits': None,\n",
       " '_arch_parameters': [Parameter containing:\n",
       "  tensor([[-0.000447, -0.000642]], requires_grad=True)],\n",
       " 'logits': [Parameter containing:\n",
       "  tensor([[-0.000447, -0.000642]], requires_grad=True)],\n",
       " 'policys': [None],\n",
       " '_wandb_hook_names': ['parameters/',\n",
       "  'gradients/task1_logits',\n",
       "  'gradients/backbone.Input_Layer.linear.weight',\n",
       "  'gradients/backbone.Input_Layer.linear.bias',\n",
       "  'gradients/task1_fc1_c0.linear.weight',\n",
       "  'gradients/task1_fc1_c0.linear.bias']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = environ.get_task_logits(0,verbose=True)\n",
    "print(d.data)\n",
    "# d = environ.get_task_logits(0,verbose=True)\n",
    "# print(type(d))\n",
    "# print(d.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "668e4b2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:47:35.436798Z",
     "start_time": "2022-06-15T17:47:35.367139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:47:35:400296 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:47:35:401120 -  get_task_logits() end\n"
     ]
    }
   ],
   "source": [
    "d = environ.get_task_logits(0,verbose=True)\n",
    "\n",
    "print(d.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d738062",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Initiate / Resume Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "554ff58d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:14:33.981525Z",
     "start_time": "2022-06-15T17:14:33.890099Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ns.wandb_run.finish()\n",
    "# check_for_resume_training(ns, opt, environ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7774f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8b6afdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:14:35.495723Z",
     "start_time": "2022-06-15T17:14:33.985041Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training preparation: - check for CUDA - cuda available as device id: [0]\n",
      " training preparation: - set print_freq to length of train loader: 115\n",
      " training preparation: - set eval_iters to length of val loader : 30\n",
      " training preparation: - set number of batches per weight training epoch to: 115\n",
      " training preparation: - set number of batches per policy training epoch to: 115\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "    folder: 1000x1_0615_1914_lr0.001_do0.45_skip_hdn\n",
      "    layers: 1 [1000] \n",
      "    \n",
      "    first dropout          : 0.45\n",
      "    middle dropout         : 0.45\n",
      "    last dropout           : 0.45\n",
      "    diff_sparsity_weights  : False\n",
      "    skip_layer             : 0\n",
      "    is_curriculum          : False\n",
      "    curriculum_speed       : 3\n",
      "    \n",
      "    task_lr                : 0.001\n",
      "    backbone_lr            : 0.001\n",
      "    decay_lr_rate          : 0.3\n",
      "    decay_lr_freq          : 10.0\n",
      "    \n",
      "    policy_lr              : 0.001\n",
      "    policy_decay_lr_rate   : 0.75\n",
      "    policy_decay_lr_freq   : 50\n",
      "    lambda_sparsity        : 0.02\n",
      "    lambda_sharing         : 0.01\n",
      "    lambda_tasks           : 1\n",
      "    \n",
      "    Gumbel init_temp       : 4\n",
      "    Gumbel decay_temp      : 0.965\n",
      "    Gumbel decay_temp_freq : 16\n",
      "    Logit init_method      : random\n",
      "    Logit init_neg_logits  : None\n",
      "    Logit hard_sampling    : False\n",
      "    Warm-up epochs         : 10\n",
      "    training epochs        : 250\n",
      "    Data split ratios      : [0.725, 0.225, 0.05]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_prep(ns, opt, environ, dldrs)\n",
    "\n",
    "# print('-'*80)\n",
    "# disp_info_1(ns, opt, environ)\n",
    "\n",
    "print('-'*80)\n",
    "print(environ.disp_for_excel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278d6d1",
   "metadata": {},
   "source": [
    "## Warmup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92380a48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:14:35.594281Z",
     "start_time": "2022-06-15T17:14:35.500828Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      " Last Epoch: 0   # of warm-up epochs to do:  2 - Run epochs 1 to 2\n",
      "---------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# environ.display_trained_policy(ns.current_epoch,out=sys.stdout)\n",
    "# ns.check_for_improvment_wait = 0\n",
    "ns.warmup_epochs = 2\n",
    "print_heading(f\" Last Epoch: {ns.current_epoch}   # of warm-up epochs to do:  {ns.warmup_epochs} - Run epochs {ns.current_epoch+1} to {ns.current_epoch + ns.warmup_epochs}\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bd29e74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:16:22.963594Z",
     "start_time": "2022-06-15T17:14:53.107472Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      " Last Epoch: 0   # of warm-up epochs to do:  2 - Run epochs 1 to 2\n",
      "---------------------------------------------------------------------- \n",
      "\n",
      " 2022-06-15 19:14:53:436741 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:53:436941 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:53:437006 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:54:315610 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:54:322383 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:54:322441 -  compute_losses() start \n",
      " 2022-06-15 19:14:54:323495 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:54:323666 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:54:323774 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:54:325067 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:54:325116 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:54:330264 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:54:330496 -  compute_losses() end \n",
      " 2022-06-15 19:14:54:519918 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:54:520754 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:54:520895 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:54:523032 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:54:533236 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:54:533431 -  compute_losses() start \n",
      " 2022-06-15 19:14:54:536590 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:54:536754 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:54:536810 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:54:538776 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:54:538813 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:54:539565 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:54:539728 -  compute_losses() end \n",
      " 2022-06-15 19:14:54:632306 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:54:632519 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:54:632598 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:54:634394 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:54:643972 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:54:644012 -  compute_losses() start \n",
      " 2022-06-15 19:14:54:645660 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:54:645750 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:54:645792 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:54:646819 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:54:646849 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:54:647254 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:54:647342 -  compute_losses() end \n",
      " 2022-06-15 19:14:54:739621 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:54:739979 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:54:740088 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:54:742441 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:54:752344 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:54:752457 -  compute_losses() start \n",
      " 2022-06-15 19:14:54:756042 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:54:756278 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:54:756418 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:54:758581 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:54:758615 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:54:759041 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:54:759134 -  compute_losses() end \n",
      " 2022-06-15 19:14:54:850119 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:54:850412 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:54:850511 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:54:852403 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:54:863523 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:54:863578 -  compute_losses() start \n",
      " 2022-06-15 19:14:54:865438 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:54:865553 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:54:865607 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:54:866755 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:54:866856 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:54:867719 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:54:867971 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:14:54:960394 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:54:960680 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:54:960738 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:54:964020 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:54:974009 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:54:974052 -  compute_losses() start \n",
      " 2022-06-15 19:14:54:975291 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:54:975412 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:54:975474 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:54:976120 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:54:976150 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:54:976550 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:54:976639 -  compute_losses() end \n",
      " 2022-06-15 19:14:55:069970 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:55:070081 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:55:070124 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:55:071778 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:55:080024 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:55:080076 -  compute_losses() start \n",
      " 2022-06-15 19:14:55:082147 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:55:082234 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:55:082276 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:55:084923 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:55:085059 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:55:086336 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:55:086731 -  compute_losses() end \n",
      " 2022-06-15 19:14:55:178084 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:55:178326 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:55:178411 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:55:180503 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:55:191487 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:55:191534 -  compute_losses() start \n",
      " 2022-06-15 19:14:55:193806 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:55:193883 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:55:193923 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:55:194771 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:55:194838 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:55:195711 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:55:195877 -  compute_losses() end \n",
      " 2022-06-15 19:14:55:287499 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:55:287681 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:55:287773 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:55:289589 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:55:299798 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:55:299843 -  compute_losses() start \n",
      " 2022-06-15 19:14:55:301517 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:55:301594 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:55:301636 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:55:303177 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:55:303224 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:55:303756 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:55:303852 -  compute_losses() end \n",
      " 2022-06-15 19:14:55:394763 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:55:395161 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:55:395231 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:55:397200 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:55:902665 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:55:902711 -  compute_losses() start \n",
      " 2022-06-15 19:14:55:903382 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:55:903446 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:55:903556 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:55:904205 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:55:904237 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:55:904732 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:55:904825 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:14:56:931691 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:56:931985 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:56:932101 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:56:934592 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:56:946944 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:56:947077 -  compute_losses() start \n",
      " 2022-06-15 19:14:56:951330 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:56:951470 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:56:951565 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:56:953272 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:56:953335 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:56:954186 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:56:954435 -  compute_losses() end \n",
      " 2022-06-15 19:14:57:047959 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:57:048138 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:57:048212 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:57:051286 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:57:062061 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:57:062159 -  compute_losses() start \n",
      " 2022-06-15 19:14:57:064387 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:57:064514 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:57:064570 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:57:065462 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:57:065499 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:57:066064 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:57:066240 -  compute_losses() end \n",
      " 2022-06-15 19:14:57:158701 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:57:159012 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:57:159115 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:57:160837 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:57:172866 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:57:173015 -  compute_losses() start \n",
      " 2022-06-15 19:14:57:174591 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:57:174709 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:57:174773 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:57:175819 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:57:175867 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:57:176416 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:57:176532 -  compute_losses() end \n",
      " 2022-06-15 19:14:57:285342 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:57:285593 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:57:285668 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:57:287672 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:57:298679 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:57:298738 -  compute_losses() start \n",
      " 2022-06-15 19:14:57:301466 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:57:301592 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:57:301661 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:57:303363 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:57:303409 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:57:304067 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:57:304198 -  compute_losses() end \n",
      " 2022-06-15 19:14:57:395764 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:57:396137 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:57:396301 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:57:399068 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:57:408727 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:57:408776 -  compute_losses() start \n",
      " 2022-06-15 19:14:57:411596 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:57:411713 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:57:411764 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:57:417981 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:57:418519 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:57:419517 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:57:420021 -  compute_losses() end \n",
      " 2022-06-15 19:14:57:511589 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:57:511796 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:57:511870 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:57:513675 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:57:521906 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:57:522049 -  compute_losses() start \n",
      " 2022-06-15 19:14:57:525856 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:57:525991 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:57:526064 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:57:526970 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:57:527004 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:57:527438 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:57:527558 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:14:57:619343 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:57:619764 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:57:619841 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:57:622173 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:57:630946 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:57:630988 -  compute_losses() start \n",
      " 2022-06-15 19:14:57:633300 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:57:633536 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:57:633616 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:57:635047 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:57:635078 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:57:635649 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:57:635744 -  compute_losses() end \n",
      " 2022-06-15 19:14:57:727048 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:57:727237 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:57:727288 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:57:729143 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:57:737644 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:57:737689 -  compute_losses() start \n",
      " 2022-06-15 19:14:57:739545 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:57:739647 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:57:739690 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:57:740391 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:57:740424 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:57:740857 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:57:740947 -  compute_losses() end \n",
      " 2022-06-15 19:14:57:837273 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:57:837518 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:57:837578 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:57:840496 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:57:850057 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:57:850142 -  compute_losses() start \n",
      " 2022-06-15 19:14:57:852861 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:57:853168 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:57:853294 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:57:854735 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:57:854779 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:57:855419 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:57:855628 -  compute_losses() end \n",
      " 2022-06-15 19:14:57:947988 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:57:948260 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:57:948323 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:57:950160 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:58:355766 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:58:355854 -  compute_losses() start \n",
      " 2022-06-15 19:14:58:356963 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:58:357087 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:58:357205 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:58:358453 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:58:358526 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:58:359281 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:58:359482 -  compute_losses() end \n",
      " 2022-06-15 19:14:59:466995 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:59:467263 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:59:467311 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:59:469422 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:59:479500 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:59:479557 -  compute_losses() start \n",
      " 2022-06-15 19:14:59:480494 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:59:480626 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:59:480684 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:59:481559 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:59:481589 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:59:482060 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:59:482164 -  compute_losses() end \n",
      " 2022-06-15 19:14:59:572864 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:59:573018 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:59:573063 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:59:574578 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:59:582415 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:59:582456 -  compute_losses() start \n",
      " 2022-06-15 19:14:59:583828 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:59:583911 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:59:583953 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:59:584550 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:59:584579 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:59:584922 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:59:585009 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:14:59:676057 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:59:676277 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:59:676338 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:59:678162 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:59:686499 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:59:686578 -  compute_losses() start \n",
      " 2022-06-15 19:14:59:688240 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:59:688434 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:59:688523 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:59:690958 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:59:691025 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:59:691587 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:59:691710 -  compute_losses() end \n",
      " 2022-06-15 19:14:59:783376 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:59:783538 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:59:783622 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:59:785514 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:59:797274 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:59:797331 -  compute_losses() start \n",
      " 2022-06-15 19:14:59:799089 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:59:799170 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:59:799212 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:59:799865 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:59:799922 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:59:800401 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:59:800490 -  compute_losses() end \n",
      " 2022-06-15 19:14:59:891779 - SparseChem network optimize() start \n",
      " 2022-06-15 19:14:59:892120 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:14:59:892179 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:14:59:897050 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:14:59:906066 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:14:59:906121 -  compute_losses() start \n",
      " 2022-06-15 19:14:59:906758 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:14:59:906867 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:14:59:907033 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:14:59:909317 -  get_sharing_loss() END  \n",
      "2022-06-15 19:14:59:909408 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:14:59:910115 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:14:59:910319 -  compute_losses() end \n",
      " 2022-06-15 19:15:00:002233 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:00:002404 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:00:002474 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:00:004625 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:00:017838 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:00:017952 -  compute_losses() start \n",
      " 2022-06-15 19:15:00:019288 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:00:019462 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:00:019560 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:00:021118 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:00:021226 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:00:022101 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:00:022288 -  compute_losses() end \n",
      " 2022-06-15 19:15:00:114425 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:00:114728 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:00:114813 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:00:116830 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:00:125249 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:00:125296 -  compute_losses() start \n",
      " 2022-06-15 19:15:00:127026 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:00:127156 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:00:127250 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:00:130958 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:00:131021 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:00:131537 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:00:131646 -  compute_losses() end \n",
      " 2022-06-15 19:15:00:226104 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:00:226352 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:00:226446 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:00:230124 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:00:243655 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:00:243760 -  compute_losses() start \n",
      " 2022-06-15 19:15:00:245625 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:00:245808 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:00:245942 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:00:247642 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:00:247732 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:00:248511 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:00:248784 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:00:342690 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:00:343246 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:00:343390 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:00:347346 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:00:359364 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:00:359445 -  compute_losses() start \n",
      " 2022-06-15 19:15:00:362511 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:00:362671 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:00:362756 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:00:364495 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:00:364581 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:00:369896 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:00:370931 -  compute_losses() end \n",
      " 2022-06-15 19:15:00:509819 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:00:510135 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:00:510346 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:00:515890 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:01:046113 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:01:046196 -  compute_losses() start \n",
      " 2022-06-15 19:15:01:047438 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:01:047560 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:01:047660 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:01:048892 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:01:048956 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:01:049732 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:01:049926 -  compute_losses() end \n",
      " 2022-06-15 19:15:02:131728 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:02:131949 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:02:132019 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:02:133941 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:02:145834 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:02:145900 -  compute_losses() start \n",
      " 2022-06-15 19:15:02:148174 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:02:148329 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:02:148408 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:02:149667 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:02:149716 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:02:150240 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:02:150548 -  compute_losses() end \n",
      " 2022-06-15 19:15:02:247858 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:02:248103 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:02:248199 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:02:250054 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:02:259621 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:02:261059 -  compute_losses() start \n",
      " 2022-06-15 19:15:02:264404 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:02:264654 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:02:264768 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:02:266693 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:02:266760 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:02:267401 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:02:267678 -  compute_losses() end \n",
      " 2022-06-15 19:15:02:359510 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:02:359791 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:02:359879 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:02:363351 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:02:371745 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:02:371791 -  compute_losses() start \n",
      " 2022-06-15 19:15:02:374051 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:02:374157 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:02:374241 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:02:375826 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:02:375907 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:02:376428 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:02:376600 -  compute_losses() end \n",
      " 2022-06-15 19:15:02:467735 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:02:467958 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:02:468008 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:02:469824 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:02:478957 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:02:478998 -  compute_losses() start \n",
      " 2022-06-15 19:15:02:481295 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:02:481566 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:02:481662 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:02:482987 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:02:483017 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:02:483366 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:02:483483 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:02:574486 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:02:574753 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:02:574802 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:02:576258 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:02:582602 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:02:582687 -  compute_losses() start \n",
      " 2022-06-15 19:15:02:584685 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:02:584811 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:02:584864 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:02:591618 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:02:591706 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:02:592610 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:02:592793 -  compute_losses() end \n",
      " 2022-06-15 19:15:02:684077 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:02:684256 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:02:684331 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:02:686648 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:02:693920 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:02:694093 -  compute_losses() start \n",
      " 2022-06-15 19:15:02:696826 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:02:697067 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:02:697196 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:02:701328 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:02:701516 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:02:702816 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:02:703163 -  compute_losses() end \n",
      " 2022-06-15 19:15:02:795843 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:02:796129 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:02:796202 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:02:798640 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:02:812126 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:02:812197 -  compute_losses() start \n",
      " 2022-06-15 19:15:02:813569 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:02:813749 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:02:813958 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:02:816448 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:02:816525 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:02:817060 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:02:817183 -  compute_losses() end \n",
      " 2022-06-15 19:15:02:908519 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:02:908640 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:02:908687 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:02:910036 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:02:920071 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:02:920256 -  compute_losses() start \n",
      " 2022-06-15 19:15:02:923485 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:02:923621 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:02:923761 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:02:924884 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:02:925025 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:02:925425 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:02:925528 -  compute_losses() end \n",
      " 2022-06-15 19:15:03:043412 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:03:043792 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:03:043850 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:03:053897 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:03:062747 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:03:062839 -  compute_losses() start \n",
      " 2022-06-15 19:15:03:065244 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:03:065558 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:03:065659 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:03:067883 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:03:067952 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:03:069114 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:03:069269 -  compute_losses() end \n",
      " 2022-06-15 19:15:03:161050 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:03:161290 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:03:161437 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:03:163685 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:03:520102 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:03:520191 -  compute_losses() start \n",
      " 2022-06-15 19:15:03:521430 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:03:521572 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:03:521689 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:03:522902 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:03:522966 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:03:523594 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:03:523700 -  compute_losses() end \n",
      " 2022-06-15 19:15:04:638740 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:04:638992 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:04:639038 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:04:641355 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:04:650297 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:04:650340 -  compute_losses() start \n",
      " 2022-06-15 19:15:04:651913 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:04:652012 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:04:652055 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:04:652662 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:04:652727 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:04:653165 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:04:653253 -  compute_losses() end \n",
      " 2022-06-15 19:15:04:744393 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:04:744528 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:04:744571 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:04:746602 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:04:754557 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:04:754629 -  compute_losses() start \n",
      " 2022-06-15 19:15:04:756828 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:04:756913 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:04:756959 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:04:757608 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:04:757638 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:04:758223 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:04:758320 -  compute_losses() end \n",
      " 2022-06-15 19:15:04:849742 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:04:849985 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:04:850036 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:04:852133 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:04:861652 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:04:861798 -  compute_losses() start \n",
      " 2022-06-15 19:15:04:865606 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:04:865768 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:04:865821 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:04:867135 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:04:867171 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:04:867795 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:04:867902 -  compute_losses() end \n",
      " 2022-06-15 19:15:04:959294 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:04:959435 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:04:959478 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:04:961330 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:04:970974 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:04:971040 -  compute_losses() start \n",
      " 2022-06-15 19:15:04:973433 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:04:973522 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:04:973564 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:04:974218 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:04:974248 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:04:974622 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:04:974740 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:05:065903 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:05:066142 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:05:066195 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:05:068483 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:05:108131 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:05:108176 -  compute_losses() start \n",
      " 2022-06-15 19:15:05:109308 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:05:109414 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:05:109455 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:05:110095 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:05:110125 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:05:110496 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:05:110585 -  compute_losses() end \n",
      " 2022-06-15 19:15:05:202121 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:05:202262 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:05:202310 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:05:204131 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:05:213121 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:05:213165 -  compute_losses() start \n",
      " 2022-06-15 19:15:05:213924 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:05:214018 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:05:214075 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:05:214665 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:05:214720 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:05:215226 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:05:215319 -  compute_losses() end \n",
      " 2022-06-15 19:15:05:307209 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:05:307581 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:05:307663 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:05:310805 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:05:319289 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:05:319348 -  compute_losses() start \n",
      " 2022-06-15 19:15:05:321083 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:05:321204 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:05:321309 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:05:330568 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:05:330626 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:05:331571 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:05:331861 -  compute_losses() end \n",
      " 2022-06-15 19:15:05:423957 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:05:424120 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:05:424175 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:05:426079 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:05:433869 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:05:433912 -  compute_losses() start \n",
      " 2022-06-15 19:15:05:435627 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:05:435747 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:05:435794 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:05:436405 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:05:436435 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:05:436826 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:05:436915 -  compute_losses() end \n",
      " 2022-06-15 19:15:05:527158 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:05:527391 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:05:527482 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:05:529567 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:05:540510 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:05:540572 -  compute_losses() start \n",
      " 2022-06-15 19:15:05:542104 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:05:542232 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:05:542276 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:05:543467 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:05:543499 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:05:544108 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:05:544266 -  compute_losses() end \n",
      " 2022-06-15 19:15:05:636151 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:05:636276 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:05:636321 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:05:639039 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:05:928964 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:05:929010 -  compute_losses() start \n",
      " 2022-06-15 19:15:05:929703 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:05:929765 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:05:929806 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:05:930417 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:05:930448 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:05:930921 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:05:931014 -  compute_losses() end \n",
      " 2022-06-15 19:15:06:991993 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:06:992211 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:06:992266 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:06:994031 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:07:003267 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:07:003321 -  compute_losses() start \n",
      " 2022-06-15 19:15:07:005756 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:07:005976 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:07:006026 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:07:008427 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:07:008461 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:07:009087 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:07:009204 -  compute_losses() end \n",
      " 2022-06-15 19:15:07:100893 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:07:101064 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:07:101121 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:07:102707 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:07:110071 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:07:110144 -  compute_losses() start \n",
      " 2022-06-15 19:15:07:113375 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:07:113502 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:07:113548 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:07:118368 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:07:118491 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:07:119340 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:07:119461 -  compute_losses() end \n",
      " 2022-06-15 19:15:07:210865 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:07:211146 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:07:211198 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:07:213281 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:07:226392 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:07:226434 -  compute_losses() start \n",
      " 2022-06-15 19:15:07:227204 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:07:227313 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:07:227355 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:07:227981 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:07:228017 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:07:228361 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:07:228448 -  compute_losses() end \n",
      " 2022-06-15 19:15:07:319191 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:07:319312 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:07:319360 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:07:321041 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:07:331887 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:07:331981 -  compute_losses() start \n",
      " 2022-06-15 19:15:07:336718 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:07:336828 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:07:336883 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:07:339100 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:07:339139 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:07:339968 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:07:340091 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:07:432465 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:07:432960 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:07:433150 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:07:436399 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:07:445992 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:07:446084 -  compute_losses() start \n",
      " 2022-06-15 19:15:07:454757 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:07:454948 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:07:455100 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:07:457136 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:07:457182 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:07:457682 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:07:457802 -  compute_losses() end \n",
      " 2022-06-15 19:15:07:548885 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:07:549025 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:07:549067 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:07:552028 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:07:559100 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:07:559144 -  compute_losses() start \n",
      " 2022-06-15 19:15:07:560966 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:07:561090 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:07:561154 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:07:563551 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:07:563587 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:07:564090 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:07:564185 -  compute_losses() end \n",
      " 2022-06-15 19:15:07:656572 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:07:656856 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:07:656939 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:07:659424 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:07:744916 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:07:744985 -  compute_losses() start \n",
      " 2022-06-15 19:15:07:747624 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:07:747735 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:07:747816 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:07:748817 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:07:748862 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:07:749594 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:07:749751 -  compute_losses() end \n",
      " 2022-06-15 19:15:07:841576 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:07:841709 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:07:841761 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:07:843162 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:07:853328 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:07:853378 -  compute_losses() start \n",
      " 2022-06-15 19:15:07:855530 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:07:855622 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:07:855671 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:07:856578 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:07:856630 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:07:857120 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:07:857232 -  compute_losses() end \n",
      " 2022-06-15 19:15:07:949207 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:07:949449 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:07:949543 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:07:951578 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:07:963314 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:07:963363 -  compute_losses() start \n",
      " 2022-06-15 19:15:07:964256 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:07:964374 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:07:964445 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:07:965369 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:07:965402 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:07:965896 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:07:966030 -  compute_losses() end \n",
      " 2022-06-15 19:15:08:057353 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:08:057612 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:08:057723 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:08:060871 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:08:622371 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:08:622436 -  compute_losses() start \n",
      " 2022-06-15 19:15:08:623277 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:08:623410 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:08:623481 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:08:624414 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:08:624449 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:08:625151 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:08:625268 -  compute_losses() end \n",
      " 2022-06-15 19:15:09:664250 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:09:664528 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:09:664617 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:09:666673 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:09:674277 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:09:674321 -  compute_losses() start \n",
      " 2022-06-15 19:15:09:676423 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:09:676529 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:09:676633 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:09:679535 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:09:679599 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:09:680256 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:09:680362 -  compute_losses() end \n",
      " 2022-06-15 19:15:09:771877 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:09:772089 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:09:772186 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:09:774339 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:09:786203 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:09:786333 -  compute_losses() start \n",
      " 2022-06-15 19:15:09:788961 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:09:789080 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:09:789134 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:09:790504 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:09:790559 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:09:791158 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:09:791461 -  compute_losses() end \n",
      " 2022-06-15 19:15:09:883255 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:09:883550 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:09:883603 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:09:886023 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:09:892395 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:09:892438 -  compute_losses() start \n",
      " 2022-06-15 19:15:09:894230 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:09:894322 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:09:894365 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:09:894988 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:09:895018 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:09:895403 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:09:895494 -  compute_losses() end \n",
      " 2022-06-15 19:15:09:986806 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:09:986946 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:09:986998 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:09:988850 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:09:996859 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:09:996938 -  compute_losses() start \n",
      " 2022-06-15 19:15:10:002175 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:10:002286 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:10:002340 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:10:003098 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:10:003131 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:10:005810 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:10:006105 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:10:097522 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:10:097752 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:10:097804 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:10:099517 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:10:106728 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:10:106833 -  compute_losses() start \n",
      " 2022-06-15 19:15:10:108916 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:10:109022 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:10:109087 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:10:110082 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:10:110117 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:10:110645 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:10:110769 -  compute_losses() end \n",
      " 2022-06-15 19:15:10:202283 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:10:202452 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:10:202521 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:10:204013 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:10:211593 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:10:211637 -  compute_losses() start \n",
      " 2022-06-15 19:15:10:213709 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:10:213816 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:10:213865 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:10:215471 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:10:215513 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:10:215980 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:10:216091 -  compute_losses() end \n",
      " 2022-06-15 19:15:10:307441 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:10:307786 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:10:307857 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:10:309633 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:10:316741 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:10:316787 -  compute_losses() start \n",
      " 2022-06-15 19:15:10:320055 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:10:320203 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:10:320316 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:10:321166 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:10:321200 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:10:322102 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:10:322378 -  compute_losses() end \n",
      " 2022-06-15 19:15:10:413966 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:10:414091 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:10:414138 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:10:415736 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:10:423057 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:10:423120 -  compute_losses() start \n",
      " 2022-06-15 19:15:10:466135 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:10:466320 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:10:466388 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:10:470098 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:10:470183 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:10:470932 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:10:471109 -  compute_losses() end \n",
      " 2022-06-15 19:15:10:563265 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:10:563649 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:10:563854 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:10:567983 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:10:575156 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:10:575201 -  compute_losses() start \n",
      " 2022-06-15 19:15:10:577746 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:10:577850 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:10:577899 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:10:578718 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:10:578750 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:10:579134 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:10:579310 -  compute_losses() end \n",
      " 2022-06-15 19:15:10:670404 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:10:670587 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:10:670634 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:10:672302 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:11:114202 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:11:114282 -  compute_losses() start \n",
      " 2022-06-15 19:15:11:115407 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:11:115525 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:11:115623 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:11:116489 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:11:116524 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:11:117104 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:11:117223 -  compute_losses() end \n",
      " 2022-06-15 19:15:12:170325 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:12:171118 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:12:171324 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:12:177272 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:12:183349 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:12:183417 -  compute_losses() start \n",
      " 2022-06-15 19:15:12:186138 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:12:186266 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:12:186315 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:12:187312 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:12:187346 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:12:187828 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:12:187994 -  compute_losses() end \n",
      " 2022-06-15 19:15:12:279630 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:12:279806 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:12:279913 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:12:282309 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:12:291274 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:12:291353 -  compute_losses() start \n",
      " 2022-06-15 19:15:12:292833 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:12:292957 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:12:293027 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:12:294015 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:12:294051 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:12:294522 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:12:294675 -  compute_losses() end \n",
      " 2022-06-15 19:15:12:385835 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:12:386067 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:12:386118 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:12:388000 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:12:399006 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:12:399049 -  compute_losses() start \n",
      " 2022-06-15 19:15:12:401998 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:12:402115 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:12:402164 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:12:403760 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:12:403811 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:12:404668 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:12:404794 -  compute_losses() end \n",
      " 2022-06-15 19:15:12:505996 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:12:506111 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:12:506157 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:12:507857 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:12:515993 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:12:516036 -  compute_losses() start \n",
      " 2022-06-15 19:15:12:518171 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:12:518293 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:12:518334 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:12:520985 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:12:521017 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:12:521605 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:12:521716 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:12:613495 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:12:613707 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:12:613768 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:12:616042 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:12:627733 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:12:627777 -  compute_losses() start \n",
      " 2022-06-15 19:15:12:629074 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:12:629227 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:12:629285 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:12:630093 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:12:630125 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:12:630612 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:12:630722 -  compute_losses() end \n",
      " 2022-06-15 19:15:12:722374 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:12:722527 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:12:722593 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:12:724614 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:12:734375 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:12:734439 -  compute_losses() start \n",
      " 2022-06-15 19:15:12:737074 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:12:737168 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:12:737233 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:12:738707 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:12:738750 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:12:739244 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:12:739374 -  compute_losses() end \n",
      " 2022-06-15 19:15:12:830872 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:12:831208 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:12:831290 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:12:833512 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:12:844372 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:12:844416 -  compute_losses() start \n",
      " 2022-06-15 19:15:12:845888 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:12:846002 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:12:846068 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:12:847345 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:12:847380 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:12:847969 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:12:848129 -  compute_losses() end \n",
      " 2022-06-15 19:15:12:939996 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:12:940119 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:12:940165 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:12:942081 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:12:950104 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:12:950151 -  compute_losses() start \n",
      " 2022-06-15 19:15:12:952316 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:12:952410 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:12:952461 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:12:953167 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:12:953198 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:12:953791 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:12:953910 -  compute_losses() end \n",
      " 2022-06-15 19:15:13:047017 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:13:047329 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:13:047431 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:13:049930 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:13:059839 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:13:060007 -  compute_losses() start \n",
      " 2022-06-15 19:15:13:062976 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:13:063147 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:13:063291 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:13:064032 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:13:064064 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:13:064524 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:13:064623 -  compute_losses() end \n",
      " 2022-06-15 19:15:13:156015 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:13:156145 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:13:156226 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:13:158039 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:13:539089 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:13:539185 -  compute_losses() start \n",
      " 2022-06-15 19:15:13:540594 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:13:540762 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:13:540991 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:13:542267 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:13:542311 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:13:542975 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:13:543085 -  compute_losses() end \n",
      " 2022-06-15 19:15:14:669693 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:14:669930 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:14:669989 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:14:671974 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:14:679911 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:14:679950 -  compute_losses() start \n",
      " 2022-06-15 19:15:14:683463 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:14:683700 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:14:683901 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:14:685811 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:14:685842 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:14:686352 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:14:686461 -  compute_losses() end \n",
      " 2022-06-15 19:15:14:777177 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:14:777319 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:14:777361 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:14:778955 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:14:789233 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:14:789368 -  compute_losses() start \n",
      " 2022-06-15 19:15:14:792299 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:14:792405 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:14:792451 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:14:793107 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:14:793164 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:14:793545 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:14:793636 -  compute_losses() end \n",
      " 2022-06-15 19:15:14:884432 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:14:884707 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:14:884783 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:14:886655 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:14:895942 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:14:895991 -  compute_losses() start \n",
      " 2022-06-15 19:15:14:898964 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:14:899108 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:14:899212 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:14:899892 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:14:899923 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:14:900341 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:14:900440 -  compute_losses() end \n",
      " 2022-06-15 19:15:14:992235 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:14:992346 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:14:992387 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:14:994643 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:15:006314 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:15:006358 -  compute_losses() start \n",
      " 2022-06-15 19:15:15:008333 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:15:008423 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:15:008465 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:15:009081 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:15:009109 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:15:009565 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:15:009657 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:15:103077 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:15:103459 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:15:103580 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:15:105891 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:15:114600 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:15:114658 -  compute_losses() start \n",
      " 2022-06-15 19:15:15:116895 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:15:116978 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:15:117020 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:15:118394 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:15:118429 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:15:119033 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:15:119279 -  compute_losses() end \n",
      " 2022-06-15 19:15:15:210778 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:15:210890 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:15:210932 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:15:212838 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:15:224632 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:15:224690 -  compute_losses() start \n",
      " 2022-06-15 19:15:15:227550 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:15:227714 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:15:227760 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:15:228581 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:15:228611 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:15:229044 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:15:229161 -  compute_losses() end \n",
      " 2022-06-15 19:15:15:319912 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:15:320178 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:15:320255 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:15:322214 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:15:331903 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:15:331997 -  compute_losses() start \n",
      " 2022-06-15 19:15:15:335680 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:15:335796 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:15:335846 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:15:338353 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:15:338388 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:15:338945 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:15:339042 -  compute_losses() end \n",
      " 2022-06-15 19:15:15:431854 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:15:431981 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:15:432044 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:15:433725 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:15:442408 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:15:442467 -  compute_losses() start \n",
      " 2022-06-15 19:15:15:444085 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:15:444216 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:15:444263 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:15:445630 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:15:445661 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:15:446339 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:15:446462 -  compute_losses() end \n",
      " 2022-06-15 19:15:15:537756 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:15:538013 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:15:538068 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:15:539906 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:15:548853 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:15:548903 -  compute_losses() start \n",
      " 2022-06-15 19:15:15:551348 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:15:551564 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:15:551629 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:15:555269 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:15:555358 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:15:557016 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:15:557611 -  compute_losses() end \n",
      " 2022-06-15 19:15:15:648629 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:15:648750 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:15:648799 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:15:650394 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:16:099206 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:16:099279 -  compute_losses() start \n",
      " 2022-06-15 19:15:16:100320 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:16:100430 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:16:100520 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:16:101553 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:16:101612 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:16:102238 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:16:102412 -  compute_losses() end \n",
      " 2022-06-15 19:15:17:172163 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:17:172415 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:17:172476 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:17:174293 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:17:181275 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:17:181316 -  compute_losses() start \n",
      " 2022-06-15 19:15:17:182985 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:17:183063 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:17:183135 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:17:185488 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:17:185544 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:17:186284 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:17:186389 -  compute_losses() end \n",
      " 2022-06-15 19:15:17:277379 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:17:277485 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:17:277527 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:17:279412 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:17:284788 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:17:284828 -  compute_losses() start \n",
      " 2022-06-15 19:15:17:287406 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:17:287492 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:17:287557 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:17:289100 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:17:289143 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:17:289712 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:17:290409 -  compute_losses() end \n",
      " 2022-06-15 19:15:17:387412 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:17:387656 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:17:387720 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:17:389600 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:17:397511 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:17:397567 -  compute_losses() start \n",
      " 2022-06-15 19:15:17:399363 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:17:399468 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:17:399511 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:17:402758 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:17:402816 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:17:403402 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:17:403548 -  compute_losses() end \n",
      " 2022-06-15 19:15:17:495934 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:17:496180 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:17:496244 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:17:498227 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:17:505464 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:17:505514 -  compute_losses() start \n",
      " 2022-06-15 19:15:17:508582 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:17:508665 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:17:508707 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:17:509516 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:17:509547 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:17:509984 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:17:510080 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:17:601130 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:17:601342 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:17:601420 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:17:603153 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:17:614018 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:17:614104 -  compute_losses() start \n",
      " 2022-06-15 19:15:17:617892 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:17:618093 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:17:618177 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:17:619522 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:17:619558 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:17:620121 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:17:620223 -  compute_losses() end \n",
      " 2022-06-15 19:15:17:711667 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:17:711918 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:17:711996 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:17:714364 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:17:723638 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:17:723704 -  compute_losses() start \n",
      " 2022-06-15 19:15:17:726503 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:17:726627 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:17:726699 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:17:728575 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:17:728651 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:17:729446 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:17:729771 -  compute_losses() end \n",
      " 2022-06-15 19:15:17:821812 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:17:822043 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:17:822095 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:17:823538 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:17:830173 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:17:830243 -  compute_losses() start \n",
      " 2022-06-15 19:15:17:832250 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:17:832373 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:17:832448 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:17:835682 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:17:835747 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:17:837000 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:17:837652 -  compute_losses() end \n",
      " 2022-06-15 19:15:17:945796 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:17:945958 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:17:946033 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:17:947901 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:17:957590 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:17:957662 -  compute_losses() start \n",
      " 2022-06-15 19:15:17:961005 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:17:961132 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:17:961203 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:17:964537 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:17:964646 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:17:965252 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:17:965461 -  compute_losses() end \n",
      " 2022-06-15 19:15:18:057245 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:18:057539 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:18:057638 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:18:059473 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:18:077708 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:18:077766 -  compute_losses() start \n",
      " 2022-06-15 19:15:18:078797 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:18:078923 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:18:078991 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:18:080085 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:18:080145 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:18:080839 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:18:081083 -  compute_losses() end \n",
      " 2022-06-15 19:15:18:175774 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:18:175987 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:18:176071 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:18:177809 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:18:585088 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:18:585189 -  compute_losses() start \n",
      " 2022-06-15 19:15:18:586224 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:18:586331 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:18:586420 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:18:587160 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:18:587192 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:18:587681 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:18:587776 -  compute_losses() end \n",
      " 2022-06-15 19:15:19:673757 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:19:673991 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:19:674037 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:19:676087 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:19:685678 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:19:685722 -  compute_losses() start \n",
      " 2022-06-15 19:15:19:686489 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:19:686590 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:19:686636 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:19:687285 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:19:687316 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:19:687700 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:19:687792 -  compute_losses() end \n",
      " 2022-06-15 19:15:19:778982 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:19:779092 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:19:779219 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:19:781300 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:19:790686 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:19:790752 -  compute_losses() start \n",
      " 2022-06-15 19:15:19:793687 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:19:793905 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:19:793969 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:19:795727 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:19:795760 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:19:796395 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:19:796496 -  compute_losses() end \n",
      " 2022-06-15 19:15:19:887964 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:19:888280 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:19:888352 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:19:890661 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:19:899620 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:19:899678 -  compute_losses() start \n",
      " 2022-06-15 19:15:19:901923 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:19:902021 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:19:902066 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:19:904518 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:19:904558 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:19:905091 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:19:905250 -  compute_losses() end \n",
      " 2022-06-15 19:15:19:996728 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:19:996926 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:19:997057 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:19:999315 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:20:008663 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:20:008811 -  compute_losses() start \n",
      " 2022-06-15 19:15:20:011239 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:20:011358 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:20:011561 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:20:012675 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:20:012730 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:20:013426 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:20:013618 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:20:105243 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:20:105491 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:20:105553 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:20:107310 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:20:115029 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:20:115075 -  compute_losses() start \n",
      " 2022-06-15 19:15:20:118237 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:20:118442 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:20:118546 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:20:119914 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:20:120005 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:20:120885 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:20:121252 -  compute_losses() end \n",
      " 2022-06-15 19:15:20:213180 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:20:213304 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:20:213346 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:20:215469 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:20:226780 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:20:226834 -  compute_losses() start \n",
      " 2022-06-15 19:15:20:229324 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:20:229422 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:20:229466 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:20:230133 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:20:230229 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:20:230619 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:20:230716 -  compute_losses() end \n",
      " 2022-06-15 19:15:20:323001 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:20:323304 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:20:323353 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:20:324863 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:20:331591 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:20:331639 -  compute_losses() start \n",
      " 2022-06-15 19:15:20:335072 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:20:335232 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:20:335287 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:20:339305 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:20:339350 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:20:340179 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:20:340382 -  compute_losses() end \n",
      " 2022-06-15 19:15:20:432179 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:20:432322 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:20:432375 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:20:434898 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:20:444016 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:20:444059 -  compute_losses() start \n",
      " 2022-06-15 19:15:20:444761 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:20:444825 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:20:444868 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:20:445699 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:20:445733 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:20:446208 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:20:446306 -  compute_losses() end \n",
      " 2022-06-15 19:15:20:537291 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:20:537527 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:20:537591 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:20:539343 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:20:550725 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:20:550774 -  compute_losses() start \n",
      " 2022-06-15 19:15:20:552270 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:20:552429 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:20:552494 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:20:553181 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:20:553211 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:20:553602 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:20:553696 -  compute_losses() end \n",
      " 2022-06-15 19:15:20:644652 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:20:644767 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:20:644827 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:20:646645 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:21:008698 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:21:008781 -  compute_losses() start \n",
      " 2022-06-15 19:15:21:009783 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:21:009937 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:21:010039 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:21:012060 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:21:012127 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:21:013253 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:21:013546 -  compute_losses() end \n",
      " 2022-06-15 19:15:22:008136 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:22:008439 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:22:008494 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:22:010645 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:22:020261 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:22:020319 -  compute_losses() start \n",
      " 2022-06-15 19:15:22:022021 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:22:022229 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:22:022344 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:22:023654 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:22:023752 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:22:024511 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:22:024697 -  compute_losses() end \n",
      " 2022-06-15 19:15:22:116628 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:22:116756 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:22:116798 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:22:118665 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:22:127479 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:22:127518 -  compute_losses() start \n",
      " 2022-06-15 19:15:22:130111 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:22:130287 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:22:130348 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:22:131359 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:22:131566 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:22:132233 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:22:132326 -  compute_losses() end \n",
      " 2022-06-15 19:15:22:224853 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:22:225131 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:22:225258 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:22:227448 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:22:236654 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:22:236732 -  compute_losses() start \n",
      " 2022-06-15 19:15:22:238048 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:22:238211 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:22:238303 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:22:239900 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:22:239952 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:22:240722 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:22:240915 -  compute_losses() end \n",
      " 2022-06-15 19:15:22:332971 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:22:333100 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:22:333167 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:22:438810 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:22:450018 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:22:450063 -  compute_losses() start \n",
      " 2022-06-15 19:15:22:450840 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:22:450904 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:22:450945 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:22:451737 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:22:451768 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:22:452332 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:22:452468 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:22:696801 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:22:697159 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:22:697224 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:22:700317 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([41, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:22:705921 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:22:705996 -  compute_losses() start \n",
      " 2022-06-15 19:15:22:707667 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:22:707872 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:22:707992 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:22:709745 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:22:709789 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:22:710257 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:22:710416 -  compute_losses() end \n",
      " 2022-06-15 19:15:22:816110 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:22:829583 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:22:844660 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:22:858208 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:22:873852 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:334195 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:352813 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:370457 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:388926 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:405874 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:420508 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:434639 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:447705 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:461080 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:485402 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:861946 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:876649 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:892079 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:907996 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:922399 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:936446 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:949935 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:964792 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:23:979594 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:24:005873 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:24:429099 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:24:446559 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:24:466253 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:24:481700 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:15:24:500975 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " Ep  | Trunk LR  Heads LR  Polcy LR  Gmbl Tmp |  trn tsk    trn spar    trn shar   trn ttl |   logloss   bceloss  avg prec    aucroc     aucpr    f1_max |  val tsk    val spar    val shar     total | time |\n",
      "   1 | 1.00e-03  1.00e-03  1.00e-03  4.00e+00 |   0.3522   3.382e-04   0.000e+00    0.3525 |   0.00002   0.24478   0.93081   0.92167   0.91657   0.93092 |   0.0904   1.155e-04   0.000e+00    0.0905 | 31.8 |\n",
      "Previous best_epoch:     0   best iter:     0,   best_value: 0.00000\n",
      "New      best_epoch:     1   best iter:   115,   best_value: 0.93081\n",
      " 2022-06-15 19:15:25:729129 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:25:729934 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:25:730065 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:25:735735 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:25:748254 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:25:748309 -  compute_losses() start \n",
      " 2022-06-15 19:15:25:749858 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:25:749962 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:25:750031 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:25:750846 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:25:750884 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:25:751760 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:25:751859 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:26:027145 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:26:027408 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:26:027453 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:26:029576 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:26:037576 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:26:037619 -  compute_losses() start \n",
      " 2022-06-15 19:15:26:039385 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:26:039490 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:26:039535 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:26:040298 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:26:040330 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:26:040744 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:26:040870 -  compute_losses() end \n",
      " 2022-06-15 19:15:26:131472 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:26:131613 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:26:131655 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:26:133646 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:26:141948 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:26:141989 -  compute_losses() start \n",
      " 2022-06-15 19:15:26:143895 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:26:144030 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:26:144087 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:26:145828 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:26:145866 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:26:146457 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:26:146639 -  compute_losses() end \n",
      " 2022-06-15 19:15:26:237617 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:26:237856 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:26:237922 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:26:239711 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:26:249041 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:26:249139 -  compute_losses() start \n",
      " 2022-06-15 19:15:26:251294 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:26:251576 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:26:251632 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:26:252862 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:26:252964 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:26:253645 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:26:253777 -  compute_losses() end \n",
      " 2022-06-15 19:15:26:345473 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:26:345593 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:26:345638 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:26:347356 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:26:719213 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:26:719294 -  compute_losses() start \n",
      " 2022-06-15 19:15:26:720549 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:26:720662 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:26:720751 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:26:721868 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:26:721926 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:26:722709 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:26:722898 -  compute_losses() end \n",
      " 2022-06-15 19:15:27:682317 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:27:682549 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:27:682670 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:27:684870 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:27:695816 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:27:695866 -  compute_losses() start \n",
      " 2022-06-15 19:15:27:697437 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:27:697599 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:27:697661 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:27:698694 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:27:698741 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:27:699554 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:27:699833 -  compute_losses() end \n",
      " 2022-06-15 19:15:27:791729 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:27:791912 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:27:791979 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:27:794182 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:27:805468 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:27:805578 -  compute_losses() start \n",
      " 2022-06-15 19:15:27:806544 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:27:806723 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:27:806771 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:27:807609 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:27:807645 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:27:808284 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:27:808534 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:27:901062 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:27:901454 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:27:901569 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:27:903537 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:27:913517 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:27:913611 -  compute_losses() start \n",
      " 2022-06-15 19:15:27:916466 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:27:916574 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:27:916628 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:27:917522 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:27:917565 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:27:918014 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:27:918138 -  compute_losses() end \n",
      " 2022-06-15 19:15:28:009823 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:28:009995 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:28:010071 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:28:012086 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:28:021292 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:28:021344 -  compute_losses() start \n",
      " 2022-06-15 19:15:28:023240 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:28:023349 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:28:023431 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:28:024339 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:28:024421 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:28:024991 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:28:025304 -  compute_losses() end \n",
      " 2022-06-15 19:15:28:116428 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:28:116669 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:28:116718 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:28:118229 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:28:126293 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:28:126344 -  compute_losses() start \n",
      " 2022-06-15 19:15:28:129883 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:28:130180 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:28:130342 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:28:132100 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:28:132160 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:28:132746 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:28:132866 -  compute_losses() end \n",
      " 2022-06-15 19:15:28:223416 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:28:223560 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:28:223605 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:28:225714 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:28:234676 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:28:234717 -  compute_losses() start \n",
      " 2022-06-15 19:15:28:236679 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:28:236809 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:28:236858 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:28:237542 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:28:237573 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:28:237958 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:28:238050 -  compute_losses() end \n",
      " 2022-06-15 19:15:28:329095 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:28:329443 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:28:329584 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:28:332189 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:28:341197 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:28:341271 -  compute_losses() start \n",
      " 2022-06-15 19:15:28:344843 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:28:344994 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:28:345063 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:28:347111 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:28:347163 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:28:347839 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:28:348104 -  compute_losses() end \n",
      " 2022-06-15 19:15:28:439896 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:28:440035 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:28:440124 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:28:441815 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:28:449458 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:28:449534 -  compute_losses() start \n",
      " 2022-06-15 19:15:28:451419 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:28:451657 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:28:451781 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:28:453002 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:28:453033 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:28:453640 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:28:453737 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:28:546652 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:28:547199 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:28:547416 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:28:550388 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:28:563449 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:28:563595 -  compute_losses() start \n",
      " 2022-06-15 19:15:28:565240 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:28:565369 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:28:565415 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:28:566708 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:28:566759 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:28:567377 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:28:567584 -  compute_losses() end \n",
      " 2022-06-15 19:15:28:659276 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:28:659412 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:28:659471 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:28:663049 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:29:035040 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:29:035092 -  compute_losses() start \n",
      " 2022-06-15 19:15:29:035816 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:29:035893 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:29:035939 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:29:037307 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:29:037381 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:29:038752 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:29:039023 -  compute_losses() end \n",
      " 2022-06-15 19:15:30:016949 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:30:017211 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:30:017281 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:30:019436 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:30:030024 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:30:030069 -  compute_losses() start \n",
      " 2022-06-15 19:15:30:031330 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:30:031521 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:30:031586 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:30:032942 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:30:032997 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:30:033598 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:30:033823 -  compute_losses() end \n",
      " 2022-06-15 19:15:30:143209 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:30:143324 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:30:143371 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:30:145325 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:30:150594 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:30:150653 -  compute_losses() start \n",
      " 2022-06-15 19:15:30:151286 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:30:151358 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:30:151479 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:30:152314 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:30:152347 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:30:152745 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:30:152847 -  compute_losses() end \n",
      " 2022-06-15 19:15:30:243559 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:30:243787 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:30:243841 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:30:245883 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:30:258037 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:30:258162 -  compute_losses() start \n",
      " 2022-06-15 19:15:30:259137 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:30:259253 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:30:259302 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:30:260044 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:30:260077 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:30:260683 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:30:260904 -  compute_losses() end \n",
      " 2022-06-15 19:15:30:353114 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:30:353249 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:30:353301 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:30:355134 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:30:365890 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:30:365954 -  compute_losses() start \n",
      " 2022-06-15 19:15:30:367383 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:30:367470 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:30:367517 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:30:368462 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:30:368495 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:30:368897 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:30:369025 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:30:460935 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:30:461153 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:30:461207 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:30:463502 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:30:475651 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:30:475715 -  compute_losses() start \n",
      " 2022-06-15 19:15:30:477478 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:30:477591 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:30:477706 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:30:478614 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:30:478704 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:30:479592 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:30:479815 -  compute_losses() end \n",
      " 2022-06-15 19:15:30:573237 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:30:573587 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:30:573738 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:30:576299 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:30:587794 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:30:587934 -  compute_losses() start \n",
      " 2022-06-15 19:15:30:588956 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:30:589056 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:30:589106 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:30:590066 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:30:590104 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:30:590710 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:30:590849 -  compute_losses() end \n",
      " 2022-06-15 19:15:30:682579 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:30:682841 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:30:682917 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:30:684994 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:30:693681 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:30:693849 -  compute_losses() start \n",
      " 2022-06-15 19:15:30:696955 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:30:697114 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:30:697228 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:30:698456 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:30:698514 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:30:699247 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:30:699501 -  compute_losses() end \n",
      " 2022-06-15 19:15:30:791873 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:30:792010 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:30:792062 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:30:794242 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:30:805170 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:30:805221 -  compute_losses() start \n",
      " 2022-06-15 19:15:30:806597 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:30:806694 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:30:806738 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:30:807508 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:30:807539 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:30:807984 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:30:808078 -  compute_losses() end \n",
      " 2022-06-15 19:15:30:899108 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:30:899341 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:30:899392 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:30:901216 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:30:909002 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:30:909050 -  compute_losses() start \n",
      " 2022-06-15 19:15:30:911206 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:30:911380 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:30:911430 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:30:912281 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:30:912353 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:30:913220 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:30:913364 -  compute_losses() end \n",
      " 2022-06-15 19:15:31:005259 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:31:005479 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:31:005565 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:31:007450 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:31:365556 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:31:365651 -  compute_losses() start \n",
      " 2022-06-15 19:15:31:366947 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:31:367086 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:31:367174 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:31:368391 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:31:368461 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:31:369298 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:31:369468 -  compute_losses() end \n",
      " 2022-06-15 19:15:32:390895 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:32:391140 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:32:391200 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:32:393567 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:32:402221 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:32:402269 -  compute_losses() start \n",
      " 2022-06-15 19:15:32:404640 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:32:404752 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:32:404798 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:32:405626 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:32:405660 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:32:406108 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:32:406224 -  compute_losses() end \n",
      " 2022-06-15 19:15:32:497723 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:32:497848 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:32:497892 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:32:499853 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:32:509493 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:32:509545 -  compute_losses() start \n",
      " 2022-06-15 19:15:32:512162 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:32:512309 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:32:512361 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:32:513238 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:32:513273 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:32:513909 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:32:514052 -  compute_losses() end \n",
      " 2022-06-15 19:15:32:605502 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:32:605792 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:32:605878 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:32:608170 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:32:621744 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:32:621900 -  compute_losses() start \n",
      " 2022-06-15 19:15:32:624008 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:32:624241 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:32:624335 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:32:625445 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:32:625485 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:32:625976 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:32:626116 -  compute_losses() end \n",
      " 2022-06-15 19:15:32:718823 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:32:718981 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:32:719053 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:32:720815 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:32:729274 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:32:729352 -  compute_losses() start \n",
      " 2022-06-15 19:15:32:731821 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:32:731984 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:32:732079 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:32:735644 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:32:735707 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:32:736369 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:32:736611 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:32:828165 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:32:828492 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:32:828563 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:32:830675 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:32:838132 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:32:838236 -  compute_losses() start \n",
      " 2022-06-15 19:15:32:840437 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:32:840606 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:32:840706 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:32:843577 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:32:843623 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:32:844248 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:32:844369 -  compute_losses() end \n",
      " 2022-06-15 19:15:32:935970 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:32:936147 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:32:936216 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:32:938541 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:32:947011 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:32:947075 -  compute_losses() start \n",
      " 2022-06-15 19:15:32:949870 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:32:949967 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:32:950030 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:32:951079 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:32:951120 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:32:951679 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:32:951823 -  compute_losses() end \n",
      " 2022-06-15 19:15:33:043188 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:33:043499 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:33:043632 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:33:045234 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:33:051663 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:33:051713 -  compute_losses() start \n",
      " 2022-06-15 19:15:33:054174 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:33:054345 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:33:054473 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:33:057912 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:33:057981 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:33:059224 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:33:059380 -  compute_losses() end \n",
      " 2022-06-15 19:15:33:151690 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:33:151926 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:33:152032 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:33:154694 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:33:165112 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:33:165196 -  compute_losses() start \n",
      " 2022-06-15 19:15:33:167503 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:33:167708 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:33:167797 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:33:168852 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:33:168896 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:33:169426 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:33:169553 -  compute_losses() end \n",
      " 2022-06-15 19:15:33:261240 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:33:261623 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:33:261713 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:33:266876 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:33:274104 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:33:274169 -  compute_losses() start \n",
      " 2022-06-15 19:15:33:275086 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:33:275225 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:33:275292 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:33:276290 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:33:276345 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:33:276926 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:33:277080 -  compute_losses() end \n",
      " 2022-06-15 19:15:33:386577 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:33:387015 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:33:387180 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:33:397181 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:33:791170 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:33:791282 -  compute_losses() start \n",
      " 2022-06-15 19:15:33:792491 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:33:792705 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:33:792799 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:33:794418 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:33:794484 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:33:795360 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:33:795547 -  compute_losses() end \n",
      " 2022-06-15 19:15:34:890214 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:34:890520 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:34:890575 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:34:892025 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:34:896455 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:34:896508 -  compute_losses() start \n",
      " 2022-06-15 19:15:34:898088 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:34:898261 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:34:898395 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:34:901172 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:34:901284 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:34:902717 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:34:903938 -  compute_losses() end \n",
      " 2022-06-15 19:15:35:008629 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:35:008781 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:35:008849 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:35:010583 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:35:017659 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:35:017706 -  compute_losses() start \n",
      " 2022-06-15 19:15:35:019727 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:35:019839 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:35:019946 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:35:023167 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:35:023569 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:35:024388 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:35:024658 -  compute_losses() end \n",
      " 2022-06-15 19:15:35:115996 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:35:116327 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:35:116430 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:35:118713 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:35:125769 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:35:125816 -  compute_losses() start \n",
      " 2022-06-15 19:15:35:129856 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:35:130635 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:35:130845 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:35:132404 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:35:132464 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:35:132930 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:35:133035 -  compute_losses() end \n",
      " 2022-06-15 19:15:35:224021 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:35:224178 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:35:224228 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:35:225548 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:35:232941 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:35:233018 -  compute_losses() start \n",
      " 2022-06-15 19:15:35:236230 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:35:236393 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:35:236482 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:35:239407 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:35:239449 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:35:240005 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:35:240125 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:35:331199 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:35:331686 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:35:331783 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:35:335522 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:35:346177 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:35:346267 -  compute_losses() start \n",
      " 2022-06-15 19:15:35:347708 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:35:347908 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:35:348030 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:35:349895 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:35:350014 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:35:350956 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:35:351302 -  compute_losses() end \n",
      " 2022-06-15 19:15:35:475153 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:35:475418 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:35:475532 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:35:507569 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:35:515372 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:35:515438 -  compute_losses() start \n",
      " 2022-06-15 19:15:35:517541 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:35:517694 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:35:517772 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:35:518923 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:35:518980 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:35:519513 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:35:519823 -  compute_losses() end \n",
      " 2022-06-15 19:15:35:611669 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:35:612000 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:35:612086 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:35:619287 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:35:628383 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:35:628468 -  compute_losses() start \n",
      " 2022-06-15 19:15:35:629622 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:35:629787 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:35:629937 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:35:631151 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:35:631187 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:35:631700 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:35:631921 -  compute_losses() end \n",
      " 2022-06-15 19:15:35:722901 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:35:723070 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:35:723140 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:35:724891 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:35:734611 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:35:734664 -  compute_losses() start \n",
      " 2022-06-15 19:15:35:739476 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:35:739628 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:35:739722 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:35:743868 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:35:743933 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:35:744474 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:35:744608 -  compute_losses() end \n",
      " 2022-06-15 19:15:35:836645 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:35:836972 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:35:837062 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:35:840087 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:35:850194 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:35:850243 -  compute_losses() start \n",
      " 2022-06-15 19:15:35:850998 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:35:851083 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:35:851129 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:35:852015 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:35:852054 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:35:852505 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:35:852628 -  compute_losses() end \n",
      " 2022-06-15 19:15:35:943910 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:35:944131 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:35:944223 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:35:946616 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:36:929833 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:36:930012 -  compute_losses() start \n",
      " 2022-06-15 19:15:36:931542 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:36:931795 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:36:931962 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:36:933195 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:36:933254 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:36:943730 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:36:944194 -  compute_losses() end \n",
      " 2022-06-15 19:15:38:063912 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:38:064321 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:38:064435 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:38:067275 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:38:074173 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:38:074221 -  compute_losses() start \n",
      " 2022-06-15 19:15:38:076631 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:38:076743 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:38:076795 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:38:079041 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:38:079105 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:38:079663 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:38:079855 -  compute_losses() end \n",
      " 2022-06-15 19:15:38:171643 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:38:171826 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:38:171899 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:38:173719 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:38:180529 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:38:180581 -  compute_losses() start \n",
      " 2022-06-15 19:15:38:185216 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:38:185422 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:38:185549 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:38:187524 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:38:187606 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:38:188180 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:38:188319 -  compute_losses() end \n",
      " 2022-06-15 19:15:38:279606 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:38:279831 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:38:279885 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:38:281427 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:38:311581 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:38:311658 -  compute_losses() start \n",
      " 2022-06-15 19:15:38:313772 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:38:313936 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:38:314041 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:38:314852 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:38:314885 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:38:315289 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:38:315408 -  compute_losses() end \n",
      " 2022-06-15 19:15:38:406134 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:38:406306 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:38:406371 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:38:408369 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:38:417246 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:38:417293 -  compute_losses() start \n",
      " 2022-06-15 19:15:38:418825 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:38:418942 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:38:418990 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:38:421184 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:38:421223 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:38:421772 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:38:421874 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:38:513701 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:38:513992 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:38:514075 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:38:516986 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:38:524927 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:38:524976 -  compute_losses() start \n",
      " 2022-06-15 19:15:38:528010 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:38:528235 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:38:528297 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:38:529563 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:38:529636 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:38:530142 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:38:530320 -  compute_losses() end \n",
      " 2022-06-15 19:15:38:621360 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:38:621550 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:38:621605 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:38:623551 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:38:632929 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:38:632979 -  compute_losses() start \n",
      " 2022-06-15 19:15:38:634112 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:38:634271 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:38:634428 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:38:636042 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:38:636118 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:38:636991 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:38:637411 -  compute_losses() end \n",
      " 2022-06-15 19:15:38:728795 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:38:729056 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:38:729138 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:38:730979 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:38:741987 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:38:742323 -  compute_losses() start \n",
      " 2022-06-15 19:15:38:744784 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:38:745097 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:38:745414 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:38:747259 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:38:747374 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:38:748338 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:38:748908 -  compute_losses() end \n",
      " 2022-06-15 19:15:38:840500 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:38:840683 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:38:840757 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:38:842637 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:38:849698 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:38:849768 -  compute_losses() start \n",
      " 2022-06-15 19:15:38:852514 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:38:852674 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:38:852770 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:38:854153 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:38:854214 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:38:854771 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:38:854925 -  compute_losses() end \n",
      " 2022-06-15 19:15:38:949866 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:38:950347 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:38:950481 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:38:953564 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:38:965177 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:38:965316 -  compute_losses() start \n",
      " 2022-06-15 19:15:38:970490 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:38:970837 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:38:971157 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:38:975743 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:38:975870 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:38:977221 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:38:977785 -  compute_losses() end \n",
      " 2022-06-15 19:15:39:070037 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:39:070224 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:39:070303 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:39:072302 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:39:692480 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:39:692703 -  compute_losses() start \n",
      " 2022-06-15 19:15:39:695521 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:39:695732 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:39:695835 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:39:697325 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:39:697393 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:39:698339 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:39:698557 -  compute_losses() end \n",
      " 2022-06-15 19:15:40:746546 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:40:746794 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:40:746889 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:40:748569 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:40:756052 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:40:756107 -  compute_losses() start \n",
      " 2022-06-15 19:15:40:757704 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:40:757783 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:40:757825 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:40:759807 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:40:759839 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:40:760309 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:40:760405 -  compute_losses() end \n",
      " 2022-06-15 19:15:40:851189 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:40:851395 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:40:851499 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:40:853678 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:40:863642 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:40:863688 -  compute_losses() start \n",
      " 2022-06-15 19:15:40:864407 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:40:864513 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:40:864561 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:40:865365 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:40:865397 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:40:865867 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:40:865964 -  compute_losses() end \n",
      " 2022-06-15 19:15:40:973995 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:40:974317 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:40:974370 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:40:977713 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:40:983977 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:40:984020 -  compute_losses() start \n",
      " 2022-06-15 19:15:40:984759 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:40:984838 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:40:984883 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:40:985539 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:40:985573 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:40:985930 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:40:986119 -  compute_losses() end \n",
      " 2022-06-15 19:15:41:076989 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:41:077177 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:41:077235 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:41:079023 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:41:087106 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:41:087147 -  compute_losses() start \n",
      " 2022-06-15 19:15:41:088831 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:41:088947 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:41:088992 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:41:089686 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:41:089718 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:41:090096 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:41:090186 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:41:180875 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:41:181102 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:41:181154 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:41:182893 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:41:190704 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:41:190749 -  compute_losses() start \n",
      " 2022-06-15 19:15:41:193789 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:41:193893 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:41:193938 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:41:195312 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:41:195347 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:41:195904 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:41:196010 -  compute_losses() end \n",
      " 2022-06-15 19:15:41:287599 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:41:287779 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:41:287858 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:41:290954 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:41:300731 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:41:300778 -  compute_losses() start \n",
      " 2022-06-15 19:15:41:301463 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:41:301600 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:41:301642 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:41:302272 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:41:302302 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:41:302720 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:41:302817 -  compute_losses() end \n",
      " 2022-06-15 19:15:41:394403 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:41:394721 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:41:394780 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:41:396605 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:41:407398 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:41:407526 -  compute_losses() start \n",
      " 2022-06-15 19:15:41:409210 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:41:409444 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:41:409591 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:41:410937 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:41:411011 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:41:411810 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:41:412047 -  compute_losses() end \n",
      " 2022-06-15 19:15:41:507568 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:41:507747 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:41:507820 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:41:510474 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:41:518451 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:41:518494 -  compute_losses() start \n",
      " 2022-06-15 19:15:41:519761 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:41:519837 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:41:519879 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:41:521704 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:41:521745 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:41:522300 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:41:522449 -  compute_losses() end \n",
      " 2022-06-15 19:15:41:613757 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:41:613999 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:41:614051 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:41:615541 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:41:623375 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:41:623538 -  compute_losses() start \n",
      " 2022-06-15 19:15:41:626903 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:41:627043 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:41:627097 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:41:628253 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:41:628338 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:41:628938 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:41:629064 -  compute_losses() end \n",
      " 2022-06-15 19:15:41:721554 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:41:721685 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:41:721727 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:41:723655 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:42:132992 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:42:133042 -  compute_losses() start \n",
      " 2022-06-15 19:15:42:133775 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:42:133852 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:42:133895 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:42:134559 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:42:134591 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:42:135376 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:42:135494 -  compute_losses() end \n",
      " 2022-06-15 19:15:43:240520 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:43:240715 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:43:240760 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:43:242937 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:43:251118 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:43:251164 -  compute_losses() start \n",
      " 2022-06-15 19:15:43:252472 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:43:252681 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:43:252937 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:43:256530 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:43:256596 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:43:257575 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:43:257787 -  compute_losses() end \n",
      " 2022-06-15 19:15:43:348838 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:43:348970 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:43:349013 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:43:350903 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:43:358002 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:43:358084 -  compute_losses() start \n",
      " 2022-06-15 19:15:43:362601 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:43:362746 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:43:362815 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:43:367138 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:43:367196 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:43:368461 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:43:368833 -  compute_losses() end \n",
      " 2022-06-15 19:15:43:460699 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:43:460964 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:43:461114 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:43:466194 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:43:478072 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:43:478129 -  compute_losses() start \n",
      " 2022-06-15 19:15:43:479611 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:43:479722 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:43:479784 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:43:480869 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:43:480906 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:43:481418 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:43:481600 -  compute_losses() end \n",
      " 2022-06-15 19:15:43:573037 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:43:573158 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:43:573201 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:43:574850 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:43:581763 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:43:581818 -  compute_losses() start \n",
      " 2022-06-15 19:15:43:584730 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:43:584915 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:43:585067 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:43:588038 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:43:588071 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:43:588569 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:43:588667 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:43:680029 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:43:680246 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:43:680300 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:43:682435 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:43:696115 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:43:696218 -  compute_losses() start \n",
      " 2022-06-15 19:15:43:698850 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:43:698962 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:43:699042 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:43:699878 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:43:699910 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:43:700451 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:43:700717 -  compute_losses() end \n",
      " 2022-06-15 19:15:43:792430 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:43:792570 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:43:792622 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:43:795264 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:43:801840 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:43:801926 -  compute_losses() start \n",
      " 2022-06-15 19:15:43:804710 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:43:804875 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:43:804936 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:43:809176 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:43:809312 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:43:810418 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:43:811009 -  compute_losses() end \n",
      " 2022-06-15 19:15:43:902746 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:43:902959 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:43:903009 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:43:904717 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:43:911968 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:43:912014 -  compute_losses() start \n",
      " 2022-06-15 19:15:43:914355 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:43:914459 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:43:914508 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:43:915279 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:43:915318 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:43:915769 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:43:915865 -  compute_losses() end \n",
      " 2022-06-15 19:15:44:007188 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:44:007398 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:44:007476 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:44:009481 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:44:017589 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:44:017638 -  compute_losses() start \n",
      " 2022-06-15 19:15:44:021418 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:44:021574 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:44:021633 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:44:024429 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:44:024514 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:44:025264 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:44:025483 -  compute_losses() end \n",
      " 2022-06-15 19:15:44:122094 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:44:122423 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:44:122516 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:44:124816 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:44:132859 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:44:132919 -  compute_losses() start \n",
      " 2022-06-15 19:15:44:137041 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:44:137287 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:44:137440 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:44:139369 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:44:139546 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:44:140543 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:44:140885 -  compute_losses() end \n",
      " 2022-06-15 19:15:44:232481 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:44:232610 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:44:232675 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:44:233975 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:44:661745 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:44:661857 -  compute_losses() start \n",
      " 2022-06-15 19:15:44:663523 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:44:663726 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:44:663876 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:44:665231 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:44:665299 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:44:666272 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:44:666504 -  compute_losses() end \n",
      " 2022-06-15 19:15:45:751095 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:45:751419 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:45:751468 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:45:753991 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:45:762851 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:45:762994 -  compute_losses() start \n",
      " 2022-06-15 19:15:45:764201 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:45:764321 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:45:764370 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:45:765129 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:45:765160 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:45:765614 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:45:765718 -  compute_losses() end \n",
      " 2022-06-15 19:15:45:857477 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:45:857727 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:45:857825 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:45:860050 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:45:870059 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:45:870128 -  compute_losses() start \n",
      " 2022-06-15 19:15:45:871846 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:45:872022 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:45:872075 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:45:873236 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:45:873293 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:45:873910 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:45:874019 -  compute_losses() end \n",
      " 2022-06-15 19:15:45:964611 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:45:964957 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:45:965051 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:45:967485 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:45:979105 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:45:979250 -  compute_losses() start \n",
      " 2022-06-15 19:15:45:981042 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:45:981250 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:45:981370 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:45:990811 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:45:990947 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:45:991680 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:45:991904 -  compute_losses() end \n",
      " 2022-06-15 19:15:46:093005 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:46:093253 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:46:093344 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:46:096432 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:46:101770 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:46:101892 -  compute_losses() start \n",
      " 2022-06-15 19:15:46:103069 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:46:103232 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:46:103344 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:46:104852 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:46:104961 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:46:105622 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:46:105801 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:46:225742 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:46:229476 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:46:229571 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:46:238312 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:46:243469 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:46:243755 -  compute_losses() start \n",
      " 2022-06-15 19:15:46:244916 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:46:245068 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:46:245145 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:46:246720 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:46:246798 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:46:247523 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:46:247777 -  compute_losses() end \n",
      " 2022-06-15 19:15:46:341126 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:46:341379 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:46:341488 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:46:344178 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:46:352901 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:46:352967 -  compute_losses() start \n",
      " 2022-06-15 19:15:46:354046 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:46:354173 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:46:354279 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:46:355804 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:46:355946 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:46:357765 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:46:358087 -  compute_losses() end \n",
      " 2022-06-15 19:15:46:449305 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:46:449529 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:46:449575 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:46:451028 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:46:458911 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:46:458960 -  compute_losses() start \n",
      " 2022-06-15 19:15:46:460758 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:46:460884 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:46:460929 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:46:461599 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:46:461662 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:46:461989 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:46:462079 -  compute_losses() end \n",
      " 2022-06-15 19:15:46:567650 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:46:567788 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:46:567840 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:46:570124 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:46:579978 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:46:580025 -  compute_losses() start \n",
      " 2022-06-15 19:15:46:580707 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:46:580785 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:46:580828 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:46:581448 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:46:581478 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:46:581849 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:46:581941 -  compute_losses() end \n",
      " 2022-06-15 19:15:46:672862 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:46:673102 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:46:673169 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:46:675356 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:46:684435 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:46:684478 -  compute_losses() start \n",
      " 2022-06-15 19:15:46:686558 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:46:686765 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:46:686808 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:46:687411 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:46:687441 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:46:687872 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:46:687961 -  compute_losses() end \n",
      " 2022-06-15 19:15:46:779552 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:46:779800 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:46:779924 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:46:782114 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:49:860542 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:49:860646 -  compute_losses() start \n",
      " 2022-06-15 19:15:49:861952 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:49:862127 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:49:862222 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:49:863578 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:49:863644 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:49:864501 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:49:864693 -  compute_losses() end \n",
      " 2022-06-15 19:15:50:932503 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:50:932739 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:50:932805 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:50:934470 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:50:941869 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:50:941913 -  compute_losses() start \n",
      " 2022-06-15 19:15:50:944635 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:50:944736 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:50:944784 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:50:945507 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:50:945540 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:50:945904 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:50:946032 -  compute_losses() end \n",
      " 2022-06-15 19:15:51:038134 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:51:038372 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:51:038443 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:51:040818 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:51:049357 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:51:049401 -  compute_losses() start \n",
      " 2022-06-15 19:15:51:050105 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:51:050171 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:51:050216 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:51:050866 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:51:050897 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:51:051259 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:51:051374 -  compute_losses() end \n",
      " 2022-06-15 19:15:51:142950 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:51:143259 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:51:143325 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:51:145705 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:51:154113 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:51:154184 -  compute_losses() start \n",
      " 2022-06-15 19:15:51:157767 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:51:157941 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:51:158070 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:51:159006 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:51:159061 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:51:159747 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:51:159900 -  compute_losses() end \n",
      " 2022-06-15 19:15:51:251820 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:51:252095 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:51:252192 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:51:254546 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:51:265725 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:51:265849 -  compute_losses() start \n",
      " 2022-06-15 19:15:51:268595 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:51:268821 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:51:269004 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:51:270774 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:51:270891 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:51:272127 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:51:272444 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:15:51:364279 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:51:364500 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:51:364555 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:51:366164 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:51:373671 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:51:373741 -  compute_losses() start \n",
      " 2022-06-15 19:15:51:376178 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:51:376284 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:51:376334 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:51:377502 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:51:377542 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:51:377957 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:51:378097 -  compute_losses() end \n",
      " 2022-06-15 19:15:51:469567 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:51:469784 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:51:469846 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:51:472340 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:51:479398 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:51:479488 -  compute_losses() start \n",
      " 2022-06-15 19:15:51:481342 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:51:481442 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:51:481490 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:51:482186 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:51:482217 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:51:482594 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:51:482685 -  compute_losses() end \n",
      " 2022-06-15 19:15:51:572904 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:51:573117 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:51:573168 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:51:574774 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:51:582643 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:51:582703 -  compute_losses() start \n",
      " 2022-06-15 19:15:51:585049 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:51:585141 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:51:585193 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:51:585934 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:51:585969 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:51:586458 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:51:586571 -  compute_losses() end \n",
      " 2022-06-15 19:15:51:677373 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:51:677489 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:51:677530 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:51:679019 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:51:686830 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:51:686890 -  compute_losses() start \n",
      " 2022-06-15 19:15:51:688667 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:51:688790 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:51:688848 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:51:690722 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:51:690775 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:51:691463 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:51:691661 -  compute_losses() end \n",
      " 2022-06-15 19:15:51:783539 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:51:783765 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:51:783833 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:51:785615 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:15:51:794695 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:15:51:794744 -  compute_losses() start \n",
      " 2022-06-15 19:15:51:795771 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:15:51:795915 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:15:51:796016 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:15:51:797087 -  get_sharing_loss() END  \n",
      "2022-06-15 19:15:51:797125 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:15:51:797626 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:15:51:797737 -  compute_losses() end \n",
      " 2022-06-15 19:15:51:888486 - SparseChem network optimize() start \n",
      " 2022-06-15 19:15:51:888612 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:15:51:888663 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:15:51:890253 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:01:099207 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:01:099298 -  compute_losses() start \n",
      " 2022-06-15 19:16:01:100829 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:01:101041 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:01:101146 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:01:112062 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:01:112164 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:01:113827 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:01:114128 -  compute_losses() end \n",
      " 2022-06-15 19:16:02:114735 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:02:115112 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:02:115256 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:02:117753 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:02:135911 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:02:136000 -  compute_losses() start \n",
      " 2022-06-15 19:16:02:138224 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:02:138422 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:02:138597 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:02:140416 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:02:140556 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:02:141436 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:02:141938 -  compute_losses() end \n",
      " 2022-06-15 19:16:02:233893 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:02:234089 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:02:234172 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:02:236861 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:02:268594 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:02:269075 -  compute_losses() start \n",
      " 2022-06-15 19:16:02:273166 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:02:273374 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:02:273556 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:02:275348 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:02:275439 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:02:276265 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:02:276547 -  compute_losses() end \n",
      " 2022-06-15 19:16:02:383205 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:02:383511 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:02:383609 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:02:385509 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:02:423449 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:02:423567 -  compute_losses() start \n",
      " 2022-06-15 19:16:02:425097 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:02:425252 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:02:425343 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:02:426717 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:02:426781 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:02:427379 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:02:427603 -  compute_losses() end \n",
      " 2022-06-15 19:16:02:806414 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:02:806826 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:02:806948 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:02:813863 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:02:832997 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:02:833074 -  compute_losses() start \n",
      " 2022-06-15 19:16:02:841711 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:02:842565 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:02:844644 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:02:846506 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:02:846598 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:02:847722 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:02:848031 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:16:03:126223 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:03:126780 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:03:126882 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:03:129832 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:03:135090 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:03:135171 -  compute_losses() start \n",
      " 2022-06-15 19:16:03:145594 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:03:145745 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:03:145804 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:03:148790 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:03:148877 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:03:150183 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:03:151403 -  compute_losses() end \n",
      " 2022-06-15 19:16:03:243603 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:03:243859 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:03:244030 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:03:246565 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:03:263268 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:03:263351 -  compute_losses() start \n",
      " 2022-06-15 19:16:03:274639 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:03:274804 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:03:274905 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:03:276290 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:03:276360 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:03:277027 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:03:277262 -  compute_losses() end \n",
      " 2022-06-15 19:16:03:413179 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:03:413566 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:03:413679 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:03:416887 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:03:432394 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:03:432483 -  compute_losses() start \n",
      " 2022-06-15 19:16:03:433784 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:03:433957 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:03:434055 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:03:435404 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:03:435477 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:03:436181 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:03:436416 -  compute_losses() end \n",
      " 2022-06-15 19:16:03:537033 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:03:537438 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:03:537643 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:03:540561 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:03:546929 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:03:547010 -  compute_losses() start \n",
      " 2022-06-15 19:16:03:558271 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:03:558443 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:03:558597 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:03:560296 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:03:560407 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:03:561865 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:03:562302 -  compute_losses() end \n",
      " 2022-06-15 19:16:03:657842 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:03:658236 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:03:658348 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:03:672826 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:03:681148 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:03:681228 -  compute_losses() start \n",
      " 2022-06-15 19:16:03:688762 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:03:689102 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:03:689724 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:03:691979 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:03:692053 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:03:692688 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:03:692909 -  compute_losses() end \n",
      " 2022-06-15 19:16:03:794616 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:03:794793 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:03:794857 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:03:796793 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:16:640299 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:16:640386 -  compute_losses() start \n",
      " 2022-06-15 19:16:16:641409 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:16:641528 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:16:641619 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:16:642951 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:16:643049 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:16:644041 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:16:644278 -  compute_losses() end \n",
      " 2022-06-15 19:16:17:677250 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:17:677653 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:17:677755 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:17:680863 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:17:692889 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:17:692944 -  compute_losses() start \n",
      " 2022-06-15 19:16:17:693907 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:17:694042 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:17:694097 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:17:695511 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:17:695561 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:17:696337 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:17:696515 -  compute_losses() end \n",
      " 2022-06-15 19:16:17:789217 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:17:789414 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:17:789501 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:17:791251 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:17:800795 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:17:800848 -  compute_losses() start \n",
      " 2022-06-15 19:16:17:802942 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:17:803090 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:17:803143 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:17:805710 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:17:805757 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:17:806377 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:17:806560 -  compute_losses() end \n",
      " 2022-06-15 19:16:17:897958 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:17:898247 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:17:898345 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:17:899973 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:17:909286 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:17:909356 -  compute_losses() start \n",
      " 2022-06-15 19:16:17:911841 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:17:911960 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:17:912015 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:17:913210 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:17:913315 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:17:914279 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:17:914429 -  compute_losses() end \n",
      " 2022-06-15 19:16:18:006166 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:18:006312 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:18:006387 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:18:007965 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:18:018416 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:18:018468 -  compute_losses() start \n",
      " 2022-06-15 19:16:18:019993 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:18:020125 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:18:020205 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:18:021219 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:18:021300 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:18:021949 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:18:022213 -  compute_losses() end \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2022-06-15 19:16:18:114342 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:18:114587 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:18:114640 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:18:116382 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:18:123917 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:18:124027 -  compute_losses() start \n",
      " 2022-06-15 19:16:18:126133 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:18:126275 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:18:126374 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:18:127183 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:18:127216 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:18:127637 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:18:127754 -  compute_losses() end \n",
      " 2022-06-15 19:16:18:219478 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:18:219623 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:18:219668 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:18:221676 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:18:231764 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:18:231840 -  compute_losses() start \n",
      " 2022-06-15 19:16:18:234254 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:18:234390 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:18:234435 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:18:235506 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:18:235598 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:18:236387 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:18:236508 -  compute_losses() end \n",
      " 2022-06-15 19:16:18:331148 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:18:331423 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:18:331491 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:18:333510 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:18:343234 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:18:343280 -  compute_losses() start \n",
      " 2022-06-15 19:16:18:344770 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:18:344863 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:18:344907 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:18:345564 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:18:345595 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:18:346162 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:18:346281 -  compute_losses() end \n",
      " 2022-06-15 19:16:18:438445 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:18:438599 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:18:438658 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:18:440089 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:18:450053 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:18:450098 -  compute_losses() start \n",
      " 2022-06-15 19:16:18:450866 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:18:450964 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:18:451011 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:18:451632 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:18:451661 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:18:452135 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:18:452225 -  compute_losses() end \n",
      " 2022-06-15 19:16:18:544667 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:18:545440 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:18:545551 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:18:548232 - MTL3 network forward() end\n",
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([128, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:18:552885 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:18:552927 -  compute_losses() start \n",
      " 2022-06-15 19:16:18:553667 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:18:553740 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:18:553794 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:18:554421 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:18:554451 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:18:554860 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:18:554996 -  compute_losses() end \n",
      " 2022-06-15 19:16:18:645649 - SparseChem network optimize() start \n",
      " 2022-06-15 19:16:18:645852 - SparseChem network FORWARD() start \n",
      " 2022-06-15 19:16:18:645903 - MTL3 network forward() start\n",
      "   num_train_layers: None    hard_sampling:False    policy sampling mode:train    temperature:4     is_policy:False    self.skip_layer:0     num_layers:1\n",
      " 2022-06-15 19:16:18:647842 - MTL3 network forward() end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set attributes: task id 1  task: class\n",
      "    output[1]:      torch.Size([41, 100])\n",
      "    policy1:        None\n",
      "    logits1:        Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0') \n",
      "    task1_logits:   Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n",
      " 2022-06-15 19:16:19:026102 - SparseChem network FORWARD() end \n",
      " 2022-06-15 19:16:19:026186 -  compute_losses() start \n",
      " 2022-06-15 19:16:19:027502 -  get_sharing_loss() START  \n",
      "\n",
      "  task 1 Sharing (Hamming) loss: \n",
      "----------------------------------\n",
      " 2022-06-15 19:16:19:027648 -  get_task_logits() start   task_id: 0  task_key: task1_logits\n",
      "  isinstance(self.networks['mtl-net'], nn.DataParallel) == False \n",
      " logits task 1 : <class 'torch.nn.parameter.Parameter'>\n",
      " 2022-06-15 19:16:19:027804 -  get_task_logits() end\n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "\n",
      "  between tasks 1 and 1 : \n",
      "---------------------------\n",
      "\n",
      "  Total Sharing loss for task 0 :  torch.Size([]) \n",
      "---------------------------------------------------\n",
      " 2022-06-15 19:16:19:028957 -  get_sharing_loss() END  \n",
      "2022-06-15 19:16:19:029016 -  get_sparsity_loss START   num_train_layers: None  \n",
      "2022-06-15 19:16:19:029882 -  get_sparsity_loss END   num_train_layers: 1  \n",
      " 2022-06-15 19:16:19:030059 -  compute_losses() end \n",
      " 2022-06-15 19:16:20:051854 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:071299 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:085303 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:096871 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:112067 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:125175 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:136960 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:148323 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:163769 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:175987 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:565875 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:579799 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:595460 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:613796 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:636267 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:652051 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:666105 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:683413 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:697879 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:20:714278 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:21:193751 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:21:210080 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:21:224760 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:21:238036 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:21:253029 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:21:269358 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:21:287880 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:21:304691 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:21:320160 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      " 2022-06-15 19:16:21:335374 - SparseChem network FORWARD() start \n",
      " Up to here 1- num_policy_layers: 1\n",
      " Up to here 2- num_policy_layers: 1\n",
      "tensor([1.])\n",
      " Up to here 4- num_policy_layers: 1\n",
      "   2 | 1.00e-03  1.00e-03  1.00e-03  4.00e+00 |   0.0140   3.382e-04   0.000e+00    0.0144 |   0.00002   0.23932   0.91336   0.89374   0.89752   0.92005 |   0.0868   1.155e-04   0.000e+00    0.0869 | 56.5 |\n",
      " save warmup checkpoint  to :  model_warmup_ep_2\n",
      " save warmup val_metrics to :  metrics_warmup_ep_2.pickle\n",
      "[Final] ep:2  it:230 -  Total Loss: 0.0869     \n",
      "Task: 0.0868   Sparsity: 1.15457e-04    Sharing: 0.00000e+00 \n",
      "\n",
      " ep:    2   softmax      s        \n",
      " ----- ----------------- -    \n",
      "  0    0.5000    0.5000  1\n",
      "\n",
      "\n",
      " ep:    2   logits       s         \n",
      " ----- ----------------- -    \n",
      "  0   -0.0004   -0.0006  1\n",
      "\n",
      "Best Epoch :       1\n",
      "Best Iteration :   115 \n",
      "Best Precision :   0.93081\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warmup_phase(ns,opt, environ, dldrs, verbose = False, disable_tqdm = False)\n",
    "\n",
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best Precision :   {ns.best_value:.5f}\\n\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef193b88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:47:12.333260Z",
     "start_time": "2022-06-15T17:47:12.043139Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'environ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12092/277954636.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_task_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'environ' is not defined"
     ]
    }
   ],
   "source": [
    "d = environ.get_task_logits(0,verbose=True)\n",
    "print(type(d))\n",
    "print(d.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62bcb043",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:16:48.577783Z",
     "start_time": "2022-06-15T17:16:48.497080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.000447, -0.000642]], device='cuda:0')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d831fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e291806d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31ccb59a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T11:08:50.820769Z",
     "start_time": "2022-04-28T11:08:50.596110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch :       23\n",
      "Best Iteration :   2645 \n",
      "Best Precision :   0.94657\n",
      "\n",
      "\n",
      "{   'auc_pr': 0.9357182859417005,\n",
      "    'avg_prec_score': 0.9429960304326884,\n",
      "    'bceloss': 0.38601235412538815,\n",
      "    'f1_max': 0.9398995764862556,\n",
      "    'kappa': 0.4139156231753311,\n",
      "    'kappa_max': 0.7667071541394691,\n",
      "    'logloss': 2.1372066841553236e-05,\n",
      "    'p_f1_max': 0.73216563440525,\n",
      "    'p_kappa_max': 0.8152552059827707,\n",
      "    'roc_auc_score': 0.8845997060665461,\n",
      "    'sc_loss': 0.0030697412006750963}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best Precision :   {ns.best_value:.5f}\\n\")\n",
    "print()\n",
    "pp.pprint(environ.val_metrics['aggregated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca127b0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T11:09:14.782725Z",
     "start_time": "2022-04-28T11:09:14.692205Z"
    }
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.val_metrics)\n",
    "df = environ.val_metrics['task1']['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb8ee94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T11:09:15.186827Z",
     "start_time": "2022-04-28T11:09:15.090906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.989003  0.998409        0.998381  0.977974  0.967152  0.729923   0.843007     0.967152  0.105100\n",
      "5          0.944444  0.996995        0.997076  0.972973  0.479137 -0.055556   0.641509     0.990281  0.124514\n",
      "6          0.998358  0.999976        0.999976  0.997543  0.977779  0.797642   0.854725     0.988166  0.020145\n",
      "7          0.833333  0.850000        0.866667  0.800000  0.982072  0.000000   0.695652     0.982072  1.264657\n",
      "8          1.000000  1.000000        1.000000  1.000000  0.981241  0.000000   1.000000     0.981241  0.097502\n",
      "9          1.000000  1.000000        1.000000  1.000000  0.998768  0.660870   1.000000     0.998768  0.016954\n",
      "14         0.993333  0.999823        0.999825  0.993377  0.966154  0.000000   0.793566     0.994513  0.067134\n",
      "19         1.000000  1.000000        1.000000  1.000000  0.969449  0.000000   1.000000     0.969449  1.327189\n",
      "28         0.935354  0.998518        0.998521  0.998487  0.942702  0.797101   0.907591     0.942702  0.036515\n",
      "35         1.000000  1.000000        1.000000  1.000000  0.977073  1.000000   1.000000     0.977073  0.008292\n",
      "36         0.750000  0.766667        0.804167  0.888889  0.050305  0.222222   0.695652     0.050305  1.265901\n",
      "37         0.714286  0.904167        0.909524  0.833333  0.863824  0.347826   0.600000     0.863824  0.601074\n",
      "38         0.486486  0.985164        0.985289  0.991071  0.000622 -0.011940   0.024588     0.998934  0.204047\n",
      "41         1.000000  1.000000        1.000000  1.000000  0.998945  0.000000   1.000000     0.998945  0.061859\n",
      "43         0.453608  0.991976        0.992039  0.994872  0.995309  0.000000   0.016660     0.999837  0.089163\n",
      "44         0.995263  0.999336        0.999339  0.988506  0.499248  0.867028   0.907256     0.851551  0.060339\n",
      "46         0.750000  0.939224        0.943012  0.952381  0.992269  0.625000   0.625000     0.992269  0.566701\n",
      "48         0.890850  0.736094        0.732778  0.750000  0.617753  0.727141   0.727141     0.617753  0.197670\n",
      "51         0.000000  0.166667        0.333333  0.500000  0.974586  0.000000   0.000000     0.994366  2.679492\n",
      "52         0.769231  0.598214        0.625000  0.666667  0.878322  0.634146   0.634146     0.878322  0.332172\n",
      "54         1.000000  1.000000        1.000000  1.000000  0.991379  0.000000   1.000000     0.991379  0.010523\n",
      "55         1.000000  1.000000        1.000000  1.000000  0.171206  0.948540   1.000000     0.171206  0.053456\n",
      "59         0.750000  0.908333        0.916667  0.857143  0.995486  0.000000   0.666667     0.995486  1.709448\n",
      "61         1.000000  1.000000        1.000000  1.000000  0.963416  1.000000   1.000000     0.963416  0.022738\n",
      "62         0.923077  0.994294        0.994505  0.962963  0.935977  0.000000   0.631579     0.993360  0.238715\n",
      "64         1.000000  1.000000        1.000000  1.000000  0.289602  0.695652   1.000000     0.289602  0.148096\n",
      "70         1.000000  1.000000        1.000000  1.000000  0.206539  0.000000   1.000000     0.206539  0.099199\n",
      "72         1.000000  1.000000        1.000000  1.000000  0.933403  1.000000   1.000000     0.933403  0.016377\n",
      "73         0.934959  0.995304        0.995360  0.964706  0.114335 -0.035294   0.557789     0.902645  0.170980\n",
      "76         0.782609  0.994799        0.994873  0.989247  0.988427  0.000000   0.132841     0.996655  0.123981\n",
      "78         0.877329  0.880754        0.880057  0.800000  0.994561  0.483240   0.700162     0.994561  1.248584\n",
      "80         0.995833  0.999383        0.999390  0.987654  0.694081  0.896861   0.910506     0.860578  0.072517\n",
      "82         0.866667  0.857540        0.873413  0.923077  0.105564  0.290323   0.813559     0.105564  0.750102\n",
      "85         0.927866  0.987627        0.987652  0.976331  0.397150  0.771983   0.771983     0.598173  0.199760\n",
      "86         1.000000  1.000000        1.000000  1.000000  0.858768  1.000000   1.000000     0.858768  0.028183\n",
      "87         0.937500  0.943750        0.950000  0.888889  0.717270  0.750000   0.750000     0.811510  0.416185\n",
      "88         1.000000  1.000000        1.000000  1.000000  0.146587  0.000000   1.000000     0.146587  0.031908\n",
      "92         1.000000  1.000000        1.000000  1.000000  0.997736  0.000000   1.000000     0.997736  0.412813\n",
      "98         1.000000  1.000000        1.000000  1.000000  0.940264  1.000000   1.000000     0.940264  0.174497\n"
     ]
    }
   ],
   "source": [
    "print(df[pd.notna(df.roc_auc_score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb489eb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T11:09:44.692326Z",
     "start_time": "2022-04-28T11:09:44.611694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "roc_auc_score     0.884600\n",
       "auc_pr            0.935718\n",
       "avg_prec_score    0.942996\n",
       "f1_max            0.939900\n",
       "p_f1_max          0.732166\n",
       "kappa             0.413916\n",
       "kappa_max         0.766707\n",
       "p_kappa_max       0.815255\n",
       "bceloss           0.386012\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[pd.notna(df.roc_auc_score)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ba324f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T10:02:21.556335Z",
     "start_time": "2022-04-28T10:02:17.852153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fe5ad48c834fde871744ebb56ffe7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.126 MB of 0.126 MB uploaded (0.115 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 62.3%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_pr</td><td></td></tr><tr><td>avg_prec_score</td><td></td></tr><tr><td>bceloss</td><td></td></tr><tr><td>best_accuracy</td><td></td></tr><tr><td>best_epoch</td><td></td></tr><tr><td>best_iter</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>f1_max</td><td></td></tr><tr><td>gumbel_temp</td><td></td></tr><tr><td>kappa</td><td></td></tr><tr><td>kappa_max</td><td></td></tr><tr><td>lambda_sharing</td><td></td></tr><tr><td>lambda_sparsity</td><td></td></tr><tr><td>lambda_tasks</td><td></td></tr><tr><td>logloss</td><td></td></tr><tr><td>lr_0</td><td></td></tr><tr><td>lr_1</td><td></td></tr><tr><td>p_f1_max</td><td></td></tr><tr><td>p_kappa_max</td><td></td></tr><tr><td>policy</td><td></td></tr><tr><td>policy_lr</td><td></td></tr><tr><td>roc_auc_score</td><td></td></tr><tr><td>sc_loss</td><td></td></tr><tr><td>task</td><td></td></tr><tr><td>task1</td><td></td></tr><tr><td>total</td><td></td></tr><tr><td>total_mean</td><td></td></tr><tr><td>train_layers</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_pr</td><td>0.87818</td></tr><tr><td>avg_prec_score</td><td>0.89614</td></tr><tr><td>bceloss</td><td>0.31752</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>f1_max</td><td>0.91049</td></tr><tr><td>gumbel_temp</td><td>4</td></tr><tr><td>kappa</td><td>0.27412</td></tr><tr><td>kappa_max</td><td>0.72071</td></tr><tr><td>lambda_sharing</td><td>0.01</td></tr><tr><td>lambda_sparsity</td><td>0.02</td></tr><tr><td>lambda_tasks</td><td>1</td></tr><tr><td>logloss</td><td>2e-05</td></tr><tr><td>lr_0</td><td>0.001</td></tr><tr><td>lr_1</td><td>0.001</td></tr><tr><td>p_f1_max</td><td>0.70919</td></tr><tr><td>p_kappa_max</td><td>0.75108</td></tr><tr><td>policy</td><td>0.00012</td></tr><tr><td>policy_lr</td><td>0.001</td></tr><tr><td>roc_auc_score</td><td>0.85785</td></tr><tr><td>sc_loss</td><td>0.00301</td></tr><tr><td>task</td><td>0.09037</td></tr><tr><td>task1</td><td>0.00012</td></tr><tr><td>total</td><td>0.00012</td></tr><tr><td>total_mean</td><td>0.00078</td></tr><tr><td>train_layers</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0428_1201_skip_hdn_skip_hdn</strong>: <a href=\"http://localhost:8080/kbardool/AdaSparseChem-Mini/runs/1sjf5nq7\" target=\"_blank\">http://localhost:8080/kbardool/AdaSparseChem-Mini/runs/1sjf5nq7</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220428_120129-1sjf5nq7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# warmup_phase(ns,opt, environ, dldrs, epochs = 25)\n",
    "ns.wandb_run.finish()\n",
    "\n",
    "# ns.wandb_run.finish()\n",
    "# environ.losses\n",
    "# environ.val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "356f564d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T10:02:21.600933Z",
     "start_time": "2022-04-28T10:02:21.561452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns.check_for_improvment_wait\n",
    "ns.curriculum_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48528a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6af28185",
   "metadata": {},
   "source": [
    "## Check values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c08a9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:39:22.031664Z",
     "start_time": "2022-06-15T17:39:21.964660Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.display_trained_policy(ns.current_epoch,out=[sys.stdout])\n",
    "# environ.num_tasks\n",
    "# print(environ.get_policy_prob().shape)\n",
    "# print(environ.val_data['task1'].keys())\n",
    "# print(environ.val_data['task1']['yc_ind'][0][:40])\n",
    "# print(environ.val_data['task1']['yc_ind'][1][:40])\n",
    "# print(environ.val_data['task1']['yc_data'][:40])\n",
    "# print(environ.val_data['task1']['yc_hat'][:40])\n",
    "# environ.display_trained_policy(ns.current_epoch,out=[sys.stdout])\n",
    "# environ.display_trained_logits(ns.current_epoch,out=[sys.stdout])\n",
    "batch = next(dldrs.warmup_trn_loader)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff34d0bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:39:22.757684Z",
     "start_time": "2022-06-15T17:39:22.679466Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_ind', 'x_data', 'row_id', 'task1', 'batch_size'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18aec2fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:39:23.282940Z",
     "start_time": "2022-06-15T17:39:23.218734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9923])\n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  8,  10,  13,  23,  26,  27,  30,  31,  41,  42,  43,  72, 110, 208, 213, 304, 309, 315, 319, 342]])\n"
     ]
    }
   ],
   "source": [
    "print(batch['x_ind'].shape)\n",
    "print(batch['x_ind'][:,:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3040aa8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:43:06.352600Z",
     "start_time": "2022-06-15T17:43:06.288637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([9923])\n"
     ]
    }
   ],
   "source": [
    "print(type(batch['x_data']))\n",
    "print(batch['x_data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23ae4ce2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:39:45.873056Z",
     "start_time": "2022-06-15T17:39:45.812606Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "[9700, 5912, 10720, 9757, 5734, 1595, 4646, 13793, 7527, 13485, 7441, 12528, 9567, 11506, 4998, 10444, 4182, 6336, 13397, 159, 11454, 4216, 571, 407, 14408, 5336, 8777, 4456, 5275, 3591, 13292, 7456, 12737, 200, 3003, 12826, 7721, 501, 4833, 7784, 10076, 10526, 1565, 1212, 12104, 14409, 7566, 11762, 7870, 4836, 13470, 11264, 2561, 13775, 8139, 5067, 187, 11333, 5431, 4464, 2843, 2961, 8241, 713, 10334, 1518, 11647, 3908, 8672, 10980, 1822, 10914, 9640, 12194, 10332, 11727, 13998, 10945, 828, 3558, 483, 7378, 8407, 1956, 2601, 471, 4770, 14008, 5027, 50, 5455, 11686, 5274, 13158, 2153, 9386, 609, 7671, 8651, 13263, 9762, 11505, 7513, 4399, 5776, 13558, 2989, 2248, 4782, 679, 11176, 1936, 3332, 8252, 544, 3973, 8115, 7803, 2138, 8970, 11598, 2856, 12789, 5153, 10123, 8549, 12184, 6168]\n"
     ]
    }
   ],
   "source": [
    "print(len(batch['row_id']))\n",
    "print(batch['row_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6812b0bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T17:44:07.505660Z",
     "start_time": "2022-06-15T17:44:07.448666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print(batch['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5607528c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T09:25:02.534297Z",
     "start_time": "2022-04-13T09:25:02.503118Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   '_runtime': 58,\n",
      "    '_timestamp': 1649841795,\n",
      "    'aggregated': {   'auc_pr': 0.8863761813736045,\n",
      "                      'avg_prec_score': 0.9038057874228314,\n",
      "                      'bceloss': 0.5405514872601578,\n",
      "                      'f1_max': 0.9285540758241476,\n",
      "                      'kappa': 0.4061207927257367,\n",
      "                      'kappa_max': 0.7299278430897939,\n",
      "                      'logloss': 3.2356826155563767e-05,\n",
      "                      'p_f1_max': 0.6895967995007641,\n",
      "                      'p_kappa_max': 0.7860043613383403,\n",
      "                      'roc_auc_score': 0.8293258801651597,\n",
      "                      'sc_loss': 0.004647518796810809},\n",
      "    'epoch': 25,\n",
      "    'parms': {   'gumbel_temp': 4,\n",
      "                 'lambda_sharing': 0.01,\n",
      "                 'lambda_sparsity': 0.02,\n",
      "                 'lambda_tasks': 1,\n",
      "                 'lr_0': 0.001,\n",
      "                 'lr_1': 0.001,\n",
      "                 'policy_lr': 0.001,\n",
      "                 'train_layers': 0},\n",
      "    'sharing': {'total': 0.0},\n",
      "    'sparsity': {   'task1': 0.00011550190538400784,\n",
      "                    'total': 0.00011550190538400784},\n",
      "    'task': {'task1': 0.13942556390432426, 'total': 0.13942556390432426},\n",
      "    'task1': {   'classification': {   '_latest_artifact_path': 'wandb-client-artifact://3tspe211do86y85wudaihuqt2z3d0iglewjf4ip21k1ex7x0i8e83rp9yr4dlvti1j8u43044j5n0wsv1h3ewsq44bi3pknhffqqnofy825r91aztyt6yh62a3yvcj45:latest/classification.table.json',\n",
      "                                       '_type': 'table-file',\n",
      "                                       'artifact_path': 'wandb-client-artifact://1es0xgr8ujqonka73urgc0fzf1my6jqu90uby7eufopqlrpw1jxuwvbiq4l9xqwzf505r4dp9acjmid2usxnz5sdvjl00r73xp08i53apjqjxjqgz5n7p1j1ohz946lx/classification.table.json',\n",
      "                                       'ncols': 9,\n",
      "                                       'nrows': 100,\n",
      "                                       'path': 'media/table/classification_29_291c259255eb9ad8933a.table.json',\n",
      "                                       'sha256': '291c259255eb9ad8933a5b327da7fefe5e0f0e4d63d829b94361a125fa578397',\n",
      "                                       'size': 8841},\n",
      "                 'classification_agg': {   'auc_pr': 0.8863761813736045,\n",
      "                                           'avg_prec_score': 0.9038057874228314,\n",
      "                                           'bceloss': 0.5405514872601578,\n",
      "                                           'f1_max': 0.9285540758241476,\n",
      "                                           'kappa': 0.4061207927257367,\n",
      "                                           'kappa_max': 0.7299278430897939,\n",
      "                                           'logloss': 3.2356826155563767e-05,\n",
      "                                           'p_f1_max': 0.6895967995007641,\n",
      "                                           'p_kappa_max': 0.7860043613383403,\n",
      "                                           'roc_auc_score': 0.8293258801651597,\n",
      "                                           'sc_loss': 0.004647518796810809}},\n",
      "    'task_mean': {   'task1': 0.0011552470713187414,\n",
      "                     'total': 0.0011552470713187414},\n",
      "    'total': {   'policy': 0.00011550190538400784,\n",
      "                 'task': 0.13942556390432426,\n",
      "                 'total': 0.13954106580970826,\n",
      "                 'total_mean': 0.0012707489767027492},\n",
      "    'train_time': 1.9346582889556885}\n"
     ]
    }
   ],
   "source": [
    "# pp.pprint(environ.val_metrics['task1'])\n",
    "pp.pprint(environ.val_metrics)\n",
    "# pp.pprint(ns.val_metrics)\n",
    "# print((environ.val_data['task1']['yc_data']).sum())\n",
    "# print(len(environ.val_data['task1']['yc_ind'][1]))\n",
    "# print(len(environ.val_data['task1']['yc_data']))\n",
    "# print(len(environ.val_data['task1']['yc_hat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e18351b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T09:12:32.452187Z",
     "start_time": "2022-04-13T09:12:32.420905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ns.val_metrics['aggregated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf831931",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T08:47:30.057623Z",
     "start_time": "2022-04-13T08:47:29.588103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   '_runtime': 344,\n",
      "    '_timestamp': 1649839198,\n",
      "    'parms': {   'gumbel_temp': 4,\n",
      "                 'lambda_sharing': 0.01,\n",
      "                 'lambda_sparsity': 0.02,\n",
      "                 'lambda_tasks': 1,\n",
      "                 'lr_0': 7.289999999999998e-07,\n",
      "                 'lr_1': 7.289999999999998e-07,\n",
      "                 'policy_lr': 0.001,\n",
      "                 'train_layers': 0},\n",
      "    'sharing': {'total': tensor(0.)},\n",
      "    'sparsity': {'task1': tensor(0.000338), 'total': tensor(0.000338)},\n",
      "    'task': {   'task1': tensor(0.000160, dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                'total': tensor(0.000160, dtype=torch.float64, grad_fn=<MulBackward0>)},\n",
      "    'task_mean': {   'task1': tensor(3.338073e-06, dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                     'total': tensor(3.338073e-06, dtype=torch.float64, grad_fn=<MulBackward0>)},\n",
      "    'total': {   'backprop': tensor(0.000160, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
      "                 'policy': tensor(0.000338),\n",
      "                 'task': 0.0,\n",
      "                 'tasks': tensor(0.000160, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
      "                 'total': tensor(0.000498, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
      "                 'total_mean': tensor(0.000341, dtype=torch.float64, grad_fn=<AddBackward0>)}}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(ns.trn_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a2ec95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:31:55.581510Z",
     "start_time": "2022-04-02T13:31:55.526855Z"
    }
   },
   "outputs": [],
   "source": [
    "(environ.val_data['task1']['yc_data'][0] == environ.val_data['task1']['yc_data']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d58803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:20:55.327255Z",
     "start_time": "2022-04-02T14:20:55.026238Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.sparsechem_utils import compute_metrics, aggregate_results\n",
    "import pandas\n",
    "cc = compute_metrics(cols   = environ.val_data['task1']['yc_ind'][1], \n",
    "                     y_true = environ.val_data['task1']['yc_data'], \n",
    "                     y_score= environ.val_data['task1']['yc_hat'] ,\n",
    "                     num_tasks=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737de288",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:34:57.196163Z",
     "start_time": "2022-04-02T13:34:57.130013Z"
    }
   },
   "outputs": [],
   "source": [
    " df   = pd.DataFrame({\"task\"   : environ.val_data['task1']['yc_ind'][1], \n",
    "                      \"y_true\" : environ.val_data['task1']['yc_data'],  \n",
    "                      \"y_score\": environ.val_data['task1']['yc_hat']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a572ba33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:44:52.754320Z",
     "start_time": "2022-04-02T13:44:52.611945Z"
    }
   },
   "outputs": [],
   "source": [
    "for task, frame in df.groupby(\"task\", sort=True):\n",
    "    print(f\" task {task}\")\n",
    "    print(frame.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0cf934",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T13:46:29.715440Z",
     "start_time": "2022-04-02T13:46:29.640674Z"
    }
   },
   "outputs": [],
   "source": [
    "# df\n",
    "df.groupby(\"task\", sort=True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b99c2fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T11:10:20.301689Z",
     "start_time": "2022-04-28T11:10:20.151621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'aggregated': {   'auc_pr': 0.9357182859417005,\n",
      "                      'avg_prec_score': 0.9429960304326884,\n",
      "                      'bceloss': 0.38601235412538815,\n",
      "                      'f1_max': 0.9398995764862556,\n",
      "                      'kappa': 0.4139156231753311,\n",
      "                      'kappa_max': 0.7667071541394691,\n",
      "                      'logloss': 2.1372066841553236e-05,\n",
      "                      'p_f1_max': 0.73216563440525,\n",
      "                      'p_kappa_max': 0.8152552059827707,\n",
      "                      'roc_auc_score': 0.8845997060665461,\n",
      "                      'sc_loss': 0.0030697412006750963},\n",
      "    'epoch': 50,\n",
      "    'parms': {   'gumbel_temp': 4,\n",
      "                 'lambda_sharing': 0.01,\n",
      "                 'lambda_sparsity': 0.02,\n",
      "                 'lambda_tasks': 1,\n",
      "                 'lr_0': 8.999999999999999e-05,\n",
      "                 'lr_1': 8.999999999999999e-05,\n",
      "                 'policy_lr': 0.001,\n",
      "                 'train_layers': 0},\n",
      "    'sharing': {'total': 0.0},\n",
      "    'sparsity': {   'task1': 0.00011545682355063036,\n",
      "                    'total': 0.00011545682355063036},\n",
      "    'task': {'task1': 0.09209223602025289, 'total': 0.09209223602025289},\n",
      "    'task1': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.989003  0.998409        0.998381  0.977974  0.967152  0.729923   0.843007     0.967152  0.105100\n",
      "1               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "2               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "3               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "4               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "...             ...       ...             ...       ...       ...       ...        ...          ...       ...\n",
      "95              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "96              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "97              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "98         1.000000  1.000000        1.000000  1.000000  0.940264  1.000000   1.000000     0.940264  0.174497\n",
      "99              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN\n",
      "\n",
      "[100 rows x 9 columns],\n",
      "                 'classification_agg': {   'auc_pr': 0.9357182859417005,\n",
      "                                           'avg_prec_score': 0.9429960304326884,\n",
      "                                           'bceloss': 0.38601235412538815,\n",
      "                                           'f1_max': 0.9398995764862556,\n",
      "                                           'kappa': 0.4139156231753311,\n",
      "                                           'kappa_max': 0.7667071541394691,\n",
      "                                           'logloss': 2.1372066841553236e-05,\n",
      "                                           'p_f1_max': 0.73216563440525,\n",
      "                                           'p_kappa_max': 0.8152552059827707,\n",
      "                                           'roc_auc_score': 0.8845997060665461,\n",
      "                                           'sc_loss': 0.0030697412006750963}},\n",
      "    'task_mean': {   'task1': 0.0006266143924552535,\n",
      "                     'total': 0.0006266143924552535},\n",
      "    'total': {   'policy': 0.00011545682355063036,\n",
      "                 'task': 0.09209223602025289,\n",
      "                 'total': 0.09220769284380352,\n",
      "                 'total_mean': 0.0007420712160058838},\n",
      "    'train_time': 35.518943548202515}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb8f8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T14:26:58.189057Z",
     "start_time": "2022-04-02T14:26:58.126134Z"
    }
   },
   "outputs": [],
   "source": [
    "print(environ.batch_data['task1']['yc_aggr_weights'])\n",
    "environ.batch['task1']['aggr_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfdf55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = aggregate_results(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e9e723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T17:11:11.578048Z",
     "start_time": "2022-04-02T17:11:11.535763Z"
    }
   },
   "outputs": [],
   "source": [
    "dldrs.trainset0.tasks_weights_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d238e8",
   "metadata": {},
   "source": [
    "#### display parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e75ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:47.732297Z",
     "start_time": "2022-03-28T04:02:47.639607Z"
    }
   },
   "outputs": [],
   "source": [
    "print( f\" Backbone Initial LR         : {environ.opt['train']['backbone_lr']:4f}      current LR : {environ.optimizers['alphas'].param_groups[0]['lr']} \\n\"\n",
    "       f\" Tasks    Initial LR         : {environ.opt['train']['task_lr']:4f}      current LR : {environ.optimizers['weights'].param_groups[0]['lr']}    \\n\"\n",
    "       f\" Policy   Initial LR         : {environ.opt['train']['policy_lr']:4f}      current LR : {environ.optimizers['weights'].param_groups[1]['lr']}  \\n\")\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db34fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:47.803657Z",
     "start_time": "2022-03-28T04:02:47.736497Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# environ.opt['train']['policy_lr'] = 0.01\n",
    "# opt['train']['policy_lr']         = 0.01\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.1\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# environ.opt['train']['decay_temp_freq'] = 2\n",
    "# print(environ.optimizers['alphas'].param_groups)\n",
    "# print(environ.optimizers['weights'].param_groups)\n",
    "# print('current lr: ', environ.optimizers['alphas'].param_groups[0]['lr'],)\n",
    "# print('current lr: ', environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "# print('current lr: ', environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49645c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Weight & Policy Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aade16",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Weight/Policy Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe24a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:47.867009Z",
     "start_time": "2022-03-28T04:02:47.807720Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ns.flag_warmup = True\n",
    "# num_train_layers = None \n",
    "# environ.opt['is_curriculum'] = True\n",
    "# environ.opt['curriculum_speed'] = 4\n",
    "# ns.num_train_layers = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365996be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:47.944530Z",
     "start_time": "2022-03-28T04:02:47.871259Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if ns.flag_warmup:\n",
    "    print_heading( f\"** {timestring()} \\n\"\n",
    "                   f\"** Training epoch: {ns.current_epoch} iter: {ns.current_iter}   flag: {ns.flag} \\n\"\n",
    "                   f\"** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\\n\"\n",
    "                   f\"** Switch from Warm Up training to Alternate training Weights & Policy \\n\"\n",
    "                   f\"** Take checkpoint and block gradient flow through Policy net\", verbose=True)\n",
    "#     environ.define_optimizer(policy_learning=True)\n",
    "#     environ.define_scheduler(policy_learning=True)\n",
    "    ns.flag_warmup = False\n",
    "    ns.flag = 'update_weights'\n",
    "    environ.fix_alpha()\n",
    "    environ.free_weights(opt['fix_BN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc79e10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:48.024063Z",
     "start_time": "2022-03-28T04:02:47.950823Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ns.training_epochs = 250\n",
    "# environ.display_trained_policy(ns.current_epoch)\n",
    "# environ.display_trained_logits(ns.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d84a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:48.115175Z",
     "start_time": "2022-03-28T04:02:48.028324Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"ns.current_epoch           : {ns.current_epoch}\")\n",
    "print(f\"ns.training_epochs         : {ns.training_epochs} \\n\") \n",
    "print(f\"ns.current_iters           : {ns.current_iter}\")  \n",
    "print(f\"Batches in weight epoch    : {ns.stop_iter_w}\")\n",
    "print(f\"Batches in policy epoch    : {ns.stop_iter_a}\")\n",
    "print(f\"num_train_layers           : {ns.num_train_layers}\")\n",
    "print()\n",
    "print_loss(environ.val_metrics, title = f\"[e] Last ep:{ns.current_epoch}  it:{ns.current_iter}\")\n",
    "print()\n",
    "\n",
    "print_heading(f\" Last Epoch Completed : {ns.current_epoch}       # of epochs to run:  {ns.training_epochs} -->  epochs {ns.current_epoch+1} to {ns.training_epochs + ns.current_epoch}\"\n",
    "              f\"\\n policy_learning rate : {environ.opt['train']['policy_lr']} \"\n",
    "              f\"\\n lambda_sparsity      : {environ.opt['train']['lambda_sparsity']}\"\n",
    "              f\"\\n lambda_sharing       : {environ.opt['train']['lambda_sharing']}\"\n",
    "              f\"\\n curriculum training  : {opt['is_curriculum']}     cirriculum speed: {opt['curriculum_speed']}     num_training_layers : {ns.num_train_layers}\", \n",
    "              verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c71af",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Weight/Policy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ad7d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:27.891351Z",
     "start_time": "2022-03-28T04:02:48.119371Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# weight_policy_training(ns, opt, environ, dldrs, epochs = 100)\n",
    "weight_policy_training(ns, opt, environ, dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27779c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:28.065212Z",
     "start_time": "2022-03-28T05:13:27.897193Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ns.best_epoch, ns.best_iter, ns.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3dcb54",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3e42e43",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Close WandB run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b31da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.216421Z",
     "start_time": "2022-03-28T05:13:28.068834Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab259da4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.253924Z",
     "start_time": "2022-03-28T05:13:32.221329Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ns.best_epoch = 0\n",
    "# from utils.notebook_modules import wrapup_phase\n",
    "# wrapup_phase(ns, opt, environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb718c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.307351Z",
     "start_time": "2022-03-28T05:13:32.262822Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['policy_lr']       = 0.002\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.05\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# # environ.opt['train']['decay_temp_freq'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8accefdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.344678Z",
     "start_time": "2022-03-28T05:13:32.310706Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" \n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\\n\") \n",
    "\n",
    "print( f\" current_iters               : {ns.current_iter}   \\n\"\n",
    "       f\" current_epochs              : {ns.current_epoch}  \\n\" \n",
    "       f\" train_total_epochs          : {ns.training_epochs}\\n\" \n",
    "       f\" stop_epoch_training         : {ns.stop_epoch_training}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac6b6a",
   "metadata": {},
   "source": [
    "## Post Training Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de4040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T16:19:42.220730Z",
     "start_time": "2022-04-05T16:19:41.747365Z"
    }
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.losses)\n",
    "# pp.pprint(environ.val_metrics)\n",
    "# environ.num_layers, environ.networks['mtl-net'].num_layers\n",
    "# environ.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ca92e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T16:22:55.037557Z",
     "start_time": "2022-04-05T16:22:54.888980Z"
    }
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e5cec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T17:44:36.218784Z",
     "start_time": "2022-02-21T17:44:36.063411Z"
    }
   },
   "outputs": [],
   "source": [
    "# print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "# environ.display_trained_policy(current_epoch)\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c1c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:32:52.580865Z",
     "start_time": "2022-03-06T00:32:52.554112Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_label   = 'model_train_ep_%d_seed_%04d' % (current_epoch, opt['random_seed'])\n",
    "# metrics_label = 'metrics_train_ep_%d_seed_%04d.pickle' % (current_epoch, opt['random_seed'])\n",
    "# environ.save_checkpoint(model_label, current_iter, current_epoch) \n",
    "# save_to_pickle(environ.val_metrics, environ.opt['paths']['checkpoint_dir'], metrics_label)\n",
    "# print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "# environ.display_trained_policy(current_epoch,out=[sys.stdout, environ.log_file])\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad3a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T22:48:27.014120Z",
     "start_time": "2022-02-20T22:48:26.982535Z"
    }
   },
   "outputs": [],
   "source": [
    "# print_loss(current_iter, environ.losses, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")\n",
    "# print()\n",
    "# print_loss(current_iter, trn_losses, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")\n",
    "# print()\n",
    "# print_loss(current_iter, environ.val_metrics, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d5db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T20:31:45.254334Z",
     "start_time": "2022-03-01T20:31:45.116895Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.losses\n",
    "# environ.val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4dd81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T20:47:29.582501Z",
     "start_time": "2022-03-01T20:47:29.492581Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.batch_data\n",
    "# print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics, 0, out=[sys.stdout])\n",
    "# environ.display_parameters()\n",
    "\n",
    "# with np.printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', precision=7, formatter={'float': lambda x: f\"{x:12.5e}\"}):\n",
    "#     environ.print_logit_grads('gradients')\n",
    "\n",
    "# environ_params = environ.get_task_specific_parameters()\n",
    "# environ_params = environ.get_arch_parameters()\n",
    "# environ_params = environ.get_backbone_parameters()\n",
    "# print(environ_params)\n",
    "# for param in environ_params:\n",
    "#     print(param.grad.shape, '\\n', param.grad)\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c80c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:12:46.806056Z",
     "start_time": "2022-03-11T21:12:46.471801Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.display_trained_logits(ns.current_epoch)\n",
    "# environ.display_trained_policy(ns.current_epoch)\n",
    "\n",
    "# environ.display_test_sample_policy(ns.current_epoch, hard_sampling = True)\n",
    "# environ.display_train_sample_policy(ns.current_epoch, hard_sampling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754b317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:33:19.474125Z",
     "start_time": "2022-03-06T00:33:19.447847Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.define_optimizer(policy_learning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e89541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T18:04:00.517922Z",
     "start_time": "2022-04-02T18:04:00.442149Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(environ.optimizers['alphas'])\n",
    "# print(environ.optimizers['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ecc91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T00:07:50.026992Z",
     "start_time": "2022-03-09T00:07:49.986101Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('Policy  initial_lr : ', environ.optimizers['alphas'].param_groups[0]['initial_lr'], 'lr : ',environ.optimizers['alphas'].param_groups[0]['lr'])\n",
    "# print('Weights initial_lr : ', environ.optimizers['weights'].param_groups[0]['initial_lr'], 'lr : ',environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "# print('Weights initial_lr : ', environ.optimizers['weights'].param_groups[1]['initial_lr'], 'lr : ',environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1306e8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T22:31:50.425696Z",
     "start_time": "2022-03-10T22:31:50.396531Z"
    }
   },
   "outputs": [],
   "source": [
    "wandb.run is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b8e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:10:03.751132Z",
     "start_time": "2022-03-05T23:10:03.724538Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [],
   "source": [
    "# opt['exp_instance'] = '0218_1358'     \n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\"\n",
    "# print()\n",
    "# opt['exp_instance'] = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "# opt['exp_description'] = f\"No Alternating Weight/Policy - training all done with both weights and policy\"\n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2affee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:12:20.322227Z",
     "start_time": "2022-03-11T21:12:20.285961Z"
    }
   },
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2527bd00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T10:48:54.253046Z",
     "start_time": "2022-04-30T10:48:54.143506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18388, 85277) (18388,)\n"
     ]
    }
   ],
   "source": [
    "from utils import load_sparse\n",
    "ecfp     = load_sparse(opt['dataload']['dataroot'], opt['dataload']['x'])\n",
    "folding  = np.load(os.path.join(opt['dataload']['dataroot'], opt['dataload']['folding']))\n",
    "\n",
    "print(ecfp.shape, folding.shape)\n",
    "\n",
    "fold_va = opt['dataload']['fold_va']\n",
    "idx_tr  = np.where(folding != fold_va)[0]\n",
    "idx_va  = np.where(folding == fold_va)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecf7ff4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T10:49:49.952523Z",
     "start_time": "2022-04-30T10:49:49.884332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 0, 3, 1, 2, 4, 0, 1, 0, 4, 2, 4, 3, 0, 0, 2, 4, 0, 4, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 0, 0, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folding[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "919068f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T10:49:50.748013Z",
     "start_time": "2022-04-30T10:49:50.690335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  3,  4,  5,  6,  8, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_tr[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef20ed3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T10:49:52.175438Z",
     "start_time": "2022-04-30T10:49:52.104968Z"
    }
   },
   "outputs": [],
   "source": [
    "idx_tr2 = np.isin(folding, [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92e8cac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T10:49:53.568860Z",
     "start_time": "2022-04-30T10:49:53.502351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False,  True,  True,  True,  True, False,  True, False,  True,  True,  True,  True, False, False,  True,  True, False,  True])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_tr2[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76dafb74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T10:51:34.176972Z",
     "start_time": "2022-04-30T10:51:34.093419Z"
    }
   },
   "outputs": [],
   "source": [
    "ecfp_tr = ecfp[idx_tr]\n",
    "ecfp_tr2 = ecfp[idx_tr2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "938b1f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T10:51:48.263281Z",
     "start_time": "2022-04-30T10:51:48.191211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14633, 85277)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecfp_tr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcde09b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T11:07:11.516007Z",
     "start_time": "2022-04-30T11:07:11.441791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14633, 85277)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "res = (ecfp_tr != ecfp_tr2)\n",
    "print(res.shape)\n",
    "print(res[:10,:10].nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d1552a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T10:58:24.177162Z",
     "start_time": "2022-04-30T10:58:23.283605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total eaqual =  14633\n"
     ]
    }
   ],
   "source": [
    "equal = 0\n",
    "for i in range(14633):\n",
    "    for j in range(1):\n",
    "        if (ecfp_tr[i,j] != ecfp_tr2[i,j]):\n",
    "            print(i, j, '     ', ecfp_tr[i,j], '    !=    ', ecfp_tr2[i,j])\n",
    "        else:\n",
    "            equal+=1 \n",
    "print(\"total eaqual = \", equal)\n",
    "# print(ecfp_tr2[0,:100])\n",
    "# print(ecfp_tr[:10,:10] != ecfp_tr2[:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0f60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74828d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c82a453",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Post Warm-up Training stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb74c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:45:43.999959Z",
     "start_time": "2022-02-01T12:45:43.862475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b47da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:36.700361Z",
     "start_time": "2022-02-01T12:46:36.367037Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].arch_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f0235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:37:10.158440Z",
     "start_time": "2022-01-28T16:37:09.742327Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p = environ.get_sample_policy(hard_sampling = False)\n",
    "print(p)\n",
    "p = environ.get_policy_prob()\n",
    "print(p)\n",
    "p = environ.get_policy_logits()\n",
    "print(p)\n",
    "\n",
    "# p = environ.get_current_policy()\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bddd44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:40:37.799917Z",
     "start_time": "2022-01-28T16:40:37.773177Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = softmax([0.0, 1])\n",
    "print(a)\n",
    "sampled = np.random.choice((1, 0), p=a)\n",
    "print(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8f376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:13:16.205889Z",
     "start_time": "2022-01-28T16:13:16.179303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.optimizers['weights'])\n",
    "print(environ.schedulers['weights'].get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf9c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:50.411465Z",
     "start_time": "2022-02-01T12:46:50.020540Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('losses.keys      : ', environ.losses.keys())\n",
    "print('losses[task]keys : ', environ.losses['task1'].keys())\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20950069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T22:57:02.151169Z",
     "start_time": "2022-01-15T22:57:02.056562Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print( environ.val_metrics.keys())\n",
    "# pp.pprint(val_metrics)\n",
    "print(type(environ.val_metrics['aggregated']))\n",
    "print()\n",
    "print(type(environ.val_metrics['task1']['classification_agg']))\n",
    "print()\n",
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6e311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.266303Z",
     "start_time": "2022-01-14T18:57:26.166878Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"val_metrics.pkl\", mode= 'wb') as f:\n",
    "#         pickle.dump(val_metrics, f)\n",
    "    \n",
    "# with open('val_metrics.pkl', 'rb') as f:    \n",
    "#     tst_val_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00a8aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.297444Z",
     "start_time": "2022-01-14T18:57:26.269323Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(environ.input.shape) \n",
    "# a = getattr(environ, 'task1_pred')\n",
    "# yc_data = environ.batch['task1_data']\n",
    "# print(yc_data.shape)\n",
    "# yc_ind = environ.batch['task1_ind']\n",
    "# print(yc_ind.shape)\n",
    "# yc_hat_all = getattr(environ, 'task1_pred')\n",
    "# print(yc_hat_all.shape)\n",
    "# yc_hat  = yc_hat_all[yc_ind[0], yc_ind[1]]\n",
    "# print(yc_hat_all.shape, yc_hat.shape)\n",
    "\n",
    "# \n",
    "# environ.losses\n",
    "# loss = {}\n",
    "# for key in environ.losses.keys():\n",
    "#     loss[key] = {}\n",
    "#     for subkey, v in environ.losses[key].items():\n",
    "#         print(f\" key:  {key}   subkey: {subkey} \")\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             loss[key][subkey] = v.data\n",
    "#             print(f\" Tensor  -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "#         else:\n",
    "#             loss[key][subkey] = v\n",
    "#             print(f\" integer -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "# pp.pprint(tst_val_metrics)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987f89f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.340792Z",
     "start_time": "2022-01-14T18:57:26.302528Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print('metrics.keys: ', environ.metrics.keys())\n",
    "# print('metrics[task].keys: ', environ.metrics['task1'].keys())\n",
    "# pp.pprint(environ.metrics['task1'])\n",
    "# pp.pprint(environ.losses['task1']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ae417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.373399Z",
     "start_time": "2022-01-14T18:57:26.345065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# title='Iteration'\n",
    "# for t_id, _ in enumerate(environ.tasks):\n",
    "#     task_key = f\"task{t_id+1}\"\n",
    "# #     print_heading(f\"{title}  {current_iter}  {task_key} : {val_metrics[task_key]['classification_agg']}\", verbose = True)\n",
    "\n",
    "#     for key, _  in val_metrics[task_key]['classification_agg'].items():\n",
    "#         print('%s/%-20s'%(task_key, key), val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print(f\"{task_key:s}/{key:20s}\", val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print()\n",
    "#             # print_current_errors(os.path.join(self.log_dir, 'loss.txt'), current_iter,key, loss[key], time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b73b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:48.162261Z",
     "start_time": "2022-01-07T22:52:48.140423Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.print_loss(current_iter, start_time, metrics = val_metrics['loss'], verbose=True)\n",
    "# print(opt['lambdas'])\n",
    "# p = (opt['lambdas'][0] * environ.losses['tasks']['task1'])\n",
    "# print(p)\n",
    "\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics , title='validation', verbose=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850378b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:47.661019Z",
     "start_time": "2022-01-07T22:52:47.639094Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(current_iter)\n",
    "# print_metrics_cr(current_iter, t1 - t0, None, val_metrics , True)\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics, title='validation', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a80b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:14:58.034384Z",
     "start_time": "2022-01-07T23:14:58.004850Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\" val_metric keys               : {val_metrics.keys()}\")\n",
    "print(f\" loss keys                     : {val_metrics['loss'].keys()}\")\n",
    "print(f\" task1 keys                    : {val_metrics['task1'].keys()}\")\n",
    "print(f\" task1 classification keys     : {val_metrics['task1']['classification'].keys()}\")\n",
    "print(f\" task1 classification_agg keys : {val_metrics['task1']['classification_agg'].keys()}\")\n",
    "print()\n",
    "print(f\" task1                       : {val_metrics['task1']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task2                       : {val_metrics['task2']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task3                       : {val_metrics['task3']['classification_agg']['loss']:5f}\")\n",
    "print(f\" loss                        : {val_metrics['loss']['total']:5f}\")\n",
    "print(f\" train_time                  : {val_metrics['train_time']:2f}\")\n",
    "print(f\" epoch                       : {val_metrics['epoch']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc43a6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Post Weight + Policy Training Stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65640cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:22:20.634818Z",
     "start_time": "2022-01-27T00:22:20.444566Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].backbone.layer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4374287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:30:31.940280Z",
     "start_time": "2022-01-26T19:30:31.910058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_blocks = 6\n",
    "num_policy_layers = 6\n",
    "gt =  torch.ones((num_blocks)).long()\n",
    "gt0 =  torch.zeros((num_blocks)).long()\n",
    "print(gt)\n",
    "print(gt0)\n",
    "\n",
    "loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "print(loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651bc43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:42:31.300891Z",
     "start_time": "2022-01-26T19:42:31.257774Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if environ.opt['diff_sparsity_weights'] and not environ.opt['is_sharing']:\n",
    "    print(' cond 1')\n",
    "    ## Assign higher weights to higher layers \n",
    "    loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "    print(f\"{task_key} sparsity error:  {2 * (loss_weights[-num_blocks:] * environ.cross_entropy2(logits[-num_blocks:], gt)).mean()})\")\n",
    "    print_dbg(f\" loss_weights :  {loss_weights}\", verbose = True)\n",
    "    print_dbg(f\" cross_entropy:  {environ.cross_entropy2(logits[-num_blocks:], gt)}  \", verbose = True)\n",
    "    print_dbg(f\" loss[sparsity][{task_key}]: {self.losses['sparsity'][task_key] } \", verbose = True)\n",
    "\n",
    "else:\n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between \\n Logits   : \\n{logits[-num_blocks:]} \\n and gt: \\n{gt} \\n\", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-num_blocks:], gt)}\")\n",
    "    \n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt[-1:])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt0[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt0[-1:])} \\n\")\n",
    "    \n",
    "    print('\\n cond 3')    \n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt[0:1])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt0[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt0[0:1])} \\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686cd05",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ee1b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:30.155045Z",
     "start_time": "2022-01-26T00:14:30.107095Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# flag = 'update_w'\n",
    "# environ.fix_alpha\n",
    "# environ.free_w(opt['fix_BN'])\n",
    "\n",
    "flag = 'update_alpha'\n",
    "environ.fix_weights()\n",
    "environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7996b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:31.184285Z",
     "start_time": "2022-01-25T23:43:31.159229Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f436ee6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:34.993711Z",
     "start_time": "2022-01-26T00:14:34.968623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") \n",
    "\n",
    "train_total_epochs += 5\n",
    "\n",
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334a0b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T17:15:02.216665Z",
     "start_time": "2022-01-25T17:15:01.848081Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - t0, None, environ.val_metrics , num_prints)      \n",
    "\n",
    "# num_prints += 1\n",
    "# t0 = time.time()\n",
    "\n",
    "# # Take check point\n",
    "# environ.save_checkpoint('latest', current_iter)\n",
    "# environ.train()\n",
    "# #-------------------------------------------------------\n",
    "# # END validation process\n",
    "# #-------------------------------------------------------       \n",
    "# flag = 'update_alpha'\n",
    "# environ.fix_w()\n",
    "# environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c4f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:08:57.366231Z",
     "start_time": "2022-01-08T01:08:57.295445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dilation = 2\n",
    "# kernel_size = np.asarray((3, 3))\n",
    "# upsampled_kernel_size = (kernel_size - 1) * (dilation - 1) + kernel_size\n",
    "# print(upsampled_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500c390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:39.763599Z",
     "start_time": "2022-01-25T23:43:39.728402Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.optimizers['weights'].param_groups[0]\n",
    "# for param_group in optimizer.param_groups:\n",
    "#     return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb71bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:41.628847Z",
     "start_time": "2022-01-25T23:43:41.602238Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.schedulers['weights'].get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7934862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:36:17.129535Z",
     "start_time": "2022-01-08T01:36:16.006144Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.optimizers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    current_state[k] = v.state_dict()\n",
    "pp.pprint(current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5faf7f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:40:22.032247Z",
     "start_time": "2022-01-08T01:40:22.006953Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.schedulers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    print(v.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd497e72",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Losses and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66169a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T16:34:44.555617Z",
     "start_time": "2022-02-09T16:34:44.507417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_losses = environ.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb8234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:35:11.758429Z",
     "start_time": "2022-02-10T03:35:11.278211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0301f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:21:49.107793Z",
     "start_time": "2022-02-10T03:21:49.084484Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498b6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:20:32.866010Z",
     "start_time": "2022-02-10T03:20:32.442919Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "pp.pprint(trn_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe30724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:34:21.945701Z",
     "start_time": "2022-02-10T03:34:21.411234Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d81167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:49.364883Z",
     "start_time": "2022-01-27T00:58:49.342931Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['Lambda_sharing'] = 0.5\n",
    "# opt['train']['Lambda_sharing'] = 0.5\n",
    "\n",
    "# environ.opt['train']['policy_lr'] = 0.001\n",
    "# opt['train']['policy_lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73aa06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T01:00:41.996410Z",
     "start_time": "2022-01-26T01:00:41.559006Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.losses.keys()\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ece74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:19:43.683550Z",
     "start_time": "2022-01-08T01:19:43.571450Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = environ.get_loss_dict()\n",
    "print(tmp.keys())\n",
    "pp.pprint(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac0256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:50.458223Z",
     "start_time": "2022-01-27T00:58:50.430889Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(opt['diff_sparsity_weights'])\n",
    "print(opt['is_sharing'])\n",
    "print(opt['diff_sparsity_weights'] and not opt['is_sharing'])\n",
    "print(environ.opt['train']['Lambda_sharing'])\n",
    "print(opt['train']['Lambda_sharing'])\n",
    "print(environ.opt['train']['Lambda_sparsity'])\n",
    "print(opt['train']['Lambda_sparsity'])\n",
    "print(environ.opt['train']['policy_lr'])\n",
    "print(opt['train']['policy_lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2d510",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Policy / Logit stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb628497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:35:14.041577Z",
     "start_time": "2022-02-08T20:35:14.018303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.special          import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eed454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:30.103364Z",
     "start_time": "2022-02-08T20:00:30.068021Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03b5cc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_task_logits(n)` Get logits for task group n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed8b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:56:35.652087Z",
     "start_time": "2022-02-08T20:56:35.327406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task_logits = environ.get_task_logits(1)\n",
    "print(task_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66fa5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_arch_parameters()`: Get last used logits from network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85521e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:31.101960Z",
     "start_time": "2022-02-08T20:00:30.757064Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b0bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:06.054699Z",
     "start_time": "2022-02-09T15:43:05.689327Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea1743",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_logits()`:  Get Policy Logits - returns same as `get_arch_parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb40c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:24.972390Z",
     "start_time": "2022-02-09T15:43:24.636629Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs = environ.get_policy_logits()\n",
    "for i in logs:\n",
    "    print(i, '\\n')\n",
    "# probs = softmax(logs, axis= -1)\n",
    "# for i in probs:\n",
    "#     print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080a364",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_prob()` : Gets the softmax of the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c75af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:29.733732Z",
     "start_time": "2022-02-09T15:43:29.699600Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "for i in policy_softmaxs:\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3160d9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = False)` : Calls test_sample_policy of network with random choices based on softmax of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f411444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:21:15.636722Z",
     "start_time": "2022-02-08T22:21:15.165456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "policies,logits = environ.get_sample_policy(hard_sampling = False)\n",
    "\n",
    "for l, p, s in zip(logits, policies, policy_softmaxs) :\n",
    "    for  l_row, p_row, s_row in zip(l, p, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802664ec",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = True)` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea65bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:59:40.790899Z",
     "start_time": "2022-02-08T20:59:40.726657Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "hard_policies, logits = environ.get_sample_policy(hard_sampling = True)\n",
    "\n",
    "for p,l,s in zip(hard_policies, logits, policy_softmaxs) :\n",
    "    for  p_row, l_row, s_row in zip(p, l, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c39cf",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fe096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:00:47.452220Z",
     "start_time": "2022-02-08T21:00:47.422902Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\" Layer    task 1      task 2      task 3\")\n",
    "print(f\" -----    ------      ------      ------\")\n",
    "for idx, (l1, l2, l3) in enumerate(zip(hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1}       {l2}       {l3}\")\n",
    "    \n",
    "\n",
    "    print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade0ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:39:39.936555Z",
     "start_time": "2022-02-08T22:39:39.911591Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_trained_policy(iter):\n",
    "\n",
    "    policy_softmaxs = environ.get_policy_prob()\n",
    "    policy_argmaxs = 1-np.argmax(policy_softmaxs, axis = -1)\n",
    "    print(f\"  Trained polcies at iteration: {iter} \")\n",
    "    print(f\"                   task 1                           task 2                         task 3        \")\n",
    "    print(f\" Layer       softmax        select          softmax        select          softmax        select   \")\n",
    "    print(f\" -----    ---------------   ------       ---------------   ------       ---------------   ------   \")\n",
    "    for idx, (l1,l2,l3,  p1,p2,p3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2], policy_argmaxs[0], policy_argmaxs[1], policy_argmaxs[2]),1):\n",
    "        print(f\"   {idx}      {l1[0]:.4f}   {l1[1]:.4f}   {p1:4d}    {l2[0]:11.4f}   {l2[1]:.4f}   {p2:4d}    {l3[0]:11.4f}   {l3[1]:.4f}   {p3:4d}\")\n",
    "\n",
    "    print()\n",
    "# print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec208dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:42:12.650813Z",
     "start_time": "2022-02-08T22:42:12.330169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display_trained_policy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec517e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:07:30.836214Z",
     "start_time": "2022-02-08T22:07:30.804575Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"                        POLICIES (SOFTMAX)                                       task 3          \")\n",
    "print(f\" Layer    task1              task2            task3 softmax         softmax         argmax         softmax         argmax   \")\n",
    "print(f\" -----    -------------     -------------     -------------   ------   \")\n",
    "for idx, (l1,l2,l3, h1,h2,h3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2],hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1[0]:.4f} {l1[1]:.4f}     {l2[0]:.4f} {l2[1]:.4f}     {l3[0]:.4f} {l3[1]:.4f}    {h3}\")\n",
    "    \n",
    "print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbeacb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:04:50.757406Z",
     "start_time": "2022-02-08T22:04:50.731736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(policy_softmaxs[2], np.argmax(1-policy_softmaxs[2], axis = -1))\n",
    "print(policy_softmaxs, np.argmax(policy_softmaxs, axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be0240",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_logits()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb7240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:19:06.155425Z",
     "start_time": "2022-02-08T21:19:06.118640Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits  = (environ.get_current_logits())\n",
    "for i in logits:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e84662",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_policy()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cfa24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:40:06.543376Z",
     "start_time": "2022-02-08T20:40:06.230711Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pols  = (environ.get_current_policy())\n",
    "\n",
    "for i in pols:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f556a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T18:27:33.593255Z",
     "start_time": "2022-01-27T18:27:33.553141Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792710e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `gumbel_softmax()`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265490e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:28:17.107529Z",
     "start_time": "2022-02-08T21:28:17.084910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', floatmode = 'maxprec_equal')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb0087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:35:11.617269Z",
     "start_time": "2022-02-08T21:35:11.569599Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.temp)\n",
    "# tau = environ.temp\n",
    "tau = 1\n",
    "for i in range(3): \n",
    "    logits_tensor = torch.tensor(logits[0])\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=tau, hard=False).cpu().numpy() \n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=tau, hard=True).cpu().numpy()\n",
    "    \n",
    "    for l, gs, gh in zip(lgts, gumbel_soft, gumbel_hard):\n",
    "        print(f\"   {l}   \\t {gs}            \\t {gh}\")\n",
    "#     print(lgts)\n",
    "#     print(gumbel_soft)\n",
    "#     print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5ef7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e0e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:21:35.524957Z",
     "start_time": "2022-02-08T21:21:35.488812Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for lgts in logits:\n",
    "    logits_tensor = torch.tensor(lgts)\n",
    "    print(lgts)\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=1, hard=False)\n",
    "    print(gumbel_soft)\n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=1, hard=True)\n",
    "    print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34a06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T20:49:37.643349Z",
     "start_time": "2022-02-03T20:49:37.580786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smax = scipy.special.softmax(logs, axis =1)\n",
    "# smax = np.array( \n",
    "# [[0.46973792, 0.530262  ],\n",
    "#  [0.45025694, 0.549743  ],\n",
    "#  [0.4443086 , 0.5556915 ],\n",
    "#  [0.4138397 , 0.58616036],\n",
    "#  [0.4140113 , 0.5859887 ],\n",
    "#  [0.42114905, 0.57885087]])\n",
    "\n",
    "print(smax.shape)\n",
    "print(smax)\n",
    "print(smax[0])\n",
    "print(smax[0].sum())\n",
    "print(np.random.choice((1,0), p =smax[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7de25c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:15:19.893888Z",
     "start_time": "2022-02-08T21:15:19.870899Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logs = np.array(\n",
    "[[0.33064184, 0.42053092],\n",
    " [0.3532089 , 0.52056104],\n",
    " [0.3888512 , 0.5680909 ],\n",
    " [0.42039296, 0.694217  ],\n",
    " [0.4519742 , 0.73311865],\n",
    " [0.48401102, 0.7522658 ]],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "399px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
