{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23a61ee",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7792b732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T21:53:02.026684Z",
     "start_time": "2022-03-08T21:53:01.930148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from copy import deepcopy\n",
    "sys.path.insert(0, './src')\n",
    "# print(sys.path)\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from tqdm import tqdm, trange\n",
    "\n",
    "from utils.notebook_modules import initialize, init_dataloaders, init_environment, init_wandb, \\\n",
    "                                   training_prep, retrain_prep, retrain_phase,  \\\n",
    "                                   disp_dataloader_info,disp_info_1, disp_for_excel, disp_gpu_info\n",
    "\n",
    "from utils.util import (print_separator, print_underline, print_yaml,  print_loss, \n",
    "                        timestring, print_heading, print_dbg, get_command_line_args ) \n",
    "\n",
    "\n",
    "# from envs.sparsechem_env_dev import SparseChemEnv_Dev\n",
    "# from utils.sparsechem_utils import load_sparse, load_task_weights, class_fold_counts, fold_and_transform_inputs, print_metrics_cr\n",
    "# from dataloaders.chembl_dataloader_dev import ClassRegrSparseDataset_v3, ClassRegrSparseDataset, InfiniteDataLoader\n",
    "from utils.util import ( makedir, print_separator, create_path, print_yaml, print_yaml2, print_loss, should, \n",
    "                         fix_random_seed, read_yaml, timestring, print_heading, print_dbg, save_to_pickle, load_from_pickle,\n",
    "                         print_underline, write_config_report, display_config, get_command_line_args, is_notebook) \n",
    "### Read Configuration File### Initialization\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Retrain.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e201d4",
   "metadata": {},
   "source": [
    "### Parse Input Args & Read yaml config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec8db9e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T20:52:20.531071Z",
     "start_time": "2022-03-08T20:52:20.471146Z"
    }
   },
   "outputs": [],
   "source": [
    "RETRAIN_FROM_PATH  = '../experiments/AdaSparseChem/50x6_0308_1204_plr0.01_sp0.01_sh0.01'\n",
    "RETRAIN_MODEL_CKPT = 'model_train_ep_25_seed_0088'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b487a31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T20:40:51.396321Z",
     "start_time": "2022-03-08T20:40:51.353925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  command line parms : \n",
      "------------------------\n",
      " config...................  yamls/chembl_3task_retrain.yaml\n",
      " exp_id...................  None\n",
      " exp_name.................  0308_1204\n",
      " folder_sfx...............  Retrain\n",
      " exp_desc.................  Retrain phase of 0308_1204 run - 1\n",
      " seed_idx.................  0\n",
      " batch_size...............  128\n",
      " backbone_lr..............  None\n",
      " task_lr..................  None\n",
      " policy_lr................  None\n",
      " decay_lr_rate............  None\n",
      " decay_lr_freq............  None\n",
      " lambda_sparsity..........  0.01\n",
      " lambda_sharing...........  0.01\n",
      " gpu_ids..................  [0]\n",
      " resume...................  False\n",
      " cpu......................  False\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_args = \" --config yamls/chembl_3task_retrain.yaml \" \\\n",
    "             \" --exp_name    0308_1204\" \\\n",
    "             \" --folder_sfx    Retrain\" \\\n",
    "             \" --exp_desc Retrain phase of 0308_1204 run - 1\" \\\n",
    "             \" --seed_idx 0 \"    \\\n",
    "             \" --batch_size 128\" \\\n",
    "             \" --lambda_sparsity  0.01\"\\\n",
    "             \" --lambda_sharing   0.01\" \n",
    "### Read Configuration File\n",
    "# get command line arguments\n",
    "# args = get_command_line_args(input_args.split())\n",
    "\n",
    "opt, ns = initialize(input_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bfa8d",
   "metadata": {},
   "source": [
    "### Setup Dataloader and Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c631eb67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T20:43:15.144227Z",
     "start_time": "2022-03-08T20:43:10.945247Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############### CREATE DATALOADERS ###############\n",
      "##################################################\n",
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      " device is  cuda:0\n",
      "--------------------------------------------------------\n",
      "* SparseChemEnv_Dev environment successfully created\n",
      "-------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dldrs = init_dataloaders(opt)\n",
    "\n",
    "environ = init_environment(ns, opt, is_train = True, policy_learning = False, display_cfg = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "895600f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T21:36:34.555573Z",
     "start_time": "2022-03-08T21:36:34.465545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['args', 'config_filename', 'wandb_run', 'eval_iters'])\n",
      "dict_keys(['trainset0', 'trainset1', 'trainset2', 'valset', 'testset', 'warmup_trn_loader', 'weight_trn_loader', 'policy_trn_loader', 'val_loader', 'test_loader'])\n"
     ]
    }
   ],
   "source": [
    "print(ns.__dict__.keys())\n",
    "print(dldrs.__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f70a390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T20:43:15.504772Z",
     "start_time": "2022-03-08T20:43:15.412872Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " trainset.y_class                                   :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " trainset1.y_class                                  :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " trainset2.y_class                                  :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " valset.y_class                                     :  [(4137, 5), (4137, 5), (4137, 5)]  \n",
      " testset.y_class                                    :  [(920, 5), (920, 5), (920, 5)]  \n",
      "                                 \n",
      " size of training set 0 (warm up)                   :  13331 \n",
      " size of training set 1 (network parms)             :  13331 \n",
      " size of training set 2 (policy weights)            :  13331 \n",
      " size of validation set                             :  4137 \n",
      " size of test set                                   :  920 \n",
      "                               Total                :  45050 \n",
      "                                 \n",
      " lenght (# batches) in training 0 (warm up)         :  105 \n",
      " lenght (# batches) in training 1 (network parms)   :  105 \n",
      " lenght (# batches) in training 2 (policy weights)  :  105 \n",
      " lenght (# batches) in validation dataset           :  33 \n",
      " lenght (# batches) in test dataset                 :  29 \n",
      "                                \n"
     ]
    }
   ],
   "source": [
    "disp_dataloader_info(dldrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320fdeee",
   "metadata": {},
   "source": [
    "###  Weights and Biases Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5dfe152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T20:45:57.488388Z",
     "start_time": "2022-03-08T20:45:57.453920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3qg62on3 0308_1204_Retrain AdaSparseChem\n"
     ]
    }
   ],
   "source": [
    "print(opt['exp_id'], opt['exp_name'], opt['project_name']) # , opt['exp_instance'])\n",
    "# opt['exp_id'] = wandb.util.generate_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cb3e2d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T20:46:00.509435Z",
     "start_time": "2022-03-08T20:45:58.582794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3qg62on3 0308_1204_Retrain AdaSparseChem\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kbardool/kusanagi/AdaSparseChem/wandb/run-20220308_124558-3qg62on3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"http://localhost:8080/kbardool/AdaSparseChem/runs/3qg62on3\" target=\"_blank\">0308_1204_Retrain</a></strong> to <a href=\"http://localhost:8080/kbardool/AdaSparseChem\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PROJECT NAME: AdaSparseChem\n",
      " RUN ID      : 3qg62on3 \n",
      " RUN NAME    : 0308_1204_Retrain\n",
      " PROJECT NAME: AdaSparseChem\n",
      " RUN ID      : 3qg62on3 \n",
      " RUN NAME    : 0308_1204_Retrain\n"
     ]
    }
   ],
   "source": [
    "init_wandb(ns, opt, environment = environ)\n",
    "\n",
    "# print(f\" PROJECT NAME: {ns.wandb_run.project}\\n\"\n",
    "#       f\" RUN ID      : {ns.wandb_run.id} \\n\"\n",
    "#       f\" RUN NAME    : {ns.wandb_run.name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f65f7ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T20:46:16.245556Z",
     "start_time": "2022-03-08T20:46:16.181173Z"
    }
   },
   "outputs": [],
   "source": [
    "# wandb.config = opt.copy()\n",
    "# wandb.watch(environ.networks['mtl-net'], log='all', log_freq=1000)     ###  Weights and Biases Initialization \n",
    "# run.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e228533",
   "metadata": {},
   "source": [
    "### Load Model Snapshot and  Saved Policy (if present)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bcef83",
   "metadata": {},
   "source": [
    "Load the following files \n",
    "    -  Desired checkpoint \n",
    "    -  Policy file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cc232d25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:11:13.697131Z",
     "start_time": "2022-03-08T22:11:13.627223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Policy Label   : policy_ep_25_seed_0088\n",
      " Hard sampling  : False\n",
      "warmup\n"
     ]
    }
   ],
   "source": [
    "current_iter, current_epoch = 0, 0\n",
    "opt['retrain_from_pl'], environ.opt['retrain_from_pl'] = True, True\n",
    "policy_label = 'policy_ep_%s_seed_%04d' % (25, opt['random_seed'])\n",
    "# policy_label = 'policy_ep_%s_seed_%04d' % (opt['train']['policy_iter'], opt['random_seed'])\n",
    "\n",
    "print(f\" Policy Label   : {policy_label}\")\n",
    "# print(f\" Retrain Resume : {opt['train']['retrain_resume']}, {environ.opt['train']['retrain_resume']}\")\n",
    "# print(f\" Retrain from PL: {opt['retrain_from_pl']}, {environ.opt['retrain_from_pl']}\")\n",
    "print(f\" Hard sampling  : {opt['train']['hard_sampling']}\")\n",
    "print(opt['train']['which_iter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b0ec48cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:11:14.527038Z",
     "start_time": "2022-03-08T22:11:14.320094Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############## START RETRAIN PHASE ###############\n",
      "##################################################\n",
      "\n",
      " I. Deep copy environ.get_current_state(0)\n",
      "-------------------------------------------\n",
      " sparsechem_env-dev get_current_state()   0    unknown\n",
      "\n",
      " \n",
      " II. environ.check_exist_policy() Check if policy_ep_25_seed_0088 exists\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      " \n",
      " A. load existing POLICY: policy_ep_25_seed_0088\n",
      "---------------------------------------------------\n",
      "\n",
      " \n",
      " 6. load checkpoint best\n",
      "---------------------------\n",
      "=> loading snapshot from ../experiments/AdaSparseChem/50x6_0308_1204_plr0.01_sp0.01_sh0.01/model_train_ep_25_seed_0088_model.pth.tar\n",
      "   Loading to GPU cuda:0\n",
      "  networks -  network:  mtl-net\n",
      "  load snapshot - network:  mtl-net\n",
      "    network mtl-net - item task1_logits\n",
      "    network mtl-net - item task2_logits\n",
      "    network mtl-net - item task3_logits\n",
      "    network mtl-net - item backbone.Input_linear.weight\n",
      "    network mtl-net - item backbone.Input_linear.bias\n",
      "    network mtl-net - item backbone.blocks.0.0.linear.weight\n",
      "    network mtl-net - item backbone.blocks.0.0.linear.bias\n",
      "    network mtl-net - item backbone.blocks.1.0.linear.weight\n",
      "    network mtl-net - item backbone.blocks.1.0.linear.bias\n",
      "    network mtl-net - item backbone.blocks.2.0.linear.weight\n",
      "    network mtl-net - item backbone.blocks.2.0.linear.bias\n",
      "    network mtl-net - item backbone.blocks.3.0.linear.weight\n",
      "    network mtl-net - item backbone.blocks.3.0.linear.bias\n",
      "    network mtl-net - item backbone.blocks.4.0.linear.weight\n",
      "    network mtl-net - item backbone.blocks.4.0.linear.bias\n",
      "    network mtl-net - item backbone.blocks.5.0.linear.weight\n",
      "    network mtl-net - item backbone.blocks.5.0.linear.bias\n",
      "    network mtl-net - item task1_fc1_c0.linear.weight\n",
      "    network mtl-net - item task1_fc1_c0.linear.bias\n",
      "    network mtl-net - item task2_fc1_c0.linear.weight\n",
      "    network mtl-net - item task2_fc1_c0.linear.bias\n",
      "    network mtl-net - item task3_fc1_c0.linear.weight\n",
      "    network mtl-net - item task3_fc1_c0.linear.bias\n",
      "  optimizers - optimizer:  weights\n",
      "    load snapshot - optimizer: weights \n",
      "  optimizers - optimizer:  alphas\n",
      "    load snapshot - optimizer: alphas \n",
      " data is :  (3675, 25)\n",
      "\n",
      " \n",
      " get_current_policy(): Get environ.policy<i> attributes and return as list\n",
      "-----------------------------------------------------------------------------\n",
      "[[0 1 1 0 0 1]\n",
      " [0 1 0 1 1 0]\n",
      " [1 0 0 1 1 0]\n",
      " [1 0 0 1 1 0]\n",
      " [0 1 0 1 1 0]\n",
      " [1 0 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "environ.define_optimizer(policy_learning=True)\n",
    "environ.define_scheduler(policy_learning=True)\n",
    "\n",
    "\n",
    "# ********************************************************************\n",
    "# **************** Initialize the environment ************************\n",
    "# ********************************************************************    \n",
    "if opt['train']['retrain_resume']:\n",
    "    print_separator('CONTINUE RETRAIN PHASE')    \n",
    "    data = environ.load_checkpoint(opt['train']['which_iter'], verbose = True)\n",
    "    if opt['policy_model'] == 'task-specific':\n",
    "        environ.load_policy(policy_label)\n",
    "else:\n",
    "    print_separator('START RETRAIN PHASE')       \n",
    "    if opt['policy_model'] == 'task-specific':\n",
    "            print_underline(f\"I. Deep copy environ.get_current_state(0)\", verbose= True)\n",
    "            init_state = deepcopy(environ.get_current_state(0))\n",
    "\n",
    "            print_underline(f\"\\n II. environ.check_exist_policy() Check if {policy_label} exists\", verbose = True)\n",
    "            \n",
    "            if environ.check_exist_policy(policy_label):\n",
    "                print_underline(f\"\\n A. load existing POLICY: {policy_label}\", verbose = True)\n",
    "                environ.load_policy(policy_label)\n",
    "            else:         \n",
    "                print_underline(f\"\\n 1. load checkpoint : {RETRAIN_FROM_PATH} - {RETRAIN_MODEL_CKPT}\", verbose = True)\n",
    "                loaded_iter, loaded_epoch = environ.load_checkpoint(RETRAIN_MODEL_CKPT, path=RETRAIN_FROM_PATH, verbose = True)\n",
    "             \n",
    "                \n",
    "                print_underline(\"\\n 2. get_policy_logits from network['mtl-net']\", verbose = True)\n",
    "                dists = environ.get_policy_logits()\n",
    "                overall_logits = np.concatenate(dists, axis=-1)\n",
    "                print(f' {type(overall_logits)}  - {overall_logits.shape}\\n {overall_logits} \\n')\n",
    "\n",
    "                print_underline(f\"\\n 3. environ.get_policy_prob(): Get logits from networks['mtl-net'], apply softmax, and print\", verbose = True)\n",
    "                dists = environ.get_policy_prob()\n",
    "                overall_dist = np.concatenate(dists, axis=-1)\n",
    "                print(f' {type(overall_dist)}  - {overall_dist.shape}\\n {overall_dist} \\n')\n",
    "\n",
    "                print_underline(f\"\\n 4. environ.sample_policy() : call test_sample_policy(hard_sampling = \"\n",
    "                                f\"{opt['train']['hard_sampling']}) and save as environ.policy<i> attributes\", verbose = True)\n",
    "                environ.sample_policy(opt['train']['hard_sampling'])\n",
    "                print(f\"logits: \\n {np.concatenate(environ.get_current_logits(), axis=-1)}\")\n",
    "                print(f\"policies: \\n {np.concatenate(environ.get_current_policy(), axis=-1)}\")\n",
    "                \n",
    "                print_underline(f'\\n 5. environ.save_policy() : save environ.policy<i> attributes to file {policy_label}', verbose = True)\n",
    "                environ.save_policy(policy_label)\n",
    "\n",
    "            if opt['retrain_from_pl']:\n",
    "                print_underline(f\"\\n 6. load checkpoint {opt['train']['policy_iter']}\", verbose = True)            \n",
    "#                 environ.load_checkpoint(opt['train']['policy_iter'])\n",
    "                loaded_iter, loaded_epoch = environ.load_checkpoint(RETRAIN_MODEL_CKPT, path=RETRAIN_FROM_PATH, verbose = True)\n",
    "            else:\n",
    "                print_underline(f\"\\n 7. load snapshot from init_state ( get_current_state(0) )\", verbose = True)                  \n",
    "                loaded_iter, loaded_epoch = environ.load_snapshot(init_state)\n",
    "\n",
    "\n",
    "print_underline(f\"\\n get_current_policy(): Get environ.policy<i> attributes and return as list\", verbose = True)          \n",
    "policys = environ.get_current_policy()\n",
    "overall_policy = np.concatenate(policys, axis=-1)\n",
    "print(overall_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c53ebfbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:11:19.641274Z",
     "start_time": "2022-03-08T22:11:19.579609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3675 25\n"
     ]
    }
   ],
   "source": [
    "print(loaded_iter, loaded_epoch)\n",
    "# current_epoch = 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c0f5c990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:11:20.847575Z",
     "start_time": "2022-03-08T22:11:20.789476Z"
    }
   },
   "outputs": [],
   "source": [
    "# print('\\n sample policy()')\n",
    "# print('-----------------')\n",
    "# environ.sample_policy(hard_sampling = opt['train'][R'hard_sampling'], verbose = True)\n",
    "# environ.sample_policy(hard_sampling = False, verbose = True)\n",
    "# print(environ.networks['mtl-net'].policys)\n",
    "# print(environ.networks['mtl-net'].policy1)\n",
    "\n",
    "# environ.display_trained_logits(0)\n",
    "# environ.display_trained_policy(0)\n",
    "\n",
    "# print_underline(f\"get_current_policy()\",verbose =True) \n",
    "# policys = environ.get_current_policy()\n",
    "# print( np.concatenate(policys, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8a811e26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:11:21.123898Z",
     "start_time": "2022-03-08T22:11:21.063221Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(environ.networks['mtl-net'].num_layers, environ.networks['mtl-net'].skip_layer)\n",
    "# environ.networks['mtl-net'].policys\n",
    "# \n",
    "# environ.display_test_sample_policy(0, hard_sampling = False)\n",
    "# environ.display_test_sample_policy(0, hard_sampling = True)\n",
    "# \n",
    "# environ.display_train_sample_policy(0, hard_sampling = False)\n",
    "# environ.display_train_sample_policy(0, hard_sampling = True)\n",
    "\n",
    "# print(f\"\\n 8. get_current_policy\")          \n",
    "# policys = environ.get_current_policy()\n",
    "# overall_policy = np.concatenate(policys, axis=-1)\n",
    "# print(overall_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "274f7cd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:11:22.181905Z",
     "start_time": "2022-03-08T22:11:22.124092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      "\n",
      "Parameter Group 1\n",
      "    dampening: 0\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(environ.optimizers['alphas'])\n",
    "print(environ.optimizers['weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc88564",
   "metadata": {},
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4828f12e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:11:28.433666Z",
     "start_time": "2022-03-08T22:11:28.091444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set eval_iters to length of val loader  : 33\n",
      "opt['train']['retrain_total_iters']:   25000\n"
     ]
    }
   ],
   "source": [
    "retrain_prep(ns, opt, environ, dldrs, phase = 'update_w', epoch = loaded_epoch, iter = loaded_iter )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "79099102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:11:30.185487Z",
     "start_time": "2022-03-08T22:11:30.100386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['args', 'config_filename', 'wandb_run', 'eval_iters', 'stop_iter_w', 'flag', 'best_results', 'best_metrics', 'best_value', 'best_iter', 'current_epoch', 'current_iter', 'stop_epoch_training', 'training_epochs'])\n",
      "dict_keys(['trainset0', 'trainset1', 'trainset2', 'valset', 'testset', 'warmup_trn_loader', 'weight_trn_loader', 'policy_trn_loader', 'val_loader', 'test_loader'])\n"
     ]
    }
   ],
   "source": [
    "print(ns.__dict__.keys())\n",
    "print(dldrs.__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "16c5365f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:21:55.436535Z",
     "start_time": "2022-03-08T22:18:14.183328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed: 35   # of epochs to do:  10 -  epochs 36 to 45\n",
      " stop_iter_w         : 105\n",
      " policy_lr           : 0.01\n",
      " lambda_sparsity     : 0.01\n",
      " lambda_sharing      : 0.01\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   36 |   8.50e-04   8.50e-04   1.00e-02  3.347e+00 |    2.6231   2.1375e+00   3.2885e-02    4.7935 |   0.60225   0.80157   0.80549   0.80144 |    9.0365   2.1375e+00   3.2885e-02    11.2069 |  21.1 |\n",
      "   37 |   8.50e-04   8.50e-04   1.00e-02  3.347e+00 |    2.7483   2.1375e+00   3.2885e-02    4.9187 |   0.60355   0.80160   0.80570   0.80147 |    9.0616   2.1375e+00   3.2885e-02    11.2320 |  21.0 |\n",
      "   38 |   8.50e-04   8.50e-04   1.00e-02  3.347e+00 |    2.6356   2.1375e+00   3.2885e-02    4.8060 |   0.60661   0.80189   0.80586   0.80176 |    9.0852   2.1375e+00   3.2885e-02    11.2556 |  21.8 |\n",
      "   39 |   8.50e-04   8.50e-04   1.00e-02  3.347e+00 |    2.6222   2.1375e+00   3.2885e-02    4.7926 |   0.61190   0.80197   0.80609   0.80184 |    9.1772   2.1375e+00   3.2885e-02    11.3476 |  21.4 |\n",
      "   40 |   8.50e-04   8.50e-04   1.00e-02  3.347e+00 |    2.5442   2.1375e+00   3.2885e-02    4.7146 |   0.61074   0.80200   0.80604   0.80187 |    9.1521   2.1375e+00   3.2885e-02    11.3225 |  22.2 |\n",
      "   41 |   8.50e-04   8.50e-04   1.00e-02  3.347e+00 |    2.3903   2.1375e+00   3.2885e-02    4.5607 |   0.61259   0.80192   0.80607   0.80180 |    9.2192   2.1375e+00   3.2885e-02    11.3896 |  21.7 |\n",
      "   42 |   8.50e-04   8.50e-04   1.00e-02  3.347e+00 |    2.5909   2.1375e+00   3.2885e-02    4.7613 |   0.61549   0.80223   0.80640   0.80210 |    9.2452   2.1375e+00   3.2885e-02    11.4156 |  23.0 |\n",
      "   43 |   8.50e-04   8.50e-04   1.00e-02  3.347e+00 |    2.5373   2.1375e+00   3.2885e-02    4.7077 |   0.61786   0.80231   0.80648   0.80219 |    9.2577   2.1375e+00   3.2885e-02    11.4281 |  21.6 |\n",
      "   44 |   8.50e-04   8.50e-04   1.00e-02  3.347e+00 |    2.6760   2.1375e+00   3.2885e-02    4.8464 |   0.61755   0.80249   0.80667   0.80236 |    9.2700   2.1375e+00   3.2885e-02    11.4404 |  22.7 |\n",
      "   45 |   7.22e-04   7.22e-04   1.00e-02  3.347e+00 |    2.5634   2.1375e+00   3.2885e-02    4.7338 |   0.62252   0.80232   0.80669   0.80219 |    9.3228   2.1375e+00   3.2885e-02    11.4932 |  22.3 |\n",
      " sparsechem_env-dev get_current_state()   5775    45\n",
      "[Final] ep:45  it:5775 -  Total Loss: 11.4932     \n",
      "Task: 9.3228   Sparsity: 2.13751e+00    Sharing: 3.28845e-02 \n",
      "\n",
      " epch:  45   softmax       sel        softmax        sel        softmax        sel \n",
      " -----  -----------------  ---    -----------------  ---    -----------------  --- \n",
      "   1    0.4229     0.5771   0     0.3763     0.6237   0     0.3072     0.6928   0\n",
      "   2    0.5211     0.4789   1     0.4969     0.5031   0     0.4598     0.5402   0\n",
      "   3    0.6552     0.3448   1     0.5251     0.4749   1     0.5784     0.4216   1\n",
      "   4    0.7290     0.2710   1     0.6255     0.3745   1     0.7547     0.2453   1\n",
      "   5    0.3828     0.6172   0     0.4478     0.5522   0     0.3600     0.6400   0\n",
      "   6    0.2866     0.7134   0     0.4781     0.5219   0     0.4054     0.5946   0\n",
      "\n",
      "\n",
      "\n",
      " epch:  45   logits        sel          logits       sel         logits        sel \n",
      " -----  -----------------  ---    ----------------   ---    ----------------   --- \n",
      "   1   -0.1159     0.1948   0    -0.1149     0.3902   0    -0.1157     0.6975   0\n",
      "   2    0.0137    -0.0708   1     0.0154     0.0277   0     0.0152     0.1763   0\n",
      "   3    0.1303    -0.5119   1     0.1325     0.0321   1     0.1279    -0.1883   1\n",
      "   4    0.3155    -0.6743   1     0.3176    -0.1953   1     0.3169    -0.8071   1\n",
      "   5   -0.0590     0.4187   0    -0.0565     0.1532   0    -0.0615     0.5137   0\n",
      "   6   -0.0645     0.8476   0    -0.0661     0.0215   0    -0.0664     0.3165   0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_phase(ns, opt, environ, dldrs, epochs = 10, display_policy = False, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c373a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d28d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29d9b481",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T21:02:46.155117Z",
     "start_time": "2022-03-02T21:02:46.086934Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone Learning Rate      : 1.000e-03\n",
      " Tasks    Learning Rate      : 1.000e-03\n",
      " Policy   Learning Rate      : 0.01\n",
      "\n",
      "\n",
      " current_iters               : 35740\n",
      " current_epochs              : 180\n",
      " train_total_epochs          : 10\n",
      " stop_epoch_training         : 180\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']:.3e}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']:.3e}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "print()\n",
    "print( f\" current_iters               : {current_iter}\")  \n",
    "print( f\" current_epochs              : {current_epoch}\") \n",
    "print( f\" train_total_epochs          : {train_total_epochs}\") \n",
    "print( f\" stop_epoch_training         : {stop_epoch_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9027ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environ.opt['train']['backbone_lr'] = 0.0005\n",
    "# environ.opt['train']['task_lr']     = 0.0005\n",
    "\n",
    "\n",
    "#  2.72e-04   2.72e-04 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a404ccd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T21:00:17.551897Z",
     "start_time": "2022-03-02T21:00:17.479658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone Learning Rate      : 0.001\n",
      " Tasks    Learning Rate      : 0.001\n",
      " Policy   Learning Rate      : 0.01\n",
      "\n",
      "\n",
      " current_iters               : 35740\n",
      " current_epochs              : 180\n",
      " train_total_epochs          : 10\n",
      " stop_epoch_training         : 180\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "print()\n",
    "print( f\" current_iters               : {current_iter}\")  \n",
    "print( f\" current_epochs              : {current_epoch}\") \n",
    "print( f\" train_total_epochs          : {train_total_epochs}\") \n",
    "print( f\" stop_epoch_training         : {stop_epoch_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "210165f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T21:38:10.037939Z",
     "start_time": "2022-03-04T21:38:06.581709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de6af4e33764eb0be676edb16bc7c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.204 MB of 1.204 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train_time</td><td>▃▁▁▅▁▁▅█▅▄▃▅▄▂▄▃▂▄▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>190</td></tr><tr><td>train_time</td><td>23.36417</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0225_1530</strong>: <a href=\"http://localhost:8080/kbardool/AdaSparseChem/runs/389d8amo\" target=\"_blank\">http://localhost:8080/kbardool/AdaSparseChem/runs/389d8amo</a><br/>Synced 7 W&B file(s), 60 media file(s), 66 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220304_132640-389d8amo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e7f83a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T22:08:43.975113Z",
     "start_time": "2022-03-04T22:08:43.944510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc_score': 0.7977660069319655,\n",
       " 'auc_pr': 0.8014618586453754,\n",
       " 'avg_prec_score': 0.8015433942620374,\n",
       " 'f1_max': 0.7484090681503753,\n",
       " 'p_f1_max': 0.12281983842452368,\n",
       " 'kappa': 0.43709999925532184,\n",
       " 'kappa_max': 0.44975542850744377,\n",
       " 'p_kappa_max': 0.5509484738111496,\n",
       " 'bceloss': 0.9510966817537944,\n",
       " 'sc_loss': 0.3957416854852666,\n",
       " 'logloss': 0.0002082394310819206}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics['aggregated']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c67dac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T22:45:33.994239Z",
     "start_time": "2022-03-04T22:45:33.913046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc_score': 0.797781100801785,\n",
       " 'auc_pr': 0.8018675064848862,\n",
       " 'avg_prec_score': 0.8019504284471113,\n",
       " 'f1_max': 0.7494570643715834,\n",
       " 'p_f1_max': 0.08885766727228958,\n",
       " 'kappa': 0.44084984851153447,\n",
       " 'kappa_max': 0.44978186934986036,\n",
       " 'p_kappa_max': 0.5494123538335165,\n",
       " 'bceloss': 1.115734883149465,\n",
       " 'sc_loss': 0.46436059796888013,\n",
       " 'logloss': 0.00024434672991127215}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics['aggregated']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30f81653",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T22:06:12.262359Z",
     "start_time": "2022-03-04T22:06:12.235636Z"
    }
   },
   "outputs": [],
   "source": [
    "# load_from_pickle(environ.opt['paths']['checkpoint_dir'], metrics_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2c40a78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T22:48:58.391115Z",
     "start_time": "2022-02-22T22:48:58.336804Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    trn_losses = environ.losses\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#     environ.save_checkpoint('retrain%03d_policyIter%s_latest' % (exp_id, opt['train']['policy_iter']), current_iter)\n",
    "    # end validation\n",
    "    \n",
    "#     # validation             \n",
    "#     if should(current_iter, opt['train']['val_freq']):\n",
    "#         environ.eval()\n",
    "#         num_seg_class = opt['tasks_num_class'][opt['tasks'].index('seg')] if 'seg' in opt['tasks'] else -1\n",
    "#         val_metrics = eval_fix_policy(environ, val_loader, opt['tasks'], num_seg_class)\n",
    "#         environ.print_loss(current_iter, start_time, val_metrics)\n",
    "#         environ.save_checkpoint('retrain%03d_policyIter%s_latest' % (exp_id, opt['train']['policy_iter']), current_iter)\n",
    "#         environ.train()\n",
    " \n",
    "##\n",
    "## Check for best metrics and checkpoint if justified\n",
    "##\n",
    "#         best_value, best_iter, best_metrics = check_for_best_metrics(best_value, current_iter, refer_metrics, val_metrics, opt)\n",
    "\n",
    "    # end validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60259",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7e3be",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ********************************************************************\n",
    "    # ****************** create folders and print options ****************\n",
    "    # ********************************************************************\n",
    "    print_separator('READ YAML')\n",
    "    opt, gpu_ids, exp_ids = read_yaml()\n",
    "    # fix_random_seed(opt[\"seed\"])\n",
    "    create_path(opt)\n",
    "    # print yaml on the screen\n",
    "    lines = print_yaml(opt)\n",
    "    for line in lines: print(line)\n",
    "    # print to file\n",
    "    with open(os.path.join(opt['paths']['log_dir'], opt['exp_name'], 'opt.txt'), 'w+') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "    best_results = {}\n",
    "    for exp_id in exp_ids:\n",
    "        fix_random_seed(opt[\"seed\"][exp_id])\n",
    "        # fix_random_seed(48)\n",
    "        _, policy = train(exp_id, opt, gpu_ids)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a6197",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def init_records(tasks, num_seg_cls):\n",
    "    records = {}\n",
    "    if 'seg' in tasks:\n",
    "        assert (num_seg_cls != -1)\n",
    "    records['seg'] = {'mIoUs'    : [], \n",
    "                      'pixelAccs': [],  \n",
    "                      'errs'     : [], \n",
    "                      'conf_mat' : np.zeros((num_seg_cls, num_seg_cls)),\n",
    "                      'labels'   : np.arange(num_seg_cls), \n",
    "                      'gts': [], \n",
    "                      'preds': []}\n",
    "    if 'sn' in tasks:\n",
    "        records['sn'] = {'cos_similaritys': []}\n",
    "    if 'depth' in tasks:\n",
    "        records['depth'] = {'abs_errs': [], \n",
    "                            'rel_errs': [], \n",
    "                            'sq_rel_errs': [], \n",
    "                            'ratios'  : [], \n",
    "                            'rms'     : [], \n",
    "                            'rms_log' : []}\n",
    "    if 'keypoint' in tasks:\n",
    "        records['keypoint'] = {'errs': []}\n",
    "    if 'edge' in tasks:\n",
    "        records['edge'] = {'errs': []}\n",
    "    return records\n",
    "\n",
    "def populate_records(recs, mtrs,tsks ):\n",
    "    if 'seg' in tasks:\n",
    "        new_mat = confusion_matrix(metrics['seg']['gt'], metrics['seg']['pred'], records['seg']['labels'])\n",
    "        assert (records['seg']['conf_mat'].shape == new_mat.shape)\n",
    "        records['seg']['conf_mat'] += new_mat\n",
    "        records['seg']['pixelAccs'].append(metrics['seg']['pixelAcc'])\n",
    "        records['seg']['errs'].append(metrics['seg']['err'])\n",
    "        records['seg']['gts'].append(metrics['seg']['gt'])\n",
    "        records['seg']['preds'].append(metrics['seg']['pred'])\n",
    "\n",
    "    if 'sn' in tasks:\n",
    "        records['sn']['cos_similaritys'].append(metrics['sn']['cos_similarity'])\n",
    "\n",
    "    if 'depth' in tasks:\n",
    "        records['depth']['abs_errs'].append(metrics['depth']['abs_err'])\n",
    "        records['depth']['rel_errs'].append(metrics['depth']['rel_err'])\n",
    "        records['depth']['sq_rel_errs'].append(metrics['depth']['sq_rel_err'])\n",
    "        records['depth']['ratios'].append(metrics['depth']['ratio'])\n",
    "        records['depth']['rms'].append(metrics['depth']['rms'])\n",
    "        records['depth']['rms_log'].append(metrics['depth']['rms_log'])\n",
    "\n",
    "    if 'keypoint' in tasks:\n",
    "        records['keypoint']['errs'].append(metrics['keypoint']['err'])\n",
    "\n",
    "    if 'edge' in tasks:\n",
    "        records['edge']['errs'].append(metrics['edge']['err'])\n",
    "\n",
    "    return recs\n",
    "\n",
    "def populate_val_metrics(records, tasks, num_seg_cls):\n",
    "    val_metrics = {}\n",
    "    \n",
    "    if 'seg' in tasks:\n",
    "        val_metrics['seg'] = {}\n",
    "        jaccard_perclass = []\n",
    "        for i in range(num_seg_cls):\n",
    "            if not records['seg']['conf_mat'][i, i] == 0:\n",
    "                jaccard_perclass.append(records['seg']['conf_mat'][i, i] / (np.sum(records['seg']['conf_mat'][i, :]) +\n",
    "                                                                            np.sum(records['seg']['conf_mat'][:, i]) -\n",
    "                                                                            records['seg']['conf_mat'][i, i]))\n",
    "\n",
    "        val_metrics['seg']['mIoU'] = np.sum(jaccard_perclass) / len(jaccard_perclass)\n",
    "\n",
    "        val_metrics['seg']['Pixel Acc'] = (np.array(records['seg']['pixelAccs']) * np.array(batch_size)).sum() / sum(\n",
    "            batch_size)\n",
    "\n",
    "        val_metrics['seg']['err'] = (np.array(records['seg']['errs']) * np.array(batch_size)).sum() / sum(batch_size)\n",
    "\n",
    "    if 'sn' in tasks:\n",
    "        val_metrics['sn'] = {}\n",
    "        overall_cos = np.clip(np.concatenate(records['sn']['cos_similaritys']), -1, 1)\n",
    "\n",
    "        angles = np.arccos(overall_cos) / np.pi * 180.0\n",
    "        val_metrics['sn']['cosine_similarity'] = overall_cos.mean()\n",
    "        val_metrics['sn']['Angle Mean'] = np.mean(angles)\n",
    "        val_metrics['sn']['Angle Median'] = np.median(angles)\n",
    "        val_metrics['sn']['Angle 11.25'] = np.mean(np.less_equal(angles, 11.25)) * 100\n",
    "        val_metrics['sn']['Angle 22.5'] = np.mean(np.less_equal(angles, 22.5)) * 100\n",
    "        val_metrics['sn']['Angle 30'] = np.mean(np.less_equal(angles, 30.0)) * 100\n",
    "        val_metrics['sn']['Angle 45'] = np.mean(np.less_equal(angles, 45.0)) * 100\n",
    "\n",
    "    if 'depth' in tasks:\n",
    "        val_metrics['depth'] = {}\n",
    "        records['depth']['abs_errs'] = np.stack(records['depth']['abs_errs'], axis=0)\n",
    "        records['depth']['rel_errs'] = np.stack(records['depth']['rel_errs'], axis=0)\n",
    "        records['depth']['ratios'] = np.concatenate(records['depth']['ratios'], axis=0)\n",
    "\n",
    "        val_metrics['depth']['abs_err'] = (records['depth']['abs_errs'] * np.array(batch_size)).sum() / sum(batch_size)\n",
    "        val_metrics['depth']['rel_err'] = (records['depth']['rel_errs'] * np.array(batch_size)).sum() / sum(batch_size)\n",
    "       \n",
    "        val_metrics['depth']['sigma_1.25'] = np.mean(np.less_equal(records['depth']['ratios'], 1.25)) * 100\n",
    "        val_metrics['depth']['sigma_1.25^2'] = np.mean(np.less_equal(records['depth']['ratios'], 1.25 ** 2)) * 100\n",
    "        val_metrics['depth']['sigma_1.25^3'] = np.mean(np.less_equal(records['depth']['ratios'], 1.25 ** 3)) * 100\n",
    "\n",
    "    if 'keypoint' in tasks:\n",
    "        val_metrics['keypoint'] = {}\n",
    "        val_metrics['keypoint']['err'] = (np.array(records['keypoint']['errs']) * np.array(batch_size)).sum() / sum(\n",
    "            batch_size)\n",
    "\n",
    "    if 'edge' in tasks:\n",
    "        val_metrics['edge'] = {}\n",
    "        val_metrics['edge']['err'] = (np.array(records['edge']['errs']) * np.array(batch_size)).sum() / sum(batch_size)\n",
    "\n",
    "    return val_metrics\n",
    "\n",
    "\n",
    "def get_reference_metrics(opt):\n",
    "    if opt['dataload']['dataset'] == 'NYU_v2':\n",
    "        if len(opt['tasks_num_class']) == 2:\n",
    "            refer_metrics = {'seg': {'mIoU': 0.413, 'Pixel Acc': 0.691},\n",
    "                             'sn': {'Angle Mean': 15, 'Angle Median': 11.5, 'Angle 11.25': 49.2, 'Angle 22.5': 76.7,\n",
    "                                    'Angle 30': 86.8}}\n",
    "        elif len(opt['tasks_num_class']) == 3:\n",
    "            refer_metrics = {'seg': {'mIoU': 0.275, 'Pixel Acc': 0.589},\n",
    "                             'sn': {'Angle Mean': 17.5, 'Angle Median': 14.2, 'Angle 11.25': 34.9, 'Angle 22.5': 73.3,\n",
    "                                    'Angle 30': 85.7},\n",
    "                             'depth': {'abs_err': 0.62, 'rel_err': 0.25, 'sigma_1.25': 57.9,\n",
    "                                       'sigma_1.25^2': 85.8, 'sigma_1.25^3': 95.7}}\n",
    "        else:\n",
    "            raise ValueError('num_class = %d is invalid' % len(opt['tasks_num_class']))\n",
    "\n",
    "    elif opt['dataload']['dataset'] == 'CityScapes':\n",
    "        num_seg_class = opt['tasks_num_class'][opt['tasks'].index('seg')] if 'seg' in opt['tasks'] else -1\n",
    "\n",
    "        if num_seg_class == 7 and opt['dataload']['small_res']:\n",
    "            refer_metrics = {'seg': {'mIoU': 0.519, 'Pixel Acc': 0.722},\n",
    "                         'depth': {'abs_err': 0.017, 'rel_err': 0.33, 'sigma_1.25': 70.3,\n",
    "                                   'sigma_1.25^2': 86.3, 'sigma_1.25^3': 93.3}}\n",
    "        elif num_seg_class == 7 and not opt['dataload']['small_res']:\n",
    "            refer_metrics = {'seg': {'mIoU': 0.644, 'Pixel Acc': 0.778},\n",
    "                         'depth': {'abs_err': 0.017, 'rel_err': 0.33, 'sigma_1.25': 70.3,\n",
    "                                   'sigma_1.25^2': 86.3, 'sigma_1.25^3': 93.3}}\n",
    "        \n",
    "        elif num_seg_class == 19 and not opt['dataload']['small_res']:\n",
    "            refer_metrics = {'seg': {'mIoU': 0.402, 'Pixel Acc': 0.747},\n",
    "                            'depth': {'abs_err': 0.017, 'rel_err': 0.33, 'sigma_1.25': 70.3,\n",
    "                                    'sigma_1.25^2': 86.3, 'sigma_1.25^3': 93.3}}\n",
    "        else:\n",
    "            raise ValueError('num_seg_class = %d and small res = %d are not supported' % (num_seg_class, opt['dataload']['small_res']))\n",
    " \n",
    "    elif opt['dataload']['dataset'] == 'Taskonomy':\n",
    "        refer_metrics = {'seg': {'err': 0.517},\n",
    "                         'sn': {'cosine_similarity': 0.716},\n",
    "                         'depth': {'abs_err': 0.021},\n",
    "                         'keypoint': {'err': 0.197},\n",
    "                         'edge': {'err': 0.212}}\n",
    "    \n",
    "    else:\n",
    "        raise NotImplementedError('Dataset %s is not implemented' % opt['dataload']['dataset'])\n",
    "    \n",
    "    return refer_metrics\n",
    "\n",
    "def check_for_best_metrics(best_value, current_iter, refer_metrics, val_metrics, opt):\n",
    "    new_value = 0\n",
    "    for k in refer_metrics.keys():\n",
    "        if k in val_metrics.keys():\n",
    "            for kk in val_metrics[k].keys():\n",
    "                if not kk in refer_metrics[k].keys():\n",
    "                    continue\n",
    "                if (k == 'sn' and kk in ['Angle Mean', 'Angle Median']) or (\n",
    "                        k == 'depth' and not kk.startswith('sigma')) or (kk == 'err'):\n",
    "                    value = refer_metrics[k][kk] / val_metrics[k][kk]\n",
    "                else:\n",
    "                    value = val_metrics[k][kk] / refer_metrics[k][kk]\n",
    "\n",
    "                value = value / len(list(set(val_metrics[k].keys()) & set(refer_metrics[k].keys())))\n",
    "                new_value += value\n",
    "\n",
    "    if new_value > best_value:\n",
    "        best_value = new_value\n",
    "        best_metrics = val_metrics\n",
    "        best_iter = current_iter\n",
    "        environ.save_checkpoint('retrain%03d_policyIter%s_best' % (exp_id, opt['train']['policy_iter']), current_iter)\n",
    "        \n",
    "        print('new value: %.3f' % new_value)\n",
    "        print('best iter: %d, best value: %.3f' % (best_iter, best_value), best_metrics)    \n",
    "    return best_value, best_iter, best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84b4da",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.util import init_records, populate_records, populate_validation_metrics\n",
    "\n",
    "def eval_fix_policy(environ, dataloader, tasks, num_seg_cls=-1, eval_iter=10):\n",
    "    batch_size = []\n",
    "    val_metrics = {}\n",
    "\n",
    "    records = init_records(tasks, num_seg_cls)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(dataloader)):\n",
    "            if eval_iter != -1:\n",
    "                if batch_idx > eval_iter:\n",
    "                    break\n",
    "\n",
    "            environ.set_inputs(batch)\n",
    "\n",
    "            metrics = environ.val_fix_policy()\n",
    "            \n",
    "            # environ.networks['mtl-net'].task1_logits\n",
    "            # mIoUs.append(mIoU)\n",
    "            ##\n",
    "            ##  Populate Records with results from metrics\n",
    "            populate_records(records, metrics, tasks)\n",
    " \n",
    "            batch_size.append(len(batch['img']))\n",
    "\n",
    "    ##  Populate Validation Metrics \n",
    "    val_metrics = populate_validation_metrics(records, tasks, num_seg_cls, batch_size)\n",
    "\n",
    "    return val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c18937",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Close WandB Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d27fde",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fdbff1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T20:26:46.766130Z",
     "start_time": "2022-03-02T20:26:46.469911Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._resume_backend at 0x7f99f9d0e1f0> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'info'"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Attribute _telemetry_obj_dirty is not supported on Run object.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26815/2127913808.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(exit_code, quiet)\u001b[0m\n\u001b[1;32m   2865\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rendering history\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2867\u001b[0;31m             sampled_history = {\n\u001b[0m\u001b[1;32m   2868\u001b[0m                 item.key: wandb.util.downsample(\n\u001b[1;32m   2869\u001b[0m                     \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_float\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_quiet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtelemetry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m             \u001b[0mtel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"finishing run {self.path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[0;31m# detach jupyter hooks / others that needs to happen before backend shutdown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/lib/telemetry.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exctype, excinst, exctb)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_telemetry_callback\u001b[0;34m(self, telem_obj)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_telemetry_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtelem_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtelemetry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTelemetryRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtelem_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj_dirty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, attr, value)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_frozen\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attribute {} is not supported on Run object.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Attribute _telemetry_obj_dirty is not supported on Run object."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7f99f6a41310> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pause_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;31m# Attempt to save the code on every execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad12a67",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
