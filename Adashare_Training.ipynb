{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408f1261",
   "metadata": {},
   "source": [
    "## Initialization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d574cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T12:58:07.301448Z",
     "start_time": "2022-03-24T12:58:05.323192Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:08.233990Z",
     "iopub.status.busy": "2022-01-07T22:44:08.233053Z",
     "iopub.status.idle": "2022-01-07T22:44:08.273284Z",
     "shell.execute_reply": "2022-01-07T22:44:08.271908Z",
     "shell.execute_reply.started": "2022-01-07T22:44:08.233943Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "import time\n",
    "import argparse\n",
    "import yaml\n",
    "import types\n",
    "import copy, pprint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import numpy  as np\n",
    "import torch  \n",
    "import wandb\n",
    "import pandas as pd\n",
    "from utils.notebook_modules import initialize, init_dataloaders, init_environment, init_wandb, \\\n",
    "                                   training_prep, disp_dataloader_info,disp_info_1, \\\n",
    "                                   warmup_phase, weight_policy_training, disp_gpu_info\n",
    "\n",
    "from utils.util import (print_separator, print_heading, timestring, print_loss) #, print_underline, load_from_pickle,\n",
    "#                       print_dbg, get_command_line_args ) \n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=6, linewidth=132)\n",
    "pd.options.display.width = 132\n",
    "# torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
    "# sys.path.insert(0, '/home/kbardool/kusanagi/AdaSparseChem/src')\n",
    "# print(sys.path)\n",
    "# disp_gpu_info() \n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Training.ipynb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33ac6e",
   "metadata": {},
   "source": [
    "## Create Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee652c57",
   "metadata": {},
   "source": [
    "### Parse Input Args  - Read YAML config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42bb98b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T22:17:01.538471Z",
     "start_time": "2022-03-23T22:17:01.500844Z"
    }
   },
   "outputs": [],
   "source": [
    "# RESUME_MODEL_CKPT = 'model_train_ep_25_seed_0088'\n",
    "\n",
    "## For RESTARTING\n",
    "##\n",
    "# input_args = \" --config yamls/chembl_3task_train.yaml \" \\\n",
    "#              \" --resume \" \\\n",
    "#              \" --exp_id      330i85cg\" \\\n",
    "#              \" --exp_name    0308_1204\" \\\n",
    "#              \" --exp_desc    Train with dropout 0.5\" \\\n",
    "#              \" --seed_idx    0 \"\\\n",
    "#              \" --batch_size  128\" \\\n",
    "#              \" --lambda_sparsity  0.01\"\\\n",
    "#              \" --lambda_sharing   0.01\" \n",
    "## get command line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd3a7f00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T12:59:07.999942Z",
     "start_time": "2022-03-24T12:59:07.975914Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [],
   "source": [
    "##  For Initiating \n",
    "##\n",
    "input_args = \" --config yamls/chembl_3task_train.yaml \" \\\n",
    "             \" --exp_desc    6x100 lyrs,dropout 0.5, weight 105 bch/ep policy 105 bch/ep \" \\\n",
    "             \" --seed_idx            0\" \\\n",
    "             \" --batch_size        128\" \\\n",
    "             \" --task_lr          0.001\" \\\n",
    "             \" --backbone_lr      0.001\" \\\n",
    "             \" --policy_lr        0.01\" \\\n",
    "             \" --lambda_sparsity  0.02\" \\\n",
    "             \" --lambda_sharing   0.01\" \n",
    "\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc14177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T12:59:09.215042Z",
     "start_time": "2022-03-24T12:59:09.137481Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  command line parms : \n",
      "------------------------\n",
      " config...................  yamls/chembl_3task_train.yaml\n",
      " exp_id...................  None\n",
      " exp_name.................  None\n",
      " folder_sfx...............  None\n",
      " exp_desc.................  6x100 lyrs,dropout 0.5, weight 105 bch/ep policy 105 bch/ep\n",
      " seed_idx.................  0\n",
      " batch_size...............  128\n",
      " backbone_lr..............  0.001\n",
      " task_lr..................  0.001\n",
      " policy_lr................  0.01\n",
      " decay_lr_rate............  None\n",
      " decay_lr_freq............  None\n",
      " lambda_sparsity..........  0.02\n",
      " lambda_sharing...........  0.01\n",
      " gpu_ids..................  [0]\n",
      " resume...................  False\n",
      " cpu......................  False\n",
      "\n",
      "\n",
      "\n",
      "##################################################\n",
      "################### READ YAML ####################\n",
      "##################################################\n",
      "\n",
      "\n",
      " log_dir              create folder:  ../experiments/AdaSparseChem/100x6_0324_1359_plr0.01_sp0.02_sh0.01_lr0.001\n",
      " result_dir           folder exists:  ../experiments/AdaSparseChem/100x6_0324_1359_plr0.01_sp0.02_sh0.01_lr0.001\n",
      " checkpoint_dir       folder exists:  ../experiments/AdaSparseChem/100x6_0324_1359_plr0.01_sp0.02_sh0.01_lr0.001\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " experiment name       : 0324_1359 \n",
      " experiment id         : 65xmlssn \n",
      " folder_name           : 100x6_0324_1359_plr0.01_sp0.02_sh0.01_lr0.001 \n",
      " experiment description: 6x100 lyrs,dropout 0.5, weight 105 bch/ep policy 105 bch/ep\n",
      " Random seeds          : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      " Random  seed used     : 88 \n",
      " log folder            : ../experiments/AdaSparseChem/100x6_0324_1359_plr0.01_sp0.02_sh0.01_lr0.001\n",
      " checkpoint folder     : ../experiments/AdaSparseChem/100x6_0324_1359_plr0.01_sp0.02_sh0.01_lr0.001\n",
      " Gpu ids               : [0]\n",
      " Seed index            : 0\n",
      " policy_iter           : best\n",
      " Data Split ratios     : [0.725, 0.225, 0.05]\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "        project_name : AdaSparseChem\n",
      "              exp_id : 65xmlssn\n",
      "            exp_name : 0324_1359\n",
      "          exp_folder : 100x6_0324_1359_plr0.01_sp0.02_sh0.01_lr0.001\n",
      "     exp_description : 6x100 lyrs,dropout 0.5, weight 105 bch/ep policy 105 bch/ep\n",
      "          folder_sfx : None\n",
      "         random_seed : 88\n",
      "           seed_list : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      "                 cpu : False\n",
      "             gpu_ids : [0]\n",
      "            backbone : SparseChem\n",
      "               tasks : ['class', 'class', 'class']\n",
      "     tasks_num_class : [5, 5, 5]\n",
      "             lambdas : [1, 1, 1]\n",
      "        policy_model : task-specific\n",
      "             verbose : False\n",
      "       backbone_orig : ResNet18\n",
      "          tasks_orig : ['seg', 'sn']\n",
      "     input_size_freq : None\n",
      "          input_size : 32000\n",
      "        hidden_sizes : [100, 100, 100, 100, 100, 100]\n",
      "    tail_hidden_size : 100\n",
      " first_non_linearity : relu\n",
      "middle_non_linearity : relu\n",
      "  last_non_linearity : relu\n",
      "      middle_dropout : 0.5\n",
      "        last_dropout : 0.5\n",
      "   class_output_size : None\n",
      "    regr_output_size : None\n",
      "              policy : True\n",
      "           is_sparse : True\n",
      "          is_sharing : True\n",
      "diff_sparsity_weights : False\n",
      "          skip_layer : 0\n",
      "       is_curriculum : False\n",
      "    curriculum_speed : 3\n",
      "              fix_BN : False\n",
      "     retrain_from_pl : False\n",
      "\n",
      "train\n",
      "-----\n",
      "          batch_size : 128\n",
      "       warmup_epochs : 75\n",
      "     training_epochs : 125\n",
      "         total_iters : 25000\n",
      "       warm_up_iters : None\n",
      "             task_lr : 0.001\n",
      "         backbone_lr : 0.001\n",
      "       decay_lr_rate : 0.75\n",
      "       decay_lr_freq : 40\n",
      "policy_decay_lr_rate : 0.75\n",
      "policy_decay_lr_freq : 50\n",
      "           policy_lr : 0.01\n",
      "     lambda_sparsity : 0.02\n",
      "      lambda_sharing : 0.01\n",
      "        lambda_tasks : 1\n",
      "         init_method : random\n",
      "           init_temp : 4\n",
      "          decay_temp : 0.965\n",
      "     decay_temp_freq : 16\n",
      "     init_neg_logits : None\n",
      "       hard_sampling : False\n",
      "            val_freq : 500\n",
      "          print_freq : -1\n",
      "           val_iters : -1\n",
      "              resume : False\n",
      "      retrain_resume : False\n",
      "         policy_iter : best\n",
      "          which_iter : warmup\n",
      "\n",
      "paths\n",
      "-----\n",
      "             log_dir : ../experiments/AdaSparseChem/100x6_0324_1359_plr0.01_sp0.02_sh0.01_lr0.001\n",
      "          result_dir : ../experiments/AdaSparseChem/100x6_0324_1359_plr0.01_sp0.02_sh0.01_lr0.001\n",
      "      checkpoint_dir : ../experiments/AdaSparseChem/100x6_0324_1359_plr0.01_sp0.02_sh0.01_lr0.001\n",
      "\n",
      "dataload\n",
      "--------\n",
      "             dataset : Chembl_23_mini\n",
      "            dataroot : /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic\n",
      "                   x : chembl_23mini_x.npy\n",
      "      x_split_ratios : [0.725, 0.225, 0.05]\n",
      "             folding : chembl_23mini_folds.npy\n",
      "         fold_inputs : 32000\n",
      "     input_transform : None\n",
      "             y_tasks : ['chembl_23mini_adashare_y1_bin_sparse.npy', 'chembl_23mini_adashare_y2_bin_sparse.npy', 'chembl_23mini_adashare_y3_bin_sparse.npy']\n",
      "            y_censor : None\n",
      "       weights_class : None\n",
      "              crop_h : 321\n",
      "              crop_w : 321\n",
      "   min_samples_class : 5\n",
      "             fold_va : 0\n",
      "             fold_te : None\n",
      "\n",
      "SC\n",
      "--\n",
      "      normalize_loss : None\n"
     ]
    }
   ],
   "source": [
    "opt, ns = initialize(input_args, build_folders = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bfa8d",
   "metadata": {},
   "source": [
    "### Setup Dataloader and Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c631eb67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:00:36.367542Z",
     "start_time": "2022-03-24T13:00:35.603014Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############### CREATE DATALOADERS ###############\n",
      "##################################################\n",
      "\n",
      " trainset.y_class                                   :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " trainset1.y_class                                  :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " trainset2.y_class                                  :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " valset.y_class                                     :  [(4137, 5), (4137, 5), (4137, 5)]  \n",
      " testset.y_class                                    :  [(920, 5), (920, 5), (920, 5)]  \n",
      "                                 \n",
      " size of training set 0 (warm up)                   :  13331 \n",
      " size of training set 1 (network parms)             :  13331 \n",
      " size of training set 2 (policy weights)            :  13331 \n",
      " size of validation set                             :  4137 \n",
      " size of test set                                   :  920 \n",
      "                               Total                :  45050 \n",
      "                                 \n",
      " lenght (# batches) in training 0 (warm up)         :  105 \n",
      " lenght (# batches) in training 1 (network parms)   :  105 \n",
      " lenght (# batches) in training 2 (policy weights)  :  105 \n",
      " lenght (# batches) in validation dataset           :  33 \n",
      " lenght (# batches) in test dataset                 :  29 \n",
      "                                \n",
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      " device is  cuda:0\n",
      "--------------------------------------------------------\n",
      "* SparseChemEnv_Dev environment successfully created\n",
      "-------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dldrs = init_dataloaders(opt)\n",
    "\n",
    "disp_dataloader_info(dldrs)\n",
    "\n",
    "environ = init_environment(ns, opt, is_train = True, policy_learning = False, display_cfg = False)\n",
    "\n",
    "# ********************************************************************\n",
    "# **************** define optimizer and schedulers *******************\n",
    "# ********************************************************************                                \n",
    "environ.define_optimizer(policy_learning=False)\n",
    "environ.define_scheduler(policy_learning=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ab8c05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:00:40.433718Z",
     "start_time": "2022-03-24T13:00:40.383140Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initial alphas LR    : 0.01   Current LR: 0.01\n",
      " Current LR: 0.001\n",
      " Current LR: 0.001\n"
     ]
    }
   ],
   "source": [
    "print(f\" Initial alphas LR    : {environ.optimizers['alphas'].param_groups[0]['initial_lr']}   Current LR: {environ.optimizers['alphas'].param_groups[0]['lr'] }\")\n",
    "print(f\" Current LR: {environ.optimizers['weights'].param_groups[0]['lr']}\")\n",
    "print(f\" Current LR: {environ.optimizers['weights'].param_groups[1]['lr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c58696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:00:41.874529Z",
     "start_time": "2022-03-24T13:00:41.832498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': [Parameter containing:\n",
       "  tensor([[ 0.054305,  0.073865, -0.079888,  0.079335,  0.040790,  0.061847, -0.047831,  0.095938, -0.037845,  0.097123,  0.002437,\n",
       "            0.035050, -0.008040, -0.046561, -0.088728,  0.020019, -0.045145,  0.098016, -0.078546,  0.003124, -0.087069,  0.049226,\n",
       "            0.083186,  0.073277,  0.049136,  0.004473, -0.035649,  0.049682,  0.098840, -0.059525, -0.024014, -0.045792, -0.096087,\n",
       "           -0.064727,  0.088230, -0.066036,  0.045381,  0.040653, -0.011709,  0.072606,  0.004199,  0.031642, -0.074879,  0.074629,\n",
       "           -0.034470,  0.025022,  0.047658, -0.017332,  0.039687,  0.096168,  0.078396,  0.054945, -0.022197,  0.028004, -0.006620,\n",
       "            0.072863,  0.080161, -0.070892, -0.066525,  0.059054,  0.040922,  0.082037, -0.080134, -0.058053,  0.088985, -0.054591,\n",
       "           -0.093486,  0.020917,  0.086113,  0.025513,  0.095772,  0.044221, -0.088343,  0.071039,  0.031189, -0.077064, -0.039500,\n",
       "            0.056883, -0.025926, -0.021946, -0.077023, -0.012399,  0.005850,  0.086507, -0.078171,  0.056686,  0.078043,  0.097127,\n",
       "            0.077245, -0.071790, -0.017465,  0.001402, -0.083523,  0.067560,  0.036064, -0.077186,  0.085284, -0.055249, -0.042282,\n",
       "           -0.006122],\n",
       "          [ 0.099780,  0.025769, -0.021588, -0.098561, -0.052715,  0.024255,  0.062625, -0.064446,  0.036320,  0.053553,  0.099057,\n",
       "           -0.055882, -0.045555,  0.011815, -0.093454, -0.036735,  0.021514, -0.026033, -0.076119, -0.069359, -0.085712, -0.019872,\n",
       "           -0.083998, -0.013372, -0.089030, -0.018492, -0.099953, -0.065564, -0.023268, -0.093264, -0.029818,  0.083806,  0.051029,\n",
       "            0.056143,  0.067983, -0.042778,  0.069653, -0.065140, -0.082075,  0.059804, -0.037731,  0.021009, -0.044831, -0.053345,\n",
       "           -0.097303, -0.053410,  0.075831, -0.089390, -0.069809,  0.073009,  0.028885, -0.019175,  0.091614,  0.071553, -0.022147,\n",
       "           -0.000638,  0.038677,  0.054360,  0.004166,  0.027746, -0.016513, -0.014460,  0.098528,  0.015669,  0.075767,  0.061172,\n",
       "           -0.061721,  0.093736,  0.075120, -0.013698, -0.049135,  0.001093, -0.076375, -0.069095, -0.011091, -0.089645, -0.072655,\n",
       "            0.027600,  0.052061, -0.089613, -0.031987,  0.099073, -0.092392,  0.094974,  0.075326,  0.047166,  0.010779,  0.014100,\n",
       "            0.084529,  0.098960,  0.027566,  0.067129, -0.097174, -0.084818,  0.013177,  0.084888, -0.020400, -0.004098, -0.069925,\n",
       "            0.050802],\n",
       "          [-0.033242,  0.092454, -0.063315, -0.030358, -0.021349,  0.033025,  0.006735,  0.011887,  0.090174, -0.036868,  0.020538,\n",
       "            0.047324, -0.085315,  0.037900, -0.055344, -0.033604, -0.021197,  0.053968, -0.045037, -0.047147, -0.033651,  0.094851,\n",
       "           -0.020312, -0.093637,  0.061932,  0.059468,  0.095302, -0.098851,  0.040893,  0.087818, -0.021707,  0.041229,  0.029903,\n",
       "            0.081010,  0.034359,  0.054311, -0.053452, -0.042273,  0.025275,  0.019226,  0.048140,  0.023271, -0.094256,  0.073525,\n",
       "            0.028339,  0.096351,  0.065559,  0.035581, -0.026279,  0.038783, -0.077617, -0.096198, -0.024524, -0.085129, -0.037831,\n",
       "           -0.006027, -0.019098, -0.001584, -0.016145,  0.069984, -0.097762,  0.018825,  0.032525,  0.042809, -0.045977, -0.078005,\n",
       "           -0.089831, -0.048925,  0.088532, -0.011111,  0.090713,  0.070154, -0.098017, -0.007465, -0.094881, -0.070467,  0.096547,\n",
       "           -0.078211,  0.061482,  0.054492,  0.018043,  0.030445, -0.002723, -0.092931,  0.058783, -0.013179, -0.011994,  0.073204,\n",
       "            0.084936,  0.020639, -0.039157, -0.020765,  0.027702,  0.083453,  0.026985,  0.018572, -0.055955,  0.024264,  0.081911,\n",
       "           -0.006768],\n",
       "          [ 0.015320, -0.077002, -0.075804, -0.050717, -0.050668,  0.033667,  0.067660, -0.079865,  0.076414,  0.084481, -0.070921,\n",
       "            0.036074, -0.095729, -0.085877,  0.057696, -0.082020, -0.097341, -0.018617,  0.071090,  0.006033,  0.047012, -0.000419,\n",
       "            0.071585, -0.078584,  0.048091, -0.025288, -0.073255, -0.084919,  0.040353, -0.008831,  0.002477,  0.020475, -0.037695,\n",
       "           -0.026080, -0.025846,  0.037296, -0.020748,  0.022531, -0.005395, -0.030092, -0.091792, -0.074364,  0.042222, -0.021105,\n",
       "            0.004329,  0.021627,  0.010149, -0.010196,  0.065691,  0.078680, -0.077593, -0.038411, -0.089263, -0.013698,  0.034294,\n",
       "           -0.012945,  0.075959, -0.055358,  0.004466,  0.096076, -0.019472, -0.030151, -0.058812, -0.014855,  0.026412,  0.063912,\n",
       "           -0.001553,  0.062507, -0.069998, -0.026597, -0.061189, -0.035353, -0.083407, -0.094662,  0.008633, -0.009379, -0.023115,\n",
       "            0.080464, -0.025423, -0.083382,  0.025437,  0.063990,  0.077868,  0.066132,  0.025671,  0.068685,  0.055231, -0.090309,\n",
       "            0.028745,  0.057660,  0.056354, -0.088962, -0.097535,  0.095055,  0.008975, -0.004222, -0.050695,  0.015207, -0.030349,\n",
       "            0.080919],\n",
       "          [-0.013106, -0.055709,  0.046951,  0.094743, -0.030439,  0.019369,  0.051723, -0.064808,  0.038487,  0.077297, -0.013434,\n",
       "            0.053099,  0.072857, -0.041467, -0.064073,  0.081253,  0.032640, -0.086629,  0.075072,  0.007256,  0.093487, -0.033131,\n",
       "           -0.001856,  0.023801, -0.060292,  0.068409, -0.068559,  0.017131,  0.097293, -0.055580, -0.011859,  0.024254, -0.059731,\n",
       "           -0.070791,  0.051935, -0.023841, -0.022295,  0.088690, -0.011468,  0.006838,  0.067518, -0.072022, -0.091342,  0.031009,\n",
       "            0.065434,  0.054779, -0.066537, -0.081134, -0.013902,  0.040976, -0.008404,  0.077882,  0.065311,  0.043176,  0.061702,\n",
       "           -0.038470, -0.043866,  0.084003,  0.090492,  0.009937, -0.011046, -0.072625, -0.047376,  0.007187, -0.015366, -0.068872,\n",
       "            0.020933,  0.017697,  0.078387,  0.009409,  0.009705, -0.023583,  0.040261, -0.074162, -0.064655, -0.044453,  0.008847,\n",
       "            0.089065, -0.060676,  0.012390, -0.099787,  0.020590,  0.091125,  0.025656,  0.007396,  0.016625,  0.055613,  0.085782,\n",
       "            0.074291, -0.013178, -0.059055,  0.087318, -0.088281, -0.077154, -0.062819, -0.051881,  0.027845, -0.080481, -0.014923,\n",
       "           -0.031078]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.024366,  0.005473,  0.099905, -0.003820, -0.011362], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-9.237170e-04,  4.365985e-02, -8.679181e-02, -2.655519e-02, -9.279861e-02, -2.857835e-02,  5.469583e-02, -9.021163e-03,\n",
       "           -3.806433e-02,  9.214676e-03,  5.038441e-02,  7.765444e-02,  6.453686e-02, -5.360985e-03,  2.482536e-02, -2.563456e-02,\n",
       "           -8.494782e-03,  6.174107e-02,  5.682051e-02,  3.799665e-02,  2.681121e-02,  1.476274e-02, -7.252264e-03, -1.847690e-02,\n",
       "           -4.533554e-02,  1.309520e-02, -8.992115e-02, -2.913864e-02, -7.604758e-02, -8.853431e-02, -5.057917e-02, -8.220121e-02,\n",
       "           -1.239061e-04, -4.291604e-02,  9.200664e-02,  7.501043e-02, -2.919954e-02, -1.621752e-02,  9.698689e-03,  7.881578e-02,\n",
       "            7.301980e-02,  3.008755e-02,  5.782419e-02, -3.123598e-02,  9.785618e-02, -6.222165e-02,  1.261919e-02,  6.913660e-02,\n",
       "           -7.127762e-03,  2.296892e-02,  9.452283e-02,  4.274000e-02,  6.848636e-02,  8.922891e-02,  6.691848e-02,  7.549808e-02,\n",
       "           -9.914249e-02,  5.651667e-02, -6.816655e-02, -3.620353e-02,  9.314239e-02, -2.828206e-02,  3.053296e-02,  4.197369e-02,\n",
       "           -4.490855e-02, -7.786515e-02, -5.681014e-02, -6.025371e-02,  9.956723e-02,  8.147744e-02, -4.865130e-02, -3.848843e-02,\n",
       "           -2.324245e-02, -6.792084e-02,  8.942225e-02,  6.987713e-02,  3.516568e-02,  1.573645e-02, -1.659989e-02, -2.026111e-02,\n",
       "            4.926185e-02,  8.785842e-02,  7.360605e-02,  3.915284e-02,  6.032204e-02, -2.087884e-02,  9.039474e-03,  5.742962e-02,\n",
       "           -4.559517e-02, -6.383896e-04,  2.090848e-03, -2.387129e-02, -9.580876e-02, -3.828732e-02,  5.621623e-02, -8.261877e-02,\n",
       "           -6.262481e-03, -9.520793e-02,  9.234751e-03, -6.927623e-02],\n",
       "          [-8.904219e-02, -4.910363e-02,  5.814106e-02, -3.208980e-02,  2.823608e-02, -3.592464e-02, -6.665470e-02,  2.898891e-02,\n",
       "           -7.209789e-02, -6.773830e-04,  3.346848e-02,  4.965942e-02, -3.283310e-02, -3.059435e-03,  6.853574e-02,  4.202008e-04,\n",
       "           -1.388507e-02, -1.276016e-03,  6.286391e-02, -9.914334e-02,  3.903667e-02, -7.208462e-02,  3.621573e-02, -9.016763e-02,\n",
       "           -8.134171e-02,  1.130414e-03, -2.951349e-02, -5.671893e-02,  9.616982e-02, -4.324457e-02, -3.524726e-02, -9.124628e-02,\n",
       "           -5.682316e-02,  3.556234e-02, -4.817996e-02,  7.889985e-02,  1.913795e-02, -9.574832e-02, -9.556063e-02,  3.996625e-02,\n",
       "           -4.857364e-02, -7.626212e-02,  7.249017e-02, -1.178209e-02, -9.168533e-02, -2.534528e-02,  2.519342e-02,  6.942415e-02,\n",
       "           -7.940886e-02, -2.087923e-02, -3.752059e-02,  4.713041e-02,  8.845403e-02, -8.671522e-04, -8.246600e-02, -3.496612e-02,\n",
       "            3.344628e-02, -3.745702e-02, -3.078043e-02,  3.762230e-02, -8.192245e-02,  1.834730e-02,  5.557178e-02, -9.839705e-02,\n",
       "            4.872888e-02,  6.030214e-03, -4.229424e-02, -7.541136e-02, -4.689174e-02,  3.430901e-02, -8.374202e-02,  9.137630e-02,\n",
       "            6.643360e-02,  6.412883e-02, -8.180630e-02, -8.966143e-02,  3.132246e-02, -1.572952e-02,  6.570607e-02,  3.187465e-02,\n",
       "            5.681533e-02, -8.689077e-02, -4.479791e-02,  1.510058e-02,  2.234945e-02, -1.402149e-02, -6.756321e-02, -5.605803e-02,\n",
       "           -6.522568e-02,  6.606497e-02, -9.796792e-02, -9.720864e-02, -3.859166e-02, -8.278854e-02,  5.819411e-02,  3.933283e-02,\n",
       "            8.608492e-02, -9.199955e-02, -9.658487e-02, -4.490612e-02],\n",
       "          [-7.926666e-02,  9.648439e-02, -6.536772e-02, -4.556470e-02,  5.622883e-02,  8.273426e-02,  1.346356e-02,  8.193325e-02,\n",
       "           -9.083786e-02, -4.870619e-02, -8.044672e-03, -6.591171e-02,  1.594365e-03,  6.140480e-02,  3.642347e-02,  2.233906e-02,\n",
       "           -8.237022e-02, -1.533723e-03, -2.664938e-02, -4.262460e-02,  6.956394e-02, -8.516919e-02, -8.484907e-02, -4.939249e-02,\n",
       "            5.527617e-02,  4.893759e-02, -4.682970e-03, -5.828455e-02,  7.295056e-02,  4.520154e-02,  2.195710e-02, -9.794736e-03,\n",
       "            1.657605e-02,  3.179104e-02, -8.270141e-02, -5.322714e-02,  3.603417e-02, -7.103348e-03,  8.127170e-02, -1.258255e-02,\n",
       "            5.453644e-02,  3.616640e-02, -7.070037e-02, -3.604179e-02,  3.063945e-02, -4.732860e-02,  2.846968e-02, -7.309981e-02,\n",
       "            4.625935e-02,  7.761250e-02,  1.003318e-02, -9.929851e-02,  5.164789e-02,  1.267571e-02,  3.553319e-03, -2.125902e-02,\n",
       "            7.585680e-02,  9.945302e-02, -4.603703e-02,  5.026740e-02, -6.343058e-02,  2.150047e-03, -6.974500e-02,  1.450652e-02,\n",
       "           -2.181107e-02,  3.116995e-02, -1.022587e-02, -2.131379e-03,  2.106787e-02, -5.303979e-04,  3.015784e-02,  2.081120e-02,\n",
       "            9.807749e-02,  6.284297e-02,  9.699094e-02,  9.957468e-02,  6.153473e-02, -6.871939e-02,  4.547135e-02, -5.981631e-02,\n",
       "            8.783298e-02,  5.565623e-02, -4.664740e-02, -2.794287e-02, -3.312783e-02, -5.473778e-02, -1.855438e-02, -6.557397e-02,\n",
       "           -9.128809e-03,  6.744552e-03, -6.404575e-02,  5.376161e-02, -2.925971e-02, -7.016968e-02,  3.968778e-02,  5.680909e-02,\n",
       "           -7.696152e-05,  6.936353e-02,  2.492536e-02,  8.506485e-02],\n",
       "          [-1.243600e-02,  7.479455e-02, -8.866312e-02,  7.482534e-02,  5.724515e-02,  3.098821e-02, -9.988063e-02,  1.348156e-02,\n",
       "           -8.956888e-02,  1.950576e-02, -1.215041e-02, -5.693973e-02, -8.547773e-02,  9.795900e-02,  4.113594e-02, -9.478386e-02,\n",
       "            2.280554e-02,  9.836697e-02, -6.251792e-02, -5.473685e-02, -4.517679e-02, -6.560805e-02, -3.991647e-02,  8.367536e-02,\n",
       "            5.799416e-02,  6.402250e-02,  9.404384e-02, -8.218426e-02, -7.131721e-02,  8.588642e-02, -2.496946e-03, -6.754478e-02,\n",
       "            3.087169e-02,  3.568602e-02, -4.468773e-02,  1.887891e-02, -6.484820e-02, -6.597897e-02, -1.069783e-02,  9.319879e-02,\n",
       "           -9.703549e-02,  4.098203e-02,  8.601546e-02, -6.732326e-02, -2.569044e-03,  2.279153e-02, -2.335401e-02,  3.751743e-03,\n",
       "           -5.405154e-02, -9.768318e-02,  8.435418e-02,  7.561827e-03,  7.676083e-02,  1.338184e-02, -1.535417e-02,  5.486816e-02,\n",
       "            7.203794e-02,  6.079381e-02, -9.454256e-02,  1.661460e-02, -6.967030e-02,  6.073819e-02, -8.590011e-02,  5.123499e-02,\n",
       "            5.461258e-02,  6.515222e-02,  1.260228e-02,  6.974133e-02,  1.570759e-02,  1.434795e-02, -2.553829e-02, -4.620945e-02,\n",
       "           -8.371067e-02, -3.660691e-02,  5.205797e-02, -2.422913e-02, -2.286799e-02,  8.880877e-02,  7.777720e-02,  9.073515e-02,\n",
       "            2.935830e-02,  7.160062e-02, -6.253910e-03,  8.297566e-02,  8.755609e-02, -2.062841e-02,  6.056144e-02, -2.417045e-02,\n",
       "           -7.005119e-02,  2.119187e-02, -3.740499e-02,  5.826604e-02, -9.561237e-02,  4.350460e-03,  7.855710e-02, -3.969477e-02,\n",
       "            3.440956e-02,  5.971199e-02,  3.409209e-02, -3.945995e-02],\n",
       "          [-9.536862e-02, -2.896192e-02, -8.761996e-02, -6.100669e-02,  5.000490e-02, -3.486004e-02,  7.797416e-02,  5.715352e-02,\n",
       "            9.545676e-02, -8.885904e-02,  6.124039e-02, -3.906531e-02, -4.162062e-02,  4.331988e-02,  3.380663e-02, -2.435384e-02,\n",
       "            7.218651e-02,  3.538990e-03, -4.881252e-02, -1.521342e-02, -6.776003e-02,  5.972076e-03, -3.646141e-02, -4.015398e-03,\n",
       "            4.792431e-02,  2.428066e-02, -4.581570e-02, -1.476137e-02, -9.578682e-02, -2.947248e-02, -8.265597e-02,  8.406321e-02,\n",
       "           -6.596201e-02, -9.327578e-03, -5.935518e-02,  7.259905e-02,  4.410877e-02, -9.035905e-02,  1.126826e-03, -1.181829e-02,\n",
       "            3.669530e-02,  6.218619e-02,  8.561789e-02,  8.573092e-03,  6.111932e-02, -6.208790e-02,  7.601985e-02, -2.869084e-02,\n",
       "           -9.774681e-02, -5.256842e-02,  4.690621e-02, -1.083764e-02, -2.085855e-02,  5.486878e-02,  5.712575e-02, -7.813622e-02,\n",
       "            3.802848e-03,  2.605983e-02, -5.749276e-02,  9.100074e-02, -4.102758e-02,  1.369966e-02,  2.862996e-02, -9.890952e-02,\n",
       "            8.143902e-03, -3.227203e-02,  8.882137e-02, -2.397491e-02, -7.683311e-02,  2.953291e-03,  6.352771e-03,  7.749993e-02,\n",
       "           -4.451597e-03, -6.721038e-02, -6.296993e-04, -8.709063e-02,  2.190268e-02,  3.659743e-02, -3.640943e-02, -3.275055e-02,\n",
       "           -6.751996e-02, -2.902002e-02,  9.827626e-02,  6.898250e-02, -9.168267e-03, -6.829562e-02, -1.699458e-02, -2.968239e-02,\n",
       "           -6.839031e-02,  5.049771e-02,  3.707654e-02,  9.423419e-02,  6.536289e-02, -6.388903e-02, -4.081584e-02,  2.396563e-02,\n",
       "            8.548696e-02,  2.170421e-02,  9.415443e-02, -5.332329e-02]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.011286,  0.021703, -0.018384,  0.046381,  0.015189], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.097961, -0.098655,  0.034025, -0.025675, -0.062211, -0.029540, -0.057129,  0.035326,  0.036541,  0.054385,  0.010059,\n",
       "            0.043639, -0.085471, -0.023357, -0.001529, -0.037431, -0.016261, -0.004102,  0.062355,  0.024771,  0.043150, -0.062572,\n",
       "            0.035259,  0.039664,  0.075429, -0.066193, -0.032783,  0.093214, -0.091434, -0.035837,  0.003829, -0.093431,  0.010586,\n",
       "           -0.092739,  0.050223, -0.067209, -0.097079,  0.017535,  0.056079, -0.095541, -0.067367,  0.019000, -0.089355,  0.099906,\n",
       "           -0.073463, -0.041054,  0.079486,  0.077286,  0.050574,  0.093631,  0.046327,  0.003747, -0.038053, -0.021572,  0.010919,\n",
       "           -0.054780,  0.049180, -0.093685,  0.065556, -0.025743,  0.050387, -0.000336,  0.011195,  0.066736, -0.013356,  0.012855,\n",
       "           -0.010797, -0.006856, -0.022020, -0.066181,  0.078406, -0.033747,  0.044782,  0.074121, -0.096226,  0.076079,  0.079792,\n",
       "           -0.057216,  0.001253, -0.017603, -0.058490, -0.041115,  0.011950,  0.029532, -0.059767, -0.053258,  0.030624,  0.062824,\n",
       "           -0.031723, -0.031150,  0.069867, -0.014692, -0.072303,  0.056274, -0.034050,  0.078377,  0.005271,  0.087864,  0.030742,\n",
       "           -0.028261],\n",
       "          [ 0.079442, -0.075577,  0.066520, -0.079937, -0.032980,  0.011152, -0.009023,  0.059730, -0.017880, -0.022160, -0.008148,\n",
       "           -0.053905, -0.099105, -0.057021, -0.081461,  0.029184, -0.096964,  0.015061, -0.001608,  0.095186, -0.097609, -0.071688,\n",
       "            0.082229,  0.078470,  0.036617,  0.085439,  0.021337,  0.045038, -0.005542, -0.018977,  0.035639,  0.084470, -0.090545,\n",
       "           -0.078814, -0.071820, -0.099498,  0.074252, -0.048888, -0.020473,  0.084638, -0.047773, -0.065782, -0.010955,  0.078736,\n",
       "           -0.013035, -0.038506, -0.075520,  0.072833,  0.000343, -0.071636, -0.064996,  0.078194, -0.046362,  0.056153,  0.056945,\n",
       "           -0.076319,  0.001487, -0.033814, -0.084100, -0.054344,  0.005472,  0.037841, -0.002090, -0.076517,  0.057896,  0.068282,\n",
       "           -0.023141, -0.050101, -0.077178, -0.024105, -0.036684,  0.014002, -0.007841,  0.076144, -0.027241,  0.041007, -0.055084,\n",
       "            0.033723,  0.042823,  0.061247, -0.073210,  0.042304, -0.057328,  0.023307, -0.055268,  0.010158,  0.011535,  0.039142,\n",
       "            0.061371,  0.001954, -0.000725, -0.077620, -0.098802, -0.083096, -0.078248, -0.046787, -0.079048,  0.061854,  0.055867,\n",
       "           -0.050080],\n",
       "          [-0.094409,  0.057828, -0.046075,  0.079099, -0.090032, -0.074340, -0.000608, -0.045024, -0.066296,  0.010199,  0.089770,\n",
       "            0.092204,  0.022238, -0.041991, -0.020984, -0.079721,  0.038915, -0.050845,  0.029509, -0.072472,  0.038947, -0.096594,\n",
       "           -0.031726,  0.093075, -0.042026, -0.096205, -0.018368,  0.050298,  0.011031,  0.076519,  0.099457, -0.004836, -0.036680,\n",
       "            0.089753, -0.018295,  0.096297,  0.085713, -0.042669,  0.098561, -0.083329,  0.053191, -0.027077, -0.063554,  0.090333,\n",
       "           -0.076196,  0.006280, -0.086064,  0.019070, -0.014722, -0.099589, -0.084102,  0.064269, -0.083566,  0.055111,  0.068912,\n",
       "           -0.084016,  0.071378, -0.049486,  0.024702,  0.022711, -0.094196, -0.087114, -0.012306, -0.003462,  0.086310, -0.013589,\n",
       "            0.049466, -0.036860, -0.014024, -0.058719,  0.062965,  0.018805, -0.057372,  0.068851, -0.013423,  0.010289,  0.078443,\n",
       "            0.032683,  0.070883,  0.056307, -0.042519,  0.038434,  0.057691,  0.003778, -0.088725, -0.099834, -0.027938, -0.012138,\n",
       "           -0.096118, -0.004118, -0.004370, -0.073195,  0.067022, -0.015804, -0.077970,  0.020453,  0.051665, -0.088366, -0.078059,\n",
       "           -0.043486],\n",
       "          [ 0.023928,  0.065683,  0.076655, -0.059939,  0.010625, -0.013541,  0.096333, -0.091904,  0.062813, -0.062813,  0.074217,\n",
       "            0.050504,  0.015713, -0.012482,  0.039289,  0.058588,  0.040271,  0.015398,  0.081399, -0.057519,  0.050571,  0.081290,\n",
       "           -0.099989,  0.041195,  0.007137, -0.016737, -0.072169,  0.076204, -0.080024, -0.084294,  0.071184,  0.076057,  0.072127,\n",
       "            0.063000,  0.089787, -0.042036,  0.025313,  0.040407, -0.004577, -0.016242,  0.017052,  0.093472,  0.078561, -0.016437,\n",
       "            0.052896, -0.051652,  0.070277, -0.062529,  0.068992, -0.055716,  0.041335, -0.002088, -0.064014, -0.017067, -0.093555,\n",
       "           -0.033640,  0.099259,  0.041882,  0.049528,  0.034782, -0.044449,  0.033828,  0.031283,  0.054601, -0.033404,  0.043443,\n",
       "            0.088989, -0.052491, -0.052444,  0.073913,  0.095580,  0.013476, -0.004063,  0.049555, -0.054764, -0.092241, -0.042064,\n",
       "           -0.095640, -0.085368, -0.049020, -0.032649,  0.093494, -0.009716, -0.001144, -0.011598,  0.044295,  0.036777, -0.090386,\n",
       "            0.040870, -0.051152, -0.060899, -0.008359, -0.030284,  0.079063,  0.077264,  0.096429,  0.090250,  0.062995, -0.009681,\n",
       "            0.069683],\n",
       "          [-0.037326,  0.056696, -0.089531,  0.006609,  0.010188,  0.067610, -0.031598, -0.024377,  0.088926,  0.046472, -0.071342,\n",
       "           -0.057064,  0.088703,  0.046561,  0.055619,  0.037462,  0.082706,  0.098825, -0.087817, -0.029542,  0.035690,  0.033174,\n",
       "           -0.059215, -0.061055, -0.056106,  0.092293,  0.043199,  0.072379,  0.028247, -0.044421, -0.006876, -0.076643,  0.070738,\n",
       "           -0.045449, -0.070178,  0.069492, -0.022936,  0.014209, -0.036842, -0.072308,  0.030296,  0.015600, -0.023526, -0.027277,\n",
       "            0.012424,  0.025556, -0.006434,  0.084827, -0.036238,  0.035291, -0.051157, -0.030810,  0.075012, -0.087737,  0.079988,\n",
       "           -0.067260, -0.019001, -0.078276,  0.062177,  0.077052,  0.099397, -0.066510,  0.048932,  0.055764, -0.013398, -0.027641,\n",
       "            0.085872, -0.013889, -0.064370, -0.078962, -0.076241,  0.014477,  0.024418, -0.081977, -0.095495,  0.039386, -0.009703,\n",
       "            0.001097,  0.095804, -0.072075, -0.048957,  0.051795, -0.050846,  0.011918,  0.016629,  0.080191,  0.073052,  0.083530,\n",
       "           -0.012346,  0.030254,  0.085068,  0.000592, -0.000295, -0.083510, -0.070958, -0.088638, -0.046350, -0.098726,  0.083254,\n",
       "           -0.001109]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.085282,  0.018351, -0.001899,  0.056434, -0.004322], requires_grad=True)],\n",
       " 'lr': 0.001,\n",
       " 'momentum': 0.9,\n",
       " 'dampening': 0,\n",
       " 'weight_decay': 0.0001,\n",
       " 'nesterov': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.optimizers['weights'].param_groups[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320fdeee",
   "metadata": {},
   "source": [
    "###  Weights and Biases Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c2469c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:00:48.513456Z",
     "start_time": "2022-03-24T13:00:43.948026Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkbardool\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65xmlssn 0324_1359 AdaSparseChem\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kbardool/kusanagi/AdaSparseChem/wandb/run-20220324_140044-65xmlssn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"http://localhost:8080/kbardool/AdaSparseChem/runs/65xmlssn\" target=\"_blank\">0324_1359</a></strong> to <a href=\"http://localhost:8080/kbardool/AdaSparseChem\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PROJECT NAME: AdaSparseChem\n",
      " RUN ID      : 65xmlssn \n",
      " RUN NAME    : 0324_1359\n",
      " PROJECT NAME: AdaSparseChem\n",
      " RUN ID      : 65xmlssn \n",
      " RUN NAME    : 0324_1359\n"
     ]
    }
   ],
   "source": [
    "init_wandb(ns, opt, environment = environ)\n",
    "\n",
    "print(f\" PROJECT NAME: {ns.wandb_run.project}\\n\"\n",
    "      f\" RUN ID      : {ns.wandb_run.id} \\n\"\n",
    "      f\" RUN NAME    : {ns.wandb_run.name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d949180d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T12:55:33.731998Z",
     "start_time": "2022-03-23T12:55:33.702906Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d738062",
   "metadata": {},
   "source": [
    "### Initiate / Resume Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bd2a36e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:00:51.515194Z",
     "start_time": "2022-03-24T13:00:51.452533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############### Initiate Training  ###############\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "if opt['train']['resume']:\n",
    "    print(opt['train']['which_iter'])\n",
    "    print(opt['paths']['checkpoint_dir'])\n",
    "    print(RESUME_MODEL_CKPT)\n",
    "    # opt['train']['resume'] = True\n",
    "    # opt['train']['which_iter'] = 'warmup_ep_40_seed_0088'\n",
    "if opt['train']['resume']:\n",
    "    print_separator('Resume training')\n",
    "    loaded_iter, loaded_epoch = environ.load_checkpoint(RESUME_MODEL_CKPT, path = opt['paths']['checkpoint_dir'], verbose = True)\n",
    "    print(loaded_iter, loaded_epoch)    \n",
    "#     current_iter = environ.load_checkpoint(opt['train']['which_iter'])\n",
    "    environ.networks['mtl-net'].reset_logits()\n",
    "    val_metrics = load_from_pickle(opt['paths']['checkpoint_dir'], RESUME_METRICS_CKPT)\n",
    "    # training_prep(ns, opt, environ, dldrs, epoch = loaded_epoch, iter = loaded_iter )\n",
    "\n",
    "else:\n",
    "    print_separator('Initiate Training ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7774f",
   "metadata": {},
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8b6afdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:00:54.032614Z",
     "start_time": "2022-03-24T13:00:53.961634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cuda available [0]\n",
      " set print_freq to length of train loader: 105\n",
      " set eval_iters to length of val loader  : 33\n"
     ]
    }
   ],
   "source": [
    "training_prep(ns, opt, environ, dldrs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ea212ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:00:55.788788Z",
     "start_time": "2022-03-24T13:00:55.722915Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:18.146907Z",
     "iopub.status.busy": "2022-01-07T22:44:18.145721Z",
     "iopub.status.idle": "2022-01-07T22:44:18.191126Z",
     "shell.execute_reply": "2022-01-07T22:44:18.189994Z",
     "shell.execute_reply.started": "2022-01-07T22:44:18.146867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Num_blocks                : 6                                \n",
      "\n",
      " batch size                : 128 \n",
      " batches/ Weight trn epoch : 105 \n",
      " batches/ Policy trn epoch : 105                                 \n",
      "\n",
      " Print Frequency           : -1 \n",
      " Config Val Frequency      : 500 \n",
      " Config Val Iterations     : -1 \n",
      " Val iterations            : 33 \n",
      " which_iter                : warmup \n",
      " train_resume              : False                                 \n",
      " \n",
      " fix BN parms              : False \n",
      " Task LR                   : 0.001 \n",
      " Backbone LR               : 0.001                                 \n",
      "\n",
      " Sharing  regularization   : 0.01 \n",
      " Sparsity regularization   : 0.02 \n",
      " Task     regularization   : 1                                 \n",
      "\n",
      " Current epoch             : 0  \n",
      " Warm-up epochs            : 75 \n",
      " Training epochs           : 125\n"
     ]
    }
   ],
   "source": [
    "disp_info_1(ns, opt, environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61bc6107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:00:57.026913Z",
     "start_time": "2022-03-24T13:00:56.967499Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:18.146907Z",
     "iopub.status.busy": "2022-01-07T22:44:18.145721Z",
     "iopub.status.idle": "2022-01-07T22:44:18.191126Z",
     "shell.execute_reply": "2022-01-07T22:44:18.189994Z",
     "shell.execute_reply.started": "2022-01-07T22:44:18.146867Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    folder: 100x6_0324_1359_plr0.01_sp0.02_sh0.01_lr0.001\n",
      "    layers: 6 [100, 100, 100, 100, 100, 100] \n",
      "    \n",
      "    middle dropout         : 0.5\n",
      "    last dropout           : 0.5\n",
      "    diff_sparsity_weights  : False\n",
      "    skip_layer             : 0\n",
      "    is_curriculum          : False\n",
      "    curriculum_speed       : 3\n",
      "    \n",
      "    task_lr                : 0.001\n",
      "    backbone_lr            : 0.001\n",
      "    decay_lr_rate          : 0.75\n",
      "    decay_lr_freq          : 40\n",
      "    \n",
      "    policy_lr              : 0.01\n",
      "    policy_decay_lr_rate   : 0.75\n",
      "    policy_decay_lr_freq   : 50\n",
      "    lambda_sparsity        : 0.02\n",
      "    lambda_sharing         : 0.01\n",
      "    lambda_tasks           : 1\n",
      "    \n",
      "    Gumbel init_temp       : 4\n",
      "    Gumbel decay_temp      : 0.965\n",
      "    Gumbel decay_temp_freq : 16\n",
      "    Logit init_method      : random\n",
      "    Logit init_neg_logits  : None\n",
      "    Logit hard_sampling    : False\n",
      "    Warm-up epochs         : 75\n",
      "    training epochs        : 125\n",
      "    Data split ratios      : [0.725, 0.225, 0.05]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(environ.disp_for_excel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278d6d1",
   "metadata": {},
   "source": [
    "## Warmup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92380a48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:00:59.180878Z",
     "start_time": "2022-03-24T13:00:59.126868Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 0\n",
      "------------------------------------------------------------------------\n",
      " Last Epoch: 0   # of warm-up epochs to do:  75 - Run epochs 1 to 75\n",
      "------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# environ.display_trained_policy(ns.current_epoch,out=sys.stdout)\n",
    "# ns.stop_epoch_warmup = 10\n",
    "# ns.warmup_epochs = 10\n",
    "print(ns.warmup_epochs, ns.current_epoch)\n",
    "print_heading(f\" Last Epoch: {ns.current_epoch}   # of warm-up epochs to do:  {ns.warmup_epochs} - Run epochs {ns.current_epoch+1} to {ns.current_epoch + ns.warmup_epochs}\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8be9d65b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:10:44.491358Z",
     "start_time": "2022-03-24T13:00:59.606235Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      " Last Epoch: 0   # of warm-up epochs to do:  75 - Run epochs 1 to 75\n",
      "------------------------------------------------------------------------ \n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "    1 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |   10.5212   4.1594e-02   2.1694e-04   10.5630 |   0.68903   0.57057   0.58071   0.57014 |   10.3354   4.1594e-02   2.1694e-04    10.3772 |   7.4 |\n",
      "    2 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |   10.0123   4.1594e-02   2.1694e-04   10.0541 |   0.68283   0.60611   0.61873   0.60573 |   10.2434   4.1594e-02   2.1694e-04    10.2852 |   7.6 |\n",
      "    3 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    9.9372   4.1594e-02   2.1694e-04    9.9790 |   0.67496   0.62836   0.63553   0.62800 |   10.1262   4.1594e-02   2.1694e-04    10.1680 |   7.5 |\n",
      "    4 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    9.7829   4.1594e-02   2.1694e-04    9.8248 |   0.66631   0.64071   0.64807   0.64038 |    9.9960   4.1594e-02   2.1694e-04    10.0378 |   7.4 |\n",
      "    5 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    9.9405   4.1594e-02   2.1694e-04    9.9823 |   0.65775   0.65839   0.66307   0.65809 |    9.8723   4.1594e-02   2.1694e-04     9.9141 |   7.6 |\n",
      "    6 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    9.4600   4.1594e-02   2.1694e-04    9.5018 |   0.64938   0.66956   0.67185   0.66930 |    9.7454   4.1594e-02   2.1694e-04     9.7873 |   7.4 |\n",
      "    7 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.6775   4.1594e-02   2.1694e-04    8.7193 |   0.64306   0.68159   0.68430   0.68136 |    9.6446   4.1594e-02   2.1694e-04     9.6864 |   7.6 |\n",
      "    8 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |   10.0263   4.1594e-02   2.1694e-04   10.0681 |   0.63788   0.68990   0.69230   0.68969 |    9.5706   4.1594e-02   2.1694e-04     9.6124 |   7.8 |\n",
      "    9 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    9.7044   4.1594e-02   2.1694e-04    9.7462 |   0.63493   0.69434   0.69642   0.69413 |    9.5239   4.1594e-02   2.1694e-04     9.5657 |   7.6 |\n",
      "   10 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.6731   4.1594e-02   2.1694e-04    8.7149 |   0.62785   0.70283   0.70406   0.70263 |    9.4240   4.1594e-02   2.1694e-04     9.4658 |   7.6 |\n",
      "   11 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.5468   4.1594e-02   2.1694e-04    8.5886 |   0.62369   0.70839   0.70971   0.70818 |    9.3530   4.1594e-02   2.1694e-04     9.3948 |   7.4 |\n",
      "   12 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.9288   4.1594e-02   2.1694e-04    8.9706 |   0.61963   0.71553   0.71716   0.71533 |    9.2964   4.1594e-02   2.1694e-04     9.3382 |   7.8 |\n",
      "   13 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.1380   4.1594e-02   2.1694e-04    8.1799 |   0.61311   0.72281   0.72532   0.72262 |    9.1974   4.1594e-02   2.1694e-04     9.2392 |   7.5 |\n",
      "   14 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.1908   4.1594e-02   2.1694e-04    8.2326 |   0.61151   0.72609   0.72886   0.72590 |    9.1694   4.1594e-02   2.1694e-04     9.2112 |   7.8 |\n",
      "   15 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.7079   4.1594e-02   2.1694e-04    7.7497 |   0.60643   0.73249   0.73449   0.73232 |    9.0944   4.1594e-02   2.1694e-04     9.1362 |   8.3 |\n",
      "   16 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.9829   4.1594e-02   2.1694e-04    8.0247 |   0.60088   0.73825   0.74145   0.73807 |    9.0094   4.1594e-02   2.1694e-04     9.0512 |   7.5 |\n",
      "   17 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.5606   4.1594e-02   2.1694e-04    7.6024 |   0.59896   0.74229   0.74463   0.74211 |    8.9825   4.1594e-02   2.1694e-04     9.0243 |   7.4 |\n",
      "   18 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.7798   4.1594e-02   2.1694e-04    7.8216 |   0.59487   0.74589   0.74839   0.74572 |    8.9277   4.1594e-02   2.1694e-04     8.9695 |   7.8 |\n",
      "   19 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.9116   4.1594e-02   2.1694e-04    6.9534 |   0.59210   0.75136   0.75350   0.75118 |    8.8865   4.1594e-02   2.1694e-04     8.9283 |   9.5 |\n",
      "   20 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.0859   4.1594e-02   2.1694e-04    7.1277 |   0.58706   0.75533   0.75669   0.75518 |    8.8022   4.1594e-02   2.1694e-04     8.8440 |   8.5 |\n",
      "   21 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.2772   4.1594e-02   2.1694e-04    7.3190 |   0.58391   0.75959   0.76146   0.75944 |    8.7554   4.1594e-02   2.1694e-04     8.7972 |   8.6 |\n",
      "   22 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.5768   4.1594e-02   2.1694e-04    6.6186 |   0.58011   0.76294   0.76433   0.76279 |    8.7012   4.1594e-02   2.1694e-04     8.7430 |   8.9 |\n",
      "   23 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.0580   4.1594e-02   2.1694e-04    7.0998 |   0.57596   0.76639   0.76750   0.76624 |    8.6489   4.1594e-02   2.1694e-04     8.6907 |   8.3 |\n",
      "   24 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.9311   4.1594e-02   2.1694e-04    6.9729 |   0.57315   0.77023   0.77144   0.77008 |    8.6080   4.1594e-02   2.1694e-04     8.6498 |   8.6 |\n",
      "   25 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.6385   4.1594e-02   2.1694e-04    6.6803 |   0.57141   0.77359   0.77487   0.77344 |    8.5672   4.1594e-02   2.1694e-04     8.6090 |   8.3 |\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   26 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.3208   4.1594e-02   2.1694e-04    7.3627 |   0.56948   0.77522   0.77632   0.77508 |    8.5434   4.1594e-02   2.1694e-04     8.5852 |   7.7 |\n",
      "   27 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.8385   4.1594e-02   2.1694e-04    6.8804 |   0.56865   0.77712   0.77766   0.77697 |    8.5283   4.1594e-02   2.1694e-04     8.5701 |   7.5 |\n",
      "   28 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.1825   4.1594e-02   2.1694e-04    7.2243 |   0.56522   0.77934   0.78022   0.77919 |    8.4706   4.1594e-02   2.1694e-04     8.5124 |   7.3 |\n",
      "   29 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.8259   4.1594e-02   2.1694e-04    5.8678 |   0.56277   0.78255   0.78325   0.78242 |    8.4379   4.1594e-02   2.1694e-04     8.4797 |   7.3 |\n",
      "   30 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.2868   4.1594e-02   2.1694e-04    6.3286 |   0.56273   0.78545   0.78599   0.78533 |    8.4482   4.1594e-02   2.1694e-04     8.4900 |   7.7 |\n",
      "   31 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.1330   4.1594e-02   2.1694e-04    6.1748 |   0.55567   0.78670   0.78756   0.78658 |    8.3449   4.1594e-02   2.1694e-04     8.3867 |   7.7 |\n",
      "   32 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.2640   4.1594e-02   2.1694e-04    6.3058 |   0.55263   0.78984   0.79075   0.78972 |    8.2849   4.1594e-02   2.1694e-04     8.3268 |   7.5 |\n",
      "   33 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.4542   4.1594e-02   2.1694e-04    6.4960 |   0.55129   0.79126   0.79187   0.79114 |    8.2769   4.1594e-02   2.1694e-04     8.3187 |   7.7 |\n",
      "   34 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.9356   4.1594e-02   2.1694e-04    5.9774 |   0.55376   0.79294   0.79344   0.79282 |    8.3170   4.1594e-02   2.1694e-04     8.3588 |   7.1 |\n",
      "   35 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.8389   4.1594e-02   2.1694e-04    5.8807 |   0.54898   0.79515   0.79442   0.79504 |    8.2185   4.1594e-02   2.1694e-04     8.2603 |   7.3 |\n",
      "   36 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.9887   4.1594e-02   2.1694e-04    6.0305 |   0.54905   0.79684   0.79620   0.79673 |    8.2431   4.1594e-02   2.1694e-04     8.2849 |   7.3 |\n",
      "   37 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.4649   4.1594e-02   2.1694e-04    5.5067 |   0.54848   0.79793   0.79768   0.79783 |    8.2221   4.1594e-02   2.1694e-04     8.2639 |   7.2 |\n",
      "   38 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.8065   4.1594e-02   2.1694e-04    4.8483 |   0.54351   0.79979   0.79951   0.79968 |    8.1385   4.1594e-02   2.1694e-04     8.1803 |   7.3 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.0632   4.1594e-02   2.1694e-04    5.1050 |   0.54292   0.80062   0.80044   0.80051 |    8.1424   4.1594e-02   2.1694e-04     8.1842 |   7.1 |\n",
      "   40 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.1329   4.1594e-02   2.1694e-04    5.1747 |   0.54445   0.80245   0.80214   0.80235 |    8.1705   4.1594e-02   2.1694e-04     8.2123 |   7.9 |\n",
      "   41 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.8953   4.1594e-02   2.1694e-04    5.9371 |   0.54543   0.80368   0.80294   0.80358 |    8.1779   4.1594e-02   2.1694e-04     8.2197 |   7.1 |\n",
      "   42 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.7173   4.1594e-02   2.1694e-04    5.7591 |   0.54211   0.80368   0.80321   0.80358 |    8.1289   4.1594e-02   2.1694e-04     8.1707 |   7.2 |\n",
      "   43 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.3632   4.1594e-02   2.1694e-04    4.4050 |   0.54141   0.80681   0.80588   0.80670 |    8.1226   4.1594e-02   2.1694e-04     8.1644 |   7.3 |\n",
      "   44 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.1623   4.1594e-02   2.1694e-04    5.2041 |   0.53634   0.80753   0.80663   0.80742 |    8.0497   4.1594e-02   2.1694e-04     8.0915 |   7.4 |\n",
      "   45 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.5477   4.1594e-02   2.1694e-04    4.5895 |   0.54106   0.80739   0.80614   0.80729 |    8.1222   4.1594e-02   2.1694e-04     8.1640 |   7.4 |\n",
      "   46 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.5915   4.1594e-02   2.1694e-04    4.6333 |   0.53965   0.80869   0.80757   0.80858 |    8.1029   4.1594e-02   2.1694e-04     8.1447 |   7.4 |\n",
      "   47 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.8019   4.1594e-02   2.1694e-04    4.8437 |   0.54000   0.80965   0.80872   0.80954 |    8.0940   4.1594e-02   2.1694e-04     8.1358 |   7.2 |\n",
      "   48 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.2830   4.1594e-02   2.1694e-04    4.3249 |   0.53658   0.81105   0.81027   0.81095 |    8.0443   4.1594e-02   2.1694e-04     8.0861 |   7.4 |\n",
      "   49 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.4994   4.1594e-02   2.1694e-04    4.5412 |   0.53766   0.81182   0.81113   0.81172 |    8.0671   4.1594e-02   2.1694e-04     8.1089 |   7.8 |\n",
      "   50 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.4858   4.1594e-02   2.1694e-04    4.5276 |   0.53962   0.81239   0.81120   0.81229 |    8.0931   4.1594e-02   2.1694e-04     8.1349 |   7.4 |\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   51 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.5203   4.1594e-02   2.1694e-04    4.5621 |   0.53847   0.81379   0.81274   0.81368 |    8.0902   4.1594e-02   2.1694e-04     8.1320 |   7.5 |\n",
      "   52 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.9098   4.1594e-02   2.1694e-04    3.9516 |   0.53655   0.81423   0.81328   0.81412 |    8.0471   4.1594e-02   2.1694e-04     8.0889 |   7.4 |\n",
      "   53 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.2907   4.1594e-02   2.1694e-04    4.3326 |   0.53464   0.81550   0.81428   0.81540 |    8.0255   4.1594e-02   2.1694e-04     8.0673 |   7.5 |\n",
      "   54 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.5613   4.1594e-02   2.1694e-04    4.6031 |   0.53887   0.81559   0.81426   0.81547 |    8.0923   4.1594e-02   2.1694e-04     8.1341 |   7.5 |\n",
      "   55 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.5402   4.1594e-02   2.1694e-04    4.5820 |   0.53709   0.81576   0.81512   0.81565 |    8.0667   4.1594e-02   2.1694e-04     8.1085 |   7.4 |\n",
      "   56 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.8423   4.1594e-02   2.1694e-04    3.8842 |   0.53866   0.81734   0.81589   0.81725 |    8.0767   4.1594e-02   2.1694e-04     8.1185 |   7.4 |\n",
      "   57 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.0782   4.1594e-02   2.1694e-04    5.1200 |   0.53952   0.81761   0.81610   0.81750 |    8.1061   4.1594e-02   2.1694e-04     8.1479 |   7.2 |\n",
      "   58 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.8218   4.1594e-02   2.1694e-04    3.8636 |   0.53881   0.81775   0.81623   0.81766 |    8.0894   4.1594e-02   2.1694e-04     8.1312 |   7.3 |\n",
      "   59 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.5956   4.1594e-02   2.1694e-04    4.6374 |   0.54035   0.81836   0.81739   0.81826 |    8.1051   4.1594e-02   2.1694e-04     8.1469 |   7.3 |\n",
      "   60 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.1704   4.1594e-02   2.1694e-04    4.2122 |   0.54106   0.81834   0.81705   0.81824 |    8.1143   4.1594e-02   2.1694e-04     8.1561 |   7.4 |\n",
      "   61 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.2437   4.1594e-02   2.1694e-04    4.2855 |   0.54141   0.81894   0.81778   0.81884 |    8.1108   4.1594e-02   2.1694e-04     8.1526 |   7.4 |\n",
      "   62 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.0768   4.1594e-02   2.1694e-04    4.1186 |   0.54180   0.81898   0.81742   0.81887 |    8.1437   4.1594e-02   2.1694e-04     8.1855 |   7.7 |\n",
      "   63 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.9285   4.1594e-02   2.1694e-04    3.9703 |   0.54229   0.81888   0.81795   0.81878 |    8.1339   4.1594e-02   2.1694e-04     8.1757 |   7.7 |\n",
      "   64 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.9231   4.1594e-02   2.1694e-04    3.9649 |   0.54105   0.82004   0.81883   0.81995 |    8.1379   4.1594e-02   2.1694e-04     8.1797 |   7.5 |\n",
      "   65 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.2310   4.1594e-02   2.1694e-04    4.2728 |   0.54315   0.82065   0.81957   0.82055 |    8.1424   4.1594e-02   2.1694e-04     8.1842 |   7.3 |\n",
      "   66 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.1016   4.1594e-02   2.1694e-04    4.1435 |   0.54594   0.82100   0.82007   0.82090 |    8.1927   4.1594e-02   2.1694e-04     8.2345 |   7.2 |\n",
      "   67 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.0789   4.1594e-02   2.1694e-04    4.1207 |   0.54401   0.82132   0.82011   0.82123 |    8.1508   4.1594e-02   2.1694e-04     8.1927 |   7.3 |\n",
      "   68 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.7126   4.1594e-02   2.1694e-04    3.7544 |   0.54695   0.82147   0.82024   0.82137 |    8.2107   4.1594e-02   2.1694e-04     8.2525 |   7.3 |\n",
      "   69 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.1076   4.1594e-02   2.1694e-04    4.1494 |   0.54381   0.82170   0.82067   0.82160 |    8.1531   4.1594e-02   2.1694e-04     8.1950 |   7.2 |\n",
      "   70 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.5567   4.1594e-02   2.1694e-04    3.5985 |   0.54646   0.82243   0.82117   0.82233 |    8.2061   4.1594e-02   2.1694e-04     8.2479 |   7.9 |\n",
      "   71 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.9384   4.1594e-02   2.1694e-04    3.9802 |   0.54803   0.82296   0.82159   0.82286 |    8.1972   4.1594e-02   2.1694e-04     8.2390 |   7.7 |\n",
      "   72 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.8936   4.1594e-02   2.1694e-04    3.9354 |   0.54891   0.82249   0.82166   0.82240 |    8.2569   4.1594e-02   2.1694e-04     8.2987 |   8.0 |\n",
      "   73 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.4281   4.1594e-02   2.1694e-04    3.4699 |   0.55069   0.82291   0.82159   0.82282 |    8.2571   4.1594e-02   2.1694e-04     8.2990 |   7.3 |\n",
      "   74 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.6179   4.1594e-02   2.1694e-04    3.6597 |   0.55285   0.82251   0.82123   0.82242 |    8.2861   4.1594e-02   2.1694e-04     8.3279 |   7.3 |\n",
      "   75 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.0615   4.1594e-02   2.1694e-04    3.1033 |   0.55519   0.82367   0.82237   0.82358 |    8.3349   4.1594e-02   2.1694e-04     8.3767 |   7.3 |\n",
      "[Final] ep:75  it:7875 -  Total Loss: 8.3767     \n",
      "Task: 8.3349   Sparsity: 4.15940e-02    Sharing: 2.16943e-04 \n",
      "\n",
      " epch:  75   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.5005    0.4995  1    0.5001    0.4999  1    0.5003    0.4997  1\n",
      "   2    0.4999    0.5001  0    0.5006    0.4994  1    0.5001    0.4999  1\n",
      "   3    0.4997    0.5003  0    0.5004    0.4996  1    0.5000    0.5000  1\n",
      "   4    0.4998    0.5002  0    0.5005    0.4995  1    0.4991    0.5009  0\n",
      "   5    0.4996    0.5004  0    0.5002    0.4998  1    0.5002    0.4998  1\n",
      "   6    0.5003    0.4997  1    0.4998    0.5002  0    0.4997    0.5003  0\n",
      "\n",
      "\n",
      "\n",
      " epch:  75   logits       s          logits      s         logits       s\n",
      " -----  ----------------- -    ----------------  -    ----------------  - \n",
      "   1    0.0009   -0.0012  1    0.0008    0.0004  1    0.0014    0.0002  1\n",
      "   2    0.0001    0.0006  0    0.0023   -0.0001  1    0.0002   -0.0002  1\n",
      "   3   -0.0007    0.0004  0    0.0004   -0.0012  1    0.0009    0.0009  1\n",
      "   4   -0.0008   -0.0001  0    0.0022    0.0003  1   -0.0012    0.0025  0\n",
      "   5   -0.0011    0.0006  0   -0.0005   -0.0011  1   -0.0003   -0.0013  1\n",
      "   6    0.0013    0.0002  1   -0.0008   -0.0002  0    0.0004    0.0017  0\n",
      "\n",
      "\n",
      " save warmup val_metrics to :  model_warmup_ep_75_seed_0088\n",
      " save warmup checkpoint  to :  model_warmup_ep_75_seed_0088\n"
     ]
    }
   ],
   "source": [
    "# warmup_phase(ns,opt, environ, dldrs, epochs = 25)\n",
    "warmup_phase(ns,opt, environ, dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b99542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T23:12:20.844680Z",
     "start_time": "2022-03-11T23:12:20.787795Z"
    }
   },
   "outputs": [],
   "source": [
    "# warmup_phase(ns,opt, environ, dldrs, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab69577b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T22:30:39.441635Z",
     "start_time": "2022-03-23T22:30:39.357347Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4ecebb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T22:30:40.295723Z",
     "start_time": "2022-03-23T22:30:40.247165Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29d68d54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:21:14.088901Z",
     "start_time": "2022-03-24T13:21:14.001140Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parms': {'gumbel_temp': 4,\n",
       "  'train_layers': 0,\n",
       "  'lr_0': 0.001,\n",
       "  'lr_1': 0.001,\n",
       "  'policy_lr': 0.01,\n",
       "  'lambda_sparsity': 0.02,\n",
       "  'lambda_sharing': 0.01,\n",
       "  'lambda_tasks': 1},\n",
       " 'task': {'total': tensor(8.673099, device='cuda:0', dtype=torch.float64),\n",
       "  'task1': tensor(2.684705, device='cuda:0', dtype=torch.float64),\n",
       "  'task2': tensor(2.954407, device='cuda:0', dtype=torch.float64),\n",
       "  'task3': tensor(3.033987, device='cuda:0', dtype=torch.float64)},\n",
       " 'task_mean': {'total': tensor(1.734620, device='cuda:0', dtype=torch.float64),\n",
       "  'task1': tensor(0.536941, device='cuda:0', dtype=torch.float64),\n",
       "  'task2': tensor(0.590881, device='cuda:0', dtype=torch.float64),\n",
       "  'task3': tensor(0.606797, device='cuda:0', dtype=torch.float64)},\n",
       " 'sparsity': {'total': tensor(0.041594, device='cuda:0'),\n",
       "  'task1': tensor(0.013862, device='cuda:0'),\n",
       "  'task2': tensor(0.013873, device='cuda:0'),\n",
       "  'task3': tensor(0.013859, device='cuda:0')},\n",
       " 'sharing': {'total': tensor(0.000217, device='cuda:0')},\n",
       " 'total': {'backprop': 0.0,\n",
       "  'task': 0.0,\n",
       "  'policy': tensor(0.041811, device='cuda:0'),\n",
       "  'total': tensor(8.714910, device='cuda:0', dtype=torch.float64),\n",
       "  'total_mean': tensor(1.776431, device='cuda:0', dtype=torch.float64),\n",
       "  'tasks': tensor(8.673099, device='cuda:0', dtype=torch.float64)}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46fadf1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T22:30:44.067519Z",
     "start_time": "2022-03-23T22:30:44.013376Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parms': {'gumbel_temp': 4,\n",
       "  'train_layers': 0,\n",
       "  'lr_0': 0.001,\n",
       "  'lr_1': 0.001,\n",
       "  'policy_lr': 0.01,\n",
       "  'lambda_sparsity': 0.03,\n",
       "  'lambda_sharing': 0.01,\n",
       "  'lambda_tasks': 1},\n",
       " 'task': {'total': 8.197446869225011,\n",
       "  'task1': 2.6417922839840293,\n",
       "  'task2': 2.756808388999536,\n",
       "  'task3': 2.7988461962414473},\n",
       " 'task_mean': {'total': 1.6394893738450027,\n",
       "  'task1': 0.5283584567968057,\n",
       "  'task2': 0.5513616777999073,\n",
       "  'task3': 0.5597692392482894},\n",
       " 'sparsity': {'total': 0.06234907731413841,\n",
       "  'task1': 0.02078135870397091,\n",
       "  'task2': 0.020778220146894455,\n",
       "  'task3': 0.02078949846327305},\n",
       " 'sharing': {'total': 0.00022678218374494463},\n",
       " 'total': {'total': 8.260022728722895,\n",
       "  'total_mean': 1.702065233342886,\n",
       "  'task': 8.197446869225011,\n",
       "  'policy': 0.06257585949788336},\n",
       " 'task1': {'classification': {'_type': 'table-file',\n",
       "   'path': 'media/table/classification_149_3227c0901b92f61b7164.table.json',\n",
       "   'sha256': '3227c0901b92f61b71642e159ca3228ea4dddf7e124440b8ba79493c19f8e1a2',\n",
       "   'size': 1050,\n",
       "   'artifact_path': 'wandb-client-artifact://c92mrb69xr0b54p4j816lpfikvby4c41khmnlvtov87iuw7zhhj3bro7izs7qo7cdhwik3yw8ben1scy9h97hdlas8ks6wt1igqzb8wvyqohznlslf4hqf7yhkn3u3vy/classification.table.json',\n",
       "   '_latest_artifact_path': 'wandb-client-artifact://15rwe3vr6dwro4t7ky645eq4oozi7bojxpujjroeqjjvri3b8aiegtvwyf3pkia78rxgz68ssmucd3rt401gwnu8lor1mg0j3o5iy0rzj1u4gvtro3oke1y7xnzj9zjx:latest/classification.table.json',\n",
       "   'ncols': 9,\n",
       "   'nrows': 5},\n",
       "  'classification_agg': {'roc_auc_score': 0.8267121361763473,\n",
       "   'auc_pr': 0.8157268218443087,\n",
       "   'avg_prec_score': 0.8158050612207415,\n",
       "   'f1_max': 0.7444407948125351,\n",
       "   'p_f1_max': 0.3237132906913758,\n",
       "   'kappa': 0.4765423605651249,\n",
       "   'kappa_max': 0.49049053522630726,\n",
       "   'p_kappa_max': 0.5524390816688538,\n",
       "   'bceloss': 0.5285730719566346,\n",
       "   'sc_loss': 0.08005431163587967,\n",
       "   'logloss': 0.00012771536301590667}},\n",
       " 'task2': {'classification': {'_type': 'table-file',\n",
       "   'path': 'media/table/classification_149_56f2ca87c7c067309fd7.table.json',\n",
       "   'sha256': '56f2ca87c7c067309fd72c88da891d1e80a0f60ddb94f6f170ec42f1d20b172a',\n",
       "   'size': 1055,\n",
       "   'artifact_path': 'wandb-client-artifact://kcoaa8qffe8b4skzicu9x0bfbnpl6uucvx6qcdirg8jxk9h3s4etjty7seehtgbjsk3xtabydoil86pebcsenblpkazfd9m6ovcncmf97ltexv0cwwfdeb11zvvk7hen/classification.table.json',\n",
       "   '_latest_artifact_path': 'wandb-client-artifact://15jwng6z00vmq9yjr6sp1gk9310l6uziyiov6404h6he2o3vv9f0ht3a2o5sgb1eb5odpw4xfz238sep1bfxrb1tv8azqeeybfo1h815c6t1ta7kbc8kco5l7a6mox0u:latest/classification.table.json',\n",
       "   'ncols': 9,\n",
       "   'nrows': 5},\n",
       "  'classification_agg': {'roc_auc_score': 0.8180951825211631,\n",
       "   'auc_pr': 0.822141067906077,\n",
       "   'avg_prec_score': 0.8222420983677212,\n",
       "   'f1_max': 0.7599708534303993,\n",
       "   'p_f1_max': 0.2634330689907074,\n",
       "   'kappa': 0.47322005624107993,\n",
       "   'kappa_max': 0.4834353806999352,\n",
       "   'p_kappa_max': 0.48064988851547247,\n",
       "   'bceloss': 0.5513423919677735,\n",
       "   'sc_loss': 0.0835396481515011,\n",
       "   'logloss': 0.00013327572583995823}},\n",
       " 'task3': {'classification': {'_type': 'table-file',\n",
       "   'path': 'media/table/classification_149_dc5674fcfe3a4abfd448.table.json',\n",
       "   'sha256': 'dc5674fcfe3a4abfd448606f3c150fbd5bfdd88ef4a5018f872bd56d09278568',\n",
       "   'size': 1056,\n",
       "   'artifact_path': 'wandb-client-artifact://6fd9vw5ym39copd7t284lv2ahsa7u07eza1yr19t2u6t6327efmxwta4qnsvijo3y8tw7t9sgr1m6h35delwx9wn2lo1otf7aej4ubu1tb6tiqdjts8lfuhve11g862s/classification.table.json',\n",
       "   '_latest_artifact_path': 'wandb-client-artifact://e4bqlqhodofo0gn8aebjp8qulm5ck19ppd6pnw46pha58lq3xxsaxd38q0kqu0gfar8xc89nzym8u4l2uft4i291ulap0gwawfxi0eexb08i8as3gsjsfj0ux4izu6fx:latest/classification.table.json',\n",
       "   'ncols': 9,\n",
       "   'nrows': 5},\n",
       "  'classification_agg': {'roc_auc_score': 0.8143147682421599,\n",
       "   'auc_pr': 0.8216789402078413,\n",
       "   'avg_prec_score': 0.8217643101379578,\n",
       "   'f1_max': 0.7689980174353418,\n",
       "   'p_f1_max': 0.3679416775703431,\n",
       "   'kappa': 0.4590756893826388,\n",
       "   'kappa_max': 0.4797872506583576,\n",
       "   'p_kappa_max': 0.552433705329895,\n",
       "   'bceloss': 0.5594912230968476,\n",
       "   'sc_loss': 0.08481352109822568,\n",
       "   'logloss': 0.00013530801045402211}},\n",
       " 'aggregated': {'roc_auc_score': 0.8197073623132234,\n",
       "  'auc_pr': 0.8198489433194088,\n",
       "  'avg_prec_score': 0.8199371565754734,\n",
       "  'f1_max': 0.7578032218927586,\n",
       "  'p_f1_max': 0.31836267908414206,\n",
       "  'kappa': 0.46961270206294786,\n",
       "  'kappa_max': 0.4845710555282,\n",
       "  'p_kappa_max': 0.5285075585047404,\n",
       "  'bceloss': 0.5464688956737518,\n",
       "  'sc_loss': 0.2484074808856064,\n",
       "  'logloss': 0.00013209969976996232},\n",
       " 'train_time': 7.6852195262908936,\n",
       " 'epoch': 75,\n",
       " '_timestamp': 1648074491,\n",
       " '_runtime': 668}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea84c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04d238e8",
   "metadata": {},
   "source": [
    "#### display parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e22e75ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:21:46.539081Z",
     "start_time": "2022-03-24T13:21:46.484458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone Learning Rate      : 0.001\n",
      " Tasks    Learning Rate      : 0.001\n",
      " Policy   Learning Rate      : 0.01\n",
      "\n",
      " Sparsity regularization     : 0.02\n",
      " Sharing  regularization     : 0.01 \n",
      "\n",
      " Tasks    regularization     : 1   \n",
      " Gumbel Temp                 : 4.0000         \n",
      " Gumbel Temp decay           : 16\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2db34fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:21:47.827772Z",
     "start_time": "2022-03-24T13:21:47.732382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'params': [Parameter containing:\n",
      "tensor([[ 9.265881e-04, -1.235903e-03],\n",
      "        [ 5.588943e-05,  6.319766e-04],\n",
      "        [-6.584334e-04,  3.764827e-04],\n",
      "        [-7.700642e-04, -1.022177e-04],\n",
      "        [-1.066945e-03,  5.982257e-04],\n",
      "        [ 1.315012e-03,  2.184580e-04]], device='cuda:0'), Parameter containing:\n",
      "tensor([[ 7.603760e-04,  3.758761e-04],\n",
      "        [ 2.285245e-03, -5.118694e-05],\n",
      "        [ 3.820481e-04, -1.171452e-03],\n",
      "        [ 2.224697e-03,  3.282016e-04],\n",
      "        [-4.551781e-04, -1.086531e-03],\n",
      "        [-8.322308e-04, -2.218975e-04]], device='cuda:0'), Parameter containing:\n",
      "tensor([[ 0.001423,  0.000156],\n",
      "        [ 0.000209, -0.000176],\n",
      "        [ 0.000879,  0.000876],\n",
      "        [-0.001247,  0.002500],\n",
      "        [-0.000269, -0.001266],\n",
      "        [ 0.000376,  0.001677]], device='cuda:0')], 'lr': 0.01, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0005, 'amsgrad': False, 'initial_lr': 0.01}]\n",
      "initial lr:  0.01 current lr:  0.01\n",
      "current lr:  0.001\n",
      "current lr:  0.001\n"
     ]
    }
   ],
   "source": [
    "# environ.opt['train']['policy_lr'] = 0.01\n",
    "# opt['train']['policy_lr']         = 0.01\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.1\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# environ.opt['train']['decay_temp_freq'] = 2\n",
    "print(environ.optimizers['alphas'].param_groups)\n",
    "# print(environ.optimizers['weights'].param_groups)\n",
    "print('initial lr: ', environ.optimizers['alphas'].param_groups[0]['initial_lr'] , 'current lr: ', environ.optimizers['alphas'].param_groups[0]['lr'],)\n",
    "print('current lr: ', environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "print('current lr: ', environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49645c",
   "metadata": {},
   "source": [
    "## Weight & Policy Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aade16",
   "metadata": {},
   "source": [
    "### Weight/Policy Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe24a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T23:38:26.687899Z",
     "start_time": "2022-03-10T23:38:26.617865Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.flag_warmup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "365996be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:21:59.145153Z",
     "start_time": "2022-03-24T13:21:59.088185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "** 2022-03-24 14:21:59:113811 \n",
      "** Training epoch: 75 iter: 7875   flag: update_w \n",
      "** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\n",
      "** Switch from Warm Up training to Alternate training Weights & Policy \n",
      "** Take checkpoint and block gradient flow through Policy net\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if ns.flag_warmup:\n",
    "    print_heading( f\"** {timestring()} \\n\"\n",
    "                   f\"** Training epoch: {ns.current_epoch} iter: {ns.current_iter}   flag: {ns.flag} \\n\"\n",
    "                   f\"** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\\n\"\n",
    "                   f\"** Switch from Warm Up training to Alternate training Weights & Policy \\n\"\n",
    "                   f\"** Take checkpoint and block gradient flow through Policy net\", verbose=True)\n",
    "#     environ.define_optimizer(policy_learning=True)\n",
    "#     environ.define_scheduler(policy_learning=True)\n",
    "    ns.flag_warmup = False\n",
    "    ns.flag = 'update_w'\n",
    "    environ.fix_alpha()\n",
    "    environ.free_weights(opt['fix_BN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8593384c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:21:59.747809Z",
     "start_time": "2022-03-24T13:21:59.699001Z"
    }
   },
   "outputs": [],
   "source": [
    "# num_train_layers = None \n",
    "# environ.opt['is_curriculum'] = True\n",
    "# environ.opt['curriculum_speed'] = 4\n",
    "# ns.num_train_layers = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "753d84a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:22:01.324270Z",
     "start_time": "2022-03-24T13:22:01.258632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 125\n",
      "ns.current_epoch           : 75\n",
      "ns.current_iters           : 7875 \n",
      "\n",
      "ns.training_epochs         : 125\n",
      "Batches in weight epoch    : 105\n",
      "Batches in policy epoch    : 105\n",
      "num_train_layers           : None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ns.current_epoch,ns.training_epochs)\n",
    "print(f\"ns.current_epoch           : {ns.current_epoch}\") \n",
    "print(f\"ns.current_iters           : {ns.current_iter} \\n\")  \n",
    "print(f\"ns.training_epochs         : {ns.training_epochs}\") \n",
    "# print(f\"ns.stop_epoch_training     : {ns.stop_epoch_training}\")\n",
    "print(f\"Batches in weight epoch    : {ns.stop_iter_w}\")\n",
    "print(f\"Batches in policy epoch    : {ns.stop_iter_a}\")\n",
    "print(f\"num_train_layers           : {ns.num_train_layers}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25e913c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T13:22:02.919037Z",
     "start_time": "2022-03-24T13:22:02.863462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[e] Last ep:75  it:7875 -  Total Loss: 8.3767     \n",
      "Task: 8.3349   Sparsity: 4.15940e-02    Sharing: 2.16943e-04 \n"
     ]
    }
   ],
   "source": [
    "# ns.training_epochs = 75\n",
    "print_loss(environ.val_metrics, title = f\"[e] Last ep:{ns.current_epoch}  it:{ns.current_iter}\")\n",
    "# environ.display_trained_policy(ns.current_epoch)\n",
    "# environ.display_trained_logits(ns.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51436760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T14:23:52.503692Z",
     "start_time": "2022-03-24T14:23:52.439879Z"
    }
   },
   "outputs": [],
   "source": [
    "ns.current_epoch = 200\n",
    "ns.flag = 'update_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fcd6751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T14:23:28.330078Z",
     "start_time": "2022-03-24T14:23:28.269220Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed : 200       # of epochs to run:  125 -->  epochs 201 to 325\n",
      " policy_learning rate : 0.01 \n",
      " lambda_sparsity      : 0.02\n",
      " lambda_sharing       : 0.01\n",
      " curriculum training  : False     cirriculum speed: 3     num_training_layers : 6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_heading(f\" Last Epoch Completed : {ns.current_epoch}       # of epochs to run:  {ns.training_epochs} -->  epochs {ns.current_epoch+1} to {ns.training_epochs + ns.current_epoch}\"\n",
    "              f\"\\n policy_learning rate : {environ.opt['train']['policy_lr']} \"\n",
    "              f\"\\n lambda_sparsity      : {environ.opt['train']['lambda_sparsity']}\"\n",
    "              f\"\\n lambda_sharing       : {environ.opt['train']['lambda_sharing']}\"\n",
    "              f\"\\n curriculum training  : {opt['is_curriculum']}     cirriculum speed: {opt['curriculum_speed']}     num_training_layers : {ns.num_train_layers}\", \n",
    "              verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c71af",
   "metadata": {},
   "source": [
    "### Weight/Policy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ad7d8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-24T14:24:16.570Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed : 200   # of epochs to run:  125 -->  epochs 201 to 325    \n",
      " policy_learning rate : 0.01      \n",
      " lambda_sparsity      : 0.02\n",
      " lambda_sharing       : 0.01 \n",
      " curriculum training  : False     cirriculum speed: 3     num_training_layers : 6\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  201 |   4.22e-04   4.22e-04   5.62e-03  3.117e+00 |    1.3567   3.8673e-02   1.6323e-04    1.3955 |   0.73789   0.81544   0.81764   0.81535 |   11.0494   3.8673e-02   1.6323e-04    11.0882 |  12.0 |\n",
      "  201 |   4.22e-04   4.22e-04   5.62e-03  3.117e+00 |    1.2647   3.8714e-02   1.6241e-04    1.3036 |   0.72758   0.81439   0.81764   0.81429 |   10.8799   3.8732e-02   2.4608e-04    10.9189 |   9.9 |\n",
      "  202 |   4.22e-04   4.22e-04   5.62e-03  3.117e+00 |    1.5423   3.8732e-02   2.4608e-04    1.5813 |   0.74461   0.81364   0.81763   0.81353 |   11.1192   3.8732e-02   2.4608e-04    11.1582 |  13.3 |\n",
      "  202 |   4.22e-04   4.22e-04   5.62e-03  3.117e+00 |    1.9314   4.0772e-02   1.5797e-04    1.9723 |   0.78287   0.81329   0.81671   0.81319 |   11.7228   4.0792e-02   2.1019e-04    11.7638 |  12.2 |\n",
      "  203 |   4.22e-04   4.22e-04   5.62e-03  3.117e+00 |    1.6855   4.0792e-02   2.1019e-04    1.7265 |   0.74386   0.81515   0.81805   0.81503 |   11.1463   4.0792e-02   2.1019e-04    11.1873 |  11.8 |\n",
      "  203 |   4.22e-04   4.22e-04   5.62e-03  3.117e+00 |    1.0320   4.1391e-02   1.0448e-04    1.0735 |   0.76394   0.81230   0.81636   0.81220 |   11.4748   4.1384e-02   8.9217e-05    11.5163 |  12.5 |\n",
      " decay gumbel softmax to 3.008004613935899\n",
      "  204 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.3109   4.1384e-02   8.9217e-05    1.3524 |   0.74627   0.81557   0.81810   0.81546 |   11.1854   4.1384e-02   8.9217e-05    11.2268 |  12.1 |\n",
      "  204 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.2113   4.1830e-02   1.7356e-04    1.2533 |   0.74565   0.81559   0.81780   0.81550 |   11.1890   4.1827e-02   1.5021e-04    11.2310 |  12.8 |\n",
      "  205 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.5398   4.1827e-02   1.5021e-04    1.5818 |   0.75329   0.81669   0.81850   0.81659 |   11.2650   4.1827e-02   1.5021e-04    11.3069 |  13.1 |\n",
      "  205 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.1705   4.2570e-02   1.7902e-04    1.2132 |   0.76608   0.81376   0.81731   0.81365 |   11.4821   4.2580e-02   2.0122e-04    11.5249 |  13.3 |\n",
      "\n",
      "[e] Policy training epoch:205  it:35175 -  Total Loss: 11.5249     \n",
      "Task: 11.4821   Sparsity: 4.25804e-02    Sharing: 2.01220e-04 \n",
      "\n",
      " epch: 205   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1501    0.8499  0    0.1586    0.8414  0    0.1639    0.8361  0\n",
      "   2    0.7943    0.2057  1    0.7172    0.2828  1    0.6440    0.3560  1\n",
      "   3    0.8097    0.1903  1    0.6970    0.3030  1    0.6541    0.3459  1\n",
      "   4    0.4140    0.5860  0    0.5344    0.4656  1    0.5590    0.4410  1\n",
      "   5    0.2297    0.7703  0    0.3818    0.6182  0    0.3418    0.6582  0\n",
      "   6    0.2817    0.7183  0    0.3386    0.6614  0    0.3596    0.6404  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  206 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.3006   4.2580e-02   2.0122e-04    1.3434 |   0.75573   0.81462   0.81742   0.81451 |   11.3680   4.2580e-02   2.0122e-04    11.4107 |  14.0 |\n",
      "  206 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.6248   4.2854e-02   1.5867e-04    1.6678 |   0.73696   0.81681   0.81861   0.81672 |   11.0859   4.2884e-02   2.3258e-04    11.1291 |  11.3 |\n",
      "  207 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.4455   4.2884e-02   2.3258e-04    1.4887 |   0.75217   0.81569   0.81907   0.81557 |   11.2825   4.2884e-02   2.3258e-04    11.3256 |  13.8 |\n",
      "  207 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    0.9381   4.2009e-02   2.1155e-04    0.9803 |   0.76822   0.81654   0.81841   0.81645 |   11.5481   4.2001e-02   1.9884e-04    11.5903 |  11.5 |\n",
      "  208 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.3915   4.2001e-02   1.9884e-04    1.4337 |   0.72767   0.81707   0.81934   0.81699 |   10.9305   4.2001e-02   1.9884e-04    10.9727 |  12.6 |\n",
      "  208 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.7977   4.0789e-02   2.2391e-04    1.8387 |   0.76034   0.81512   0.81846   0.81499 |   11.4553   4.0761e-02   1.3364e-04    11.4962 |  10.2 |\n",
      "  209 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.0631   4.0761e-02   1.3364e-04    1.1040 |   0.76041   0.81532   0.81839   0.81523 |   11.4059   4.0761e-02   1.3364e-04    11.4468 |  12.4 |\n",
      "  209 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.7554   4.0243e-02   1.7670e-04    1.7958 |   0.74702   0.81529   0.81844   0.81518 |   11.2412   4.0231e-02   2.0968e-04    11.2817 |  10.6 |\n",
      "  210 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.2982   4.0231e-02   2.0968e-04    1.3386 |   0.75287   0.81514   0.81823   0.81504 |   11.2582   4.0231e-02   2.0968e-04    11.2986 |  12.3 |\n",
      "  210 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.4186   4.1522e-02   1.9238e-04    1.4603 |   0.75124   0.81494   0.81775   0.81484 |   11.2047   4.1519e-02   2.1089e-04    11.2464 |  10.6 |\n",
      "\n",
      "[e] Policy training epoch:210  it:36225 -  Total Loss: 11.2464     \n",
      "Task: 11.2047   Sparsity: 4.15193e-02    Sharing: 2.10889e-04 \n",
      "\n",
      " epch: 210   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1467    0.8533  0    0.1661    0.8339  0    0.1584    0.8416  0\n",
      "   2    0.7784    0.2216  1    0.6870    0.3130  1    0.6311    0.3689  1\n",
      "   3    0.8162    0.1838  1    0.7018    0.2982  1    0.6436    0.3564  1\n",
      "   4    0.4181    0.5819  0    0.5058    0.4942  1    0.5481    0.4519  1\n",
      "   5    0.2279    0.7721  0    0.3876    0.6124  0    0.3090    0.6910  0\n",
      "   6    0.3015    0.6985  0    0.3342    0.6658  0    0.3411    0.6589  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  211 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.3150   4.1519e-02   2.1089e-04    1.3568 |   0.76855   0.81643   0.81858   0.81634 |   11.5343   4.1519e-02   2.1089e-04    11.5760 |  11.7 |\n",
      "  211 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.5225   4.1103e-02   1.9541e-04    1.5638 |   0.76352   0.81310   0.81637   0.81300 |   11.4721   4.1109e-02   2.5867e-04    11.5135 |  10.6 |\n",
      "  212 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.2241   4.1109e-02   2.5867e-04    1.2655 |   0.74979   0.81708   0.81903   0.81697 |   11.3270   4.1109e-02   2.5867e-04    11.3683 |  12.2 |\n",
      "  212 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.3786   3.9826e-02   2.0192e-04    1.4187 |   0.74637   0.81399   0.81714   0.81390 |   11.1798   3.9790e-02   1.9073e-04    11.2198 |  11.2 |\n",
      "  213 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.1705   3.9790e-02   1.9073e-04    1.2105 |   0.74769   0.81451   0.81791   0.81440 |   11.2108   3.9790e-02   1.9073e-04    11.2508 |  11.1 |\n",
      "  213 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.1058   4.1412e-02   2.5700e-04    1.1475 |   0.77293   0.81680   0.81861   0.81671 |   11.6136   4.1419e-02   1.7405e-04    11.6552 |  10.0 |\n",
      "  214 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.5946   4.1419e-02   1.7405e-04    1.6362 |   0.75929   0.81470   0.81791   0.81460 |   11.3707   4.1419e-02   1.7405e-04    11.4123 |  11.8 |\n",
      "  214 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    0.8985   4.2240e-02   2.0032e-04    0.9410 |   0.77790   0.81379   0.81675   0.81368 |   11.6802   4.2233e-02   1.6102e-04    11.7226 |  10.2 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  215 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.3631   4.2233e-02   1.6102e-04    1.4055 |   0.75782   0.81630   0.81881   0.81621 |   11.3832   4.2233e-02   1.6102e-04    11.4256 |  12.3 |\n",
      "  215 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.3013   4.1847e-02   1.8554e-04    1.3433 |   0.78512   0.81399   0.81765   0.81386 |   11.7575   4.1841e-02   2.1063e-04    11.7996 |  11.3 |\n",
      "\n",
      "[e] Policy training epoch:215  it:37275 -  Total Loss: 11.7996     \n",
      "Task: 11.7575   Sparsity: 4.18410e-02    Sharing: 2.10629e-04 \n",
      "\n",
      " epch: 215   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1528    0.8472  0    0.1625    0.8375  0    0.1570    0.8430  0\n",
      "   2    0.7492    0.2508  1    0.6817    0.3183  1    0.6153    0.3847  1\n",
      "   3    0.8219    0.1781  1    0.7077    0.2923  1    0.6777    0.3223  1\n",
      "   4    0.4187    0.5813  0    0.4846    0.5154  0    0.5642    0.4358  1\n",
      "   5    0.2599    0.7401  0    0.3674    0.6326  0    0.3438    0.6562  0\n",
      "   6    0.3331    0.6669  0    0.3138    0.6862  0    0.3749    0.6251  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  216 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.3778   4.1841e-02   2.1063e-04    1.4199 |   0.77245   0.81434   0.81831   0.81423 |   11.5520   4.1841e-02   2.1063e-04    11.5941 |  11.7 |\n",
      "  216 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.3517   4.2827e-02   1.5809e-04    1.3947 |   0.79158   0.81514   0.81704   0.81504 |   11.8984   4.2857e-02   1.8404e-04    11.9414 |  10.2 |\n",
      "  217 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.4139   4.2857e-02   1.8404e-04    1.4569 |   0.77527   0.81452   0.81804   0.81441 |   11.5801   4.2857e-02   1.8404e-04    11.6231 |  11.8 |\n",
      "  217 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.2740   4.2188e-02   2.1278e-04    1.3164 |   0.78051   0.81426   0.81713   0.81415 |   11.6917   4.2168e-02   2.2578e-04    11.7341 |  10.4 |\n",
      "  218 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.4007   4.2168e-02   2.2578e-04    1.4431 |   0.76692   0.81559   0.81867   0.81548 |   11.4977   4.2168e-02   2.2578e-04    11.5401 |  11.9 |\n",
      "  218 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.1292   4.1655e-02   1.3166e-04    1.1710 |   0.77665   0.81421   0.81696   0.81410 |   11.6133   4.1652e-02   1.5835e-04    11.6551 |   9.9 |\n",
      "  219 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.5617   4.1652e-02   1.5835e-04    1.6035 |   0.77735   0.81351   0.81755   0.81340 |   11.6649   4.1652e-02   1.5835e-04    11.7067 |  11.6 |\n",
      "  219 |   4.22e-04   4.22e-04   5.62e-03  3.008e+00 |    1.0968   4.1787e-02   1.4651e-04    1.1387 |   0.77234   0.81553   0.81804   0.81542 |   11.5696   4.1817e-02   1.7599e-04    11.6116 |  10.6 |\n",
      " decay gumbel softmax to 2.9027244524481426\n",
      "  220 |   4.22e-04   4.22e-04   5.62e-03  2.903e+00 |    1.4324   4.1817e-02   1.7599e-04    1.4744 |   0.77280   0.81364   0.81687   0.81352 |   11.5920   4.1817e-02   1.7599e-04    11.6340 |  12.4 |\n",
      "  220 |   4.22e-04   4.22e-04   5.62e-03  2.903e+00 |    1.3293   4.3449e-02   1.7004e-04    1.3729 |   0.79269   0.81523   0.81756   0.81513 |   11.9123   4.3444e-02   1.8418e-04    11.9559 |  10.8 |\n",
      "\n",
      "[e] Policy training epoch:220  it:38325 -  Total Loss: 11.9559     \n",
      "Task: 11.9123   Sparsity: 4.34438e-02    Sharing: 1.84177e-04 \n",
      "\n",
      " epch: 220   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1683    0.8317  0    0.1722    0.8278  0    0.1717    0.8283  0\n",
      "   2    0.7675    0.2325  1    0.7130    0.2870  1    0.6166    0.3834  1\n",
      "   3    0.8389    0.1611  1    0.7174    0.2826  1    0.6530    0.3470  1\n",
      "   4    0.4059    0.5941  0    0.5470    0.4530  1    0.5902    0.4098  1\n",
      "   5    0.2498    0.7502  0    0.3668    0.6332  0    0.3510    0.6490  0\n",
      "   6    0.3222    0.6778  0    0.3426    0.6574  0    0.3735    0.6265  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  221 |   4.22e-04   4.22e-04   5.62e-03  2.903e+00 |    0.8297   4.3444e-02   1.8418e-04    0.8734 |   0.79980   0.81508   0.81763   0.81496 |   11.9696   4.3444e-02   1.8418e-04    12.0132 |  12.3 |\n",
      "  221 |   4.22e-04   4.22e-04   5.62e-03  2.903e+00 |    1.0459   4.2712e-02   1.5482e-04    1.0888 |   0.77910   0.81528   0.81743   0.81519 |   11.7021   4.2693e-02   1.5807e-04    11.7449 |  10.2 |\n",
      "  222 |   4.22e-04   4.22e-04   5.62e-03  2.903e+00 |    1.3508   4.2693e-02   1.5807e-04    1.3937 |   0.76790   0.81523   0.81794   0.81512 |   11.4733   4.2693e-02   1.5807e-04    11.5162 |  11.9 |\n",
      "  222 |   4.22e-04   4.22e-04   5.62e-03  2.903e+00 |    1.6724   4.3278e-02   2.3978e-04    1.7159 |   0.77601   0.81450   0.81753   0.81439 |   11.6231   4.3248e-02   2.4097e-04    11.6666 |  10.2 |\n",
      "  223 |   4.22e-04   4.22e-04   5.62e-03  2.903e+00 |    1.5565   4.3248e-02   2.4097e-04    1.6000 |   0.78460   0.81577   0.81805   0.81568 |   11.7294   4.3248e-02   2.4097e-04    11.7729 |  11.8 |\n",
      "  223 |   4.22e-04   4.22e-04   5.62e-03  2.903e+00 |    1.5108   4.3775e-02   1.2681e-04    1.5547 |   0.80367   0.81490   0.81736   0.81480 |   12.0315   4.3764e-02   1.8049e-04    12.0754 |  10.7 |\n",
      "  224 |   4.22e-04   4.22e-04   5.62e-03  2.903e+00 |    1.3075   4.3764e-02   1.8049e-04    1.3514 |   0.77949   0.81585   0.81814   0.81575 |   11.7131   4.3764e-02   1.8049e-04    11.7570 |  11.9 |\n",
      "  224 |   4.22e-04   4.22e-04   5.62e-03  2.903e+00 |    1.1415   4.3735e-02   1.5209e-04    1.1854 |   0.77748   0.81459   0.81767   0.81447 |   11.6337   4.3755e-02   2.1163e-04    11.6777 |  10.1 |\n",
      "  225 |   4.22e-04   4.22e-04   5.62e-03  2.903e+00 |    1.6112   4.3755e-02   2.1163e-04    1.6551 |   0.77725   0.81761   0.81891   0.81751 |   11.6477   4.3755e-02   2.1163e-04    11.6917 |  11.7 |\n",
      "  225 |   4.22e-04   4.22e-04   5.62e-03  2.903e+00 |    1.1928   4.3001e-02   1.6364e-04    1.2360 |   0.78318   0.81490   0.81871   0.81478 |   11.8447   4.3012e-02   1.7441e-04    11.8879 |  10.6 |\n",
      "\n",
      "[e] Policy training epoch:225  it:39375 -  Total Loss: 11.8879     \n",
      "Task: 11.8447   Sparsity: 4.30116e-02    Sharing: 1.74408e-04 \n",
      "\n",
      " epch: 225   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1442    0.8558  0    0.1625    0.8375  0    0.1617    0.8383  0\n",
      "   2    0.7660    0.2340  1    0.7000    0.3000  1    0.5907    0.4093  1\n",
      "   3    0.8321    0.1679  1    0.7113    0.2887  1    0.6363    0.3637  1\n",
      "   4    0.4537    0.5463  0    0.5498    0.4502  1    0.5616    0.4384  1\n",
      "   5    0.2655    0.7345  0    0.4371    0.5629  0    0.3545    0.6455  0\n",
      "   6    0.3615    0.6385  0    0.3173    0.6827  0    0.3480    0.6520  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  226 |   4.22e-04   4.22e-04   4.22e-03  2.903e+00 |    1.0594   4.3012e-02   1.7441e-04    1.1026 |   0.79017   0.81467   0.81771   0.81456 |   11.8385   4.3012e-02   1.7441e-04    11.8817 |  11.9 |\n",
      "  226 |   4.22e-04   4.22e-04   4.22e-03  2.903e+00 |    1.4854   4.2606e-02   1.9571e-04    1.5282 |   0.76763   0.81681   0.81869   0.81671 |   11.5548   4.2617e-02   2.0385e-04    11.5976 |  10.5 |\n",
      "  227 |   4.22e-04   4.22e-04   4.22e-03  2.903e+00 |    1.3973   4.2617e-02   2.0385e-04    1.4402 |   0.78741   0.81566   0.81780   0.81557 |   11.7684   4.2617e-02   2.0385e-04    11.8112 |  11.7 |\n",
      "  227 |   4.22e-04   4.22e-04   4.22e-03  2.903e+00 |    1.0949   4.2874e-02   1.4147e-04    1.1379 |   0.78633   0.81430   0.81801   0.81419 |   11.7898   4.2882e-02   1.2794e-04    11.8328 |  11.7 |\n",
      "  228 |   4.22e-04   4.22e-04   4.22e-03  2.903e+00 |    1.4851   4.2882e-02   1.2794e-04    1.5281 |   0.76466   0.81663   0.81925   0.81653 |   11.4816   4.2882e-02   1.2794e-04    11.5246 |  12.9 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  228 |   4.22e-04   4.22e-04   4.22e-03  2.903e+00 |    0.8637   4.2895e-02   8.8387e-05    0.9067 |   0.79459   0.81484   0.81789   0.81474 |   11.8592   4.2883e-02   7.6284e-05    11.9022 |  10.2 |\n",
      "  229 |   4.22e-04   4.22e-04   4.22e-03  2.903e+00 |    1.1089   4.2883e-02   7.6284e-05    1.1519 |   0.76352   0.81580   0.81828   0.81570 |   11.4181   4.2883e-02   7.6284e-05    11.4611 |  12.0 |\n",
      "  229 |   4.22e-04   4.22e-04   4.22e-03  2.903e+00 |    1.0978   4.2491e-02   1.1286e-04    1.1404 |   0.77165   0.81569   0.81855   0.81559 |   11.5788   4.2504e-02   1.4889e-04    11.6215 |  10.7 |\n",
      "  230 |   4.22e-04   4.22e-04   4.22e-03  2.903e+00 |    1.2092   4.2504e-02   1.4889e-04    1.2519 |   0.77727   0.81420   0.81710   0.81408 |   11.6253   4.2504e-02   1.4889e-04    11.6680 |  11.5 |\n",
      "  230 |   4.22e-04   4.22e-04   4.22e-03  2.903e+00 |    1.3824   4.2975e-02   1.8721e-04    1.4255 |   0.79653   0.81651   0.81844   0.81639 |   12.0055   4.2971e-02   1.9572e-04    12.0487 |  10.3 |\n",
      "\n",
      "[e] Policy training epoch:230  it:40425 -  Total Loss: 12.0487     \n",
      "Task: 12.0055   Sparsity: 4.29712e-02    Sharing: 1.95717e-04 \n",
      "\n",
      " epch: 230   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1504    0.8496  0    0.1793    0.8207  0    0.1657    0.8343  0\n",
      "   2    0.7545    0.2455  1    0.6827    0.3173  1    0.6330    0.3670  1\n",
      "   3    0.8210    0.1790  1    0.7025    0.2975  1    0.6557    0.3443  1\n",
      "   4    0.4239    0.5761  0    0.5644    0.4356  1    0.5878    0.4122  1\n",
      "   5    0.2571    0.7429  0    0.4226    0.5774  0    0.3340    0.6660  0\n",
      "   6    0.3271    0.6729  0    0.3412    0.6588  0    0.3693    0.6307  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  231 |   4.22e-04   4.22e-04   4.22e-03  2.903e+00 |    1.1883   4.2971e-02   1.9572e-04    1.2314 |   0.75644   0.81647   0.81867   0.81637 |   11.3915   4.2971e-02   1.9572e-04    11.4346 |  12.4 |\n",
      "  231 |   4.22e-04   4.22e-04   4.22e-03  2.903e+00 |    1.2567   4.1855e-02   1.4962e-04    1.2987 |   0.77615   0.81539   0.81791   0.81530 |   11.6316   4.1849e-02   1.2822e-04    11.6735 |  10.7 |\n",
      "  232 |   4.22e-04   4.22e-04   4.22e-03  2.903e+00 |    1.0574   4.1849e-02   1.2822e-04    1.0994 |   0.77995   0.81511   0.81801   0.81501 |   11.6996   4.1849e-02   1.2822e-04    11.7415 |  12.0 |\n",
      "Epoch   232: reducing learning rate of group 0 to 3.1641e-04.\n",
      "Epoch   232: reducing learning rate of group 1 to 3.1641e-04.\n",
      "  232 |   3.16e-04   3.16e-04   4.22e-03  2.903e+00 |    0.9233   4.2520e-02   1.3174e-04    0.9660 |   0.76951   0.81663   0.81848   0.81653 |   11.5471   4.2519e-02   1.5815e-04    11.5898 |  10.5 |\n",
      "  233 |   3.16e-04   3.16e-04   4.22e-03  2.903e+00 |    1.1819   4.2519e-02   1.5815e-04    1.2246 |   0.79158   0.81510   0.81758   0.81499 |   11.8498   4.2519e-02   1.5815e-04    11.8924 |  12.0 |\n",
      "  233 |   3.16e-04   3.16e-04   4.22e-03  2.903e+00 |    1.5275   4.3571e-02   1.0655e-04    1.5712 |   0.81029   0.81413   0.81755   0.81403 |   12.1251   4.3588e-02   1.5540e-04    12.1689 |  10.8 |\n",
      "  234 |   3.16e-04   3.16e-04   4.22e-03  2.903e+00 |    1.2831   4.3588e-02   1.5540e-04    1.3268 |   0.78968   0.81529   0.81722   0.81519 |   11.9262   4.3588e-02   1.5540e-04    11.9700 |  12.1 |\n",
      "  234 |   3.16e-04   3.16e-04   4.22e-03  2.903e+00 |    1.3448   4.3645e-02   1.5954e-04    1.3886 |   0.79912   0.81460   0.81801   0.81450 |   12.0424   4.3630e-02   1.5522e-04    12.0862 |  10.6 |\n",
      "  235 |   3.16e-04   3.16e-04   4.22e-03  2.903e+00 |    1.1454   4.3630e-02   1.5522e-04    1.1892 |   0.77863   0.81575   0.81814   0.81566 |   11.6709   4.3630e-02   1.5522e-04    11.7147 |  11.9 |\n",
      "  235 |   3.16e-04   3.16e-04   4.22e-03  2.903e+00 |    1.0807   4.4086e-02   5.3070e-05    1.1249 |   0.77901   0.81655   0.81869   0.81644 |   11.6826   4.4106e-02   1.0399e-04    11.7268 |  10.8 |\n",
      " decay gumbel softmax to 2.8011290966124576\n",
      "\n",
      "[e] Policy training epoch:235  it:41475 -  Total Loss: 11.7268     \n",
      "Task: 11.6826   Sparsity: 4.41065e-02    Sharing: 1.03990e-04 \n",
      "\n",
      " epch: 235   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1479    0.8521  0    0.1808    0.8192  0    0.1740    0.8260  0\n",
      "   2    0.7662    0.2338  1    0.6999    0.3001  1    0.6219    0.3781  1\n",
      "   3    0.8239    0.1761  1    0.6979    0.3021  1    0.6651    0.3349  1\n",
      "   4    0.4402    0.5598  0    0.5664    0.4336  1    0.5988    0.4012  1\n",
      "   5    0.2484    0.7516  0    0.4418    0.5582  0    0.3827    0.6173  0\n",
      "   6    0.3433    0.6567  0    0.3628    0.6372  0    0.3767    0.6233  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  236 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.0626   4.4106e-02   1.0399e-04    1.1069 |   0.79061   0.81492   0.81805   0.81483 |   11.8999   4.4106e-02   1.0399e-04    11.9441 |  13.8 |\n",
      "  236 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.0050   4.3860e-02   1.6968e-04    1.0491 |   0.79247   0.81452   0.81754   0.81443 |   11.8913   4.3844e-02   1.3933e-04    11.9353 |  12.1 |\n",
      "  237 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.1038   4.3844e-02   1.3933e-04    1.1477 |   0.78654   0.81482   0.81732   0.81472 |   11.7797   4.3844e-02   1.3933e-04    11.8237 |  13.0 |\n",
      "  237 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.0504   4.3618e-02   1.4496e-04    1.0942 |   0.79408   0.81380   0.81716   0.81369 |   11.9545   4.3600e-02   1.8010e-04    11.9983 |  10.9 |\n",
      "  238 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.5621   4.3600e-02   1.8010e-04    1.6059 |   0.79873   0.81479   0.81802   0.81470 |   11.9529   4.3600e-02   1.8010e-04    11.9967 |  12.4 |\n",
      "  238 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.3606   4.3793e-02   1.5403e-04    1.4045 |   0.79465   0.81596   0.81830   0.81585 |   11.9379   4.3782e-02   1.2789e-04    11.9818 |  11.5 |\n",
      "  239 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.2040   4.3782e-02   1.2789e-04    1.2479 |   0.78300   0.81429   0.81742   0.81419 |   11.7143   4.3782e-02   1.2789e-04    11.7582 |  11.9 |\n",
      "  239 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.5075   4.3633e-02   1.4284e-04    1.5513 |   0.79196   0.81554   0.81848   0.81544 |   11.8553   4.3632e-02   1.4579e-04    11.8990 |  11.4 |\n",
      "  240 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    0.8454   4.3632e-02   1.4579e-04    0.8891 |   0.78975   0.81595   0.81823   0.81586 |   11.8119   4.3632e-02   1.4579e-04    11.8557 |  12.2 |\n",
      "  240 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.1988   4.3007e-02   1.3459e-04    1.2419 |   0.76074   0.81492   0.81815   0.81481 |   11.4406   4.3006e-02   1.2408e-04    11.4837 |  10.3 |\n",
      "\n",
      "[e] Policy training epoch:240  it:42525 -  Total Loss: 11.4837     \n",
      "Task: 11.4406   Sparsity: 4.30058e-02    Sharing: 1.24076e-04 \n",
      "\n",
      " epch: 240   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1545    0.8455  0    0.1840    0.8160  0    0.1802    0.8198  0\n",
      "   2    0.7694    0.2306  1    0.6874    0.3126  1    0.6237    0.3763  1\n",
      "   3    0.8121    0.1879  1    0.6781    0.3219  1    0.6444    0.3556  1\n",
      "   4    0.4538    0.5462  0    0.5592    0.4408  1    0.5662    0.4338  1\n",
      "   5    0.2319    0.7681  0    0.4270    0.5730  0    0.3664    0.6336  0\n",
      "   6    0.3385    0.6615  0    0.3596    0.6404  0    0.3873    0.6127  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  241 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.3539   4.3006e-02   1.2408e-04    1.3970 |   0.77587   0.81493   0.81820   0.81483 |   11.6338   4.3006e-02   1.2408e-04    11.6769 |  14.3 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  241 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    0.8267   4.2967e-02   1.3918e-04    0.8698 |   0.80057   0.81559   0.81822   0.81549 |   12.0208   4.2961e-02   1.7167e-04    12.0640 |  10.8 |\n",
      "  242 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.0138   4.2961e-02   1.7167e-04    1.0569 |   0.78315   0.81456   0.81776   0.81443 |   11.7588   4.2961e-02   1.7167e-04    11.8019 |  12.2 |\n",
      "  242 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    0.9942   4.3042e-02   1.4200e-04    1.0374 |   0.77396   0.81571   0.81884   0.81562 |   11.6145   4.3038e-02   1.5484e-04    11.6577 |  10.5 |\n",
      "  243 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.4627   4.3038e-02   1.5484e-04    1.5059 |   0.80558   0.81530   0.81808   0.81519 |   12.0410   4.3038e-02   1.5484e-04    12.0842 |  11.8 |\n",
      "  243 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.1254   4.3821e-02   1.0224e-04    1.1693 |   0.80373   0.81576   0.81791   0.81567 |   12.0476   4.3828e-02   9.7723e-05    12.0915 |  10.9 |\n",
      "  244 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.1979   4.3828e-02   9.7723e-05    1.2418 |   0.78203   0.81670   0.81878   0.81659 |   11.7119   4.3828e-02   9.7723e-05    11.7558 |  12.2 |\n",
      "  244 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    0.9966   4.3849e-02   8.4461e-05    1.0405 |   0.78878   0.81550   0.81771   0.81539 |   11.8413   4.3851e-02   1.2372e-04    11.8853 |  11.0 |\n",
      "  245 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    0.9123   4.3851e-02   1.2372e-04    0.9563 |   0.79511   0.81500   0.81832   0.81490 |   11.9224   4.3851e-02   1.2372e-04    11.9663 |  13.9 |\n",
      "  245 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.1898   4.3719e-02   1.2959e-04    1.2336 |   0.78803   0.81618   0.81816   0.81608 |   11.8104   4.3723e-02   1.3514e-04    11.8542 |  11.5 |\n",
      "\n",
      "[e] Policy training epoch:245  it:43575 -  Total Loss: 11.8542     \n",
      "Task: 11.8104   Sparsity: 4.37234e-02    Sharing: 1.35139e-04 \n",
      "\n",
      " epch: 245   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1507    0.8493  0    0.1708    0.8292  0    0.1621    0.8379  0\n",
      "   2    0.7943    0.2057  1    0.6979    0.3021  1    0.6301    0.3699  1\n",
      "   3    0.8244    0.1756  1    0.6898    0.3102  1    0.6632    0.3368  1\n",
      "   4    0.4491    0.5509  0    0.5423    0.4577  1    0.6029    0.3971  1\n",
      "   5    0.2276    0.7724  0    0.3957    0.6043  0    0.3703    0.6297  0\n",
      "   6    0.3152    0.6848  0    0.3474    0.6526  0    0.3857    0.6143  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  246 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    0.9485   4.3723e-02   1.3514e-04    0.9924 |   0.80179   0.81481   0.81765   0.81471 |   12.0390   4.3723e-02   1.3514e-04    12.0828 |  13.5 |\n",
      "  246 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.2172   4.3806e-02   1.1429e-04    1.2611 |   0.80496   0.81608   0.81782   0.81597 |   12.1498   4.3845e-02   1.4782e-04    12.1938 |  11.0 |\n",
      "  247 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.2801   4.3845e-02   1.4782e-04    1.3241 |   0.79956   0.81549   0.81820   0.81540 |   12.0769   4.3845e-02   1.4782e-04    12.1209 |  12.5 |\n",
      "  247 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.3124   4.4549e-02   1.6541e-04    1.3571 |   0.78259   0.81688   0.81882   0.81678 |   11.7980   4.4528e-02   1.9194e-04    11.8427 |  10.6 |\n",
      "  248 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.3971   4.4528e-02   1.9194e-04    1.4418 |   0.77536   0.81688   0.81809   0.81679 |   11.6265   4.4528e-02   1.9194e-04    11.6713 |  12.6 |\n",
      "  248 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.3927   4.4367e-02   1.0809e-04    1.4372 |   0.79955   0.81576   0.81793   0.81567 |   11.9784   4.4367e-02   1.0684e-04    12.0229 |  11.1 |\n",
      "  249 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.1901   4.4367e-02   1.0684e-04    1.2346 |   0.81001   0.81464   0.81736   0.81454 |   12.1060   4.4367e-02   1.0684e-04    12.1505 |  12.1 |\n",
      "  249 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.1562   4.3419e-02   9.9223e-05    1.1997 |   0.81016   0.81366   0.81678   0.81356 |   12.1909   4.3388e-02   1.2238e-04    12.2344 |  10.8 |\n",
      "  250 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.0318   4.3388e-02   1.2238e-04    1.0753 |   0.80930   0.81357   0.81726   0.81345 |   12.1149   4.3388e-02   1.2238e-04    12.1584 |  11.8 |\n",
      "  250 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    0.9110   4.2603e-02   1.6961e-04    0.9538 |   0.81730   0.81293   0.81588   0.81282 |   12.2379   4.2610e-02   1.3336e-04    12.2807 |  10.7 |\n",
      "\n",
      "[e] Policy training epoch:250  it:44625 -  Total Loss: 12.2807     \n",
      "Task: 12.2379   Sparsity: 4.26102e-02    Sharing: 1.33363e-04 \n",
      "\n",
      " epch: 250   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1478    0.8522  0    0.1777    0.8223  0    0.1646    0.8354  0\n",
      "   2    0.7615    0.2385  1    0.6815    0.3185  1    0.6281    0.3719  1\n",
      "   3    0.8162    0.1838  1    0.7020    0.2980  1    0.6549    0.3451  1\n",
      "   4    0.4305    0.5695  0    0.5265    0.4735  1    0.5982    0.4018  1\n",
      "   5    0.2639    0.7361  0    0.4011    0.5989  0    0.3589    0.6411  0\n",
      "   6    0.3299    0.6701  0    0.3150    0.6850  0    0.3611    0.6389  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  251 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    0.9806   4.2610e-02   1.3336e-04    1.0233 |   0.80124   0.81427   0.81705   0.81418 |   12.0208   4.2610e-02   1.3336e-04    12.0636 |  12.9 |\n",
      "  251 |   3.16e-04   3.16e-04   4.22e-03  2.801e+00 |    1.1986   4.2814e-02   1.4036e-04    1.2416 |   0.80963   0.81596   0.81852   0.81585 |   12.1654   4.2830e-02   1.5590e-04    12.2084 |  10.9 |\n",
      " decay gumbel softmax to 2.7030895782310216\n",
      "  252 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    0.9972   4.2830e-02   1.5590e-04    1.0401 |   0.78923   0.81578   0.81834   0.81569 |   11.8158   4.2830e-02   1.5590e-04    11.8587 |  13.0 |\n",
      "  252 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    0.9688   4.2528e-02   1.3292e-04    1.0114 |   0.78318   0.81387   0.81759   0.81377 |   11.8245   4.2534e-02   1.2290e-04    11.8672 |  10.3 |\n",
      "  253 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    0.9296   4.2534e-02   1.2290e-04    0.9722 |   0.81489   0.81513   0.81777   0.81502 |   12.2071   4.2534e-02   1.2290e-04    12.2497 |  12.4 |\n",
      "  253 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.2328   4.2284e-02   1.2079e-04    1.2752 |   0.77870   0.81407   0.81705   0.81395 |   11.6901   4.2284e-02   1.4823e-04    11.7325 |  11.7 |\n",
      "  254 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.4498   4.2284e-02   1.4823e-04    1.4922 |   0.79961   0.81630   0.81823   0.81619 |   11.9707   4.2284e-02   1.4823e-04    12.0132 |  12.1 |\n",
      "  254 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.5502   4.2475e-02   1.8595e-04    1.5929 |   0.81165   0.81361   0.81657   0.81351 |   12.1504   4.2471e-02   2.3208e-04    12.1931 |  12.1 |\n",
      "  255 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.1251   4.2471e-02   2.3208e-04    1.1678 |   0.76868   0.81452   0.81707   0.81441 |   11.5705   4.2471e-02   2.3208e-04    11.6132 |  12.1 |\n",
      "  255 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    0.8939   4.2507e-02   1.3741e-04    0.9365 |   0.78919   0.81512   0.81812   0.81501 |   11.8673   4.2513e-02   1.5793e-04    11.9099 |  10.9 |\n",
      "\n",
      "[e] Policy training epoch:255  it:45675 -  Total Loss: 11.9099     \n",
      "Task: 11.8673   Sparsity: 4.25127e-02    Sharing: 1.57931e-04 \n",
      "\n",
      " epch: 255   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1423    0.8577  0    0.1742    0.8258  0    0.1698    0.8302  0\n",
      "   2    0.7784    0.2216  1    0.7129    0.2871  1    0.6252    0.3748  1\n",
      "   3    0.8203    0.1797  1    0.6972    0.3028  1    0.6069    0.3931  1\n",
      "   4    0.4282    0.5718  0    0.5489    0.4511  1    0.5564    0.4436  1\n",
      "   5    0.2356    0.7644  0    0.4187    0.5813  0    0.3525    0.6475  0\n",
      "   6    0.3213    0.6787  0    0.3445    0.6555  0    0.3421    0.6579  0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  256 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    0.8449   4.2513e-02   1.5793e-04    0.8876 |   0.77928   0.81691   0.81858   0.81680 |   11.7135   4.2513e-02   1.5793e-04    11.7562 |  11.9 |\n",
      "  256 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.3677   4.2864e-02   1.2642e-04    1.4107 |   0.78421   0.81470   0.81795   0.81460 |   11.7818   4.2877e-02   1.3460e-04    11.8248 |  10.7 |\n",
      "  257 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.3725   4.2877e-02   1.3460e-04    1.4155 |   0.81067   0.81283   0.81581   0.81272 |   12.1666   4.2877e-02   1.3460e-04    12.2096 |  12.3 |\n",
      "  257 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.1888   4.3333e-02   1.6920e-04    1.2323 |   0.78161   0.81530   0.81743   0.81519 |   11.7129   4.3344e-02   1.5742e-04    11.7564 |  11.3 |\n",
      "  258 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.1555   4.3344e-02   1.5742e-04    1.1990 |   0.77819   0.81664   0.81817   0.81654 |   11.6555   4.3344e-02   1.5742e-04    11.6990 |  12.2 |\n",
      "  258 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.1739   4.3682e-02   1.2304e-04    1.2177 |   0.81396   0.81504   0.81717   0.81495 |   12.2410   4.3659e-02   1.4917e-04    12.2848 |  10.9 |\n",
      "  259 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.4418   4.3659e-02   1.4917e-04    1.4856 |   0.80692   0.81529   0.81756   0.81519 |   12.1117   4.3659e-02   1.4917e-04    12.1555 |  12.3 |\n",
      "  259 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.1781   4.3326e-02   1.1130e-04    1.2215 |   0.78224   0.81597   0.81789   0.81588 |   11.7113   4.3331e-02   1.5510e-04    11.7548 |  10.6 |\n",
      "  260 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.0851   4.3331e-02   1.5510e-04    1.1286 |   0.80272   0.81511   0.81776   0.81501 |   12.0287   4.3331e-02   1.5510e-04    12.0722 |  12.4 |\n",
      "  260 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.2839   4.3357e-02   1.2321e-04    1.3274 |   0.79080   0.81520   0.81789   0.81510 |   11.7922   4.3339e-02   1.8508e-04    11.8358 |  11.5 |\n",
      "\n",
      "[e] Policy training epoch:260  it:46725 -  Total Loss: 11.8358     \n",
      "Task: 11.7922   Sparsity: 4.33389e-02    Sharing: 1.85080e-04 \n",
      "\n",
      " epch: 260   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1473    0.8527  0    0.1702    0.8298  0    0.1710    0.8290  0\n",
      "   2    0.7773    0.2227  1    0.7177    0.2823  1    0.6289    0.3711  1\n",
      "   3    0.8251    0.1749  1    0.7068    0.2932  1    0.6238    0.3762  1\n",
      "   4    0.4477    0.5523  0    0.5637    0.4363  1    0.5690    0.4310  1\n",
      "   5    0.2196    0.7804  0    0.4136    0.5864  0    0.3309    0.6691  0\n",
      "   6    0.3315    0.6685  0    0.3525    0.6475  0    0.3786    0.6214  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  261 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.2235   4.3339e-02   1.8508e-04    1.2671 |   0.80526   0.81510   0.81750   0.81500 |   12.1329   4.3339e-02   1.8508e-04    12.1764 |  12.5 |\n",
      "  261 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.2471   4.3656e-02   1.3937e-04    1.2909 |   0.78960   0.81504   0.81714   0.81494 |   11.8486   4.3645e-02   1.3177e-04    11.8924 |  11.0 |\n",
      "  262 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.0815   4.3645e-02   1.3177e-04    1.1253 |   0.77553   0.81749   0.81961   0.81740 |   11.6458   4.3645e-02   1.3177e-04    11.6896 |  12.2 |\n",
      "  262 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.3108   4.3411e-02   1.1989e-04    1.3543 |   0.79790   0.81469   0.81675   0.81459 |   12.0218   4.3406e-02   1.2157e-04    12.0653 |  10.8 |\n",
      "  263 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.5700   4.3406e-02   1.2157e-04    1.6135 |   0.79654   0.81496   0.81751   0.81485 |   11.9363   4.3406e-02   1.2157e-04    11.9799 |  12.0 |\n",
      "  263 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.0157   4.3353e-02   2.0542e-04    1.0592 |   0.82593   0.81438   0.81713   0.81426 |   12.3890   4.3347e-02   2.2198e-04    12.4326 |  10.8 |\n",
      "  264 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.1915   4.3347e-02   2.2198e-04    1.2351 |   0.80585   0.81460   0.81782   0.81450 |   12.0701   4.3347e-02   2.2198e-04    12.1136 |  12.3 |\n",
      "  264 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    0.8051   4.3375e-02   1.7124e-04    0.8486 |   0.81670   0.81383   0.81748   0.81373 |   12.2503   4.3373e-02   1.6054e-04    12.2938 |  10.8 |\n",
      "  265 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.1148   4.3373e-02   1.6054e-04    1.1583 |   0.81820   0.81631   0.81736   0.81622 |   12.2369   4.3373e-02   1.6054e-04    12.2804 |  11.9 |\n",
      "  265 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.3636   4.3235e-02   1.9671e-04    1.4070 |   0.80130   0.81612   0.81912   0.81601 |   12.0714   4.3231e-02   1.6209e-04    12.1148 |  10.5 |\n",
      "\n",
      "[e] Policy training epoch:265  it:47775 -  Total Loss: 12.1148     \n",
      "Task: 12.0714   Sparsity: 4.32315e-02    Sharing: 1.62090e-04 \n",
      "\n",
      " epch: 265   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1389    0.8611  0    0.1503    0.8497  0    0.1672    0.8328  0\n",
      "   2    0.7685    0.2315  1    0.7031    0.2969  1    0.6307    0.3693  1\n",
      "   3    0.8402    0.1598  1    0.7057    0.2943  1    0.6530    0.3470  1\n",
      "   4    0.4545    0.5455  0    0.5441    0.4559  1    0.5905    0.4095  1\n",
      "   5    0.2378    0.7622  0    0.3835    0.6165  0    0.3283    0.6717  0\n",
      "   6    0.3272    0.6728  0    0.3341    0.6659  0    0.3590    0.6410  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  266 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.3196   4.3231e-02   1.6209e-04    1.3630 |   0.78774   0.81567   0.81846   0.81557 |   11.7903   4.3231e-02   1.6209e-04    11.8336 |  12.9 |\n",
      "  266 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.0021   4.4216e-02   2.2380e-04    1.0466 |   0.79840   0.81628   0.81884   0.81617 |   11.9974   4.4229e-02   2.0123e-04    12.0418 |  11.6 |\n",
      "  267 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.4537   4.4229e-02   2.0123e-04    1.4981 |   0.83212   0.81484   0.81693   0.81473 |   12.4610   4.4229e-02   2.0123e-04    12.5055 |  12.1 |\n",
      "  267 |   3.16e-04   3.16e-04   4.22e-03  2.703e+00 |    1.1551   4.4323e-02   1.3330e-04    1.1996 |   0.79260   0.81702   0.81897   0.81690 |   11.8574   4.4304e-02   1.3299e-04    11.9019 |  10.5 |\n",
      " decay gumbel softmax to 2.608481442992936\n",
      "  268 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    0.9576   4.4304e-02   1.3299e-04    1.0020 |   0.84064   0.81494   0.81772   0.81485 |   12.5974   4.4304e-02   1.3299e-04    12.6418 |  12.3 |\n",
      "  268 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    0.9950   4.3600e-02   2.1255e-04    1.0388 |   0.80609   0.81424   0.81704   0.81414 |   12.1362   4.3587e-02   1.5010e-04    12.1800 |  10.9 |\n",
      "  269 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    1.1729   4.3587e-02   1.5010e-04    1.2166 |   0.80416   0.81413   0.81755   0.81403 |   12.0257   4.3587e-02   1.5010e-04    12.0695 |  11.9 |\n",
      "  269 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    0.8110   4.2560e-02   1.3911e-04    0.8537 |   0.81220   0.81353   0.81699   0.81341 |   12.1665   4.2577e-02   1.4781e-04    12.2092 |  10.7 |\n",
      "  270 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    0.7572   4.2577e-02   1.4781e-04    0.7999 |   0.79938   0.81525   0.81719   0.81515 |   11.9948   4.2577e-02   1.4781e-04    12.0375 |  12.1 |\n",
      "  270 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    1.7381   4.3576e-02   1.1124e-04    1.7818 |   0.81586   0.81515   0.81725   0.81503 |   12.2733   4.3554e-02   1.2463e-04    12.3170 |  10.7 |\n",
      "\n",
      "[e] Policy training epoch:270  it:48825 -  Total Loss: 12.3170     \n",
      "Task: 12.2733   Sparsity: 4.35538e-02    Sharing: 1.24631e-04 \n",
      "\n",
      " epch: 270   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1450    0.8550  0    0.1719    0.8281  0    0.1693    0.8307  0\n",
      "   2    0.7628    0.2372  1    0.7085    0.2915  1    0.6014    0.3986  1\n",
      "   3    0.8374    0.1626  1    0.7322    0.2678  1    0.6243    0.3757  1\n",
      "   4    0.4432    0.5568  0    0.5534    0.4466  1    0.6000    0.4000  1\n",
      "   5    0.2381    0.7619  0    0.4246    0.5754  0    0.3418    0.6582  0\n",
      "   6    0.3211    0.6789  0    0.3556    0.6444  0    0.3642    0.6358  0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  271 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    0.9363   4.3554e-02   1.2463e-04    0.9800 |   0.81745   0.81338   0.81718   0.81326 |   12.2906   4.3554e-02   1.2463e-04    12.3343 |  11.9 |\n",
      "  271 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    1.2569   4.4423e-02   1.7043e-04    1.3015 |   0.81238   0.81573   0.81835   0.81563 |   12.1939   4.4441e-02   1.4291e-04    12.2385 |  11.4 |\n",
      "  272 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    1.2777   4.4441e-02   1.4291e-04    1.3223 |   0.81725   0.81431   0.81687   0.81421 |   12.2935   4.4441e-02   1.4291e-04    12.3381 |  12.0 |\n",
      "  272 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    1.2140   4.4415e-02   1.5816e-04    1.2586 |   0.82726   0.81361   0.81678   0.81351 |   12.4332   4.4417e-02   1.5478e-04    12.4778 |  10.6 |\n",
      "  273 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    1.2466   4.4417e-02   1.5478e-04    1.2912 |   0.80861   0.81534   0.81767   0.81524 |   12.1628   4.4417e-02   1.5478e-04    12.2074 |  11.8 |\n",
      "  273 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    1.0426   4.4348e-02   1.4863e-04    1.0871 |   0.80914   0.81346   0.81687   0.81334 |   12.1231   4.4333e-02   1.3446e-04    12.1676 |  12.5 |\n",
      "  274 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    1.0234   4.4333e-02   1.3446e-04    1.0679 |   0.82533   0.81632   0.81882   0.81621 |   12.4415   4.4333e-02   1.3446e-04    12.4860 |  12.4 |\n",
      "  274 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    0.9391   4.4306e-02   1.7314e-04    0.9836 |   0.82420   0.81527   0.81753   0.81515 |   12.3496   4.4307e-02   1.3757e-04    12.3940 |  11.6 |\n",
      "  275 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    0.8444   4.4307e-02   1.3757e-04    0.8889 |   0.80850   0.81356   0.81660   0.81347 |   12.0937   4.4307e-02   1.3757e-04    12.1382 |  12.1 |\n",
      "  275 |   3.16e-04   3.16e-04   4.22e-03  2.608e+00 |    1.0496   4.3618e-02   2.3279e-04    1.0934 |   0.80234   0.81515   0.81788   0.81505 |   12.0445   4.3618e-02   2.0644e-04    12.0883 |  10.8 |\n",
      "\n",
      "[e] Policy training epoch:275  it:49875 -  Total Loss: 12.0883     \n",
      "Task: 12.0445   Sparsity: 4.36178e-02    Sharing: 2.06437e-04 \n",
      "\n",
      " epch: 275   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1415    0.8585  0    0.1634    0.8366  0    0.1605    0.8395  0\n",
      "   2    0.7756    0.2244  1    0.7073    0.2927  1    0.6264    0.3736  1\n",
      "   3    0.8308    0.1692  1    0.7250    0.2750  1    0.6271    0.3729  1\n",
      "   4    0.4463    0.5537  0    0.5478    0.4522  1    0.5961    0.4039  1\n",
      "   5    0.2352    0.7648  0    0.4286    0.5714  0    0.3426    0.6574  0\n",
      "   6    0.3336    0.6664  0    0.3374    0.6626  0    0.3698    0.6302  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  276 |   3.16e-04   3.16e-04   3.16e-03  2.608e+00 |    1.4228   4.3618e-02   2.0644e-04    1.4666 |   0.81724   0.81494   0.81790   0.81483 |   12.2464   4.3618e-02   2.0644e-04    12.2902 |  13.0 |\n",
      "  276 |   3.16e-04   3.16e-04   3.16e-03  2.608e+00 |    1.2223   4.4446e-02   1.3572e-04    1.2669 |   0.83100   0.81437   0.81748   0.81426 |   12.4299   4.4435e-02   1.5112e-04    12.4745 |  11.4 |\n",
      "  277 |   3.16e-04   3.16e-04   3.16e-03  2.608e+00 |    1.6087   4.4435e-02   1.5112e-04    1.6533 |   0.82126   0.81601   0.81880   0.81591 |   12.3404   4.4435e-02   1.5112e-04    12.3850 |  12.9 |\n",
      "  277 |   3.16e-04   3.16e-04   3.16e-03  2.608e+00 |    1.6431   4.4099e-02   1.0470e-04    1.6873 |   0.81440   0.81487   0.81766   0.81475 |   12.2098   4.4086e-02   1.2521e-04    12.2541 |  10.7 |\n",
      "  278 |   3.16e-04   3.16e-04   3.16e-03  2.608e+00 |    0.9186   4.4086e-02   1.2521e-04    0.9628 |   0.83062   0.81730   0.81883   0.81721 |   12.4637   4.4086e-02   1.2521e-04    12.5079 |  12.7 |\n",
      "Epoch   278: reducing learning rate of group 0 to 2.3730e-04.\n",
      "Epoch   278: reducing learning rate of group 1 to 2.3730e-04.\n",
      "  278 |   2.37e-04   2.37e-04   3.16e-03  2.608e+00 |    0.9653   4.3464e-02   1.1394e-04    1.0089 |   0.79821   0.81385   0.81685   0.81375 |   11.9994   4.3446e-02   1.2215e-04    12.0429 |  11.9 |\n",
      "  279 |   2.37e-04   2.37e-04   3.16e-03  2.608e+00 |    0.9233   4.3446e-02   1.2215e-04    0.9669 |   0.80867   0.81579   0.81787   0.81568 |   12.1054   4.3446e-02   1.2215e-04    12.1489 |  12.3 |\n",
      "  279 |   2.37e-04   2.37e-04   3.16e-03  2.608e+00 |    0.8931   4.3500e-02   1.0208e-04    0.9367 |   0.82264   0.81577   0.81781   0.81567 |   12.3373   4.3521e-02   1.0944e-04    12.3809 |  11.2 |\n",
      "  280 |   2.37e-04   2.37e-04   3.16e-03  2.608e+00 |    1.0725   4.3521e-02   1.0944e-04    1.1161 |   0.79048   0.81637   0.81810   0.81628 |   11.8010   4.3521e-02   1.0944e-04    11.8447 |  14.2 |\n",
      "  280 |   2.37e-04   2.37e-04   3.16e-03  2.608e+00 |    1.1834   4.3606e-02   9.1414e-05    1.2271 |   0.81009   0.81598   0.81789   0.81587 |   12.2215   4.3595e-02   1.2792e-04    12.2652 |  11.6 |\n",
      "\n",
      "[e] Policy training epoch:280  it:50925 -  Total Loss: 12.2652     \n",
      "Task: 12.2215   Sparsity: 4.35950e-02    Sharing: 1.27921e-04 \n",
      "\n",
      " epch: 280   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1540    0.8460  0    0.1654    0.8346  0    0.1703    0.8297  0\n",
      "   2    0.7703    0.2297  1    0.6985    0.3015  1    0.6368    0.3632  1\n",
      "   3    0.8257    0.1743  1    0.7175    0.2825  1    0.6401    0.3599  1\n",
      "   4    0.4586    0.5414  0    0.5445    0.4555  1    0.5930    0.4070  1\n",
      "   5    0.2533    0.7467  0    0.4065    0.5935  0    0.3603    0.6397  0\n",
      "   6    0.3367    0.6633  0    0.3233    0.6767  0    0.3735    0.6265  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  281 |   2.37e-04   2.37e-04   3.16e-03  2.608e+00 |    1.0439   4.3595e-02   1.2792e-04    1.0877 |   0.81684   0.81304   0.81633   0.81294 |   12.3182   4.3595e-02   1.2792e-04    12.3620 |  13.0 |\n",
      "  281 |   2.37e-04   2.37e-04   3.16e-03  2.608e+00 |    0.9290   4.4450e-02   1.2223e-04    0.9736 |   0.81378   0.81473   0.81805   0.81463 |   12.1960   4.4455e-02   1.2018e-04    12.2406 |  11.1 |\n",
      "  282 |   2.37e-04   2.37e-04   3.16e-03  2.608e+00 |    1.1950   4.4455e-02   1.2018e-04    1.2396 |   0.83789   0.81412   0.81731   0.81403 |   12.5601   4.4455e-02   1.2018e-04    12.6047 |  11.7 |\n",
      "  282 |   2.37e-04   2.37e-04   3.16e-03  2.608e+00 |    0.8235   4.4151e-02   1.2096e-04    0.8678 |   0.80273   0.81500   0.81753   0.81487 |   12.0236   4.4166e-02   1.1368e-04    12.0679 |  10.7 |\n",
      "  283 |   2.37e-04   2.37e-04   3.16e-03  2.608e+00 |    0.9613   4.4166e-02   1.1368e-04    1.0056 |   0.81513   0.81504   0.81750   0.81493 |   12.2234   4.4166e-02   1.1368e-04    12.2677 |  12.1 |\n",
      "  283 |   2.37e-04   2.37e-04   3.16e-03  2.608e+00 |    0.9060   4.4337e-02   1.6119e-04    0.9505 |   0.82063   0.81573   0.81804   0.81563 |   12.3230   4.4340e-02   1.1021e-04    12.3675 |  12.5 |\n",
      " decay gumbel softmax to 2.5171845924881833\n",
      "  284 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    0.7083   4.4340e-02   1.1021e-04    0.7527 |   0.82950   0.81337   0.81729   0.81325 |   12.4171   4.4340e-02   1.1021e-04    12.4615 |  12.4 |\n",
      "  284 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.2049   4.4438e-02   1.2518e-04    1.2494 |   0.83085   0.81411   0.81638   0.81400 |   12.4148   4.4434e-02   1.3764e-04    12.4594 |  11.5 |\n",
      "  285 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.3732   4.4434e-02   1.3764e-04    1.4178 |   0.82389   0.81430   0.81757   0.81420 |   12.2965   4.4434e-02   1.3764e-04    12.3411 |  11.8 |\n",
      "  285 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    0.9970   4.4989e-02   1.6416e-04    1.0421 |   0.82363   0.81609   0.81801   0.81599 |   12.3444   4.4997e-02   1.7098e-04    12.3895 |  10.7 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[e] Policy training epoch:285  it:51975 -  Total Loss: 12.3895     \n",
      "Task: 12.3444   Sparsity: 4.49968e-02    Sharing: 1.70983e-04 \n",
      "\n",
      " epch: 285   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1560    0.8440  0    0.1653    0.8347  0    0.1738    0.8262  0\n",
      "   2    0.7916    0.2084  1    0.6981    0.3019  1    0.6493    0.3507  1\n",
      "   3    0.8457    0.1543  1    0.7140    0.2860  1    0.6494    0.3506  1\n",
      "   4    0.4764    0.5236  0    0.5638    0.4362  1    0.5815    0.4185  1\n",
      "   5    0.2660    0.7340  0    0.4203    0.5797  0    0.3524    0.6476  0\n",
      "   6    0.3575    0.6425  0    0.3366    0.6634  0    0.3852    0.6148  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  286 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    0.9471   4.4997e-02   1.7098e-04    0.9922 |   0.83235   0.81457   0.81697   0.81447 |   12.5726   4.4997e-02   1.7098e-04    12.6178 |  13.6 |\n",
      "  286 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    0.9952   4.5315e-02   1.5195e-04    1.0407 |   0.81502   0.81392   0.81644   0.81380 |   12.1838   4.5323e-02   1.5197e-04    12.2293 |  11.4 |\n",
      "  287 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.1428   4.5323e-02   1.5197e-04    1.1883 |   0.84351   0.81493   0.81814   0.81483 |   12.7249   4.5323e-02   1.5197e-04    12.7703 |  12.2 |\n",
      "  287 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.2518   4.4570e-02   1.0987e-04    1.2965 |   0.81828   0.81392   0.81725   0.81381 |   12.2679   4.4567e-02   8.2612e-05    12.3126 |  10.9 |\n",
      "  288 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.0732   4.4567e-02   8.2612e-05    1.1179 |   0.81890   0.81495   0.81783   0.81484 |   12.2689   4.4567e-02   8.2612e-05    12.3135 |  13.1 |\n",
      "  288 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.0793   4.4404e-02   1.2804e-04    1.1238 |   0.82145   0.81632   0.81771   0.81623 |   12.3550   4.4385e-02   1.2486e-04    12.3995 |  10.8 |\n",
      "  289 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.2248   4.4385e-02   1.2486e-04    1.2694 |   0.82637   0.81464   0.81722   0.81453 |   12.4043   4.4385e-02   1.2486e-04    12.4488 |  11.9 |\n",
      "  289 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.4753   4.5752e-02   1.2199e-04    1.5212 |   0.83519   0.81572   0.81817   0.81562 |   12.5821   4.5762e-02   1.3873e-04    12.6280 |  11.3 |\n",
      "  290 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    0.9139   4.5762e-02   1.3873e-04    0.9598 |   0.82087   0.81443   0.81752   0.81433 |   12.2757   4.5762e-02   1.3873e-04    12.3216 |  12.4 |\n",
      "  290 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.0439   4.6050e-02   1.6755e-04    1.0901 |   0.83634   0.81404   0.81775   0.81392 |   12.5187   4.6047e-02   1.5755e-04    12.5649 |  10.9 |\n",
      "\n",
      "[e] Policy training epoch:290  it:53025 -  Total Loss: 12.5649     \n",
      "Task: 12.5187   Sparsity: 4.60471e-02    Sharing: 1.57548e-04 \n",
      "\n",
      " epch: 290   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1477    0.8523  0    0.1645    0.8355  0    0.1707    0.8293  0\n",
      "   2    0.7975    0.2025  1    0.7160    0.2840  1    0.6609    0.3391  1\n",
      "   3    0.8509    0.1491  1    0.7394    0.2606  1    0.6662    0.3338  1\n",
      "   4    0.4729    0.5271  0    0.5662    0.4338  1    0.5986    0.4014  1\n",
      "   5    0.2568    0.7432  0    0.4221    0.5779  0    0.3363    0.6637  0\n",
      "   6    0.3675    0.6325  0    0.3408    0.6592  0    0.3855    0.6145  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  291 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.3217   4.6047e-02   1.5755e-04    1.3679 |   0.84759   0.81490   0.81728   0.81480 |   12.6823   4.6047e-02   1.5755e-04    12.7285 |  14.5 |\n",
      "  291 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.0274   4.5374e-02   8.9873e-05    1.0729 |   0.83471   0.81673   0.81828   0.81663 |   12.4706   4.5368e-02   9.6956e-05    12.5161 |  10.6 |\n",
      "  292 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    0.8692   4.5368e-02   9.6956e-05    0.9147 |   0.82027   0.81414   0.81637   0.81405 |   12.3009   4.5368e-02   9.6956e-05    12.3463 |  13.7 |\n",
      "  292 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    0.8787   4.5847e-02   1.1238e-04    0.9247 |   0.83809   0.81477   0.81761   0.81468 |   12.5633   4.5824e-02   1.0184e-04    12.6092 |  11.0 |\n",
      "  293 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.0375   4.5824e-02   1.0184e-04    1.0834 |   0.80492   0.81603   0.81802   0.81593 |   12.0757   4.5824e-02   1.0184e-04    12.1216 |  12.9 |\n",
      "  293 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.0651   4.4738e-02   1.1920e-04    1.1100 |   0.83661   0.81476   0.81743   0.81465 |   12.5724   4.4718e-02   1.4606e-04    12.6173 |  10.9 |\n",
      "  294 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.1739   4.4718e-02   1.4606e-04    1.2188 |   0.83397   0.81531   0.81754   0.81521 |   12.4888   4.4718e-02   1.4606e-04    12.5337 |  12.5 |\n",
      "  294 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    0.9359   4.4529e-02   1.1589e-04    0.9805 |   0.83926   0.81606   0.81759   0.81596 |   12.6123   4.4548e-02   1.0530e-04    12.6569 |  11.7 |\n",
      "  295 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.0657   4.4548e-02   1.0530e-04    1.1103 |   0.84856   0.81506   0.81735   0.81496 |   12.7629   4.4548e-02   1.0530e-04    12.8075 |  13.0 |\n",
      "  295 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    0.7940   4.5190e-02   6.4509e-05    0.8392 |   0.83378   0.81390   0.81713   0.81378 |   12.5144   4.5204e-02   1.0306e-04    12.5597 |  11.2 |\n",
      "\n",
      "[e] Policy training epoch:295  it:54075 -  Total Loss: 12.5597     \n",
      "Task: 12.5144   Sparsity: 4.52039e-02    Sharing: 1.03058e-04 \n",
      "\n",
      " epch: 295   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1346    0.8654  0    0.1810    0.8190  0    0.1663    0.8337  0\n",
      "   2    0.7994    0.2006  1    0.7103    0.2897  1    0.6585    0.3415  1\n",
      "   3    0.8362    0.1638  1    0.7289    0.2711  1    0.6594    0.3406  1\n",
      "   4    0.4358    0.5642  0    0.5682    0.4318  1    0.5956    0.4044  1\n",
      "   5    0.2337    0.7663  0    0.4382    0.5618  0    0.3371    0.6629  0\n",
      "   6    0.3444    0.6556  0    0.3423    0.6577  0    0.4002    0.5998  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  296 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    0.9895   4.5204e-02   1.0306e-04    1.0348 |   0.83450   0.81585   0.81763   0.81576 |   12.5014   4.5204e-02   1.0306e-04    12.5467 |  12.6 |\n",
      "  296 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    0.8954   4.4659e-02   9.2277e-05    0.9402 |   0.85610   0.81739   0.81895   0.81728 |   12.8307   4.4636e-02   1.2223e-04    12.8754 |  10.4 |\n",
      "  297 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    0.9874   4.4636e-02   1.2223e-04    1.0322 |   0.81336   0.81767   0.81883   0.81756 |   12.2193   4.4636e-02   1.2223e-04    12.2641 |  11.8 |\n",
      "  297 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.0168   4.4750e-02   1.1132e-04    1.0616 |   0.83972   0.81455   0.81701   0.81446 |   12.5536   4.4754e-02   9.0145e-05    12.5985 |  11.0 |\n",
      "  298 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    0.9120   4.4754e-02   9.0145e-05    0.9569 |   0.85068   0.81426   0.81689   0.81415 |   12.6909   4.4754e-02   9.0145e-05    12.7358 |  11.8 |\n",
      "  298 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.0823   4.4143e-02   1.1921e-04    1.1266 |   0.81431   0.81422   0.81729   0.81410 |   12.2274   4.4140e-02   1.0706e-04    12.2716 |  12.3 |\n",
      "  299 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.4250   4.4140e-02   1.0706e-04    1.4692 |   0.83690   0.81668   0.81919   0.81657 |   12.5844   4.4140e-02   1.0706e-04    12.6287 |  12.5 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  299 |   2.37e-04   2.37e-04   3.16e-03  2.517e+00 |    1.2525   4.4915e-02   1.1928e-04    1.2975 |   0.82225   0.81537   0.81775   0.81525 |   12.3681   4.4926e-02   1.2180e-04    12.4131 |  10.7 |\n",
      " decay gumbel softmax to 2.4290831317510966\n",
      "  300 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.8786   4.4926e-02   1.2180e-04    0.9236 |   0.83591   0.81444   0.81757   0.81433 |   12.5156   4.4926e-02   1.2180e-04    12.5606 |  12.3 |\n",
      "  300 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9432   4.5336e-02   1.0694e-04    0.9887 |   0.82994   0.81616   0.81846   0.81604 |   12.4635   4.5354e-02   8.2510e-05    12.5089 |  11.4 |\n",
      "\n",
      "[e] Policy training epoch:300  it:55125 -  Total Loss: 12.5089     \n",
      "Task: 12.4635   Sparsity: 4.53539e-02    Sharing: 8.25096e-05 \n",
      "\n",
      " epch: 300   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1408    0.8592  0    0.1769    0.8231  0    0.1653    0.8347  0\n",
      "   2    0.7981    0.2019  1    0.7092    0.2908  1    0.6273    0.3727  1\n",
      "   3    0.8484    0.1516  1    0.7336    0.2664  1    0.6457    0.3543  1\n",
      "   4    0.4554    0.5446  0    0.5717    0.4283  1    0.5878    0.4122  1\n",
      "   5    0.2425    0.7575  0    0.4356    0.5644  0    0.3410    0.6590  0\n",
      "   6    0.3592    0.6408  0    0.3654    0.6346  0    0.3945    0.6055  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  301 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9295   4.5354e-02   8.2510e-05    0.9749 |   0.82533   0.81538   0.81812   0.81527 |   12.4092   4.5354e-02   8.2510e-05    12.4546 |  13.0 |\n",
      "  301 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.6770   4.5017e-02   9.3244e-05    0.7221 |   0.82058   0.81509   0.81749   0.81499 |   12.3289   4.5019e-02   1.1441e-04    12.3741 |  10.7 |\n",
      "  302 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    1.1623   4.5019e-02   1.1441e-04    1.2075 |   0.83493   0.81454   0.81751   0.81443 |   12.5592   4.5019e-02   1.1441e-04    12.6043 |  12.1 |\n",
      "  302 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9551   4.4855e-02   1.2512e-04    1.0001 |   0.82721   0.81570   0.81760   0.81561 |   12.4160   4.4863e-02   1.4233e-04    12.4610 |  10.5 |\n",
      "  303 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9274   4.4863e-02   1.4233e-04    0.9725 |   0.84427   0.81490   0.81712   0.81478 |   12.6754   4.4863e-02   1.4233e-04    12.7204 |  12.9 |\n",
      "  303 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.8145   4.5495e-02   1.4073e-04    0.8602 |   0.82987   0.81568   0.81862   0.81559 |   12.4296   4.5497e-02   1.3595e-04    12.4752 |  10.9 |\n",
      "  304 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9965   4.5497e-02   1.3595e-04    1.0421 |   0.82572   0.81440   0.81738   0.81431 |   12.3615   4.5497e-02   1.3595e-04    12.4072 |  12.2 |\n",
      "  304 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9270   4.5925e-02   1.1158e-04    0.9731 |   0.82267   0.81500   0.81806   0.81489 |   12.3556   4.5914e-02   6.5262e-05    12.4016 |  10.3 |\n",
      "  305 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    1.4734   4.5914e-02   6.5262e-05    1.5194 |   0.84549   0.81357   0.81626   0.81347 |   12.7106   4.5914e-02   6.5262e-05    12.7566 |  12.0 |\n",
      "  305 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    1.0059   4.6713e-02   8.5570e-05    1.0527 |   0.79842   0.81486   0.81814   0.81474 |   12.0118   4.6732e-02   1.1038e-04    12.0587 |  10.5 |\n",
      "\n",
      "[e] Policy training epoch:305  it:56175 -  Total Loss: 12.0587     \n",
      "Task: 12.0118   Sparsity: 4.67317e-02    Sharing: 1.10383e-04 \n",
      "\n",
      " epch: 305   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1407    0.8593  0    0.1806    0.8194  0    0.1640    0.8360  0\n",
      "   2    0.7997    0.2003  1    0.7159    0.2841  1    0.6491    0.3509  1\n",
      "   3    0.8495    0.1505  1    0.7382    0.2618  1    0.6614    0.3386  1\n",
      "   4    0.4782    0.5218  0    0.5773    0.4227  1    0.6191    0.3809  1\n",
      "   5    0.2333    0.7667  0    0.4398    0.5602  0    0.3712    0.6288  0\n",
      "   6    0.3721    0.6279  0    0.3790    0.6210  0    0.4126    0.5874  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  306 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9827   4.6732e-02   1.1038e-04    1.0296 |   0.83828   0.81509   0.81742   0.81500 |   12.5760   4.6732e-02   1.1038e-04    12.6229 |  13.7 |\n",
      "  306 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9619   4.6279e-02   8.5631e-05    1.0082 |   0.81841   0.81610   0.81864   0.81600 |   12.3106   4.6275e-02   7.7792e-05    12.3569 |  11.9 |\n",
      "  307 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9594   4.6275e-02   7.7792e-05    1.0058 |   0.83936   0.81409   0.81649   0.81401 |   12.6389   4.6275e-02   7.7792e-05    12.6852 |  13.4 |\n",
      "  307 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    1.1997   4.5788e-02   1.6716e-04    1.2456 |   0.82248   0.81598   0.81797   0.81589 |   12.3534   4.5784e-02   1.2669e-04    12.3993 |  11.3 |\n",
      "  308 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    1.0303   4.5784e-02   1.2669e-04    1.0762 |   0.85776   0.81539   0.81775   0.81529 |   12.8398   4.5784e-02   1.2669e-04    12.8857 |  12.7 |\n",
      "  308 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    1.0372   4.5884e-02   9.4039e-05    1.0832 |   0.84875   0.81486   0.81738   0.81475 |   12.7829   4.5871e-02   1.1054e-04    12.8289 |  11.9 |\n",
      "  309 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    1.0948   4.5871e-02   1.1054e-04    1.1408 |   0.83779   0.81555   0.81801   0.81545 |   12.6002   4.5871e-02   1.1054e-04    12.6462 |  12.2 |\n",
      "  309 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    1.0816   4.6170e-02   9.7322e-05    1.1279 |   0.82408   0.81471   0.81766   0.81460 |   12.3624   4.6164e-02   1.0702e-04    12.4087 |  11.5 |\n",
      "  310 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.5520   4.6164e-02   1.0702e-04    0.5983 |   0.82845   0.81396   0.81699   0.81383 |   12.4061   4.6164e-02   1.0702e-04    12.4524 |  13.6 |\n",
      "  310 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    1.2758   4.6680e-02   1.1067e-04    1.3226 |   0.83367   0.81559   0.81750   0.81547 |   12.4944   4.6660e-02   1.1617e-04    12.5412 |  11.8 |\n",
      "\n",
      "[e] Policy training epoch:310  it:57225 -  Total Loss: 12.5412     \n",
      "Task: 12.4944   Sparsity: 4.66604e-02    Sharing: 1.16174e-04 \n",
      "\n",
      " epch: 310   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1470    0.8530  0    0.1956    0.8044  0    0.1757    0.8243  0\n",
      "   2    0.7925    0.2075  1    0.7327    0.2673  1    0.6420    0.3580  1\n",
      "   3    0.8486    0.1514  1    0.7406    0.2594  1    0.6533    0.3467  1\n",
      "   4    0.4522    0.5478  0    0.5848    0.4152  1    0.6248    0.3752  1\n",
      "   5    0.2757    0.7243  0    0.4555    0.5445  0    0.3782    0.6218  0\n",
      "   6    0.3445    0.6555  0    0.3530    0.6470  0    0.3860    0.6140  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  311 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    1.0621   4.6660e-02   1.1617e-04    1.1088 |   0.86969   0.81357   0.81693   0.81346 |   12.9973   4.6660e-02   1.1617e-04    13.0440 |  13.5 |\n",
      "  311 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9010   4.6525e-02   1.3011e-04    0.9477 |   0.82730   0.81537   0.81727   0.81528 |   12.4009   4.6525e-02   1.2346e-04    12.4475 |  10.4 |\n",
      "  312 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.7610   4.6525e-02   1.2346e-04    0.8076 |   0.83652   0.81388   0.81723   0.81378 |   12.5852   4.6525e-02   1.2346e-04    12.6318 |  11.9 |\n",
      "  312 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9002   4.7088e-02   1.4449e-04    0.9475 |   0.82783   0.81492   0.81738   0.81482 |   12.4238   4.7111e-02   1.2893e-04    12.4711 |  11.3 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  313 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9519   4.7111e-02   1.2893e-04    0.9991 |   0.84172   0.81482   0.81766   0.81471 |   12.6633   4.7111e-02   1.2893e-04    12.7106 |  11.8 |\n",
      "  313 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9391   4.7281e-02   1.3497e-04    0.9865 |   0.85318   0.81427   0.81705   0.81417 |   12.8010   4.7290e-02   1.5580e-04    12.8485 |  11.0 |\n",
      "  314 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.7924   4.7290e-02   1.5580e-04    0.8398 |   0.82778   0.81669   0.81867   0.81656 |   12.4372   4.7290e-02   1.5580e-04    12.4847 |  12.4 |\n",
      "  314 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    0.9189   4.7680e-02   9.6948e-05    0.9666 |   0.86262   0.81502   0.81756   0.81490 |   12.9082   4.7689e-02   1.0395e-04    12.9559 |  10.4 |\n",
      "  315 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    1.0508   4.7689e-02   1.0395e-04    1.0986 |   0.84580   0.81567   0.81731   0.81558 |   12.7106   4.7689e-02   1.0395e-04    12.7584 |  13.6 |\n",
      "  315 |   2.37e-04   2.37e-04   3.16e-03  2.429e+00 |    1.0581   4.7101e-02   1.2625e-04    1.1054 |   0.85692   0.81434   0.81705   0.81424 |   12.8362   4.7114e-02   1.3198e-04    12.8834 |  12.2 |\n",
      " decay gumbel softmax to 2.344065222139808\n",
      "\n",
      "[e] Policy training epoch:315  it:58275 -  Total Loss: 12.8834     \n",
      "Task: 12.8362   Sparsity: 4.71144e-02    Sharing: 1.31982e-04 \n",
      "\n",
      " epch: 315   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.1458    0.8542  0    0.1994    0.8006  0    0.1786    0.8214  0\n",
      "   2    0.7920    0.2080  1    0.7298    0.2702  1    0.6503    0.3497  1\n",
      "   3    0.8552    0.1448  1    0.7312    0.2688  1    0.6629    0.3371  1\n",
      "   4    0.4584    0.5416  0    0.5768    0.4232  1    0.6313    0.3687  1\n",
      "   5    0.2811    0.7189  0    0.4656    0.5344  0    0.3918    0.6082  0\n",
      "   6    0.3465    0.6535  0    0.3535    0.6465  0    0.3986    0.6014  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  316 |   2.37e-04   2.37e-04   3.16e-03  2.344e+00 |    0.8795   4.7114e-02   1.3198e-04    0.9268 |   0.84186   0.81618   0.81780   0.81607 |   12.6013   4.7114e-02   1.3198e-04    12.6485 |  13.4 |\n",
      "  316 |   2.37e-04   2.37e-04   3.16e-03  2.344e+00 |    0.9594   4.6524e-02   1.3175e-04    1.0061 |   0.83783   0.81481   0.81746   0.81470 |   12.5354   4.6507e-02   8.0594e-05    12.5820 |  11.8 |\n",
      "  317 |   2.37e-04   2.37e-04   3.16e-03  2.344e+00 |    1.0475   4.6507e-02   8.0594e-05    1.0941 |   0.85134   0.81538   0.81783   0.81528 |   12.7361   4.6507e-02   8.0594e-05    12.7827 |  13.4 |\n",
      "  317 |   2.37e-04   2.37e-04   3.16e-03  2.344e+00 |    0.9016   4.6538e-02   1.2070e-04    0.9483 |   0.82711   0.81521   0.81771   0.81511 |   12.4205   4.6539e-02   1.4350e-04    12.4672 |  11.4 |\n",
      "  318 |   2.37e-04   2.37e-04   3.16e-03  2.344e+00 |    1.0184   4.6539e-02   1.4350e-04    1.0651 |   0.82918   0.81717   0.81896   0.81707 |   12.4465   4.6539e-02   1.4350e-04    12.4932 |  13.5 |\n",
      "  318 |   2.37e-04   2.37e-04   3.16e-03  2.344e+00 |    0.8825   4.7091e-02   8.1683e-05    0.9297 |   0.84879   0.81665   0.81849   0.81656 |   12.6708   4.7109e-02   9.9946e-05    12.7180 |  11.3 |\n",
      "  319 |   2.37e-04   2.37e-04   3.16e-03  2.344e+00 |    0.5660   4.7109e-02   9.9946e-05    0.6132 |   0.85227   0.81441   0.81746   0.81432 |   12.7761   4.7109e-02   9.9946e-05    12.8233 |  13.7 |\n",
      "  319 |   2.37e-04   2.37e-04   3.16e-03  2.344e+00 |    1.1940   4.5965e-02   1.2719e-04    1.2401 |   0.83906   0.81368   0.81707   0.81358 |   12.6327   4.5953e-02   8.1531e-05    12.6788 |  13.3 |\n",
      "  320 |   2.37e-04   2.37e-04   3.16e-03  2.344e+00 |    0.7332   4.5953e-02   8.1531e-05    0.7793 |   0.80429   0.81601   0.81817   0.81592 |   12.1157   4.5953e-02   8.1531e-05    12.1618 |  13.2 |\n",
      "Ep:320 [policy] :  21%|▋  | 22/105 [00:02<00:08,  9.53it/s, it=59244, Lss=0.8262, Spr=4.5944e-02, Shr=1.2023e-04, lyr=6]"
     ]
    }
   ],
   "source": [
    "# weight_policy_training(ns, opt, environ, dldrs, epochs = 100)\n",
    "weight_policy_training(ns, opt, environ, dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27779c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T17:00:48.177935Z",
     "start_time": "2022-03-23T17:00:48.014182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 23940, 0.8217469868335131)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns.best_epoch, ns.best_iter, ns.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be1060",
   "metadata": {},
   "source": [
    "### Close WandB run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c5f6dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T12:57:30.971894Z",
     "start_time": "2022-03-24T12:57:27.154297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0731659d504e9d9a8040542df722ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='7.157 MB of 7.157 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_time</td><td>▄▁▂▂▃▁▅▅▆▅▄▅▅█▅▅▄▄▄▅▅▄▅▅▅▄▄▅▆▆▆▆▅▄▄▅▅▅▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>325</td></tr><tr><td>train_time</td><td>9.89502</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0323_2317</strong>: <a href=\"http://localhost:8080/kbardool/AdaSparseChem/runs/2jpxa2v2\" target=\"_blank\">http://localhost:8080/kbardool/AdaSparseChem/runs/2jpxa2v2</a><br/>Synced 7 W&B file(s), 1725 media file(s), 1733 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220323_231703-2jpxa2v2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49cc3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T21:40:38.885929Z",
     "start_time": "2022-03-10T21:40:38.783808Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.best_epoch = 0\n",
    "# from utils.notebook_modules import wrapup_phase\n",
    "# wrapup_phase(ns, opt, environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1656da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T01:52:34.096090Z",
     "start_time": "2022-03-10T01:52:34.003457Z"
    }
   },
   "outputs": [],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #\n",
    "print(opt['train']['decay_temp_freq'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570db82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T23:15:53.792025Z",
     "start_time": "2022-03-09T23:15:53.736492Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['policy_lr']       = 0.002\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.05\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# # environ.opt['train']['decay_temp_freq'] = 2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26efa07b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:10:08.772444Z",
     "start_time": "2022-03-10T03:10:08.706432Z"
    }
   },
   "outputs": [],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #\n",
    "\n",
    "print()\n",
    "print( f\" current_iters               : {ns.current_iter}\")  \n",
    "print( f\" current_epochs              : {ns.current_epoch}\") \n",
    "print( f\" train_total_epochs          : {ns.training_epochs}\") \n",
    "print( f\" stop_epoch_training         : {ns.stop_epoch_training}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac6b6a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Post Training Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04de4040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T22:17:44.833671Z",
     "start_time": "2022-03-13T22:17:44.799394Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "# pp.pprint(environ.val_metrics)\n",
    "environ.num_layers, environ.networks['mtl-net'].num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ca92e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T23:23:43.744498Z",
     "start_time": "2022-03-10T23:23:43.696990Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.val_metrics['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e5cec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T17:44:36.218784Z",
     "start_time": "2022-02-21T17:44:36.063411Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "# environ.display_trained_policy(current_epoch)\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c1c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:32:52.580865Z",
     "start_time": "2022-03-06T00:32:52.554112Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_label   = 'model_train_ep_%d_seed_%04d' % (current_epoch, opt['random_seed'])\n",
    "# metrics_label = 'metrics_train_ep_%d_seed_%04d.pickle' % (current_epoch, opt['random_seed'])\n",
    "# environ.save_checkpoint(model_label, current_iter, current_epoch) \n",
    "# save_to_pickle(environ.val_metrics, environ.opt['paths']['checkpoint_dir'], metrics_label)\n",
    "# print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "# environ.display_trained_policy(current_epoch,out=[sys.stdout, environ.log_file])\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad3a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T22:48:27.014120Z",
     "start_time": "2022-02-20T22:48:26.982535Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_loss(current_iter, environ.losses, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")\n",
    "# print()\n",
    "# print_loss(current_iter, trn_losses, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")\n",
    "# print()\n",
    "# print_loss(current_iter, environ.val_metrics, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d5db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T20:31:45.254334Z",
     "start_time": "2022-03-01T20:31:45.116895Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.losses\n",
    "# environ.val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4dd81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T20:47:29.582501Z",
     "start_time": "2022-03-01T20:47:29.492581Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.batch_data\n",
    "# print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics, 0, out=[sys.stdout])\n",
    "# environ.display_parameters()\n",
    "\n",
    "# with np.printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', precision=7, formatter={'float': lambda x: f\"{x:12.5e}\"}):\n",
    "#     environ.print_logit_grads('gradients')\n",
    "\n",
    "# environ_params = environ.get_task_specific_parameters()\n",
    "# environ_params = environ.get_arch_parameters()\n",
    "# environ_params = environ.get_backbone_parameters()\n",
    "# print(environ_params)\n",
    "# for param in environ_params:\n",
    "#     print(param.grad.shape, '\\n', param.grad)\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c80c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:12:46.806056Z",
     "start_time": "2022-03-11T21:12:46.471801Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.display_trained_logits(ns.current_epoch)\n",
    "environ.display_trained_policy(ns.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d47dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:13:19.578964Z",
     "start_time": "2022-03-11T21:13:19.242252Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.display_test_sample_policy(ns.current_epoch, hard_sampling = True)\n",
    "environ.display_train_sample_policy(ns.current_epoch, hard_sampling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754b317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:33:19.474125Z",
     "start_time": "2022-03-06T00:33:19.447847Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.define_optimizer(policy_learning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e89541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T00:07:08.097708Z",
     "start_time": "2022-03-09T00:07:08.070721Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.optimizers['alphas'])\n",
    "print(environ.optimizers['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ecc91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T00:07:50.026992Z",
     "start_time": "2022-03-09T00:07:49.986101Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Policy  initial_lr : ', environ.optimizers['alphas'].param_groups[0]['initial_lr'], 'lr : ',environ.optimizers['alphas'].param_groups[0]['lr'])\n",
    "print('Weights initial_lr : ', environ.optimizers['weights'].param_groups[0]['initial_lr'], 'lr : ',environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "print('Weights initial_lr : ', environ.optimizers['weights'].param_groups[1]['initial_lr'], 'lr : ',environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1306e8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T22:31:50.425696Z",
     "start_time": "2022-03-10T22:31:50.396531Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wandb.run is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b8e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:10:03.751132Z",
     "start_time": "2022-03-05T23:10:03.724538Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# opt['exp_instance'] = '0218_1358'     \n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\"\n",
    "# print()\n",
    "# opt['exp_instance'] = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "# opt['exp_description'] = f\"No Alternating Weight/Policy - training all done with both weights and policy\"\n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2affee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:12:20.322227Z",
     "start_time": "2022-03-11T21:12:20.285961Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527bd00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:25:11.319751Z",
     "start_time": "2022-02-20T21:25:11.210062Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "p = environ.get_current_state(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919068f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:25:26.324030Z",
     "start_time": "2022-02-20T21:25:26.112782Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82a453",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Post Warm-up Training stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb74c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:45:43.999959Z",
     "start_time": "2022-02-01T12:45:43.862475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b47da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:36.700361Z",
     "start_time": "2022-02-01T12:46:36.367037Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].arch_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f0235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:37:10.158440Z",
     "start_time": "2022-01-28T16:37:09.742327Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p = environ.get_sample_policy(hard_sampling = False)\n",
    "print(p)\n",
    "p = environ.get_policy_prob()\n",
    "print(p)\n",
    "p = environ.get_policy_logits()\n",
    "print(p)\n",
    "\n",
    "# p = environ.get_current_policy()\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bddd44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:40:37.799917Z",
     "start_time": "2022-01-28T16:40:37.773177Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = softmax([0.0, 1])\n",
    "print(a)\n",
    "sampled = np.random.choice((1, 0), p=a)\n",
    "print(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8f376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:13:16.205889Z",
     "start_time": "2022-01-28T16:13:16.179303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.optimizers['weights'])\n",
    "print(environ.schedulers['weights'].get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf9c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:50.411465Z",
     "start_time": "2022-02-01T12:46:50.020540Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('losses.keys      : ', environ.losses.keys())\n",
    "print('losses[task]keys : ', environ.losses['task1'].keys())\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20950069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T22:57:02.151169Z",
     "start_time": "2022-01-15T22:57:02.056562Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print( environ.val_metrics.keys())\n",
    "# pp.pprint(val_metrics)\n",
    "print(type(environ.val_metrics['aggregated']))\n",
    "print()\n",
    "print(type(environ.val_metrics['task1']['classification_agg']))\n",
    "print()\n",
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6e311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.266303Z",
     "start_time": "2022-01-14T18:57:26.166878Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"val_metrics.pkl\", mode= 'wb') as f:\n",
    "#         pickle.dump(val_metrics, f)\n",
    "    \n",
    "# with open('val_metrics.pkl', 'rb') as f:    \n",
    "#     tst_val_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00a8aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.297444Z",
     "start_time": "2022-01-14T18:57:26.269323Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(environ.input.shape) \n",
    "# a = getattr(environ, 'task1_pred')\n",
    "# yc_data = environ.batch['task1_data']\n",
    "# print(yc_data.shape)\n",
    "# yc_ind = environ.batch['task1_ind']\n",
    "# print(yc_ind.shape)\n",
    "# yc_hat_all = getattr(environ, 'task1_pred')\n",
    "# print(yc_hat_all.shape)\n",
    "# yc_hat  = yc_hat_all[yc_ind[0], yc_ind[1]]\n",
    "# print(yc_hat_all.shape, yc_hat.shape)\n",
    "\n",
    "# \n",
    "# environ.losses\n",
    "# loss = {}\n",
    "# for key in environ.losses.keys():\n",
    "#     loss[key] = {}\n",
    "#     for subkey, v in environ.losses[key].items():\n",
    "#         print(f\" key:  {key}   subkey: {subkey} \")\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             loss[key][subkey] = v.data\n",
    "#             print(f\" Tensor  -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "#         else:\n",
    "#             loss[key][subkey] = v\n",
    "#             print(f\" integer -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "# pp.pprint(tst_val_metrics)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987f89f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.340792Z",
     "start_time": "2022-01-14T18:57:26.302528Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print('metrics.keys: ', environ.metrics.keys())\n",
    "# print('metrics[task].keys: ', environ.metrics['task1'].keys())\n",
    "# pp.pprint(environ.metrics['task1'])\n",
    "# pp.pprint(environ.losses['task1']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ae417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.373399Z",
     "start_time": "2022-01-14T18:57:26.345065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# title='Iteration'\n",
    "# for t_id, _ in enumerate(environ.tasks):\n",
    "#     task_key = f\"task{t_id+1}\"\n",
    "# #     print_heading(f\"{title}  {current_iter}  {task_key} : {val_metrics[task_key]['classification_agg']}\", verbose = True)\n",
    "\n",
    "#     for key, _  in val_metrics[task_key]['classification_agg'].items():\n",
    "#         print('%s/%-20s'%(task_key, key), val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print(f\"{task_key:s}/{key:20s}\", val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print()\n",
    "#             # print_current_errors(os.path.join(self.log_dir, 'loss.txt'), current_iter,key, loss[key], time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b73b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:48.162261Z",
     "start_time": "2022-01-07T22:52:48.140423Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.print_loss(current_iter, start_time, metrics = val_metrics['loss'], verbose=True)\n",
    "# print(opt['lambdas'])\n",
    "# p = (opt['lambdas'][0] * environ.losses['tasks']['task1'])\n",
    "# print(p)\n",
    "\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics , title='validation', verbose=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850378b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:47.661019Z",
     "start_time": "2022-01-07T22:52:47.639094Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(current_iter)\n",
    "# print_metrics_cr(current_iter, t1 - t0, None, val_metrics , True)\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics, title='validation', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a80b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:14:58.034384Z",
     "start_time": "2022-01-07T23:14:58.004850Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\" val_metric keys               : {val_metrics.keys()}\")\n",
    "print(f\" loss keys                     : {val_metrics['loss'].keys()}\")\n",
    "print(f\" task1 keys                    : {val_metrics['task1'].keys()}\")\n",
    "print(f\" task1 classification keys     : {val_metrics['task1']['classification'].keys()}\")\n",
    "print(f\" task1 classification_agg keys : {val_metrics['task1']['classification_agg'].keys()}\")\n",
    "print()\n",
    "print(f\" task1                       : {val_metrics['task1']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task2                       : {val_metrics['task2']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task3                       : {val_metrics['task3']['classification_agg']['loss']:5f}\")\n",
    "print(f\" loss                        : {val_metrics['loss']['total']:5f}\")\n",
    "print(f\" train_time                  : {val_metrics['train_time']:2f}\")\n",
    "print(f\" epoch                       : {val_metrics['epoch']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc43a6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Post Weight + Policy Training Stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65640cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:22:20.634818Z",
     "start_time": "2022-01-27T00:22:20.444566Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].backbone.layer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4374287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:30:31.940280Z",
     "start_time": "2022-01-26T19:30:31.910058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_blocks = 6\n",
    "num_policy_layers = 6\n",
    "gt =  torch.ones((num_blocks)).long()\n",
    "gt0 =  torch.zeros((num_blocks)).long()\n",
    "print(gt)\n",
    "print(gt0)\n",
    "\n",
    "loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "print(loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651bc43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:42:31.300891Z",
     "start_time": "2022-01-26T19:42:31.257774Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if environ.opt['diff_sparsity_weights'] and not environ.opt['is_sharing']:\n",
    "    print(' cond 1')\n",
    "    ## Assign higher weights to higher layers \n",
    "    loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "    print(f\"{task_key} sparsity error:  {2 * (loss_weights[-num_blocks:] * environ.cross_entropy2(logits[-num_blocks:], gt)).mean()})\")\n",
    "    print_dbg(f\" loss_weights :  {loss_weights}\", verbose = True)\n",
    "    print_dbg(f\" cross_entropy:  {environ.cross_entropy2(logits[-num_blocks:], gt)}  \", verbose = True)\n",
    "    print_dbg(f\" loss[sparsity][{task_key}]: {self.losses['sparsity'][task_key] } \", verbose = True)\n",
    "\n",
    "else:\n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between \\n Logits   : \\n{logits[-num_blocks:]} \\n and gt: \\n{gt} \\n\", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-num_blocks:], gt)}\")\n",
    "    \n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt[-1:])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt0[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt0[-1:])} \\n\")\n",
    "    \n",
    "    print('\\n cond 3')    \n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt[0:1])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt0[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt0[0:1])} \\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686cd05",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ee1b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:30.155045Z",
     "start_time": "2022-01-26T00:14:30.107095Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# flag = 'update_w'\n",
    "# environ.fix_alpha\n",
    "# environ.free_w(opt['fix_BN'])\n",
    "\n",
    "flag = 'update_alpha'\n",
    "environ.fix_weights()\n",
    "environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7996b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:31.184285Z",
     "start_time": "2022-01-25T23:43:31.159229Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f436ee6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:34.993711Z",
     "start_time": "2022-01-26T00:14:34.968623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") \n",
    "\n",
    "train_total_epochs += 5\n",
    "\n",
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334a0b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T17:15:02.216665Z",
     "start_time": "2022-01-25T17:15:01.848081Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - t0, None, environ.val_metrics , num_prints)      \n",
    "\n",
    "# num_prints += 1\n",
    "# t0 = time.time()\n",
    "\n",
    "# # Take check point\n",
    "# environ.save_checkpoint('latest', current_iter)\n",
    "# environ.train()\n",
    "# #-------------------------------------------------------\n",
    "# # END validation process\n",
    "# #-------------------------------------------------------       \n",
    "# flag = 'update_alpha'\n",
    "# environ.fix_w()\n",
    "# environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c4f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:08:57.366231Z",
     "start_time": "2022-01-08T01:08:57.295445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dilation = 2\n",
    "# kernel_size = np.asarray((3, 3))\n",
    "# upsampled_kernel_size = (kernel_size - 1) * (dilation - 1) + kernel_size\n",
    "# print(upsampled_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500c390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:39.763599Z",
     "start_time": "2022-01-25T23:43:39.728402Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.optimizers['weights'].param_groups[0]\n",
    "# for param_group in optimizer.param_groups:\n",
    "#     return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb71bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:41.628847Z",
     "start_time": "2022-01-25T23:43:41.602238Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.schedulers['weights'].get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7934862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:36:17.129535Z",
     "start_time": "2022-01-08T01:36:16.006144Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.optimizers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    current_state[k] = v.state_dict()\n",
    "pp.pprint(current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5faf7f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:40:22.032247Z",
     "start_time": "2022-01-08T01:40:22.006953Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.schedulers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    print(v.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd497e72",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Losses and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66169a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T16:34:44.555617Z",
     "start_time": "2022-02-09T16:34:44.507417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_losses = environ.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb8234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:35:11.758429Z",
     "start_time": "2022-02-10T03:35:11.278211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0301f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:21:49.107793Z",
     "start_time": "2022-02-10T03:21:49.084484Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498b6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:20:32.866010Z",
     "start_time": "2022-02-10T03:20:32.442919Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "pp.pprint(trn_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe30724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:34:21.945701Z",
     "start_time": "2022-02-10T03:34:21.411234Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d81167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:49.364883Z",
     "start_time": "2022-01-27T00:58:49.342931Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['Lambda_sharing'] = 0.5\n",
    "# opt['train']['Lambda_sharing'] = 0.5\n",
    "\n",
    "# environ.opt['train']['policy_lr'] = 0.001\n",
    "# opt['train']['policy_lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73aa06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T01:00:41.996410Z",
     "start_time": "2022-01-26T01:00:41.559006Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.losses.keys()\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ece74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:19:43.683550Z",
     "start_time": "2022-01-08T01:19:43.571450Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = environ.get_loss_dict()\n",
    "print(tmp.keys())\n",
    "pp.pprint(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac0256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:50.458223Z",
     "start_time": "2022-01-27T00:58:50.430889Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(opt['diff_sparsity_weights'])\n",
    "print(opt['is_sharing'])\n",
    "print(opt['diff_sparsity_weights'] and not opt['is_sharing'])\n",
    "print(environ.opt['train']['Lambda_sharing'])\n",
    "print(opt['train']['Lambda_sharing'])\n",
    "print(environ.opt['train']['Lambda_sparsity'])\n",
    "print(opt['train']['Lambda_sparsity'])\n",
    "print(environ.opt['train']['policy_lr'])\n",
    "print(opt['train']['policy_lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2d510",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Policy / Logit stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb628497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:35:14.041577Z",
     "start_time": "2022-02-08T20:35:14.018303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.special          import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eed454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:30.103364Z",
     "start_time": "2022-02-08T20:00:30.068021Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03b5cc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_task_logits(n)` Get logits for task group n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed8b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:56:35.652087Z",
     "start_time": "2022-02-08T20:56:35.327406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task_logits = environ.get_task_logits(1)\n",
    "print(task_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66fa5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_arch_parameters()`: Get last used logits from network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85521e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:31.101960Z",
     "start_time": "2022-02-08T20:00:30.757064Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b0bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:06.054699Z",
     "start_time": "2022-02-09T15:43:05.689327Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea1743",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_logits()`:  Get Policy Logits - returns same as `get_arch_parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb40c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:24.972390Z",
     "start_time": "2022-02-09T15:43:24.636629Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs = environ.get_policy_logits()\n",
    "for i in logs:\n",
    "    print(i, '\\n')\n",
    "# probs = softmax(logs, axis= -1)\n",
    "# for i in probs:\n",
    "#     print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080a364",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_prob()` : Gets the softmax of the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c75af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:29.733732Z",
     "start_time": "2022-02-09T15:43:29.699600Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "for i in policy_softmaxs:\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3160d9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = False)` : Calls test_sample_policy of network with random choices based on softmax of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f411444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:21:15.636722Z",
     "start_time": "2022-02-08T22:21:15.165456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "policies,logits = environ.get_sample_policy(hard_sampling = False)\n",
    "\n",
    "for l, p, s in zip(logits, policies, policy_softmaxs) :\n",
    "    for  l_row, p_row, s_row in zip(l, p, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802664ec",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = True)` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea65bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:59:40.790899Z",
     "start_time": "2022-02-08T20:59:40.726657Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "hard_policies, logits = environ.get_sample_policy(hard_sampling = True)\n",
    "\n",
    "for p,l,s in zip(hard_policies, logits, policy_softmaxs) :\n",
    "    for  p_row, l_row, s_row in zip(p, l, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c39cf",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fe096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:00:47.452220Z",
     "start_time": "2022-02-08T21:00:47.422902Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\" Layer    task 1      task 2      task 3\")\n",
    "print(f\" -----    ------      ------      ------\")\n",
    "for idx, (l1, l2, l3) in enumerate(zip(hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1}       {l2}       {l3}\")\n",
    "    \n",
    "\n",
    "    print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade0ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:39:39.936555Z",
     "start_time": "2022-02-08T22:39:39.911591Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_trained_policy(iter):\n",
    "\n",
    "    policy_softmaxs = environ.get_policy_prob()\n",
    "    policy_argmaxs = 1-np.argmax(policy_softmaxs, axis = -1)\n",
    "    print(f\"  Trained polcies at iteration: {iter} \")\n",
    "    print(f\"                   task 1                           task 2                         task 3        \")\n",
    "    print(f\" Layer       softmax        select          softmax        select          softmax        select   \")\n",
    "    print(f\" -----    ---------------   ------       ---------------   ------       ---------------   ------   \")\n",
    "    for idx, (l1,l2,l3,  p1,p2,p3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2], policy_argmaxs[0], policy_argmaxs[1], policy_argmaxs[2]),1):\n",
    "        print(f\"   {idx}      {l1[0]:.4f}   {l1[1]:.4f}   {p1:4d}    {l2[0]:11.4f}   {l2[1]:.4f}   {p2:4d}    {l3[0]:11.4f}   {l3[1]:.4f}   {p3:4d}\")\n",
    "\n",
    "    print()\n",
    "# print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec208dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:42:12.650813Z",
     "start_time": "2022-02-08T22:42:12.330169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display_trained_policy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec517e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:07:30.836214Z",
     "start_time": "2022-02-08T22:07:30.804575Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"                        POLICIES (SOFTMAX)                                       task 3          \")\n",
    "print(f\" Layer    task1              task2            task3 softmax         softmax         argmax         softmax         argmax   \")\n",
    "print(f\" -----    -------------     -------------     -------------   ------   \")\n",
    "for idx, (l1,l2,l3, h1,h2,h3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2],hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1[0]:.4f} {l1[1]:.4f}     {l2[0]:.4f} {l2[1]:.4f}     {l3[0]:.4f} {l3[1]:.4f}    {h3}\")\n",
    "    \n",
    "print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbeacb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:04:50.757406Z",
     "start_time": "2022-02-08T22:04:50.731736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(policy_softmaxs[2], np.argmax(1-policy_softmaxs[2], axis = -1))\n",
    "print(policy_softmaxs, np.argmax(policy_softmaxs, axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be0240",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_logits()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb7240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:19:06.155425Z",
     "start_time": "2022-02-08T21:19:06.118640Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits  = (environ.get_current_logits())\n",
    "for i in logits:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e84662",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_policy()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cfa24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:40:06.543376Z",
     "start_time": "2022-02-08T20:40:06.230711Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pols  = (environ.get_current_policy())\n",
    "\n",
    "for i in pols:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f556a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T18:27:33.593255Z",
     "start_time": "2022-01-27T18:27:33.553141Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792710e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `gumbel_softmax()`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265490e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:28:17.107529Z",
     "start_time": "2022-02-08T21:28:17.084910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', floatmode = 'maxprec_equal')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb0087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:35:11.617269Z",
     "start_time": "2022-02-08T21:35:11.569599Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.temp)\n",
    "# tau = environ.temp\n",
    "tau = 1\n",
    "for i in range(3): \n",
    "    logits_tensor = torch.tensor(logits[0])\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=tau, hard=False).cpu().numpy() \n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=tau, hard=True).cpu().numpy()\n",
    "    \n",
    "    for l, gs, gh in zip(lgts, gumbel_soft, gumbel_hard):\n",
    "        print(f\"   {l}   \\t {gs}            \\t {gh}\")\n",
    "#     print(lgts)\n",
    "#     print(gumbel_soft)\n",
    "#     print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5ef7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e0e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:21:35.524957Z",
     "start_time": "2022-02-08T21:21:35.488812Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for lgts in logits:\n",
    "    logits_tensor = torch.tensor(lgts)\n",
    "    print(lgts)\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=1, hard=False)\n",
    "    print(gumbel_soft)\n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=1, hard=True)\n",
    "    print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34a06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T20:49:37.643349Z",
     "start_time": "2022-02-03T20:49:37.580786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smax = scipy.special.softmax(logs, axis =1)\n",
    "# smax = np.array( \n",
    "# [[0.46973792, 0.530262  ],\n",
    "#  [0.45025694, 0.549743  ],\n",
    "#  [0.4443086 , 0.5556915 ],\n",
    "#  [0.4138397 , 0.58616036],\n",
    "#  [0.4140113 , 0.5859887 ],\n",
    "#  [0.42114905, 0.57885087]])\n",
    "\n",
    "print(smax.shape)\n",
    "print(smax)\n",
    "print(smax[0])\n",
    "print(smax[0].sum())\n",
    "print(np.random.choice((1,0), p =smax[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7de25c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:15:19.893888Z",
     "start_time": "2022-02-08T21:15:19.870899Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logs = np.array(\n",
    "[[0.33064184, 0.42053092],\n",
    " [0.3532089 , 0.52056104],\n",
    " [0.3888512 , 0.5680909 ],\n",
    " [0.42039296, 0.694217  ],\n",
    " [0.4519742 , 0.73311865],\n",
    " [0.48401102, 0.7522658 ]],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "399px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
