{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408f1261",
   "metadata": {},
   "source": [
    "## Initialization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d574cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:44:46.464895Z",
     "start_time": "2022-03-25T09:44:44.416418Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:08.233990Z",
     "iopub.status.busy": "2022-01-07T22:44:08.233053Z",
     "iopub.status.idle": "2022-01-07T22:44:08.273284Z",
     "shell.execute_reply": "2022-01-07T22:44:08.271908Z",
     "shell.execute_reply.started": "2022-01-07T22:44:08.233943Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "import time\n",
    "import argparse\n",
    "import yaml\n",
    "import types\n",
    "import copy, pprint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import numpy  as np\n",
    "import torch  \n",
    "import wandb\n",
    "import pandas as pd\n",
    "from utils.notebook_modules import initialize, init_dataloaders, init_environment, init_wandb, \\\n",
    "                                   training_prep, disp_dataloader_info,disp_info_1, \\\n",
    "                                   warmup_phase, weight_policy_training, disp_gpu_info\n",
    "\n",
    "from utils.util import (print_separator, print_heading, timestring, print_loss) #, print_underline, load_from_pickle,\n",
    "#                       print_dbg, get_command_line_args ) \n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=6, linewidth=132)\n",
    "pd.options.display.width = 132\n",
    "# torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
    "# sys.path.insert(0, '/home/kbardool/kusanagi/AdaSparseChem/src')\n",
    "# print(sys.path)\n",
    "# disp_gpu_info() \n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Training.ipynb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33ac6e",
   "metadata": {},
   "source": [
    "## Create Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee652c57",
   "metadata": {},
   "source": [
    "### Parse Input Args  - Read YAML config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42bb98b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:44:48.366583Z",
     "start_time": "2022-03-25T09:44:48.329620Z"
    }
   },
   "outputs": [],
   "source": [
    "# RESUME_MODEL_CKPT = 'model_train_ep_25_seed_0088'\n",
    "\n",
    "## For RESTARTING\n",
    "##\n",
    "# input_args = \" --config yamls/chembl_3task_train.yaml \" \\\n",
    "#              \" --resume \" \\\n",
    "#              \" --exp_id      330i85cg\" \\\n",
    "#              \" --exp_name    0308_1204\" \\\n",
    "#              \" --exp_desc    Train with dropout 0.5\" \\\n",
    "#              \" --seed_idx    0 \"\\\n",
    "#              \" --batch_size  128\" \\\n",
    "#              \" --lambda_sparsity  0.01\"\\\n",
    "#              \" --lambda_sharing   0.01\" \n",
    "## get command line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd3a7f00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:44:57.165622Z",
     "start_time": "2022-03-25T09:44:57.119753Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [],
   "source": [
    "##  For Initiating \n",
    "##\n",
    "input_args = \" --config yamls/chembl_3task_train.yaml \" \\\n",
    "             \" --exp_desc    6 lyrs,dropout 0.5, weight 105 bch/ep policy 105 bch/ep \" \\\n",
    "             \" --hidden_size   150 150 150 150 150 150   \" \\\n",
    "             \" --tail_hidden_size   150\" \\\n",
    "             \" --seed_idx            0\" \\\n",
    "             \" --batch_size        128\" \\\n",
    "             \" --task_lr          0.001\" \\\n",
    "             \" --backbone_lr      0.001\" \\\n",
    "             \" --policy_lr        0.01\" \\\n",
    "             \" --lambda_sparsity  0.03\" \\\n",
    "             \" --lambda_sharing   0.01\" \n",
    "\n",
    "#              \" --hidden_size   100 100 100 100 100 100\" \\\n",
    "#              \" --tail_hidden_size  100 \" \\\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc14177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:44:59.333395Z",
     "start_time": "2022-03-25T09:44:58.383704Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  command line parms : \n",
      "------------------------\n",
      " config...................  yamls/chembl_3task_train.yaml\n",
      " exp_id...................  None\n",
      " exp_name.................  None\n",
      " folder_sfx...............  None\n",
      " exp_desc.................  6 lyrs,dropout 0.5, weight 105 bch/ep policy 105 bch/ep\n",
      " hidden_sizes.............  [150, 150, 150, 150, 150, 150]\n",
      " tail_hidden_size.........  150\n",
      " seed_idx.................  0\n",
      " batch_size...............  128\n",
      " backbone_lr..............  0.001\n",
      " task_lr..................  0.001\n",
      " policy_lr................  0.01\n",
      " decay_lr_rate............  None\n",
      " decay_lr_freq............  None\n",
      " lambda_sparsity..........  0.03\n",
      " lambda_sharing...........  0.01\n",
      " gpu_ids..................  [0]\n",
      " resume...................  False\n",
      " cpu......................  False\n",
      "\n",
      "\n",
      "\n",
      "##################################################\n",
      "################### READ YAML ####################\n",
      "##################################################\n",
      "\n",
      "\n",
      " log_dir              create folder:  ../experiments/AdaSparseChem/150x6_0325_1044_plr0.01_sp0.03_sh0.01_lr0.001\n",
      " result_dir           folder exists:  ../experiments/AdaSparseChem/150x6_0325_1044_plr0.01_sp0.03_sh0.01_lr0.001\n",
      " checkpoint_dir       folder exists:  ../experiments/AdaSparseChem/150x6_0325_1044_plr0.01_sp0.03_sh0.01_lr0.001\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " experiment name       : 0325_1044 \n",
      " experiment id         : 1oii7m2w \n",
      " folder_name           : 150x6_0325_1044_plr0.01_sp0.03_sh0.01_lr0.001 \n",
      " experiment description: 6 lyrs,dropout 0.5, weight 105 bch/ep policy 105 bch/ep\n",
      " Random seeds          : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      " Random  seed used     : 88 \n",
      " log folder            : ../experiments/AdaSparseChem/150x6_0325_1044_plr0.01_sp0.03_sh0.01_lr0.001\n",
      " checkpoint folder     : ../experiments/AdaSparseChem/150x6_0325_1044_plr0.01_sp0.03_sh0.01_lr0.001\n",
      " Gpu ids               : [0]\n",
      " Seed index            : 0\n",
      " policy_iter           : best\n",
      " Data Split ratios     : [0.725, 0.225, 0.05]\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "        project_name : AdaSparseChem\n",
      "              exp_id : 1oii7m2w\n",
      "            exp_name : 0325_1044\n",
      "          exp_folder : 150x6_0325_1044_plr0.01_sp0.03_sh0.01_lr0.001\n",
      "     exp_description : 6 lyrs,dropout 0.5, weight 105 bch/ep policy 105 bch/ep\n",
      "          folder_sfx : None\n",
      "         random_seed : 88\n",
      "           seed_list : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      "                 cpu : False\n",
      "             gpu_ids : [0]\n",
      "            backbone : SparseChem\n",
      "               tasks : ['class', 'class', 'class']\n",
      "     tasks_num_class : [5, 5, 5]\n",
      "             lambdas : [1, 1, 1]\n",
      "        policy_model : task-specific\n",
      "             verbose : False\n",
      "       backbone_orig : ResNet18\n",
      "          tasks_orig : ['seg', 'sn']\n",
      "     input_size_freq : None\n",
      "          input_size : 32000\n",
      " first_non_linearity : relu\n",
      "middle_non_linearity : relu\n",
      "  last_non_linearity : relu\n",
      "      middle_dropout : 0.5\n",
      "        last_dropout : 0.5\n",
      "   class_output_size : None\n",
      "    regr_output_size : None\n",
      "              policy : True\n",
      "           is_sparse : True\n",
      "          is_sharing : True\n",
      "diff_sparsity_weights : False\n",
      "          skip_layer : 0\n",
      "       is_curriculum : False\n",
      "    curriculum_speed : 3\n",
      "              fix_BN : False\n",
      "     retrain_from_pl : False\n",
      "\n",
      "train\n",
      "-----\n",
      "          batch_size : 128\n",
      "       warmup_epochs : 75\n",
      "     training_epochs : 125\n",
      "         total_iters : 25000\n",
      "       warm_up_iters : None\n",
      "             task_lr : 0.001\n",
      "         backbone_lr : 0.001\n",
      "       decay_lr_rate : 0.75\n",
      "       decay_lr_freq : 40\n",
      "policy_decay_lr_rate : 0.75\n",
      "policy_decay_lr_freq : 50\n",
      "           policy_lr : 0.01\n",
      "     lambda_sparsity : 0.03\n",
      "      lambda_sharing : 0.01\n",
      "        lambda_tasks : 1\n",
      "         init_method : random\n",
      "           init_temp : 4\n",
      "          decay_temp : 0.965\n",
      "     decay_temp_freq : 16\n",
      "     init_neg_logits : None\n",
      "       hard_sampling : False\n",
      "            val_freq : 500\n",
      "          print_freq : -1\n",
      "           val_iters : -1\n",
      "              resume : False\n",
      "      retrain_resume : False\n",
      "         policy_iter : best\n",
      "          which_iter : warmup\n",
      "\n",
      "paths\n",
      "-----\n",
      "             log_dir : ../experiments/AdaSparseChem/150x6_0325_1044_plr0.01_sp0.03_sh0.01_lr0.001\n",
      "          result_dir : ../experiments/AdaSparseChem/150x6_0325_1044_plr0.01_sp0.03_sh0.01_lr0.001\n",
      "      checkpoint_dir : ../experiments/AdaSparseChem/150x6_0325_1044_plr0.01_sp0.03_sh0.01_lr0.001\n",
      "\n",
      "dataload\n",
      "--------\n",
      "             dataset : Chembl_23_mini\n",
      "            dataroot : /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic\n",
      "                   x : chembl_23mini_x.npy\n",
      "      x_split_ratios : [0.725, 0.225, 0.05]\n",
      "             folding : chembl_23mini_folds.npy\n",
      "         fold_inputs : 32000\n",
      "     input_transform : None\n",
      "             y_tasks : ['chembl_23mini_adashare_y1_bin_sparse.npy', 'chembl_23mini_adashare_y2_bin_sparse.npy', 'chembl_23mini_adashare_y3_bin_sparse.npy']\n",
      "            y_censor : None\n",
      "       weights_class : None\n",
      "              crop_h : 321\n",
      "              crop_w : 321\n",
      "   min_samples_class : 5\n",
      "             fold_va : 0\n",
      "             fold_te : None\n",
      "\n",
      "SC\n",
      "--\n",
      "      normalize_loss : None\n",
      "        hidden_sizes : [150, 150, 150, 150, 150, 150]\n",
      "    tail_hidden_size : 150\n"
     ]
    }
   ],
   "source": [
    "opt, ns = initialize(input_args, build_folders = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bfa8d",
   "metadata": {},
   "source": [
    "### Setup Dataloader and Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c631eb67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:45:01.645771Z",
     "start_time": "2022-03-25T09:45:00.876768Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############### CREATE DATALOADERS ###############\n",
      "##################################################\n",
      "\n",
      " trainset.y_class                                   :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " trainset1.y_class                                  :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " trainset2.y_class                                  :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " valset.y_class                                     :  [(4137, 5), (4137, 5), (4137, 5)]  \n",
      " testset.y_class                                    :  [(920, 5), (920, 5), (920, 5)]  \n",
      "                                 \n",
      " size of training set 0 (warm up)                   :  13331 \n",
      " size of training set 1 (network parms)             :  13331 \n",
      " size of training set 2 (policy weights)            :  13331 \n",
      " size of validation set                             :  4137 \n",
      " size of test set                                   :  920 \n",
      "                               Total                :  45050 \n",
      "                                 \n",
      " lenght (# batches) in training 0 (warm up)         :  105 \n",
      " lenght (# batches) in training 1 (network parms)   :  105 \n",
      " lenght (# batches) in training 2 (policy weights)  :  105 \n",
      " lenght (# batches) in validation dataset           :  33 \n",
      " lenght (# batches) in test dataset                 :  29 \n",
      "                                \n",
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      " device is  cuda:0\n",
      "--------------------------------------------------------\n",
      "* SparseChemEnv_Dev environment successfully created\n",
      "-------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dldrs = init_dataloaders(opt)\n",
    "\n",
    "disp_dataloader_info(dldrs)\n",
    "\n",
    "environ = init_environment(ns, opt, is_train = True, policy_learning = False, display_cfg = False)\n",
    "\n",
    "# ********************************************************************\n",
    "# **************** define optimizer and schedulers *******************\n",
    "# ********************************************************************                                \n",
    "environ.define_optimizer(policy_learning=False)\n",
    "environ.define_scheduler(policy_learning=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41ab8c05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:45:02.670228Z",
     "start_time": "2022-03-25T09:45:02.585430Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Current LR: 0.01\n",
      " Current LR: 0.001\n",
      " Current LR: 0.001\n"
     ]
    }
   ],
   "source": [
    "print(f\" Current LR: {environ.optimizers['alphas'].param_groups[0]['lr'] }\")\n",
    "print(f\" Current LR: {environ.optimizers['weights'].param_groups[0]['lr']}\")\n",
    "print(f\" Current LR: {environ.optimizers['weights'].param_groups[1]['lr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677fa3f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:45:03.661295Z",
     "start_time": "2022-03-25T09:45:03.576190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': [Parameter containing:\n",
       "  tensor([[-0.039199, -0.026896,  0.015696,  0.021018, -0.059028, -0.069487,  0.080026, -0.056681, -0.030938, -0.002778, -0.044748,\n",
       "           -0.045918,  0.050549, -0.007592,  0.062252,  0.069579,  0.070078, -0.059879, -0.039095, -0.014477, -0.044603, -0.005471,\n",
       "           -0.007979,  0.061740, -0.011913, -0.033068, -0.045195,  0.048141, -0.052791, -0.053301, -0.031594, -0.055418,  0.068755,\n",
       "            0.066495,  0.022349, -0.073826, -0.070488,  0.055380, -0.035242, -0.051436, -0.033102,  0.021591,  0.002433, -0.058409,\n",
       "           -0.067490,  0.052191,  0.049606,  0.080167, -0.030325,  0.017604, -0.036159,  0.000493,  0.012687, -0.063100, -0.050174,\n",
       "            0.028348,  0.077406,  0.003578, -0.057715, -0.013247,  0.013125, -0.007682, -0.010720,  0.048879, -0.077897,  0.074210,\n",
       "            0.035563, -0.036086,  0.035048, -0.032139,  0.058121, -0.018512,  0.068136,  0.060880,  0.065124, -0.050969,  0.052900,\n",
       "            0.034117,  0.076649,  0.075088,  0.036992,  0.068735, -0.067918, -0.076465,  0.028462,  0.019605, -0.054009,  0.051673,\n",
       "            0.069913,  0.071001, -0.054234, -0.060914, -0.074910,  0.028995,  0.072102,  0.078452, -0.028503,  0.019075,  0.008240,\n",
       "            0.057729, -0.012729,  0.013957, -0.030766,  0.079269, -0.067778,  0.024189,  0.058026, -0.022121, -0.064795,  0.067678,\n",
       "           -0.054849,  0.016785,  0.062783, -0.029436,  0.036163, -0.043371,  0.032376, -0.028825,  0.014442,  0.026169, -0.018930,\n",
       "           -0.036455, -0.075549, -0.073437,  0.002148,  0.050986, -0.055305,  0.005797,  0.041817,  0.059759,  0.054568, -0.047738,\n",
       "            0.044254, -0.044744,  0.006984, -0.069004,  0.010703, -0.001401, -0.058905, -0.017672,  0.072299, -0.068495, -0.020765,\n",
       "            0.056195, -0.002603,  0.073687,  0.004208, -0.059592, -0.053700, -0.031167],\n",
       "          [-0.081599,  0.012214, -0.065654, -0.031546,  0.057978,  0.046256, -0.069046, -0.063230, -0.063324,  0.048009, -0.017843,\n",
       "            0.057062, -0.046138,  0.006017, -0.039380,  0.040120, -0.010855, -0.057323,  0.081074, -0.012191,  0.020510,  0.021556,\n",
       "            0.061634, -0.022933,  0.027345,  0.007760, -0.062151,  0.000646, -0.069337, -0.051062,  0.061002, -0.037279,  0.064373,\n",
       "           -0.042016,  0.001313,  0.050813, -0.020559,  0.047077,  0.025773, -0.008718, -0.060957,  0.026281, -0.055330, -0.077761,\n",
       "            0.048804,  0.003064,  0.039975, -0.068337, -0.021523,  0.037502,  0.042648, -0.021481, -0.036652, -0.074992, -0.065388,\n",
       "           -0.057911,  0.073004,  0.017887, -0.065974,  0.024591, -0.031759, -0.068766, -0.066169, -0.030255,  0.015552, -0.042552,\n",
       "           -0.046728, -0.031365,  0.007606, -0.001160,  0.009216,  0.013291, -0.058053,  0.046394,  0.043158, -0.067850, -0.043744,\n",
       "           -0.009468, -0.031856, -0.044117,  0.038355, -0.058841, -0.046904, -0.000956,  0.024708,  0.014355, -0.065709,  0.076864,\n",
       "           -0.044972,  0.026008,  0.047620,  0.042302, -0.054998,  0.045962,  0.025012, -0.025064, -0.012208, -0.054593,  0.041880,\n",
       "            0.013081,  0.059865, -0.006386,  0.006395,  0.045689, -0.069943, -0.013546, -0.041386,  0.054976,  0.005946, -0.031125,\n",
       "           -0.031862, -0.004607,  0.061331, -0.007895, -0.015428,  0.027006,  0.064557, -0.000272, -0.037749, -0.053111,  0.018912,\n",
       "           -0.059434, -0.065422, -0.004300, -0.009762, -0.054280, -0.071824, -0.011723,  0.061000, -0.015867,  0.039372, -0.009117,\n",
       "            0.004363,  0.035755, -0.030175,  0.008162,  0.031361,  0.019005, -0.066520, -0.025575, -0.034376,  0.070882, -0.035969,\n",
       "           -0.014187, -0.019245, -0.000277,  0.032363, -0.023242, -0.043427, -0.049978],\n",
       "          [-0.021267,  0.006009,  0.073065,  0.044103, -0.061315, -0.008950,  0.012747, -0.077474, -0.005332,  0.051941,  0.011191,\n",
       "            0.040726,  0.036584,  0.071498,  0.049490, -0.003317, -0.027694,  0.006401,  0.075383,  0.003972,  0.007366, -0.061089,\n",
       "            0.025999, -0.069125, -0.020928,  0.069913, -0.048106,  0.009371, -0.004903,  0.007645,  0.024930,  0.046982,  0.054559,\n",
       "            0.077473,  0.057460,  0.044955,  0.053290,  0.008048, -0.065725,  0.030622,  0.007469, -0.050762, -0.046219,  0.039298,\n",
       "            0.065073, -0.005766,  0.034236,  0.002162,  0.010986,  0.081420, -0.075816, -0.044147,  0.021308, -0.077516, -0.044417,\n",
       "            0.058394,  0.028356, -0.007383,  0.072544,  0.039314,  0.029991,  0.071114,  0.072097,  0.030191, -0.069798, -0.045830,\n",
       "            0.009463, -0.054703, -0.069664,  0.044449,  0.027745, -0.021263, -0.059157,  0.058018, -0.042685,  0.069099,  0.061590,\n",
       "            0.058012,  0.039248,  0.062275, -0.035339, -0.075309,  0.025862,  0.057397,  0.031066, -0.007427,  0.062020,  0.004611,\n",
       "            0.071103, -0.052164,  0.054523,  0.031413,  0.030708, -0.068181,  0.030121,  0.012417, -0.081603,  0.068246,  0.058918,\n",
       "           -0.021075,  0.048919, -0.064770, -0.001290, -0.059280,  0.054998, -0.049645, -0.019225, -0.028070,  0.005540, -0.009312,\n",
       "           -0.060280,  0.033590,  0.052498, -0.022219,  0.030373, -0.000839,  0.012715,  0.054792,  0.064456,  0.062369,  0.005261,\n",
       "           -0.053439, -0.078450,  0.048476,  0.080361,  0.028536, -0.078416,  0.021879, -0.033555,  0.029759,  0.063393, -0.001888,\n",
       "            0.031753,  0.021373, -0.009159,  0.053274,  0.014706, -0.042878, -0.038083,  0.046340,  0.053564, -0.045601,  0.052911,\n",
       "           -0.000902, -0.048913, -0.071287,  0.016552,  0.064228, -0.043242, -0.018229],\n",
       "          [-0.011827,  0.020060, -0.031901,  0.018510,  0.016276,  0.016235, -0.017499,  0.000528,  0.079261,  0.021754, -0.019632,\n",
       "           -0.075409, -0.070097, -0.073519, -0.079812,  0.005990,  0.069678,  0.065834, -0.043905,  0.028491, -0.045445,  0.059839,\n",
       "           -0.007842,  0.021881,  0.000321,  0.064277,  0.031845,  0.060282,  0.057296,  0.002754, -0.023413,  0.057808,  0.032024,\n",
       "           -0.071829,  0.033434,  0.044186, -0.005884,  0.061388,  0.005639,  0.029318, -0.016173,  0.023706, -0.017975,  0.015121,\n",
       "           -0.071527, -0.046366,  0.000813,  0.000843, -0.009556,  0.037759, -0.042886,  0.031161,  0.023273,  0.063208, -0.031770,\n",
       "            0.067870,  0.064515,  0.034101,  0.060346, -0.022166, -0.013639,  0.043288, -0.037905, -0.036307, -0.059464,  0.064893,\n",
       "            0.024406,  0.000959, -0.074525, -0.055980,  0.004758, -0.030221,  0.078596,  0.065006, -0.027038,  0.005762,  0.054536,\n",
       "            0.072217, -0.046377,  0.014009, -0.030866, -0.020306,  0.003662, -0.011037,  0.055179,  0.061221,  0.021937, -0.033482,\n",
       "           -0.038235, -0.048951, -0.047573,  0.033064,  0.023190,  0.052426,  0.079797,  0.007528, -0.023896, -0.006498,  0.081397,\n",
       "            0.027231, -0.029722, -0.021160,  0.069177, -0.071373,  0.002974, -0.014547,  0.065094,  0.010401,  0.048438,  0.011023,\n",
       "           -0.016209,  0.067557,  0.074137, -0.075620, -0.051645,  0.007896,  0.027742,  0.016007,  0.004862, -0.051380,  0.002875,\n",
       "            0.044130,  0.038976, -0.042215,  0.041343,  0.077320,  0.017977,  0.036818,  0.000472,  0.061736, -0.007412,  0.003855,\n",
       "           -0.033721,  0.051175, -0.022855,  0.027277, -0.022077,  0.031145, -0.045768,  0.066938,  0.065667,  0.018853, -0.039186,\n",
       "            0.026064,  0.004951, -0.056715, -0.028096,  0.027166, -0.041199,  0.077871],\n",
       "          [-0.075137,  0.012502,  0.026929,  0.018860, -0.073011,  0.000898,  0.052862, -0.060212,  0.002593, -0.033600,  0.003865,\n",
       "            0.046488, -0.016199, -0.078761,  0.059581,  0.050973,  0.080515, -0.053030,  0.034965,  0.033604, -0.061152,  0.062815,\n",
       "           -0.063519, -0.013719,  0.054088,  0.030300, -0.006030,  0.046748,  0.001322,  0.074679, -0.022003, -0.017868,  0.070183,\n",
       "           -0.023454, -0.068397, -0.072162,  0.056677,  0.028992, -0.060390, -0.041587,  0.022975, -0.042607,  0.018656,  0.043062,\n",
       "            0.031553, -0.011043, -0.001401, -0.021200, -0.039074,  0.010661,  0.078353, -0.014823, -0.054274, -0.067193, -0.022225,\n",
       "           -0.000922,  0.017366, -0.007643, -0.008526,  0.072682, -0.051314, -0.069249, -0.007791,  0.068754,  0.063183, -0.033105,\n",
       "           -0.066907, -0.049626,  0.078910, -0.028260, -0.005822, -0.071674, -0.061097, -0.074251, -0.000365, -0.069769, -0.065502,\n",
       "            0.011154,  0.012483,  0.042873,  0.048000, -0.024700, -0.062759,  0.046675,  0.052702,  0.069467, -0.037005, -0.026350,\n",
       "           -0.059724, -0.009220,  0.000635, -0.063504, -0.040193, -0.041391,  0.069539,  0.017753,  0.078228, -0.059821, -0.046846,\n",
       "            0.035977,  0.032251,  0.064891, -0.048606, -0.046673, -0.070701,  0.040264,  0.040228, -0.060399,  0.054199, -0.029810,\n",
       "           -0.040324,  0.036373,  0.070910,  0.050464,  0.035605,  0.003038, -0.027285, -0.005272, -0.034239, -0.028152, -0.060539,\n",
       "            0.023918,  0.047115,  0.011890,  0.070836,  0.064901, -0.033921, -0.030801,  0.030536, -0.047345, -0.000792, -0.047291,\n",
       "           -0.012142,  0.024087,  0.004799,  0.063915,  0.063923,  0.017007, -0.028412,  0.062279,  0.018623, -0.014690,  0.000500,\n",
       "            0.040421, -0.076381, -0.064308, -0.046398, -0.016675, -0.057814, -0.053224]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.060648, -0.053339, -0.038770,  0.027143,  0.032191], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.031159, -0.008569, -0.028148,  0.051561,  0.041041, -0.044325, -0.054808,  0.067915,  0.060538, -0.063665,  0.045926,\n",
       "           -0.011634, -0.059158, -0.071491,  0.013491, -0.075958,  0.010756, -0.016360,  0.052714, -0.023748,  0.057396,  0.003433,\n",
       "            0.038474,  0.050216,  0.015676, -0.076951,  0.017377,  0.032400, -0.038981,  0.032007,  0.024375, -0.007342, -0.079949,\n",
       "           -0.042007, -0.064650, -0.001917, -0.014182, -0.037526, -0.064284, -0.047487,  0.079542,  0.042868,  0.033409,  0.065830,\n",
       "           -0.024403, -0.079634, -0.025394,  0.058799,  0.074335,  0.056083, -0.055645,  0.003666, -0.010145,  0.004439,  0.042110,\n",
       "           -0.036484,  0.079774,  0.036542,  0.021884, -0.015035,  0.066417,  0.066450, -0.035788,  0.052238, -0.076579,  0.021591,\n",
       "           -0.053924,  0.002947,  0.033149, -0.072848,  0.067197,  0.071621, -0.032741,  0.063131, -0.002910, -0.075083,  0.049678,\n",
       "            0.053086,  0.051264, -0.024526, -0.019259,  0.065687,  0.068680,  0.016971,  0.060641, -0.081367,  0.058434, -0.031993,\n",
       "            0.022135,  0.080928, -0.074781,  0.000421,  0.063498,  0.029574, -0.053522,  0.027770, -0.078427, -0.028288,  0.004123,\n",
       "           -0.004860, -0.017660, -0.017857,  0.060810,  0.075666,  0.013128, -0.002472,  0.000400,  0.040927,  0.053491, -0.079409,\n",
       "            0.058526,  0.060257,  0.053594,  0.013727,  0.076858,  0.043208,  0.022640,  0.061782,  0.019977, -0.026990, -0.053630,\n",
       "            0.070124,  0.035203, -0.055945, -0.072531, -0.007924, -0.045238,  0.016652,  0.006777,  0.077074, -0.057185,  0.004049,\n",
       "            0.003801, -0.039058, -0.024804, -0.060450, -0.058982,  0.062996,  0.071130,  0.078747,  0.045460,  0.017201, -0.027861,\n",
       "            0.044065, -0.027393, -0.009074,  0.001562, -0.046678, -0.071502, -0.065178],\n",
       "          [-0.080320,  0.063842,  0.022049,  0.080740,  0.045029, -0.022796, -0.025635, -0.023787, -0.071487,  0.067612,  0.001881,\n",
       "           -0.030004,  0.046355, -0.013802, -0.041918, -0.039980,  0.031345,  0.055404, -0.019862, -0.040318, -0.060255, -0.027614,\n",
       "           -0.070156, -0.011581,  0.039226,  0.077643, -0.000926,  0.055324, -0.024818,  0.047574,  0.017610,  0.070011,  0.001629,\n",
       "            0.057124, -0.044058, -0.025712, -0.018152,  0.050173,  0.000232, -0.014588,  0.073276, -0.012611,  0.009071, -0.002227,\n",
       "            0.004714, -0.070996,  0.056621,  0.070242,  0.042073, -0.070973,  0.070833, -0.071451,  0.035090, -0.018242,  0.008206,\n",
       "            0.047832,  0.008717,  0.010315, -0.040826,  0.037548,  0.006259,  0.022905,  0.032581,  0.033073,  0.042457,  0.057500,\n",
       "            0.042799,  0.029679,  0.067928,  0.025067,  0.008125,  0.028676,  0.069809, -0.017951, -0.004659, -0.009774, -0.007342,\n",
       "            0.051045,  0.026290, -0.031295, -0.072948, -0.044684,  0.013661, -0.062465, -0.059741, -0.035585, -0.079800, -0.078698,\n",
       "           -0.018703,  0.021958, -0.045230,  0.009756, -0.049926,  0.077531,  0.069905, -0.068079,  0.050967, -0.063885,  0.044967,\n",
       "           -0.072547,  0.068375,  0.002153, -0.050483,  0.064063, -0.048983,  0.076011,  0.065857, -0.074378,  0.071558,  0.035139,\n",
       "            0.030920,  0.059614,  0.062290, -0.039562,  0.070765,  0.049789,  0.024183, -0.055770,  0.000477,  0.025808, -0.050675,\n",
       "            0.054599,  0.025928, -0.058508, -0.045932, -0.008338,  0.070445,  0.003976,  0.078412, -0.028264, -0.032327, -0.051803,\n",
       "           -0.072886,  0.077842,  0.001084, -0.052093, -0.015037,  0.070646, -0.020900, -0.027713,  0.007441, -0.052108,  0.004324,\n",
       "           -0.048407,  0.041857,  0.059443, -0.049047,  0.021061, -0.039349, -0.031199],\n",
       "          [ 0.065360,  0.061281,  0.014963, -0.005007, -0.078848,  0.006023,  0.056077,  0.046166, -0.070752, -0.066175,  0.056144,\n",
       "           -0.016863, -0.020531,  0.040084, -0.057531,  0.038026,  0.034967,  0.051651, -0.071032,  0.076594,  0.009845, -0.055462,\n",
       "           -0.005381, -0.044452,  0.031137, -0.049577, -0.055565,  0.012503, -0.016303, -0.053467,  0.067818,  0.081388, -0.064869,\n",
       "            0.029444, -0.034079,  0.022478,  0.072045,  0.019675,  0.020438,  0.043728,  0.061076,  0.012889, -0.005731,  0.076397,\n",
       "           -0.005736, -0.006497,  0.016914, -0.012974, -0.014601, -0.049411,  0.018721, -0.027687, -0.081394, -0.045791,  0.068637,\n",
       "            0.020537, -0.061422,  0.047910, -0.061620, -0.040534, -0.001199,  0.077451,  0.009701,  0.080273, -0.035936,  0.026201,\n",
       "            0.002975,  0.062712, -0.030863, -0.032842, -0.020025, -0.035909, -0.042205,  0.073371,  0.026097, -0.023576,  0.009335,\n",
       "           -0.020466, -0.016016,  0.024136, -0.005328,  0.017892,  0.022615, -0.025737, -0.023411, -0.077986,  0.041732, -0.039799,\n",
       "            0.045484,  0.055577, -0.029319,  0.076680, -0.056557,  0.028850, -0.042421, -0.048146,  0.074854,  0.039255, -0.014236,\n",
       "           -0.058722, -0.016729,  0.013232, -0.035423,  0.075776,  0.037391, -0.047659,  0.051028, -0.013416,  0.058605,  0.079933,\n",
       "            0.057840, -0.059577, -0.002374,  0.008577,  0.008674, -0.066213,  0.063545, -0.072142,  0.026035, -0.000996,  0.054034,\n",
       "           -0.069052, -0.068826,  0.066694,  0.013881,  0.075492, -0.052132, -0.034386,  0.055198,  0.022763, -0.073908, -0.061430,\n",
       "           -0.009325, -0.002765,  0.036341,  0.015754,  0.076676,  0.044584, -0.073466, -0.036956, -0.030919,  0.050317,  0.006866,\n",
       "           -0.027746, -0.038683, -0.068644,  0.024086,  0.011353, -0.025406,  0.004487],\n",
       "          [-0.042385,  0.027072, -0.015308, -0.005862,  0.064903,  0.049231, -0.047083, -0.012857, -0.020356,  0.036542, -0.040195,\n",
       "           -0.028181, -0.081135, -0.022118, -0.034974,  0.074270,  0.047990,  0.046458,  0.062477, -0.032182,  0.034079,  0.012443,\n",
       "           -0.006005, -0.073722,  0.019723,  0.005587, -0.011911, -0.062301, -0.051082,  0.059047, -0.056560, -0.040465, -0.038310,\n",
       "           -0.051388,  0.075021,  0.064034, -0.019864,  0.040610, -0.065189, -0.071020,  0.017799, -0.068970,  0.060668, -0.002516,\n",
       "           -0.030101,  0.050835,  0.073669, -0.070269, -0.050981,  0.045536,  0.011832, -0.014813,  0.029151, -0.059737, -0.014117,\n",
       "           -0.039306,  0.046842,  0.067333, -0.073070,  0.023840, -0.030807,  0.041248,  0.058340,  0.003114, -0.060831, -0.049361,\n",
       "           -0.069146,  0.066297,  0.055054,  0.042847, -0.021219, -0.037597,  0.072424,  0.020146, -0.036317,  0.040967,  0.044915,\n",
       "            0.008777, -0.018215, -0.021820,  0.017621, -0.045452,  0.044500,  0.059513, -0.060590,  0.058243,  0.004241,  0.055968,\n",
       "            0.016977, -0.002382,  0.064559, -0.079961, -0.030721,  0.003873, -0.002160, -0.047859,  0.032673,  0.049880, -0.023963,\n",
       "            0.057307, -0.062559, -0.076780,  0.033414, -0.075934, -0.070510,  0.036580, -0.008767,  0.045773,  0.054832, -0.014404,\n",
       "           -0.066302, -0.069773,  0.031387,  0.081120,  0.045585,  0.047043,  0.062466, -0.059100, -0.030737, -0.042019,  0.059230,\n",
       "            0.012993,  0.079190, -0.008952,  0.049482,  0.072195, -0.040021, -0.057996,  0.045063,  0.069023,  0.017146, -0.074583,\n",
       "           -0.074140, -0.077869,  0.060614,  0.019417, -0.006516, -0.007938, -0.058222, -0.046126, -0.005074,  0.052034, -0.049459,\n",
       "           -0.018459,  0.009617,  0.033989, -0.017340, -0.031031,  0.049268,  0.011222],\n",
       "          [ 0.071839, -0.069546, -0.081522,  0.026560,  0.080434, -0.050064,  0.030416, -0.051332,  0.062786, -0.062553, -0.014436,\n",
       "           -0.021446, -0.074013,  0.032988,  0.046907, -0.038956, -0.035001, -0.036364, -0.065186,  0.002414, -0.080791, -0.064940,\n",
       "            0.077159,  0.047991, -0.033036,  0.037759, -0.056956,  0.049631,  0.081435,  0.078230, -0.020186,  0.045118, -0.000960,\n",
       "            0.000835,  0.070447,  0.066556,  0.072892,  0.071711,  0.074141,  0.063719,  0.001741, -0.074705, -0.038832,  0.024195,\n",
       "           -0.055058,  0.024754, -0.010855, -0.063399,  0.054812,  0.023093,  0.021018, -0.026598, -0.044298, -0.050169,  0.029546,\n",
       "           -0.036680, -0.074243, -0.080877, -0.032583, -0.045905, -0.067359,  0.050656, -0.039368, -0.015618,  0.079046,  0.009253,\n",
       "           -0.064470,  0.043621,  0.067929, -0.032171, -0.072317, -0.035820, -0.061442, -0.036181,  0.024740, -0.012128,  0.036029,\n",
       "            0.072120,  0.022292, -0.021922,  0.025711,  0.051734,  0.065915, -0.036374, -0.056266,  0.022800, -0.050404, -0.056906,\n",
       "            0.041698, -0.074005, -0.081450, -0.066076,  0.001785, -0.070788,  0.050329, -0.051538, -0.042900, -0.045133,  0.028845,\n",
       "            0.058677, -0.047246,  0.007180,  0.059324, -0.001439, -0.079332,  0.040511,  0.071933,  0.052381,  0.036043, -0.042893,\n",
       "           -0.002739, -0.044170,  0.025615, -0.023978,  0.023344, -0.052604,  0.025160,  0.042986,  0.068514,  0.080493,  0.062266,\n",
       "           -0.044914, -0.079669, -0.064111,  0.050449,  0.026671,  0.045010, -0.027713,  0.041502, -0.003242,  0.050379, -0.063332,\n",
       "           -0.044373, -0.076884,  0.070735,  0.036772,  0.022143, -0.041709, -0.025353,  0.059361,  0.011792, -0.074033, -0.015388,\n",
       "           -0.033131, -0.021171,  0.043960,  0.021810, -0.026383, -0.007634,  0.008428]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.009832,  0.062295, -0.039765, -0.073711,  0.074219], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-7.370479e-02,  7.196674e-02,  5.777785e-02,  4.045662e-02,  3.640554e-02,  4.410785e-02,  3.166294e-02,  4.760089e-02,\n",
       "           -7.385305e-02, -7.035030e-02,  1.495692e-02, -4.445991e-02,  5.291305e-02, -2.660996e-02,  3.373498e-04, -4.970770e-02,\n",
       "           -9.561020e-03,  6.068232e-02, -1.017393e-03, -1.514713e-02,  1.869384e-02,  6.290890e-03, -3.960500e-03,  7.017618e-02,\n",
       "            5.707372e-03,  4.263153e-02, -2.436920e-02,  4.749177e-02,  2.254691e-02,  4.516038e-02, -6.545810e-02, -6.366925e-02,\n",
       "           -5.524643e-02,  6.545830e-02,  3.133798e-02, -8.596079e-03,  4.960354e-03, -8.104306e-02, -3.215016e-02, -5.256635e-02,\n",
       "           -7.996141e-02, -3.189108e-02,  4.755811e-02,  2.533018e-02,  6.795923e-02, -3.228818e-02, -2.465271e-02, -4.185329e-02,\n",
       "           -7.363103e-02,  3.028999e-02, -3.390669e-02,  3.362919e-02, -1.018452e-02, -6.730824e-02, -5.993827e-02,  5.777751e-02,\n",
       "            5.044413e-02, -3.257978e-02,  5.329800e-02,  4.408295e-02,  6.076838e-02,  1.577395e-02,  4.901078e-03, -3.557651e-02,\n",
       "            1.372796e-02,  3.060738e-02, -1.011660e-03,  7.163309e-02, -2.569321e-02, -4.236121e-02,  4.722169e-02, -8.076999e-02,\n",
       "           -7.151146e-02,  6.340002e-02, -2.099182e-03, -5.721821e-02,  5.418456e-03, -2.513393e-02, -5.345003e-02, -5.304936e-02,\n",
       "           -7.506299e-04, -2.123921e-02,  8.119571e-03,  3.405497e-02,  7.753978e-02, -6.072218e-02, -4.802640e-02,  3.276011e-02,\n",
       "            7.150657e-02,  7.414243e-02,  1.554657e-03,  2.712649e-03,  3.201042e-03, -1.030745e-02,  1.926254e-02,  7.288720e-02,\n",
       "            7.351079e-02, -4.923174e-02, -3.998773e-02,  3.468039e-02,  4.374345e-03, -2.340870e-02, -8.170204e-03,  4.490029e-02,\n",
       "           -5.455233e-02,  1.037535e-02, -7.457885e-02,  2.062622e-02,  3.363130e-02,  3.786150e-02,  3.896864e-02, -4.307665e-02,\n",
       "            6.147526e-02, -5.766672e-02,  7.001140e-02,  4.297276e-02, -1.617878e-02, -4.204039e-02, -7.374996e-05,  1.586940e-02,\n",
       "           -7.145685e-02,  7.591493e-02, -3.676982e-02,  6.200511e-02, -5.147127e-02, -3.114456e-02, -8.084755e-04, -2.964011e-02,\n",
       "           -3.707977e-03,  9.374956e-03, -4.700259e-02, -3.833119e-03, -7.824720e-02, -8.689588e-04,  5.058521e-02,  4.728852e-02,\n",
       "            4.460180e-02,  5.323056e-02, -3.237688e-02, -5.998741e-02, -1.547096e-02,  6.968553e-02,  8.102148e-02,  3.386277e-02,\n",
       "           -6.212917e-02, -1.774648e-02, -4.319952e-02,  5.850214e-02, -4.335364e-02, -6.254721e-03],\n",
       "          [ 6.400962e-02, -2.439899e-02, -4.681244e-02,  5.150757e-02,  7.671339e-03,  3.371515e-02, -3.475037e-02, -7.238366e-02,\n",
       "            6.736270e-02, -1.392314e-02,  8.112352e-02,  6.349119e-02,  6.917713e-02,  5.019483e-02, -4.534011e-02,  3.411316e-02,\n",
       "            1.059996e-02, -7.881615e-02,  7.499590e-02, -1.672207e-03, -3.622512e-02, -4.252449e-02,  3.716256e-02,  6.768411e-02,\n",
       "            7.938901e-02,  2.970203e-02,  5.597873e-02,  6.147721e-02,  4.179920e-02, -2.767654e-02, -2.015678e-02,  3.325855e-02,\n",
       "            4.749776e-02, -4.939066e-02, -1.401415e-04,  1.927885e-02, -7.504980e-02,  6.089895e-04,  4.903890e-03,  3.004408e-03,\n",
       "            3.652035e-02, -8.242942e-03,  8.152507e-02,  2.708347e-03,  2.420550e-02,  6.484341e-02,  5.330520e-02,  6.104921e-02,\n",
       "            7.036448e-02,  6.874022e-02,  2.605849e-02, -5.412518e-02,  7.882006e-02,  1.138390e-02, -2.110334e-02,  9.034754e-03,\n",
       "           -7.513814e-03,  4.021780e-02,  3.828531e-02,  1.642229e-02, -2.722825e-02, -7.637407e-02, -7.672179e-02, -7.525455e-03,\n",
       "            5.713921e-02,  1.695515e-02,  6.361184e-02,  5.246850e-02, -6.041835e-02,  6.621981e-03,  5.660110e-02,  7.670946e-02,\n",
       "            7.063552e-02, -5.677658e-02,  7.011999e-02, -6.421946e-02, -1.105557e-02,  6.858768e-02,  2.492514e-02,  6.109420e-02,\n",
       "            6.454505e-02, -7.001105e-02,  3.150319e-02,  2.872515e-02, -7.863051e-02, -2.230572e-02, -2.638975e-02,  6.376165e-02,\n",
       "           -6.506349e-02, -5.801362e-02,  4.324121e-02,  5.260272e-02, -6.513481e-02, -3.438308e-02, -3.889627e-02,  6.129253e-02,\n",
       "           -6.928033e-02,  3.542295e-03,  7.316487e-02, -2.770602e-03, -1.201636e-02, -1.508512e-02, -3.438121e-02,  4.854321e-02,\n",
       "            4.364057e-02,  6.106191e-02, -7.048401e-02, -9.836533e-03,  4.824512e-02, -6.573685e-02,  4.853383e-02,  7.869907e-02,\n",
       "            7.238176e-02, -4.304006e-02,  3.033555e-02, -4.073923e-02,  6.866047e-02,  7.679012e-02, -2.948246e-02,  1.813423e-02,\n",
       "            3.678564e-02,  2.312057e-02,  3.097187e-03,  6.921621e-02, -6.600101e-02,  5.723380e-02,  4.507324e-02,  4.495721e-02,\n",
       "            4.562725e-04,  5.646129e-02, -6.431479e-03,  7.652057e-03, -4.842193e-02,  7.559632e-02, -4.488912e-02, -5.973387e-05,\n",
       "            3.105803e-02,  2.527669e-02, -2.415384e-02, -2.219015e-02,  5.642772e-03,  7.268403e-02, -5.994464e-02,  3.097791e-02,\n",
       "           -1.010774e-03, -4.640584e-02, -6.324600e-02, -1.984525e-02, -2.381218e-02, -4.712176e-02],\n",
       "          [-1.885134e-02, -1.662849e-02, -3.925074e-02,  7.617464e-03,  6.799912e-02,  2.330789e-03,  2.192806e-02, -4.932001e-02,\n",
       "            3.764594e-02, -7.428556e-02, -6.053234e-02, -6.278420e-02,  6.391400e-02,  8.063199e-02,  5.924038e-03, -5.393748e-02,\n",
       "            6.649402e-02,  4.401387e-02,  1.344060e-02,  5.311885e-03, -3.598792e-02,  7.857818e-02,  2.042653e-02, -3.935010e-02,\n",
       "            4.286184e-02, -7.671365e-02,  2.278310e-02, -7.965394e-02,  7.361029e-02,  7.151492e-02, -6.255208e-02, -3.944002e-02,\n",
       "           -7.766037e-02,  3.723696e-03, -5.342350e-02,  6.567392e-02, -1.211769e-02, -3.142340e-02,  6.435392e-02,  7.723542e-02,\n",
       "            7.434759e-02, -3.783259e-02,  6.172662e-02,  2.432940e-02,  5.189926e-02,  6.675680e-02, -1.619127e-02, -5.593814e-02,\n",
       "           -3.225824e-02,  1.081866e-02, -4.432051e-02,  6.754231e-02,  6.321456e-02,  2.596379e-02, -1.328198e-02,  2.647510e-02,\n",
       "            1.130542e-02, -4.179423e-02,  7.077171e-02, -2.150806e-02,  7.932817e-03,  3.709700e-02, -5.246013e-02,  7.079137e-02,\n",
       "           -4.807571e-02,  3.177133e-02, -3.324278e-02,  4.255059e-02, -8.100040e-02,  6.282153e-02,  6.078877e-02,  3.847527e-02,\n",
       "            3.218935e-02, -1.657580e-02,  2.521007e-02, -1.867222e-02, -2.968243e-02, -1.953230e-02,  6.106176e-02, -2.454823e-02,\n",
       "            1.033921e-02,  1.145980e-02,  7.328593e-02, -2.492606e-02, -7.344919e-02,  3.344327e-03,  2.794896e-02, -3.498534e-02,\n",
       "            3.964176e-02,  6.666495e-02, -5.928017e-02, -3.068707e-03,  5.719070e-02, -4.570825e-02, -5.416412e-03,  4.382890e-02,\n",
       "            1.248084e-03,  2.207155e-03,  4.835766e-03, -2.730218e-05, -3.696266e-02, -7.554250e-02, -1.713807e-02, -4.626270e-02,\n",
       "            2.329679e-02,  6.127901e-02,  3.674276e-02,  4.041209e-02,  1.093576e-02,  3.114181e-03, -1.476727e-02,  3.094404e-02,\n",
       "           -2.887064e-02, -2.429087e-02,  4.137634e-02,  4.834349e-02,  3.825413e-02,  7.358339e-02,  3.293351e-02,  2.997653e-03,\n",
       "            2.140265e-02, -7.372227e-02,  6.835248e-02,  3.859852e-02, -2.594007e-02,  1.719413e-02, -2.010950e-02, -6.721122e-02,\n",
       "           -7.200965e-02,  6.172126e-02,  5.730112e-02, -5.742668e-02,  4.982222e-02,  2.613722e-02, -5.180188e-02, -4.546857e-02,\n",
       "           -6.328305e-02, -4.149766e-03,  9.755658e-03, -3.012925e-02,  1.827308e-02,  5.741733e-02, -6.169411e-02,  6.774921e-02,\n",
       "            7.894217e-02,  3.853989e-02,  3.660144e-02, -3.159710e-02,  3.726811e-02, -6.370796e-02],\n",
       "          [ 2.570824e-02, -1.702240e-02, -1.066058e-02,  7.354400e-02, -3.862055e-02, -4.529233e-03,  5.368973e-02, -1.581276e-02,\n",
       "           -5.440135e-02, -3.977998e-02, -7.149213e-02, -4.473956e-03,  1.872477e-02,  2.501651e-02, -7.474902e-02,  4.606957e-02,\n",
       "           -4.500061e-02, -7.580341e-03,  2.283856e-02, -7.079958e-02, -6.547435e-02,  3.891731e-02, -5.827685e-02,  4.409905e-02,\n",
       "            6.702155e-03, -1.199019e-02, -7.662471e-02,  4.987621e-02,  6.366675e-02,  1.247627e-04, -1.713730e-02,  1.727462e-02,\n",
       "            5.780602e-02, -2.663845e-02,  3.269884e-02,  5.776126e-02, -2.772490e-02,  6.981448e-02,  7.753827e-02, -3.982922e-02,\n",
       "           -7.544832e-02, -4.208994e-02,  6.193798e-02, -5.056627e-02, -6.753937e-03,  2.980403e-02, -5.820874e-03, -3.507660e-02,\n",
       "           -6.540738e-02, -6.981292e-02,  1.693885e-02,  5.930868e-02,  4.149067e-02,  4.057552e-03,  1.988836e-02, -6.418546e-02,\n",
       "            5.272445e-02, -3.383671e-02,  4.245061e-02,  2.382741e-02, -2.556876e-03, -7.308097e-02, -1.403338e-02, -1.835132e-02,\n",
       "           -3.485183e-02, -2.806305e-02, -3.707185e-02,  2.949872e-03, -1.615547e-02,  7.431138e-03, -4.254787e-02,  4.292795e-02,\n",
       "           -4.249449e-02, -1.170346e-02, -3.333592e-02, -5.050747e-02, -3.975562e-02, -3.224926e-02, -5.981479e-02, -7.767336e-02,\n",
       "           -1.532809e-02, -7.097439e-02, -4.905446e-02,  6.815352e-02, -6.788208e-02, -1.146607e-02, -1.069918e-02,  1.475739e-03,\n",
       "           -3.364647e-02, -1.459602e-02,  2.871874e-02,  2.000620e-02, -3.251294e-02, -7.017066e-02,  2.595897e-02,  6.218154e-02,\n",
       "           -4.125857e-02, -5.511294e-02, -2.925246e-02,  4.664868e-02, -3.749002e-02, -3.738112e-03,  6.207684e-02, -8.871583e-03,\n",
       "           -6.014398e-02, -3.283754e-02,  1.075083e-02,  3.792034e-02,  7.252264e-02, -2.347322e-02,  3.507226e-03, -5.154302e-02,\n",
       "            1.448733e-02,  3.795595e-02,  3.886417e-02,  7.223392e-02,  7.122750e-02,  7.045774e-02, -7.012349e-03, -2.006503e-02,\n",
       "            1.981141e-02, -6.638458e-02,  1.059111e-02,  4.891521e-02, -9.291298e-03,  5.424849e-02,  1.807046e-02, -7.004765e-02,\n",
       "            4.339772e-03,  2.438842e-02,  1.149541e-02, -1.593494e-02,  2.163517e-02,  1.024107e-02,  3.523012e-02, -4.418322e-02,\n",
       "            3.431603e-02, -2.388835e-02, -6.702796e-02,  4.993322e-02,  5.704393e-02,  1.393242e-02, -8.354146e-03, -2.057050e-02,\n",
       "            7.007297e-03, -4.628830e-02, -7.876883e-02,  6.352921e-03, -5.429876e-02, -5.325322e-02],\n",
       "          [-5.748697e-02, -4.820074e-02,  2.302367e-02,  7.624521e-02, -4.420996e-02,  3.566210e-02, -5.936295e-02, -1.278024e-03,\n",
       "           -3.270307e-02,  4.799060e-02, -1.741451e-02, -6.301511e-02, -6.663792e-02, -4.147811e-02, -4.830819e-02, -5.942311e-02,\n",
       "           -4.905564e-02, -2.833528e-03,  2.763032e-02,  6.950665e-02,  5.593739e-02, -6.644884e-02, -6.654081e-02,  4.468679e-02,\n",
       "           -4.182876e-02, -7.495321e-02, -5.150582e-02, -7.694674e-02,  1.141225e-02,  2.786341e-03,  6.667007e-02, -1.954444e-02,\n",
       "            4.281755e-02, -1.935152e-02,  2.567792e-02, -1.431976e-02, -1.793659e-02, -1.979841e-02,  4.224763e-02,  1.926349e-02,\n",
       "            3.655955e-02, -1.846074e-02,  6.041044e-02,  4.819809e-02,  7.240845e-02, -5.815837e-02, -4.211790e-02, -3.542012e-02,\n",
       "            3.478541e-03, -5.838869e-02,  8.046493e-02,  2.187815e-03,  8.379784e-03, -4.101138e-03, -7.151455e-02,  1.118458e-02,\n",
       "           -3.089512e-02,  4.352307e-02, -3.626915e-02,  8.113465e-02, -1.112963e-02, -7.790548e-02, -1.897557e-02,  3.203766e-02,\n",
       "           -6.311101e-02, -1.515029e-02, -2.806781e-02,  4.859837e-02, -2.689148e-02,  4.235524e-02, -7.922740e-02,  4.335066e-02,\n",
       "            2.866135e-02,  3.092405e-02, -1.172621e-02,  2.536134e-02,  3.539414e-03, -7.696051e-02, -6.355433e-02,  3.956985e-02,\n",
       "            4.012107e-04,  4.461724e-02,  3.588944e-02,  5.340302e-02,  4.188066e-02,  5.251037e-02, -3.906697e-02,  4.506252e-02,\n",
       "           -3.599812e-02, -8.020910e-02,  3.679070e-02,  1.543655e-02, -1.689486e-02,  6.805021e-02, -3.770178e-02,  6.345560e-02,\n",
       "            5.652846e-03, -1.967833e-02, -7.014058e-02,  5.199378e-02, -7.710643e-02,  2.200942e-02, -4.176933e-02, -1.510780e-02,\n",
       "           -4.618258e-02, -2.739124e-02, -6.030301e-02, -4.265550e-02, -5.850587e-02, -5.904282e-02,  6.119446e-02, -8.120117e-03,\n",
       "           -8.849051e-03,  1.618748e-02,  4.344000e-02, -4.808329e-02, -4.642237e-03,  5.825288e-02, -1.688537e-02, -6.192483e-02,\n",
       "            6.555413e-02,  1.396581e-02, -6.376436e-02, -5.242561e-02,  4.702506e-03, -7.914351e-02,  7.618558e-02,  1.252594e-02,\n",
       "           -1.380677e-02,  1.356880e-02,  2.589166e-02, -3.567715e-02,  5.271972e-02,  5.922431e-02,  4.229691e-02,  1.027555e-02,\n",
       "           -6.016151e-02, -1.466675e-02,  7.883449e-02,  5.023886e-02, -2.881526e-02,  6.594075e-02,  3.202884e-02,  2.564260e-02,\n",
       "            6.329042e-02, -3.469146e-02,  1.706576e-02,  1.089626e-02,  6.891234e-02,  3.511877e-02]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.026783, -0.034074,  0.043837,  0.017333,  0.000220], requires_grad=True)],\n",
       " 'lr': 0.001,\n",
       " 'momentum': 0.9,\n",
       " 'dampening': 0,\n",
       " 'weight_decay': 0.0001,\n",
       " 'nesterov': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.optimizers['weights'].param_groups[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320fdeee",
   "metadata": {},
   "source": [
    "###  Weights and Biases Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c2469c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:45:12.404842Z",
     "start_time": "2022-03-25T09:45:08.158917Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkbardool\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1oii7m2w 0325_1044 AdaSparseChem\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kbardool/kusanagi/AdaSparseChem/wandb/run-20220325_104508-1oii7m2w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"http://localhost:8080/kbardool/AdaSparseChem/runs/1oii7m2w\" target=\"_blank\">0325_1044</a></strong> to <a href=\"http://localhost:8080/kbardool/AdaSparseChem\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PROJECT NAME: AdaSparseChem\n",
      " RUN ID      : 1oii7m2w \n",
      " RUN NAME    : 0325_1044\n",
      " PROJECT NAME: AdaSparseChem\n",
      " RUN ID      : 1oii7m2w \n",
      " RUN NAME    : 0325_1044\n"
     ]
    }
   ],
   "source": [
    "init_wandb(ns, opt, environment = environ)\n",
    "\n",
    "print(f\" PROJECT NAME: {ns.wandb_run.project}\\n\"\n",
    "      f\" RUN ID      : {ns.wandb_run.id} \\n\"\n",
    "      f\" RUN NAME    : {ns.wandb_run.name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d949180d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:45:12.508156Z",
     "start_time": "2022-03-25T09:45:12.411763Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d738062",
   "metadata": {},
   "source": [
    "### Initiate / Resume Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bd2a36e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:45:12.596382Z",
     "start_time": "2022-03-25T09:45:12.512684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############### Initiate Training  ###############\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "if opt['train']['resume']:\n",
    "    print(opt['train']['which_iter'])\n",
    "    print(opt['paths']['checkpoint_dir'])\n",
    "    print(RESUME_MODEL_CKPT)\n",
    "    # opt['train']['resume'] = True\n",
    "    # opt['train']['which_iter'] = 'warmup_ep_40_seed_0088'\n",
    "if opt['train']['resume']:\n",
    "    print_separator('Resume training')\n",
    "    loaded_iter, loaded_epoch = environ.load_checkpoint(RESUME_MODEL_CKPT, path = opt['paths']['checkpoint_dir'], verbose = True)\n",
    "    print(loaded_iter, loaded_epoch)    \n",
    "#     current_iter = environ.load_checkpoint(opt['train']['which_iter'])\n",
    "    environ.networks['mtl-net'].reset_logits()\n",
    "    val_metrics = load_from_pickle(opt['paths']['checkpoint_dir'], RESUME_METRICS_CKPT)\n",
    "    # training_prep(ns, opt, environ, dldrs, epoch = loaded_epoch, iter = loaded_iter )\n",
    "\n",
    "else:\n",
    "    print_separator('Initiate Training ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7774f",
   "metadata": {},
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8b6afdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:45:14.516249Z",
     "start_time": "2022-03-25T09:45:14.415693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cuda available [0]\n",
      " set print_freq to length of train loader: 105\n",
      " set eval_iters to length of val loader  : 33\n"
     ]
    }
   ],
   "source": [
    "training_prep(ns, opt, environ, dldrs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ea212ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:45:15.215715Z",
     "start_time": "2022-03-25T09:45:15.160925Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:18.146907Z",
     "iopub.status.busy": "2022-01-07T22:44:18.145721Z",
     "iopub.status.idle": "2022-01-07T22:44:18.191126Z",
     "shell.execute_reply": "2022-01-07T22:44:18.189994Z",
     "shell.execute_reply.started": "2022-01-07T22:44:18.146867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Num_blocks                : 6                                \n",
      "\n",
      " batch size                : 128 \n",
      " batches/ Weight trn epoch : 105 \n",
      " batches/ Policy trn epoch : 105                                 \n",
      "\n",
      " Print Frequency           : -1 \n",
      " Config Val Frequency      : 500 \n",
      " Config Val Iterations     : -1 \n",
      " Val iterations            : 33 \n",
      " which_iter                : warmup \n",
      " train_resume              : False                                 \n",
      " \n",
      " fix BN parms              : False \n",
      " Task LR                   : 0.001 \n",
      " Backbone LR               : 0.001                                 \n",
      "\n",
      " Sharing  regularization   : 0.01 \n",
      " Sparsity regularization   : 0.03 \n",
      " Task     regularization   : 1                                 \n",
      "\n",
      " Current epoch             : 0  \n",
      " Warm-up epochs            : 75 \n",
      " Training epochs           : 125\n"
     ]
    }
   ],
   "source": [
    "disp_info_1(ns, opt, environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61bc6107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:45:16.746907Z",
     "start_time": "2022-03-25T09:45:16.680169Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:18.146907Z",
     "iopub.status.busy": "2022-01-07T22:44:18.145721Z",
     "iopub.status.idle": "2022-01-07T22:44:18.191126Z",
     "shell.execute_reply": "2022-01-07T22:44:18.189994Z",
     "shell.execute_reply.started": "2022-01-07T22:44:18.146867Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    folder: 150x6_0325_1044_plr0.01_sp0.03_sh0.01_lr0.001\n",
      "    layers: 6 [150, 150, 150, 150, 150, 150] \n",
      "    \n",
      "    middle dropout         : 0.5\n",
      "    last dropout           : 0.5\n",
      "    diff_sparsity_weights  : False\n",
      "    skip_layer             : 0\n",
      "    is_curriculum          : False\n",
      "    curriculum_speed       : 3\n",
      "    \n",
      "    task_lr                : 0.001\n",
      "    backbone_lr            : 0.001\n",
      "    decay_lr_rate          : 0.75\n",
      "    decay_lr_freq          : 40\n",
      "    \n",
      "    policy_lr              : 0.01\n",
      "    policy_decay_lr_rate   : 0.75\n",
      "    policy_decay_lr_freq   : 50\n",
      "    lambda_sparsity        : 0.03\n",
      "    lambda_sharing         : 0.01\n",
      "    lambda_tasks           : 1\n",
      "    \n",
      "    Gumbel init_temp       : 4\n",
      "    Gumbel decay_temp      : 0.965\n",
      "    Gumbel decay_temp_freq : 16\n",
      "    Logit init_method      : random\n",
      "    Logit init_neg_logits  : None\n",
      "    Logit hard_sampling    : False\n",
      "    Warm-up epochs         : 75\n",
      "    training epochs        : 125\n",
      "    Data split ratios      : [0.725, 0.225, 0.05]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(environ.disp_for_excel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278d6d1",
   "metadata": {},
   "source": [
    "## Warmup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92380a48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:45:20.283955Z",
     "start_time": "2022-03-25T09:45:20.214660Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 0\n",
      "------------------------------------------------------------------------\n",
      " Last Epoch: 0   # of warm-up epochs to do:  75 - Run epochs 1 to 75\n",
      "------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# environ.display_trained_policy(ns.current_epoch,out=sys.stdout)\n",
    "# ns.stop_epoch_warmup = 10\n",
    "# ns.warmup_epochs = 10\n",
    "print(ns.warmup_epochs, ns.current_epoch)\n",
    "print_heading(f\" Last Epoch: {ns.current_epoch}   # of warm-up epochs to do:  {ns.warmup_epochs} - Run epochs {ns.current_epoch+1} to {ns.current_epoch + ns.warmup_epochs}\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8be9d65b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:58:06.090749Z",
     "start_time": "2022-03-25T09:45:21.666309Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      " Last Epoch: 0   # of warm-up epochs to do:  75 - Run epochs 1 to 75\n",
      "------------------------------------------------------------------------ \n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "    1 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |   10.3443   6.2375e-02   1.8974e-04   10.4069 |   0.68862   0.57713   0.58059   0.57676 |   10.3291   6.2375e-02   1.8974e-04    10.3917 |   9.3 |\n",
      "    2 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    9.8342   6.2375e-02   1.8974e-04    9.8967 |   0.68006   0.61722   0.62208   0.61689 |   10.2011   6.2375e-02   1.8974e-04    10.2637 |   9.9 |\n",
      "    3 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    9.8170   6.2375e-02   1.8974e-04    9.8795 |   0.67029   0.63643   0.64230   0.63612 |   10.0561   6.2375e-02   1.8974e-04    10.1186 |   8.8 |\n",
      "    4 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    9.8681   6.2375e-02   1.8974e-04    9.9307 |   0.66223   0.65462   0.66007   0.65435 |    9.9335   6.2375e-02   1.8974e-04     9.9961 |   9.7 |\n",
      "    5 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    9.2626   6.2375e-02   1.8974e-04    9.3251 |   0.65366   0.67100   0.67565   0.67074 |    9.8058   6.2375e-02   1.8974e-04     9.8683 |   9.9 |\n",
      "    6 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    9.0800   6.2375e-02   1.8974e-04    9.1425 |   0.64307   0.68350   0.68832   0.68325 |    9.6483   6.2375e-02   1.8974e-04     9.7109 |   9.4 |\n",
      "    7 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    9.2420   6.2375e-02   1.8974e-04    9.3045 |   0.63513   0.69472   0.69877   0.69448 |    9.5294   6.2375e-02   1.8974e-04     9.5920 |   9.3 |\n",
      "    8 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.5643   6.2375e-02   1.8974e-04    8.6269 |   0.62831   0.70328   0.70771   0.70305 |    9.4227   6.2375e-02   1.8974e-04     9.4853 |  10.6 |\n",
      "    9 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.9463   6.2375e-02   1.8974e-04    9.0088 |   0.62225   0.71090   0.71699   0.71068 |    9.3278   6.2375e-02   1.8974e-04     9.3904 |  10.0 |\n",
      "   10 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.4007   6.2375e-02   1.8974e-04    8.4633 |   0.61830   0.71818   0.72260   0.71798 |    9.2823   6.2375e-02   1.8974e-04     9.3448 |  15.4 |\n",
      "   11 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.0336   6.2375e-02   1.8974e-04    8.0962 |   0.60968   0.72691   0.73029   0.72675 |    9.1422   6.2375e-02   1.8974e-04     9.2047 |   9.6 |\n",
      "   12 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.9491   6.2375e-02   1.8974e-04    8.0117 |   0.60601   0.73345   0.73709   0.73329 |    9.0868   6.2375e-02   1.8974e-04     9.1494 |   9.9 |\n",
      "   13 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.1763   6.2375e-02   1.8974e-04    8.2389 |   0.60220   0.73853   0.74210   0.73838 |    9.0308   6.2375e-02   1.8974e-04     9.0934 |  10.9 |\n",
      "   14 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.1355   6.2375e-02   1.8974e-04    8.1981 |   0.59901   0.74292   0.74588   0.74278 |    8.9880   6.2375e-02   1.8974e-04     9.0506 |   9.7 |\n",
      "   15 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.1888   6.2375e-02   1.8974e-04    7.2513 |   0.59251   0.74793   0.75082   0.74779 |    8.8819   6.2375e-02   1.8974e-04     8.9445 |   9.7 |\n",
      "   16 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.3901   6.2375e-02   1.8974e-04    7.4527 |   0.58936   0.75335   0.75589   0.75321 |    8.8502   6.2375e-02   1.8974e-04     8.9127 |   9.9 |\n",
      "   17 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.3965   6.2375e-02   1.8974e-04    7.4590 |   0.58217   0.75721   0.76016   0.75707 |    8.7421   6.2375e-02   1.8974e-04     8.8047 |   9.4 |\n",
      "   18 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.3732   6.2375e-02   1.8974e-04    7.4357 |   0.57988   0.76265   0.76586   0.76251 |    8.6941   6.2375e-02   1.8974e-04     8.7567 |  10.2 |\n",
      "   19 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.9103   6.2375e-02   1.8974e-04    6.9729 |   0.57648   0.76656   0.76932   0.76643 |    8.6414   6.2375e-02   1.8974e-04     8.7040 |  10.1 |\n",
      "   20 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.1584   6.2375e-02   1.8974e-04    7.2209 |   0.57232   0.76911   0.77232   0.76895 |    8.5750   6.2375e-02   1.8974e-04     8.6376 |   9.5 |\n",
      "   21 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.5784   6.2375e-02   1.8974e-04    6.6410 |   0.56801   0.77355   0.77669   0.77342 |    8.5210   6.2375e-02   1.8974e-04     8.5836 |   8.8 |\n",
      "   22 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.7952   6.2375e-02   1.8974e-04    6.8577 |   0.56553   0.77766   0.78067   0.77752 |    8.4773   6.2375e-02   1.8974e-04     8.5398 |   9.8 |\n",
      "   23 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.9960   6.2375e-02   1.8974e-04    6.0586 |   0.56252   0.78085   0.78323   0.78073 |    8.4377   6.2375e-02   1.8974e-04     8.5003 |   9.7 |\n",
      "   24 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.6955   6.2375e-02   1.8974e-04    6.7580 |   0.56079   0.78346   0.78596   0.78332 |    8.3954   6.2375e-02   1.8974e-04     8.4580 |   9.6 |\n",
      "   25 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.0033   6.2375e-02   1.8974e-04    6.0659 |   0.55725   0.78651   0.78880   0.78640 |    8.3578   6.2375e-02   1.8974e-04     8.4204 |   9.1 |\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   26 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.8678   6.2375e-02   1.8974e-04    5.9303 |   0.54941   0.79025   0.79286   0.79013 |    8.2454   6.2375e-02   1.8974e-04     8.3080 |   9.9 |\n",
      "   27 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.8987   6.2375e-02   1.8974e-04    5.9613 |   0.55221   0.79132   0.79253   0.79121 |    8.2884   6.2375e-02   1.8974e-04     8.3510 |   9.7 |\n",
      "   28 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.9619   6.2375e-02   1.8974e-04    6.0245 |   0.54639   0.79500   0.79679   0.79490 |    8.1995   6.2375e-02   1.8974e-04     8.2621 |   9.9 |\n",
      "   29 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.8073   6.2375e-02   1.8974e-04    5.8699 |   0.54948   0.79613   0.79814   0.79601 |    8.2381   6.2375e-02   1.8974e-04     8.3007 |   9.2 |\n",
      "   30 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.9556   6.2375e-02   1.8974e-04    6.0181 |   0.54257   0.79930   0.80062   0.79920 |    8.1367   6.2375e-02   1.8974e-04     8.1992 |   9.9 |\n",
      "   31 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.4395   6.2375e-02   1.8974e-04    5.5021 |   0.53962   0.80139   0.80244   0.80129 |    8.0963   6.2375e-02   1.8974e-04     8.1589 |  10.1 |\n",
      "   32 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.0647   6.2375e-02   1.8974e-04    5.1273 |   0.53862   0.80287   0.80370   0.80277 |    8.0801   6.2375e-02   1.8974e-04     8.1426 |  10.4 |\n",
      "   33 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.4372   6.2375e-02   1.8974e-04    5.4998 |   0.53757   0.80436   0.80526   0.80426 |    8.0577   6.2375e-02   1.8974e-04     8.1203 |   9.7 |\n",
      "   34 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.3865   6.2375e-02   1.8974e-04    5.4491 |   0.53695   0.80591   0.80675   0.80581 |    8.0422   6.2375e-02   1.8974e-04     8.1048 |  10.0 |\n",
      "   35 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.3283   6.2375e-02   1.8974e-04    5.3908 |   0.53958   0.80583   0.80718   0.80573 |    8.1035   6.2375e-02   1.8974e-04     8.1661 |   9.5 |\n",
      "   36 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.8219   6.2375e-02   1.8974e-04    4.8845 |   0.53884   0.80834   0.80960   0.80824 |    8.0760   6.2375e-02   1.8974e-04     8.1385 |   9.7 |\n",
      "   37 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.7347   6.2375e-02   1.8974e-04    4.7973 |   0.53496   0.81006   0.81060   0.80997 |    8.0277   6.2375e-02   1.8974e-04     8.0903 |   9.6 |\n",
      "   38 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.4950   6.2375e-02   1.8974e-04    4.5576 |   0.53521   0.81123   0.81215   0.81113 |    8.0193   6.2375e-02   1.8974e-04     8.0819 |  10.3 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.8681   6.2375e-02   1.8974e-04    4.9307 |   0.53333   0.81173   0.81285   0.81164 |    7.9961   6.2375e-02   1.8974e-04     8.0586 |   9.7 |\n",
      "   40 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.7278   6.2375e-02   1.8974e-04    4.7904 |   0.53278   0.81354   0.81405   0.81345 |    7.9919   6.2375e-02   1.8974e-04     8.0545 |  10.2 |\n",
      "   41 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.2963   6.2375e-02   1.8974e-04    3.3589 |   0.53259   0.81279   0.81431   0.81269 |    7.9821   6.2375e-02   1.8974e-04     8.0447 |   9.5 |\n",
      "   42 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.0915   6.2375e-02   1.8974e-04    5.1541 |   0.53672   0.81416   0.81482   0.81406 |    8.0455   6.2375e-02   1.8974e-04     8.1080 |  11.1 |\n",
      "   43 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.5429   6.2375e-02   1.8974e-04    4.6055 |   0.53364   0.81394   0.81395   0.81385 |    7.9934   6.2375e-02   1.8974e-04     8.0560 |  10.3 |\n",
      "   44 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.8341   6.2375e-02   1.8974e-04    4.8967 |   0.53550   0.81475   0.81501   0.81466 |    8.0139   6.2375e-02   1.8974e-04     8.0764 |  10.8 |\n",
      "   45 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.0625   6.2375e-02   1.8974e-04    4.1251 |   0.53544   0.81510   0.81584   0.81500 |    8.0401   6.2375e-02   1.8974e-04     8.1027 |  10.3 |\n",
      "   46 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.3834   6.2375e-02   1.8974e-04    4.4460 |   0.53362   0.81759   0.81806   0.81750 |    7.9971   6.2375e-02   1.8974e-04     8.0597 |  10.0 |\n",
      "   47 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.6204   6.2375e-02   1.8974e-04    4.6830 |   0.53465   0.81737   0.81750   0.81728 |    8.0182   6.2375e-02   1.8974e-04     8.0808 |   9.4 |\n",
      "   48 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.3600   6.2375e-02   1.8974e-04    4.4226 |   0.53851   0.81843   0.81872   0.81834 |    8.0879   6.2375e-02   1.8974e-04     8.1505 |   9.2 |\n",
      "   49 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.2671   6.2375e-02   1.8974e-04    4.3296 |   0.53927   0.81906   0.81886   0.81897 |    8.0865   6.2375e-02   1.8974e-04     8.1490 |   9.2 |\n",
      "   50 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.1904   6.2375e-02   1.8974e-04    4.2530 |   0.53752   0.81990   0.81968   0.81981 |    8.0521   6.2375e-02   1.8974e-04     8.1147 |   9.3 |\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   51 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.9241   6.2375e-02   1.8974e-04    3.9866 |   0.53598   0.81988   0.82022   0.81979 |    8.0488   6.2375e-02   1.8974e-04     8.1114 |   9.0 |\n",
      "   52 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.6720   6.2375e-02   1.8974e-04    4.7346 |   0.53517   0.82091   0.82091   0.82082 |    8.0241   6.2375e-02   1.8974e-04     8.0867 |   9.2 |\n",
      "   53 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.3524   6.2375e-02   1.8974e-04    3.4149 |   0.53578   0.82021   0.82049   0.82011 |    8.0329   6.2375e-02   1.8974e-04     8.0954 |   8.9 |\n",
      "   54 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.5884   6.2375e-02   1.8974e-04    3.6510 |   0.53739   0.82032   0.82025   0.82022 |    8.0547   6.2375e-02   1.8974e-04     8.1173 |   9.4 |\n",
      "   55 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.7353   6.2375e-02   1.8974e-04    3.7979 |   0.53857   0.82296   0.82260   0.82287 |    8.0755   6.2375e-02   1.8974e-04     8.1381 |   9.1 |\n",
      "   56 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.9224   6.2375e-02   1.8974e-04    3.9849 |   0.53950   0.82244   0.82231   0.82235 |    8.0933   6.2375e-02   1.8974e-04     8.1559 |   9.3 |\n",
      "   57 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.0464   6.2375e-02   1.8974e-04    4.1090 |   0.54480   0.82246   0.82201   0.82236 |    8.1746   6.2375e-02   1.8974e-04     8.2372 |   9.7 |\n",
      "   58 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.5542   6.2375e-02   1.8974e-04    3.6168 |   0.54039   0.82268   0.82303   0.82257 |    8.0840   6.2375e-02   1.8974e-04     8.1465 |  11.8 |\n",
      "   59 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.9521   6.2375e-02   1.8974e-04    3.0146 |   0.54309   0.82286   0.82276   0.82277 |    8.1489   6.2375e-02   1.8974e-04     8.2115 |  12.3 |\n",
      "   60 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.8809   6.2375e-02   1.8974e-04    2.9435 |   0.54809   0.82324   0.82299   0.82315 |    8.2298   6.2375e-02   1.8974e-04     8.2923 |  10.2 |\n",
      "   61 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.9082   6.2375e-02   1.8974e-04    3.9707 |   0.54554   0.82328   0.82318   0.82319 |    8.1823   6.2375e-02   1.8974e-04     8.2449 |  10.9 |\n",
      "   62 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.4637   6.2375e-02   1.8974e-04    3.5262 |   0.54538   0.82467   0.82398   0.82458 |    8.1851   6.2375e-02   1.8974e-04     8.2476 |  10.9 |\n",
      "   63 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.3953   6.2375e-02   1.8974e-04    3.4579 |   0.55035   0.82335   0.82333   0.82325 |    8.2480   6.2375e-02   1.8974e-04     8.3106 |   9.2 |\n",
      "   64 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.6041   6.2375e-02   1.8974e-04    3.6667 |   0.55250   0.82433   0.82431   0.82424 |    8.2860   6.2375e-02   1.8974e-04     8.3485 |  10.5 |\n",
      "   65 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.8837   6.2375e-02   1.8974e-04    2.9462 |   0.55399   0.82330   0.82336   0.82321 |    8.3046   6.2375e-02   1.8974e-04     8.3672 |  10.0 |\n",
      "   66 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.8784   6.2375e-02   1.8974e-04    2.9410 |   0.55424   0.82414   0.82395   0.82405 |    8.3161   6.2375e-02   1.8974e-04     8.3786 |  10.2 |\n",
      "   67 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.6047   6.2375e-02   1.8974e-04    3.6673 |   0.55829   0.82404   0.82402   0.82394 |    8.3752   6.2375e-02   1.8974e-04     8.4378 |   9.6 |\n",
      "   68 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.4455   6.2375e-02   1.8974e-04    3.5080 |   0.55509   0.82455   0.82430   0.82445 |    8.3185   6.2375e-02   1.8974e-04     8.3810 |  10.9 |\n",
      "   69 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.5227   6.2375e-02   1.8974e-04    3.5852 |   0.56169   0.82501   0.82389   0.82491 |    8.4095   6.2375e-02   1.8974e-04     8.4720 |  10.7 |\n",
      "   70 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.1484   6.2375e-02   1.8974e-04    3.2110 |   0.56382   0.82455   0.82367   0.82445 |    8.4356   6.2375e-02   1.8974e-04     8.4981 |  10.9 |\n",
      "   71 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.8620   6.2375e-02   1.8974e-04    2.9245 |   0.56076   0.82542   0.82443   0.82533 |    8.4152   6.2375e-02   1.8974e-04     8.4778 |  10.6 |\n",
      "   72 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.9374   6.2375e-02   1.8974e-04    3.0000 |   0.56918   0.82542   0.82496   0.82532 |    8.5348   6.2375e-02   1.8974e-04     8.5974 |  10.4 |\n",
      "   73 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.1523   6.2375e-02   1.8974e-04    3.2149 |   0.56344   0.82590   0.82506   0.82581 |    8.4417   6.2375e-02   1.8974e-04     8.5043 |  10.1 |\n",
      "   74 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.2271   6.2375e-02   1.8974e-04    3.2897 |   0.56946   0.82623   0.82567   0.82614 |    8.5487   6.2375e-02   1.8974e-04     8.6113 |   9.3 |\n",
      "   75 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.1401   6.2375e-02   1.8974e-04    3.2026 |   0.56641   0.82659   0.82666   0.82649 |    8.5051   6.2375e-02   1.8974e-04     8.5676 |   9.5 |\n",
      "[Final] ep:75  it:7875 -  Total Loss: 8.5676     \n",
      "Task: 8.5051   Sparsity: 6.23750e-02    Sharing: 1.89744e-04 \n",
      "\n",
      " epch:  75   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.4997    0.5003  0    0.5001    0.4999  1    0.5000    0.5000  1\n",
      "   2    0.5001    0.4999  1    0.5001    0.4999  1    0.4995    0.5005  0\n",
      "   3    0.5002    0.4998  1    0.4997    0.5003  0    0.5001    0.4999  1\n",
      "   4    0.5004    0.4996  1    0.5007    0.4993  1    0.5000    0.5000  0\n",
      "   5    0.4997    0.5003  0    0.5004    0.4996  1    0.4993    0.5007  0\n",
      "   6    0.4998    0.5002  0    0.4999    0.5001  0    0.4996    0.5004  0\n",
      "\n",
      "\n",
      "\n",
      " epch:  75   logits       s          logits      s         logits       s\n",
      " -----  ----------------- -    ----------------  -    ----------------  - \n",
      "   1   -0.0011    0.0001  0   -0.0009   -0.0012  1    0.0006    0.0005  1\n",
      "   2    0.0002   -0.0004  1    0.0002   -0.0001  1   -0.0003    0.0018  0\n",
      "   3   -0.0011   -0.0019  1   -0.0000    0.0010  0    0.0004   -0.0002  1\n",
      "   4    0.0014   -0.0001  1    0.0018   -0.0009  1    0.0006    0.0006  0\n",
      "   5   -0.0009    0.0004  0    0.0008   -0.0008  1   -0.0023    0.0003  0\n",
      "   6   -0.0001    0.0007  0   -0.0003    0.0003  0   -0.0016    0.0002  0\n",
      "\n",
      "\n",
      " save warmup val_metrics to :  model_warmup_ep_75\n",
      " save warmup checkpoint  to :  model_warmup_ep_75\n"
     ]
    }
   ],
   "source": [
    "# warmup_phase(ns,opt, environ, dldrs, epochs = 25)\n",
    "warmup_phase(ns,opt, environ, dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05b99542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T21:44:30.672751Z",
     "start_time": "2022-03-24T21:44:30.591558Z"
    }
   },
   "outputs": [],
   "source": [
    "# warmup_phase(ns,opt, environ, dldrs, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3dc43cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T21:44:30.990570Z",
     "start_time": "2022-03-24T21:44:30.929741Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06410fec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T21:44:31.240474Z",
     "start_time": "2022-03-24T21:44:31.176977Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29d68d54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T21:44:31.880310Z",
     "start_time": "2022-03-24T21:44:31.827007Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# environ.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46fadf1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T21:44:32.326057Z",
     "start_time": "2022-03-24T21:44:32.259212Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# environ.val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea84c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04d238e8",
   "metadata": {},
   "source": [
    "#### display parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e22e75ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T11:39:36.168928Z",
     "start_time": "2022-03-25T11:39:36.065057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone Learning Rate      : 0.001\n",
      " Tasks    Learning Rate      : 0.001\n",
      " Policy   Learning Rate      : 0.01\n",
      "\n",
      " Sparsity regularization     : 0.03\n",
      " Sharing  regularization     : 0.01 \n",
      "\n",
      " Tasks    regularization     : 1   \n",
      " Gumbel Temp                 : 4.0000         \n",
      " Gumbel Temp decay           : 16\n",
      " current lr:  0.01\n",
      " current lr:  0.001\n",
      " current lr:  0.001\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #\n",
    "print(' current lr: ', environ.optimizers['alphas'].param_groups[0]['lr'],)\n",
    "print(' current lr: ', environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "print(' current lr: ', environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2db34fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T21:44:33.516966Z",
     "start_time": "2022-03-24T21:44:33.448462Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['policy_lr'] = 0.01\n",
    "# opt['train']['policy_lr']         = 0.01\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.1\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# environ.opt['train']['decay_temp_freq'] = 2\n",
    "# print(environ.optimizers['alphas'].param_groups)\n",
    "# print(environ.optimizers['weights'].param_groups)\n",
    "# print('initial lr: ', environ.optimizers['alphas'].param_groups[0]['initial_lr'] , 'current lr: ', environ.optimizers['alphas'].param_groups[0]['lr'],)\n",
    "# print('current lr: ', environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "# print('current lr: ', environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49645c",
   "metadata": {},
   "source": [
    "## Weight & Policy Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aade16",
   "metadata": {},
   "source": [
    "### Weight/Policy Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fe24a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T21:44:35.165637Z",
     "start_time": "2022-03-24T21:44:35.112114Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.flag_warmup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "365996be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T11:39:42.033447Z",
     "start_time": "2022-03-25T11:39:41.973256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "** 2022-03-25 12:39:41:997292 \n",
      "** Training epoch: 75 iter: 7875   flag: update_weights \n",
      "** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\n",
      "** Switch from Warm Up training to Alternate training Weights & Policy \n",
      "** Take checkpoint and block gradient flow through Policy net\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if ns.flag_warmup:\n",
    "    print_heading( f\"** {timestring()} \\n\"\n",
    "                   f\"** Training epoch: {ns.current_epoch} iter: {ns.current_iter}   flag: {ns.flag} \\n\"\n",
    "                   f\"** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\\n\"\n",
    "                   f\"** Switch from Warm Up training to Alternate training Weights & Policy \\n\"\n",
    "                   f\"** Take checkpoint and block gradient flow through Policy net\", verbose=True)\n",
    "#     environ.define_optimizer(policy_learning=True)\n",
    "#     environ.define_scheduler(policy_learning=True)\n",
    "    ns.flag_warmup = False\n",
    "    ns.flag = 'update_weights'\n",
    "    environ.fix_alpha()\n",
    "    environ.free_weights(opt['fix_BN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8593384c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T11:39:42.603625Z",
     "start_time": "2022-03-25T11:39:42.540961Z"
    }
   },
   "outputs": [],
   "source": [
    "# num_train_layers = None \n",
    "# environ.opt['is_curriculum'] = True\n",
    "# environ.opt['curriculum_speed'] = 4\n",
    "# ns.num_train_layers = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "753d84a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T11:39:44.218984Z",
     "start_time": "2022-03-25T11:39:44.162506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 125\n",
      "ns.current_epoch           : 75\n",
      "ns.current_iters           : 7875 \n",
      "\n",
      "ns.training_epochs         : 125\n",
      "Batches in weight epoch    : 105\n",
      "Batches in policy epoch    : 105\n",
      "num_train_layers           : None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ns.current_epoch,ns.training_epochs)\n",
    "print(f\"ns.current_epoch           : {ns.current_epoch}\") \n",
    "print(f\"ns.current_iters           : {ns.current_iter} \\n\")  \n",
    "print(f\"ns.training_epochs         : {ns.training_epochs}\") \n",
    "# print(f\"ns.stop_epoch_training     : {ns.stop_epoch_training}\")\n",
    "print(f\"Batches in weight epoch    : {ns.stop_iter_w}\")\n",
    "print(f\"Batches in policy epoch    : {ns.stop_iter_a}\")\n",
    "print(f\"num_train_layers           : {ns.num_train_layers}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25e913c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T11:39:44.532709Z",
     "start_time": "2022-03-25T11:39:44.476154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[e] Last ep:75  it:7875 -  Total Loss: 8.5676     \n",
      "Task: 8.5051   Sparsity: 6.23750e-02    Sharing: 1.89744e-04 \n"
     ]
    }
   ],
   "source": [
    "ns.training_epochs = 250\n",
    "print_loss(environ.val_metrics, title = f\"[e] Last ep:{ns.current_epoch}  it:{ns.current_iter}\")\n",
    "# environ.display_trained_policy(ns.current_epoch)\n",
    "# environ.display_trained_logits(ns.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a1c72de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T11:39:45.143991Z",
     "start_time": "2022-03-25T11:39:45.060883Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.current_epoch = 200\n",
    "# ns.flag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fcd6751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T11:39:45.620329Z",
     "start_time": "2022-03-25T11:39:45.558264Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed : 75       # of epochs to run:  250 -->  epochs 76 to 325\n",
      " policy_learning rate : 0.01 \n",
      " lambda_sparsity      : 0.03\n",
      " lambda_sharing       : 0.01\n",
      " curriculum training  : False     cirriculum speed: 3     num_training_layers : None\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_heading(f\" Last Epoch Completed : {ns.current_epoch}       # of epochs to run:  {ns.training_epochs} -->  epochs {ns.current_epoch+1} to {ns.training_epochs + ns.current_epoch}\"\n",
    "              f\"\\n policy_learning rate : {environ.opt['train']['policy_lr']} \"\n",
    "              f\"\\n lambda_sparsity      : {environ.opt['train']['lambda_sparsity']}\"\n",
    "              f\"\\n lambda_sharing       : {environ.opt['train']['lambda_sharing']}\"\n",
    "              f\"\\n curriculum training  : {opt['is_curriculum']}     cirriculum speed: {opt['curriculum_speed']}     num_training_layers : {ns.num_train_layers}\", \n",
    "              verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c71af",
   "metadata": {},
   "source": [
    "### Weight/Policy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ad7d8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-25T11:39:45.877Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed : 75   # of epochs to run:  250 -->  epochs 76 to 325    \n",
      " policy_learning rate : 0.01      \n",
      " lambda_sparsity      : 0.03\n",
      " lambda_sharing       : 0.01 \n",
      " curriculum training  : False     cirriculum speed: 3     num_training_layers : None\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   76 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.9032   6.2375e-02   1.8974e-04    2.9658 |   0.59069   0.80070   0.80344   0.80060 |    8.8564   6.2375e-02   1.8974e-04     8.9189 |  13.4 |\n",
      "Previous best_epoch:     0   best iter:     0,   best_value: 0.00000\n",
      "New      best_epoch:    76   best iter:  7980,   best_value: 0.80070\n",
      "   76 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.5756   8.9609e-02   4.7025e-04    2.6657 |   0.62010   0.80679   0.80890   0.80666 |    9.3061   8.9770e-02   3.5669e-04     9.3962 |  12.6 |\n",
      "Previous best_epoch:    76   best iter:  7980,   best_value: 0.80070\n",
      "New      best_epoch:    76   best iter:  8085,   best_value: 0.80679\n",
      "   77 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.6672   8.9770e-02   3.5669e-04    2.7573 |   0.62512   0.80731   0.80819   0.80721 |    9.3940   8.9770e-02   3.5669e-04     9.4842 |  15.0 |\n",
      "Previous best_epoch:    76   best iter:  8085,   best_value: 0.80679\n",
      "New      best_epoch:    77   best iter:  8190,   best_value: 0.80731\n",
      "   77 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.8849   9.8785e-02   3.5931e-04    2.9841 |   0.63068   0.81032   0.81126   0.81020 |    9.4578   9.8808e-02   3.3787e-04     9.5570 |  11.3 |\n",
      "Previous best_epoch:    77   best iter:  8190,   best_value: 0.80731\n",
      "New      best_epoch:    77   best iter:  8295,   best_value: 0.81032\n",
      "   78 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.5298   9.8808e-02   3.3786e-04    2.6289 |   0.61959   0.80974   0.81206   0.80963 |    9.2658   9.8808e-02   3.3787e-04     9.3649 |  15.3 |\n",
      "   78 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.6739   9.8845e-02   3.6657e-04    2.7732 |   0.64924   0.81151   0.81227   0.81140 |    9.7244   9.8833e-02   2.8156e-04     9.8235 |  12.0 |\n",
      "Previous best_epoch:    77   best iter:  8295,   best_value: 0.81032\n",
      "New      best_epoch:    78   best iter:  8505,   best_value: 0.81151\n",
      "   79 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.4835   9.8833e-02   2.8156e-04    2.5826 |   0.64298   0.81381   0.81567   0.81372 |    9.6456   9.8833e-02   2.8156e-04     9.7447 |  15.4 |\n",
      "Previous best_epoch:    78   best iter:  8505,   best_value: 0.81151\n",
      "New      best_epoch:    79   best iter:  8610,   best_value: 0.81381\n",
      "   79 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.7081   1.0209e-01   3.1272e-04    2.8105 |   0.64844   0.81175   0.81289   0.81164 |    9.7418   1.0198e-01   3.0774e-04     9.8441 |  12.8 |\n",
      "   80 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.0069   1.0198e-01   3.0774e-04    3.1092 |   0.65341   0.81016   0.81137   0.81007 |    9.7877   1.0198e-01   3.0774e-04     9.8900 |  17.3 |\n",
      "   80 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.7484   9.4375e-02   2.9598e-04    2.8431 |   0.63538   0.80800   0.81046   0.80788 |    9.5373   9.4222e-02   3.2643e-04     9.6318 |  13.0 |\n",
      "\n",
      "[e] Policy training epoch:80  it:8925 -  Total Loss: 9.6318     \n",
      "Task: 9.5373   Sparsity: 9.42221e-02    Sharing: 3.26432e-04 \n",
      "\n",
      " epch:  80   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.4933    0.5067  0    0.5674    0.4326  1    0.4234    0.5766  0\n",
      "   2    0.6483    0.3517  1    0.6261    0.3739  1    0.6771    0.3229  1\n",
      "   3    0.6028    0.3972  1    0.6358    0.3642  1    0.6647    0.3353  1\n",
      "   4    0.8444    0.1556  1    0.8507    0.1493  1    0.8454    0.1546  1\n",
      "   5    0.7162    0.2838  1    0.7149    0.2851  1    0.6706    0.3294  1\n",
      "   6    0.3811    0.6189  0    0.3659    0.6341  0    0.3303    0.6697  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   81 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.2738   9.4222e-02   3.2643e-04    3.3683 |   0.66136   0.81064   0.81236   0.81054 |    9.8945   9.4222e-02   3.2643e-04     9.9890 |  13.6 |\n",
      "   81 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.7732   9.5457e-02   3.1950e-04    2.8690 |   0.64754   0.81059   0.81143   0.81049 |    9.6980   9.5400e-02   2.8037e-04     9.7937 |  12.3 |\n",
      "   82 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    2.9481   9.5400e-02   2.8037e-04    3.0438 |   0.65854   0.81260   0.81368   0.81250 |    9.8834   9.5400e-02   2.8037e-04     9.9791 |  16.8 |\n",
      "Epoch    82: reducing learning rate of group 0 to 7.5000e-04.\n",
      "Epoch    82: reducing learning rate of group 1 to 7.5000e-04.\n",
      "   82 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.2835   8.9134e-02   3.0585e-04    2.3729 |   0.66020   0.80995   0.81089   0.80985 |    9.8868   8.9112e-02   2.9541e-04     9.9762 |  11.6 |\n",
      "   83 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    3.2258   8.9112e-02   2.9541e-04    3.3152 |   0.65885   0.81114   0.81256   0.81104 |    9.8804   8.9112e-02   2.9541e-04     9.9698 |  14.5 |\n",
      "   83 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.2057   8.4381e-02   4.4179e-04    2.2905 |   0.64627   0.80940   0.81123   0.80930 |    9.7141   8.4378e-02   4.0240e-04     9.7988 |  11.2 |\n",
      "   84 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.9411   8.4378e-02   4.0240e-04    3.0259 |   0.64787   0.81001   0.81127   0.80991 |    9.7268   8.4378e-02   4.0240e-04     9.8115 |  15.0 |\n",
      "   84 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.7530   8.2526e-02   3.7612e-04    2.8359 |   0.64485   0.81169   0.81285   0.81159 |    9.6656   8.2498e-02   3.8804e-04     9.7484 |  11.0 |\n",
      "   85 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.7214   8.2498e-02   3.8804e-04    2.8043 |   0.65927   0.81194   0.81309   0.81184 |    9.8584   8.2498e-02   3.8804e-04     9.9413 |  15.8 |\n",
      "   85 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    1.9899   8.5254e-02   3.2124e-04    2.0754 |   0.66487   0.80974   0.81222   0.80963 |    9.9830   8.5390e-02   3.6438e-04    10.0688 |  13.1 |\n",
      "\n",
      "[e] Policy training epoch:85  it:9975 -  Total Loss: 10.0688     \n",
      "Task: 9.9830   Sparsity: 8.53901e-02    Sharing: 3.64383e-04 \n",
      "\n",
      " epch:  85   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.4478    0.5522  0    0.5221    0.4779  1    0.4064    0.5936  0\n",
      "   2    0.6390    0.3610  1    0.6637    0.3363  1    0.6611    0.3389  1\n",
      "   3    0.5697    0.4303  1    0.6585    0.3415  1    0.6172    0.3828  1\n",
      "   4    0.8058    0.1942  1    0.8350    0.1650  1    0.7863    0.2137  1\n",
      "   5    0.6368    0.3632  1    0.6309    0.3691  1    0.5867    0.4133  1\n",
      "   6    0.3579    0.6421  0    0.3340    0.6660  0    0.3492    0.6508  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   86 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.1761   8.5390e-02   3.6438e-04    2.2619 |   0.65549   0.80862   0.81185   0.80850 |    9.8184   8.5390e-02   3.6438e-04     9.9042 |  16.4 |\n",
      "   86 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.1574   8.0401e-02   4.9833e-04    2.2383 |   0.66970   0.81110   0.81275   0.81100 |   10.0523   8.0353e-02   4.8089e-04    10.1331 |  11.9 |\n",
      "   87 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.2733   8.0353e-02   4.8089e-04    2.3541 |   0.63436   0.80938   0.81281   0.80926 |    9.5086   8.0353e-02   4.8089e-04     9.5894 |  14.9 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   87 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.5133   7.8480e-02   1.9979e-04    2.5920 |   0.64675   0.80878   0.81156   0.80867 |    9.7281   7.8529e-02   2.6835e-04     9.8069 |  10.6 |\n",
      "   88 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.5355   7.8529e-02   2.6835e-04    2.6143 |   0.64162   0.80849   0.81182   0.80840 |    9.6366   7.8529e-02   2.6835e-04     9.7154 |  14.4 |\n",
      "   88 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.2297   8.3823e-02   5.2425e-04    2.3140 |   0.67408   0.80787   0.81009   0.80778 |   10.0769   8.3970e-02   4.5137e-04    10.1614 |  10.9 |\n",
      "   89 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.3032   8.3970e-02   4.5137e-04    2.3876 |   0.66568   0.81229   0.81409   0.81219 |   10.0015   8.3970e-02   4.5137e-04    10.0859 |  14.8 |\n",
      "   89 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.9681   8.1361e-02   3.5664e-04    3.0498 |   0.65547   0.81282   0.81370   0.81272 |    9.8153   8.1314e-02   3.8608e-04     9.8970 |  11.6 |\n",
      "   90 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.6238   8.1314e-02   3.8608e-04    2.7055 |   0.67616   0.81272   0.81404   0.81262 |   10.1207   8.1314e-02   3.8608e-04    10.2024 |  14.5 |\n",
      "   90 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.2500   7.8961e-02   3.1659e-04    2.3293 |   0.65826   0.81152   0.81259   0.81143 |    9.8738   7.8917e-02   3.2061e-04     9.9530 |  10.9 |\n",
      "\n",
      "[e] Policy training epoch:90  it:11025 -  Total Loss: 9.9530     \n",
      "Task: 9.8738   Sparsity: 7.89170e-02    Sharing: 3.20608e-04 \n",
      "\n",
      " epch:  90   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.3315    0.6685  0    0.4610    0.5390  0    0.3042    0.6958  0\n",
      "   2    0.6818    0.3182  1    0.6717    0.3283  1    0.6647    0.3353  1\n",
      "   3    0.5344    0.4656  1    0.5638    0.4362  1    0.5927    0.4073  1\n",
      "   4    0.8211    0.1789  1    0.7932    0.2068  1    0.8190    0.1810  1\n",
      "   5    0.5924    0.4076  1    0.5546    0.4454  1    0.5501    0.4499  1\n",
      "   6    0.2925    0.7075  0    0.2877    0.7123  0    0.3021    0.6979  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   91 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    1.8889   7.8917e-02   3.2061e-04    1.9681 |   0.66759   0.80913   0.81247   0.80902 |   10.0285   7.8917e-02   3.2061e-04    10.1078 |  13.7 |\n",
      "   91 |   7.50e-04   7.50e-04   1.00e-02  4.000e+00 |    2.9663   7.9208e-02   3.8711e-04    3.0459 |   0.66465   0.81038   0.81256   0.81027 |   10.0284   7.9169e-02   2.8383e-04    10.1079 |  10.8 |\n",
      " decay gumbel softmax to 3.86\n",
      "   92 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.5983   7.9169e-02   2.8383e-04    2.6777 |   0.66899   0.81155   0.81316   0.81146 |   10.0229   7.9169e-02   2.8383e-04    10.1023 |  14.2 |\n",
      "   92 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.6080   7.9349e-02   2.9098e-04    2.6876 |   0.65947   0.81172   0.81358   0.81162 |    9.8875   7.9375e-02   2.8658e-04     9.9671 |  11.8 |\n",
      "   93 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.1824   7.9375e-02   2.8658e-04    2.2621 |   0.65768   0.81048   0.81314   0.81038 |    9.9321   7.9375e-02   2.8658e-04    10.0118 |  15.0 |\n",
      "   93 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.7453   7.8714e-02   4.3801e-04    2.8244 |   0.68476   0.81179   0.81421   0.81169 |   10.2542   7.8714e-02   4.9872e-04    10.3334 |  10.7 |\n",
      "   94 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.4576   7.8714e-02   4.9872e-04    2.5368 |   0.66410   0.81063   0.81330   0.81050 |    9.9595   7.8714e-02   4.9872e-04    10.0387 |  16.1 |\n",
      "   94 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.6463   7.9850e-02   2.9627e-04    2.7265 |   0.65448   0.80822   0.81160   0.80810 |    9.8448   7.9844e-02   4.4625e-04     9.9251 |  11.6 |\n",
      "   95 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.1541   7.9844e-02   4.4625e-04    2.2344 |   0.65074   0.81228   0.81464   0.81219 |    9.7708   7.9844e-02   4.4625e-04     9.8511 |  15.1 |\n",
      "   95 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.3918   7.7128e-02   5.2640e-04    2.4694 |   0.68519   0.81191   0.81369   0.81181 |   10.2720   7.7183e-02   5.2702e-04    10.3497 |  12.0 |\n",
      "\n",
      "[e] Policy training epoch:95  it:12075 -  Total Loss: 10.3497     \n",
      "Task: 10.2720   Sparsity: 7.71827e-02    Sharing: 5.27018e-04 \n",
      "\n",
      " epch:  95   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.2840    0.7160  0    0.3846    0.6154  0    0.2610    0.7390  0\n",
      "   2    0.6614    0.3386  1    0.6481    0.3519  1    0.6703    0.3297  1\n",
      "   3    0.5815    0.4185  1    0.6037    0.3963  1    0.6394    0.3606  1\n",
      "   4    0.8232    0.1768  1    0.8127    0.1873  1    0.7695    0.2305  1\n",
      "   5    0.5397    0.4603  1    0.5870    0.4130  1    0.4890    0.5110  0\n",
      "   6    0.2976    0.7024  0    0.3151    0.6849  0    0.2759    0.7241  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   96 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.1658   7.7183e-02   5.2702e-04    2.2435 |   0.66507   0.80924   0.81318   0.80912 |    9.9830   7.7183e-02   5.2702e-04    10.0607 |  15.6 |\n",
      "   96 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.5589   7.8450e-02   2.1976e-04    2.6375 |   0.66778   0.81261   0.81486   0.81251 |   10.0232   7.8409e-02   2.7075e-04    10.1019 |  12.0 |\n",
      "   97 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.4209   7.8409e-02   2.7075e-04    2.4996 |   0.66678   0.80963   0.81240   0.80952 |   10.0250   7.8409e-02   2.7075e-04    10.1037 |  15.1 |\n",
      "   97 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    1.7951   7.8331e-02   3.5035e-04    1.8738 |   0.68580   0.81168   0.81367   0.81155 |   10.2784   7.8346e-02   3.7875e-04    10.3572 |  12.1 |\n",
      "   98 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.4852   7.8346e-02   3.7875e-04    2.5640 |   0.67203   0.81031   0.81266   0.81021 |   10.0780   7.8346e-02   3.7875e-04    10.1567 |  15.5 |\n",
      "   98 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    1.9523   7.6719e-02   3.3998e-04    2.0293 |   0.68267   0.81321   0.81411   0.81310 |   10.2490   7.6763e-02   3.3839e-04    10.3261 |  12.0 |\n",
      "   99 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.2517   7.6763e-02   3.3839e-04    2.3288 |   0.66526   0.80977   0.81218   0.80967 |    9.9902   7.6763e-02   3.3839e-04    10.0673 |  15.6 |\n",
      "   99 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    1.7768   7.9903e-02   3.5028e-04    1.8571 |   0.67843   0.80981   0.81296   0.80970 |   10.1781   7.9854e-02   3.1446e-04    10.2582 |  11.7 |\n",
      "  100 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.5818   7.9853e-02   3.1446e-04    2.6620 |   0.70394   0.81096   0.81362   0.81086 |   10.5811   7.9854e-02   3.1446e-04    10.6613 |  15.3 |\n",
      "  100 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    1.9689   7.5349e-02   3.7415e-04    2.0447 |   0.68113   0.81203   0.81437   0.81194 |   10.2738   7.5326e-02   3.1458e-04    10.3495 |  12.4 |\n",
      "\n",
      "[e] Policy training epoch:100  it:13125 -  Total Loss: 10.3495     \n",
      "Task: 10.2738   Sparsity: 7.53260e-02    Sharing: 3.14581e-04 \n",
      "\n",
      " epch: 100   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.2731    0.7269  0    0.3663    0.6337  0    0.2917    0.7083  0\n",
      "   2    0.6626    0.3374  1    0.6261    0.3739  1    0.7201    0.2799  1\n",
      "   3    0.4862    0.5138  0    0.5893    0.4107  1    0.6149    0.3851  1\n",
      "   4    0.7684    0.2316  1    0.7924    0.2076  1    0.7840    0.2160  1\n",
      "   5    0.5779    0.4221  1    0.5809    0.4191  1    0.5626    0.4374  1\n",
      "   6    0.2709    0.7291  0    0.3088    0.6912  0    0.2443    0.7557  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  101 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.4162   7.5326e-02   3.1458e-04    2.4919 |   0.68227   0.81277   0.81538   0.81266 |   10.2172   7.5326e-02   3.1458e-04    10.2929 |  14.5 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  101 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.1510   7.5024e-02   2.7501e-04    2.2263 |   0.68595   0.81178   0.81377   0.81169 |   10.2628   7.5129e-02   2.5132e-04    10.3382 |  11.6 |\n",
      "  102 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.0833   7.5129e-02   2.5132e-04    2.1587 |   0.67866   0.80990   0.81273   0.80979 |   10.1576   7.5129e-02   2.5132e-04    10.2330 |  14.8 |\n",
      "  102 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.0288   6.9265e-02   3.7653e-04    2.0984 |   0.66689   0.81172   0.81374   0.81161 |   10.0140   6.9306e-02   3.3574e-04    10.0836 |  11.6 |\n",
      "  103 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.0494   6.9306e-02   3.3574e-04    2.1191 |   0.66958   0.80775   0.81189   0.80763 |   10.0584   6.9306e-02   3.3574e-04    10.1280 |  14.6 |\n",
      "  103 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.2328   6.9870e-02   3.3173e-04    2.3030 |   0.68997   0.81312   0.81426   0.81302 |   10.3281   6.9911e-02   3.4250e-04    10.3984 |  12.2 |\n",
      "  104 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.0003   6.9911e-02   3.4250e-04    2.0705 |   0.70396   0.80844   0.81189   0.80835 |   10.5550   6.9911e-02   3.4250e-04    10.6253 |  14.5 |\n",
      "  104 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.0187   6.7816e-02   2.5755e-04    2.0867 |   0.66470   0.80879   0.81178   0.80869 |    9.9866   6.7789e-02   2.6597e-04    10.0547 |  10.8 |\n",
      "  105 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.1727   6.7788e-02   2.6597e-04    2.2407 |   0.66708   0.81155   0.81498   0.81144 |   10.0407   6.7789e-02   2.6597e-04    10.1088 |  15.3 |\n",
      "  105 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.0497   7.0830e-02   2.6066e-04    2.1208 |   0.68997   0.80921   0.81188   0.80911 |   10.3585   7.1010e-02   3.6186e-04    10.4298 |  12.6 |\n",
      "\n",
      "[e] Policy training epoch:105  it:14175 -  Total Loss: 10.4298     \n",
      "Task: 10.3585   Sparsity: 7.10099e-02    Sharing: 3.61863e-04 \n",
      "\n",
      " epch: 105   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.2588    0.7412  0    0.3908    0.6092  0    0.2635    0.7365  0\n",
      "   2    0.6496    0.3504  1    0.6057    0.3943  1    0.6703    0.3297  1\n",
      "   3    0.5031    0.4969  1    0.5718    0.4282  1    0.5823    0.4177  1\n",
      "   4    0.7577    0.2423  1    0.7637    0.2363  1    0.7789    0.2211  1\n",
      "   5    0.5660    0.4340  1    0.5324    0.4676  1    0.5104    0.4896  1\n",
      "   6    0.2524    0.7476  0    0.2876    0.7124  0    0.2469    0.7531  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  106 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.9851   7.1010e-02   3.6186e-04    3.0565 |   0.69247   0.81045   0.81227   0.81034 |   10.3510   7.1010e-02   3.6186e-04    10.4223 |  15.0 |\n",
      "  106 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.0466   7.1898e-02   2.9507e-04    2.1188 |   0.69542   0.81207   0.81418   0.81197 |   10.4082   7.1969e-02   2.0941e-04    10.4804 |  11.2 |\n",
      "  107 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.0302   7.1969e-02   2.0941e-04    2.1024 |   0.70261   0.80858   0.81190   0.80847 |   10.5616   7.1969e-02   2.0941e-04    10.6338 |  14.9 |\n",
      "  107 |   7.50e-04   7.50e-04   1.00e-02  3.860e+00 |    2.0743   7.1526e-02   5.2998e-04    2.1463 |   0.67668   0.81235   0.81335   0.81226 |   10.1467   7.1613e-02   3.5779e-04    10.2187 |  11.8 |\n",
      " decay gumbel softmax to 3.7249\n",
      "  108 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    2.0622   7.1613e-02   3.5779e-04    2.1341 |   0.71271   0.81164   0.81447   0.81152 |   10.6584   7.1613e-02   3.5779e-04    10.7304 |  15.1 |\n",
      "  108 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    2.0342   7.4613e-02   3.2810e-04    2.1091 |   0.70652   0.81087   0.81398   0.81077 |   10.5641   7.4706e-02   2.7856e-04    10.6391 |  11.4 |\n",
      "  109 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.9981   7.4705e-02   2.7856e-04    2.0731 |   0.70214   0.81133   0.81337   0.81122 |   10.5553   7.4706e-02   2.7856e-04    10.6303 |  14.6 |\n",
      "  109 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    2.4650   7.2807e-02   3.4866e-04    2.5382 |   0.70323   0.81106   0.81337   0.81095 |   10.5407   7.2884e-02   3.7296e-04    10.6140 |  12.6 |\n",
      "  110 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    2.1592   7.2884e-02   3.7296e-04    2.2325 |   0.69063   0.80962   0.81296   0.80948 |   10.3409   7.2884e-02   3.7296e-04    10.4142 |  14.6 |\n",
      "  110 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    2.1300   7.1333e-02   3.3996e-04    2.2017 |   0.70904   0.81109   0.81254   0.81099 |   10.6036   7.1246e-02   4.4657e-04    10.6753 |  11.8 |\n",
      "\n",
      "[e] Policy training epoch:110  it:15225 -  Total Loss: 10.6753     \n",
      "Task: 10.6036   Sparsity: 7.12456e-02    Sharing: 4.46568e-04 \n",
      "\n",
      " epch: 110   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.2787    0.7213  0    0.3744    0.6256  0    0.2259    0.7741  0\n",
      "   2    0.6449    0.3551  1    0.5910    0.4090  1    0.6548    0.3452  1\n",
      "   3    0.4901    0.5099  0    0.5761    0.4239  1    0.6181    0.3819  1\n",
      "   4    0.7519    0.2481  1    0.7849    0.2151  1    0.7546    0.2454  1\n",
      "   5    0.5987    0.4013  1    0.5643    0.4357  1    0.4993    0.5007  0\n",
      "   6    0.2539    0.7461  0    0.2696    0.7304  0    0.2824    0.7176  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  111 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.9261   7.1246e-02   4.4657e-04    1.9978 |   0.69867   0.81039   0.81166   0.81030 |   10.4401   7.1246e-02   4.4657e-04    10.5117 |  14.9 |\n",
      "  111 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.8759   7.1957e-02   4.6504e-04    1.9484 |   0.71588   0.81113   0.81344   0.81103 |   10.7152   7.2025e-02   4.6843e-04    10.7877 |  11.4 |\n",
      "  112 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    2.4970   7.2025e-02   4.6843e-04    2.5695 |   0.70748   0.80910   0.81178   0.80899 |   10.6345   7.2025e-02   4.6843e-04    10.7070 |  15.1 |\n",
      "  112 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.8121   6.8993e-02   2.1345e-04    1.8813 |   0.69835   0.80950   0.81254   0.80940 |   10.5250   6.9021e-02   2.1918e-04    10.5943 |  11.6 |\n",
      "  113 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    2.2633   6.9021e-02   2.1918e-04    2.3326 |   0.70050   0.81138   0.81375   0.81128 |   10.4968   6.9021e-02   2.1918e-04    10.5660 |  15.6 |\n",
      "  113 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.9498   6.9887e-02   2.5465e-04    2.0200 |   0.70346   0.81110   0.81349   0.81101 |   10.5688   6.9853e-02   2.9161e-04    10.6390 |  11.1 |\n",
      "  114 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    2.0945   6.9853e-02   2.9161e-04    2.1647 |   0.68411   0.80852   0.81101   0.80841 |   10.2654   6.9853e-02   2.9161e-04    10.3356 |  15.5 |\n",
      "  114 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    2.1990   6.4182e-02   2.8300e-04    2.2634 |   0.71594   0.80828   0.81179   0.80818 |   10.7249   6.4156e-02   3.5295e-04    10.7894 |  10.3 |\n",
      "  115 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.7207   6.4156e-02   3.5295e-04    1.7852 |   0.70299   0.80605   0.81004   0.80594 |   10.5829   6.4156e-02   3.5295e-04    10.6474 |  15.0 |\n",
      "  115 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.5457   6.3810e-02   4.1688e-04    1.6099 |   0.67194   0.81013   0.81252   0.81002 |   10.1332   6.3793e-02   4.2945e-04    10.1974 |  11.0 |\n",
      "\n",
      "[e] Policy training epoch:115  it:16275 -  Total Loss: 10.1974     \n",
      "Task: 10.1332   Sparsity: 6.37931e-02    Sharing: 4.29452e-04 \n",
      "\n",
      " epch: 115   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.2816    0.7184  0    0.3547    0.6453  0    0.2251    0.7749  0\n",
      "   2    0.6236    0.3764  1    0.6303    0.3697  1    0.6083    0.3917  1\n",
      "   3    0.4653    0.5347  0    0.5469    0.4531  1    0.5662    0.4338  1\n",
      "   4    0.7044    0.2956  1    0.6951    0.3049  1    0.6961    0.3039  1\n",
      "   5    0.5560    0.4440  1    0.4639    0.5361  0    0.4762    0.5238  0\n",
      "   6    0.2567    0.7433  0    0.2874    0.7126  0    0.2268    0.7732  0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  116 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.9062   6.3793e-02   4.2945e-04    1.9704 |   0.69637   0.80863   0.81243   0.80853 |   10.4308   6.3793e-02   4.2945e-04    10.4950 |  14.8 |\n",
      "  116 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.7491   6.1782e-02   4.6018e-04    1.8114 |   0.67536   0.80758   0.81153   0.80748 |   10.1220   6.1785e-02   3.9774e-04    10.1842 |  12.0 |\n",
      "  117 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    2.0551   6.1785e-02   3.9774e-04    2.1173 |   0.69173   0.80728   0.81087   0.80717 |   10.3826   6.1785e-02   3.9774e-04    10.4448 |  15.6 |\n",
      "  117 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.9108   6.2830e-02   2.4953e-04    1.9738 |   0.68504   0.81096   0.81403   0.81085 |   10.2709   6.2840e-02   2.2896e-04    10.3339 |  12.1 |\n",
      "  118 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.7996   6.2840e-02   2.2896e-04    1.8626 |   0.70759   0.81192   0.81390   0.81182 |   10.5822   6.2840e-02   2.2896e-04    10.6452 |  16.1 |\n",
      "  118 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    2.2049   6.5076e-02   2.9451e-04    2.2702 |   0.69454   0.81178   0.81366   0.81167 |   10.4054   6.5192e-02   3.6485e-04    10.4709 |  10.8 |\n",
      "  119 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.7109   6.5192e-02   3.6485e-04    1.7765 |   0.69591   0.81064   0.81266   0.81054 |   10.4107   6.5192e-02   3.6485e-04    10.4763 |  14.8 |\n",
      "  119 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    2.1235   6.5088e-02   3.0900e-04    2.1889 |   0.71309   0.80911   0.81215   0.80900 |   10.6897   6.5118e-02   4.3372e-04    10.7553 |  11.1 |\n",
      "  120 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.6316   6.5118e-02   4.3372e-04    1.6972 |   0.72334   0.81165   0.81425   0.81155 |   10.8435   6.5118e-02   4.3372e-04    10.9090 |  15.2 |\n",
      "  120 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.8979   6.0366e-02   4.7257e-04    1.9587 |   0.70370   0.80791   0.81088   0.80780 |   10.5962   6.0220e-02   4.1309e-04    10.6568 |  11.9 |\n",
      "\n",
      "[e] Policy training epoch:120  it:17325 -  Total Loss: 10.6568     \n",
      "Task: 10.5962   Sparsity: 6.02204e-02    Sharing: 4.13095e-04 \n",
      "\n",
      " epch: 120   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.2313    0.7687  0    0.3243    0.6757  0    0.2050    0.7950  0\n",
      "   2    0.6149    0.3851  1    0.5859    0.4141  1    0.6240    0.3760  1\n",
      "   3    0.4126    0.5874  0    0.4936    0.5064  0    0.5457    0.4543  1\n",
      "   4    0.6470    0.3530  1    0.7127    0.2873  1    0.7082    0.2918  1\n",
      "   5    0.5560    0.4440  1    0.4786    0.5214  0    0.4474    0.5526  0\n",
      "   6    0.2110    0.7890  0    0.2320    0.7680  0    0.2341    0.7659  0\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "  121 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    2.0063   6.0220e-02   4.1309e-04    2.0670 |   0.72294   0.80632   0.81051   0.80622 |   10.8271   6.0220e-02   4.1309e-04    10.8878 |  15.6 |\n",
      "  121 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.9643   6.2477e-02   4.0252e-04    2.0272 |   0.71791   0.80760   0.81081   0.80749 |   10.7775   6.2435e-02   4.4621e-04    10.8404 |  11.0 |\n",
      "  122 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.4851   6.2435e-02   4.4621e-04    1.5480 |   0.71587   0.81079   0.81296   0.81069 |   10.7740   6.2435e-02   4.4621e-04    10.8369 |  16.1 |\n",
      "  122 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.7912   6.2061e-02   3.9923e-04    1.8537 |   0.72785   0.80996   0.81230   0.80987 |   10.9087   6.2011e-02   4.5333e-04    10.9712 |  11.6 |\n",
      "  123 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.7247   6.2011e-02   4.5333e-04    1.7872 |   0.70998   0.80692   0.81016   0.80682 |   10.6613   6.2011e-02   4.5333e-04    10.7238 |  15.3 |\n",
      "  123 |   7.50e-04   7.50e-04   1.00e-02  3.725e+00 |    1.9536   6.0461e-02   4.0298e-04    2.0144 |   0.71112   0.80775   0.81131   0.80765 |   10.6571   6.0531e-02   2.7341e-04    10.7179 |  12.7 |\n",
      " decay gumbel softmax to 3.5945284999999996\n",
      "  124 |   7.50e-04   7.50e-04   1.00e-02  3.595e+00 |    2.2698   6.0531e-02   2.7341e-04    2.3306 |   0.70043   0.80527   0.80957   0.80517 |   10.5516   6.0531e-02   2.7341e-04    10.6124 |  15.9 |\n",
      "  124 |   7.50e-04   7.50e-04   1.00e-02  3.595e+00 |    1.6327   6.5154e-02   4.4996e-04    1.6983 |   0.70067   0.81023   0.81184   0.81014 |   10.5632   6.5130e-02   3.3660e-04    10.6287 |  11.8 |\n",
      "validation:  58%|██████▉     | 19/33 [00:01<00:00, 14.79it/s, it=20, Lss=10.2256, Spr=6.5130e-02, Shr=3.3660e-04, lyr=6]            "
     ]
    }
   ],
   "source": [
    "# weight_policy_training(ns, opt, environ, dldrs, epochs = 100)\n",
    "weight_policy_training(ns, opt, environ, dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27779c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:44:18.873599Z",
     "start_time": "2022-03-25T09:44:18.727581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 10920, 0.8168097033305215)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns.best_epoch, ns.best_iter, ns.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be1060",
   "metadata": {},
   "source": [
    "### Close WandB run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c5f6dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T09:44:24.001425Z",
     "start_time": "2022-03-25T09:44:20.070831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72dcd994b8cf4d9a94a994617fe719e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='7.454 MB of 7.454 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_time</td><td>▁▁▁▁▁▂▅▄▅▅▅▅▅▅▄▅▄▅▅▄█▅▅▅▇▆▆▅▅▅▅▆▅▄▅▄▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>325</td></tr><tr><td>train_time</td><td>10.22264</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0324_2226</strong>: <a href=\"http://localhost:8080/kbardool/AdaSparseChem/runs/3r6r3abu\" target=\"_blank\">http://localhost:8080/kbardool/AdaSparseChem/runs/3r6r3abu</a><br/>Synced 7 W&B file(s), 1725 media file(s), 1732 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220324_222606-3r6r3abu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49cc3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T21:40:38.885929Z",
     "start_time": "2022-03-10T21:40:38.783808Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.best_epoch = 0\n",
    "# from utils.notebook_modules import wrapup_phase\n",
    "# wrapup_phase(ns, opt, environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1656da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T01:52:34.096090Z",
     "start_time": "2022-03-10T01:52:34.003457Z"
    }
   },
   "outputs": [],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #\n",
    "print(opt['train']['decay_temp_freq'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570db82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T23:15:53.792025Z",
     "start_time": "2022-03-09T23:15:53.736492Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['policy_lr']       = 0.002\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.05\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# # environ.opt['train']['decay_temp_freq'] = 2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26efa07b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:10:08.772444Z",
     "start_time": "2022-03-10T03:10:08.706432Z"
    }
   },
   "outputs": [],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #\n",
    "\n",
    "print()\n",
    "print( f\" current_iters               : {ns.current_iter}\")  \n",
    "print( f\" current_epochs              : {ns.current_epoch}\") \n",
    "print( f\" train_total_epochs          : {ns.training_epochs}\") \n",
    "print( f\" stop_epoch_training         : {ns.stop_epoch_training}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac6b6a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Post Training Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04de4040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T22:17:44.833671Z",
     "start_time": "2022-03-13T22:17:44.799394Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "# pp.pprint(environ.val_metrics)\n",
    "environ.num_layers, environ.networks['mtl-net'].num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ca92e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T23:23:43.744498Z",
     "start_time": "2022-03-10T23:23:43.696990Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.val_metrics['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e5cec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T17:44:36.218784Z",
     "start_time": "2022-02-21T17:44:36.063411Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "# environ.display_trained_policy(current_epoch)\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c1c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:32:52.580865Z",
     "start_time": "2022-03-06T00:32:52.554112Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_label   = 'model_train_ep_%d_seed_%04d' % (current_epoch, opt['random_seed'])\n",
    "# metrics_label = 'metrics_train_ep_%d_seed_%04d.pickle' % (current_epoch, opt['random_seed'])\n",
    "# environ.save_checkpoint(model_label, current_iter, current_epoch) \n",
    "# save_to_pickle(environ.val_metrics, environ.opt['paths']['checkpoint_dir'], metrics_label)\n",
    "# print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "# environ.display_trained_policy(current_epoch,out=[sys.stdout, environ.log_file])\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad3a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T22:48:27.014120Z",
     "start_time": "2022-02-20T22:48:26.982535Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_loss(current_iter, environ.losses, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")\n",
    "# print()\n",
    "# print_loss(current_iter, trn_losses, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")\n",
    "# print()\n",
    "# print_loss(current_iter, environ.val_metrics, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d5db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T20:31:45.254334Z",
     "start_time": "2022-03-01T20:31:45.116895Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.losses\n",
    "# environ.val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4dd81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T20:47:29.582501Z",
     "start_time": "2022-03-01T20:47:29.492581Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.batch_data\n",
    "# print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics, 0, out=[sys.stdout])\n",
    "# environ.display_parameters()\n",
    "\n",
    "# with np.printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', precision=7, formatter={'float': lambda x: f\"{x:12.5e}\"}):\n",
    "#     environ.print_logit_grads('gradients')\n",
    "\n",
    "# environ_params = environ.get_task_specific_parameters()\n",
    "# environ_params = environ.get_arch_parameters()\n",
    "# environ_params = environ.get_backbone_parameters()\n",
    "# print(environ_params)\n",
    "# for param in environ_params:\n",
    "#     print(param.grad.shape, '\\n', param.grad)\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c80c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:12:46.806056Z",
     "start_time": "2022-03-11T21:12:46.471801Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.display_trained_logits(ns.current_epoch)\n",
    "environ.display_trained_policy(ns.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d47dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:13:19.578964Z",
     "start_time": "2022-03-11T21:13:19.242252Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.display_test_sample_policy(ns.current_epoch, hard_sampling = True)\n",
    "environ.display_train_sample_policy(ns.current_epoch, hard_sampling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754b317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:33:19.474125Z",
     "start_time": "2022-03-06T00:33:19.447847Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.define_optimizer(policy_learning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e89541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T00:07:08.097708Z",
     "start_time": "2022-03-09T00:07:08.070721Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.optimizers['alphas'])\n",
    "print(environ.optimizers['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ecc91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T00:07:50.026992Z",
     "start_time": "2022-03-09T00:07:49.986101Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Policy  initial_lr : ', environ.optimizers['alphas'].param_groups[0]['initial_lr'], 'lr : ',environ.optimizers['alphas'].param_groups[0]['lr'])\n",
    "print('Weights initial_lr : ', environ.optimizers['weights'].param_groups[0]['initial_lr'], 'lr : ',environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "print('Weights initial_lr : ', environ.optimizers['weights'].param_groups[1]['initial_lr'], 'lr : ',environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1306e8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T22:31:50.425696Z",
     "start_time": "2022-03-10T22:31:50.396531Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wandb.run is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b8e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:10:03.751132Z",
     "start_time": "2022-03-05T23:10:03.724538Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# opt['exp_instance'] = '0218_1358'     \n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\"\n",
    "# print()\n",
    "# opt['exp_instance'] = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "# opt['exp_description'] = f\"No Alternating Weight/Policy - training all done with both weights and policy\"\n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2affee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:12:20.322227Z",
     "start_time": "2022-03-11T21:12:20.285961Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527bd00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:25:11.319751Z",
     "start_time": "2022-02-20T21:25:11.210062Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "p = environ.get_current_state(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919068f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:25:26.324030Z",
     "start_time": "2022-02-20T21:25:26.112782Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82a453",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Post Warm-up Training stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb74c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:45:43.999959Z",
     "start_time": "2022-02-01T12:45:43.862475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b47da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:36.700361Z",
     "start_time": "2022-02-01T12:46:36.367037Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].arch_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f0235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:37:10.158440Z",
     "start_time": "2022-01-28T16:37:09.742327Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p = environ.get_sample_policy(hard_sampling = False)\n",
    "print(p)\n",
    "p = environ.get_policy_prob()\n",
    "print(p)\n",
    "p = environ.get_policy_logits()\n",
    "print(p)\n",
    "\n",
    "# p = environ.get_current_policy()\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bddd44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:40:37.799917Z",
     "start_time": "2022-01-28T16:40:37.773177Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = softmax([0.0, 1])\n",
    "print(a)\n",
    "sampled = np.random.choice((1, 0), p=a)\n",
    "print(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8f376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:13:16.205889Z",
     "start_time": "2022-01-28T16:13:16.179303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.optimizers['weights'])\n",
    "print(environ.schedulers['weights'].get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf9c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:50.411465Z",
     "start_time": "2022-02-01T12:46:50.020540Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('losses.keys      : ', environ.losses.keys())\n",
    "print('losses[task]keys : ', environ.losses['task1'].keys())\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20950069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T22:57:02.151169Z",
     "start_time": "2022-01-15T22:57:02.056562Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print( environ.val_metrics.keys())\n",
    "# pp.pprint(val_metrics)\n",
    "print(type(environ.val_metrics['aggregated']))\n",
    "print()\n",
    "print(type(environ.val_metrics['task1']['classification_agg']))\n",
    "print()\n",
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6e311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.266303Z",
     "start_time": "2022-01-14T18:57:26.166878Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"val_metrics.pkl\", mode= 'wb') as f:\n",
    "#         pickle.dump(val_metrics, f)\n",
    "    \n",
    "# with open('val_metrics.pkl', 'rb') as f:    \n",
    "#     tst_val_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00a8aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.297444Z",
     "start_time": "2022-01-14T18:57:26.269323Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(environ.input.shape) \n",
    "# a = getattr(environ, 'task1_pred')\n",
    "# yc_data = environ.batch['task1_data']\n",
    "# print(yc_data.shape)\n",
    "# yc_ind = environ.batch['task1_ind']\n",
    "# print(yc_ind.shape)\n",
    "# yc_hat_all = getattr(environ, 'task1_pred')\n",
    "# print(yc_hat_all.shape)\n",
    "# yc_hat  = yc_hat_all[yc_ind[0], yc_ind[1]]\n",
    "# print(yc_hat_all.shape, yc_hat.shape)\n",
    "\n",
    "# \n",
    "# environ.losses\n",
    "# loss = {}\n",
    "# for key in environ.losses.keys():\n",
    "#     loss[key] = {}\n",
    "#     for subkey, v in environ.losses[key].items():\n",
    "#         print(f\" key:  {key}   subkey: {subkey} \")\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             loss[key][subkey] = v.data\n",
    "#             print(f\" Tensor  -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "#         else:\n",
    "#             loss[key][subkey] = v\n",
    "#             print(f\" integer -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "# pp.pprint(tst_val_metrics)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987f89f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.340792Z",
     "start_time": "2022-01-14T18:57:26.302528Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print('metrics.keys: ', environ.metrics.keys())\n",
    "# print('metrics[task].keys: ', environ.metrics['task1'].keys())\n",
    "# pp.pprint(environ.metrics['task1'])\n",
    "# pp.pprint(environ.losses['task1']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ae417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.373399Z",
     "start_time": "2022-01-14T18:57:26.345065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# title='Iteration'\n",
    "# for t_id, _ in enumerate(environ.tasks):\n",
    "#     task_key = f\"task{t_id+1}\"\n",
    "# #     print_heading(f\"{title}  {current_iter}  {task_key} : {val_metrics[task_key]['classification_agg']}\", verbose = True)\n",
    "\n",
    "#     for key, _  in val_metrics[task_key]['classification_agg'].items():\n",
    "#         print('%s/%-20s'%(task_key, key), val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print(f\"{task_key:s}/{key:20s}\", val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print()\n",
    "#             # print_current_errors(os.path.join(self.log_dir, 'loss.txt'), current_iter,key, loss[key], time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b73b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:48.162261Z",
     "start_time": "2022-01-07T22:52:48.140423Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.print_loss(current_iter, start_time, metrics = val_metrics['loss'], verbose=True)\n",
    "# print(opt['lambdas'])\n",
    "# p = (opt['lambdas'][0] * environ.losses['tasks']['task1'])\n",
    "# print(p)\n",
    "\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics , title='validation', verbose=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850378b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:47.661019Z",
     "start_time": "2022-01-07T22:52:47.639094Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(current_iter)\n",
    "# print_metrics_cr(current_iter, t1 - t0, None, val_metrics , True)\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics, title='validation', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a80b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:14:58.034384Z",
     "start_time": "2022-01-07T23:14:58.004850Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\" val_metric keys               : {val_metrics.keys()}\")\n",
    "print(f\" loss keys                     : {val_metrics['loss'].keys()}\")\n",
    "print(f\" task1 keys                    : {val_metrics['task1'].keys()}\")\n",
    "print(f\" task1 classification keys     : {val_metrics['task1']['classification'].keys()}\")\n",
    "print(f\" task1 classification_agg keys : {val_metrics['task1']['classification_agg'].keys()}\")\n",
    "print()\n",
    "print(f\" task1                       : {val_metrics['task1']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task2                       : {val_metrics['task2']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task3                       : {val_metrics['task3']['classification_agg']['loss']:5f}\")\n",
    "print(f\" loss                        : {val_metrics['loss']['total']:5f}\")\n",
    "print(f\" train_time                  : {val_metrics['train_time']:2f}\")\n",
    "print(f\" epoch                       : {val_metrics['epoch']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc43a6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Post Weight + Policy Training Stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65640cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:22:20.634818Z",
     "start_time": "2022-01-27T00:22:20.444566Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].backbone.layer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4374287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:30:31.940280Z",
     "start_time": "2022-01-26T19:30:31.910058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_blocks = 6\n",
    "num_policy_layers = 6\n",
    "gt =  torch.ones((num_blocks)).long()\n",
    "gt0 =  torch.zeros((num_blocks)).long()\n",
    "print(gt)\n",
    "print(gt0)\n",
    "\n",
    "loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "print(loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651bc43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:42:31.300891Z",
     "start_time": "2022-01-26T19:42:31.257774Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if environ.opt['diff_sparsity_weights'] and not environ.opt['is_sharing']:\n",
    "    print(' cond 1')\n",
    "    ## Assign higher weights to higher layers \n",
    "    loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "    print(f\"{task_key} sparsity error:  {2 * (loss_weights[-num_blocks:] * environ.cross_entropy2(logits[-num_blocks:], gt)).mean()})\")\n",
    "    print_dbg(f\" loss_weights :  {loss_weights}\", verbose = True)\n",
    "    print_dbg(f\" cross_entropy:  {environ.cross_entropy2(logits[-num_blocks:], gt)}  \", verbose = True)\n",
    "    print_dbg(f\" loss[sparsity][{task_key}]: {self.losses['sparsity'][task_key] } \", verbose = True)\n",
    "\n",
    "else:\n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between \\n Logits   : \\n{logits[-num_blocks:]} \\n and gt: \\n{gt} \\n\", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-num_blocks:], gt)}\")\n",
    "    \n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt[-1:])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt0[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt0[-1:])} \\n\")\n",
    "    \n",
    "    print('\\n cond 3')    \n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt[0:1])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt0[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt0[0:1])} \\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686cd05",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ee1b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:30.155045Z",
     "start_time": "2022-01-26T00:14:30.107095Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# flag = 'update_w'\n",
    "# environ.fix_alpha\n",
    "# environ.free_w(opt['fix_BN'])\n",
    "\n",
    "flag = 'update_alpha'\n",
    "environ.fix_weights()\n",
    "environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7996b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:31.184285Z",
     "start_time": "2022-01-25T23:43:31.159229Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f436ee6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:34.993711Z",
     "start_time": "2022-01-26T00:14:34.968623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") \n",
    "\n",
    "train_total_epochs += 5\n",
    "\n",
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334a0b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T17:15:02.216665Z",
     "start_time": "2022-01-25T17:15:01.848081Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - t0, None, environ.val_metrics , num_prints)      \n",
    "\n",
    "# num_prints += 1\n",
    "# t0 = time.time()\n",
    "\n",
    "# # Take check point\n",
    "# environ.save_checkpoint('latest', current_iter)\n",
    "# environ.train()\n",
    "# #-------------------------------------------------------\n",
    "# # END validation process\n",
    "# #-------------------------------------------------------       \n",
    "# flag = 'update_alpha'\n",
    "# environ.fix_w()\n",
    "# environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c4f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:08:57.366231Z",
     "start_time": "2022-01-08T01:08:57.295445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dilation = 2\n",
    "# kernel_size = np.asarray((3, 3))\n",
    "# upsampled_kernel_size = (kernel_size - 1) * (dilation - 1) + kernel_size\n",
    "# print(upsampled_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500c390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:39.763599Z",
     "start_time": "2022-01-25T23:43:39.728402Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.optimizers['weights'].param_groups[0]\n",
    "# for param_group in optimizer.param_groups:\n",
    "#     return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb71bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:41.628847Z",
     "start_time": "2022-01-25T23:43:41.602238Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.schedulers['weights'].get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7934862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:36:17.129535Z",
     "start_time": "2022-01-08T01:36:16.006144Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.optimizers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    current_state[k] = v.state_dict()\n",
    "pp.pprint(current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5faf7f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:40:22.032247Z",
     "start_time": "2022-01-08T01:40:22.006953Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.schedulers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    print(v.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd497e72",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Losses and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66169a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T16:34:44.555617Z",
     "start_time": "2022-02-09T16:34:44.507417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_losses = environ.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb8234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:35:11.758429Z",
     "start_time": "2022-02-10T03:35:11.278211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0301f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:21:49.107793Z",
     "start_time": "2022-02-10T03:21:49.084484Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498b6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:20:32.866010Z",
     "start_time": "2022-02-10T03:20:32.442919Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "pp.pprint(trn_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe30724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:34:21.945701Z",
     "start_time": "2022-02-10T03:34:21.411234Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d81167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:49.364883Z",
     "start_time": "2022-01-27T00:58:49.342931Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['Lambda_sharing'] = 0.5\n",
    "# opt['train']['Lambda_sharing'] = 0.5\n",
    "\n",
    "# environ.opt['train']['policy_lr'] = 0.001\n",
    "# opt['train']['policy_lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73aa06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T01:00:41.996410Z",
     "start_time": "2022-01-26T01:00:41.559006Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.losses.keys()\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ece74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:19:43.683550Z",
     "start_time": "2022-01-08T01:19:43.571450Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = environ.get_loss_dict()\n",
    "print(tmp.keys())\n",
    "pp.pprint(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac0256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:50.458223Z",
     "start_time": "2022-01-27T00:58:50.430889Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(opt['diff_sparsity_weights'])\n",
    "print(opt['is_sharing'])\n",
    "print(opt['diff_sparsity_weights'] and not opt['is_sharing'])\n",
    "print(environ.opt['train']['Lambda_sharing'])\n",
    "print(opt['train']['Lambda_sharing'])\n",
    "print(environ.opt['train']['Lambda_sparsity'])\n",
    "print(opt['train']['Lambda_sparsity'])\n",
    "print(environ.opt['train']['policy_lr'])\n",
    "print(opt['train']['policy_lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2d510",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Policy / Logit stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb628497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:35:14.041577Z",
     "start_time": "2022-02-08T20:35:14.018303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.special          import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eed454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:30.103364Z",
     "start_time": "2022-02-08T20:00:30.068021Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03b5cc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_task_logits(n)` Get logits for task group n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed8b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:56:35.652087Z",
     "start_time": "2022-02-08T20:56:35.327406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task_logits = environ.get_task_logits(1)\n",
    "print(task_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66fa5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_arch_parameters()`: Get last used logits from network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85521e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:31.101960Z",
     "start_time": "2022-02-08T20:00:30.757064Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b0bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:06.054699Z",
     "start_time": "2022-02-09T15:43:05.689327Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea1743",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_logits()`:  Get Policy Logits - returns same as `get_arch_parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb40c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:24.972390Z",
     "start_time": "2022-02-09T15:43:24.636629Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs = environ.get_policy_logits()\n",
    "for i in logs:\n",
    "    print(i, '\\n')\n",
    "# probs = softmax(logs, axis= -1)\n",
    "# for i in probs:\n",
    "#     print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080a364",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_prob()` : Gets the softmax of the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c75af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:29.733732Z",
     "start_time": "2022-02-09T15:43:29.699600Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "for i in policy_softmaxs:\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3160d9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = False)` : Calls test_sample_policy of network with random choices based on softmax of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f411444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:21:15.636722Z",
     "start_time": "2022-02-08T22:21:15.165456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "policies,logits = environ.get_sample_policy(hard_sampling = False)\n",
    "\n",
    "for l, p, s in zip(logits, policies, policy_softmaxs) :\n",
    "    for  l_row, p_row, s_row in zip(l, p, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802664ec",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = True)` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea65bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:59:40.790899Z",
     "start_time": "2022-02-08T20:59:40.726657Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "hard_policies, logits = environ.get_sample_policy(hard_sampling = True)\n",
    "\n",
    "for p,l,s in zip(hard_policies, logits, policy_softmaxs) :\n",
    "    for  p_row, l_row, s_row in zip(p, l, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c39cf",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fe096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:00:47.452220Z",
     "start_time": "2022-02-08T21:00:47.422902Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\" Layer    task 1      task 2      task 3\")\n",
    "print(f\" -----    ------      ------      ------\")\n",
    "for idx, (l1, l2, l3) in enumerate(zip(hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1}       {l2}       {l3}\")\n",
    "    \n",
    "\n",
    "    print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade0ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:39:39.936555Z",
     "start_time": "2022-02-08T22:39:39.911591Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_trained_policy(iter):\n",
    "\n",
    "    policy_softmaxs = environ.get_policy_prob()\n",
    "    policy_argmaxs = 1-np.argmax(policy_softmaxs, axis = -1)\n",
    "    print(f\"  Trained polcies at iteration: {iter} \")\n",
    "    print(f\"                   task 1                           task 2                         task 3        \")\n",
    "    print(f\" Layer       softmax        select          softmax        select          softmax        select   \")\n",
    "    print(f\" -----    ---------------   ------       ---------------   ------       ---------------   ------   \")\n",
    "    for idx, (l1,l2,l3,  p1,p2,p3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2], policy_argmaxs[0], policy_argmaxs[1], policy_argmaxs[2]),1):\n",
    "        print(f\"   {idx}      {l1[0]:.4f}   {l1[1]:.4f}   {p1:4d}    {l2[0]:11.4f}   {l2[1]:.4f}   {p2:4d}    {l3[0]:11.4f}   {l3[1]:.4f}   {p3:4d}\")\n",
    "\n",
    "    print()\n",
    "# print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec208dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:42:12.650813Z",
     "start_time": "2022-02-08T22:42:12.330169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display_trained_policy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec517e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:07:30.836214Z",
     "start_time": "2022-02-08T22:07:30.804575Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"                        POLICIES (SOFTMAX)                                       task 3          \")\n",
    "print(f\" Layer    task1              task2            task3 softmax         softmax         argmax         softmax         argmax   \")\n",
    "print(f\" -----    -------------     -------------     -------------   ------   \")\n",
    "for idx, (l1,l2,l3, h1,h2,h3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2],hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1[0]:.4f} {l1[1]:.4f}     {l2[0]:.4f} {l2[1]:.4f}     {l3[0]:.4f} {l3[1]:.4f}    {h3}\")\n",
    "    \n",
    "print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbeacb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:04:50.757406Z",
     "start_time": "2022-02-08T22:04:50.731736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(policy_softmaxs[2], np.argmax(1-policy_softmaxs[2], axis = -1))\n",
    "print(policy_softmaxs, np.argmax(policy_softmaxs, axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be0240",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_logits()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb7240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:19:06.155425Z",
     "start_time": "2022-02-08T21:19:06.118640Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits  = (environ.get_current_logits())\n",
    "for i in logits:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e84662",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_policy()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cfa24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:40:06.543376Z",
     "start_time": "2022-02-08T20:40:06.230711Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pols  = (environ.get_current_policy())\n",
    "\n",
    "for i in pols:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f556a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T18:27:33.593255Z",
     "start_time": "2022-01-27T18:27:33.553141Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792710e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `gumbel_softmax()`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265490e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:28:17.107529Z",
     "start_time": "2022-02-08T21:28:17.084910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', floatmode = 'maxprec_equal')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb0087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:35:11.617269Z",
     "start_time": "2022-02-08T21:35:11.569599Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.temp)\n",
    "# tau = environ.temp\n",
    "tau = 1\n",
    "for i in range(3): \n",
    "    logits_tensor = torch.tensor(logits[0])\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=tau, hard=False).cpu().numpy() \n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=tau, hard=True).cpu().numpy()\n",
    "    \n",
    "    for l, gs, gh in zip(lgts, gumbel_soft, gumbel_hard):\n",
    "        print(f\"   {l}   \\t {gs}            \\t {gh}\")\n",
    "#     print(lgts)\n",
    "#     print(gumbel_soft)\n",
    "#     print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5ef7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e0e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:21:35.524957Z",
     "start_time": "2022-02-08T21:21:35.488812Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for lgts in logits:\n",
    "    logits_tensor = torch.tensor(lgts)\n",
    "    print(lgts)\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=1, hard=False)\n",
    "    print(gumbel_soft)\n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=1, hard=True)\n",
    "    print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34a06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T20:49:37.643349Z",
     "start_time": "2022-02-03T20:49:37.580786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smax = scipy.special.softmax(logs, axis =1)\n",
    "# smax = np.array( \n",
    "# [[0.46973792, 0.530262  ],\n",
    "#  [0.45025694, 0.549743  ],\n",
    "#  [0.4443086 , 0.5556915 ],\n",
    "#  [0.4138397 , 0.58616036],\n",
    "#  [0.4140113 , 0.5859887 ],\n",
    "#  [0.42114905, 0.57885087]])\n",
    "\n",
    "print(smax.shape)\n",
    "print(smax)\n",
    "print(smax[0])\n",
    "print(smax[0].sum())\n",
    "print(np.random.choice((1,0), p =smax[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7de25c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:15:19.893888Z",
     "start_time": "2022-02-08T21:15:19.870899Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logs = np.array(\n",
    "[[0.33064184, 0.42053092],\n",
    " [0.3532089 , 0.52056104],\n",
    " [0.3888512 , 0.5680909 ],\n",
    " [0.42039296, 0.694217  ],\n",
    " [0.4519742 , 0.73311865],\n",
    " [0.48401102, 0.7522658 ]],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "399px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
