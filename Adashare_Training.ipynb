{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408f1261",
   "metadata": {},
   "source": [
    "## Initialization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d574cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T02:58:24.182251Z",
     "start_time": "2022-03-29T02:58:22.259792Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:08.233990Z",
     "iopub.status.busy": "2022-01-07T22:44:08.233053Z",
     "iopub.status.idle": "2022-01-07T22:44:08.273284Z",
     "shell.execute_reply": "2022-01-07T22:44:08.271908Z",
     "shell.execute_reply.started": "2022-01-07T22:44:08.233943Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "import time\n",
    "import argparse\n",
    "import yaml\n",
    "import types\n",
    "import copy, pprint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import numpy  as np\n",
    "import torch  \n",
    "import wandb\n",
    "import pandas as pd\n",
    "from utils.notebook_modules import initialize, init_dataloaders, init_environment, init_wandb, \\\n",
    "                                   training_prep, disp_dataloader_info,disp_info_1, \\\n",
    "                                   warmup_phase, weight_policy_training, disp_gpu_info\n",
    "\n",
    "from utils.util import (print_separator, print_heading, timestring, print_loss, load_from_pickle) #, print_underline, \n",
    "#                       print_dbg, get_command_line_args ) \n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=6, linewidth=132)\n",
    "pd.options.display.width = 132\n",
    "# torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
    "# sys.path.insert(0, '/home/kbardool/kusanagi/AdaSparseChem/src')\n",
    "# print(sys.path)\n",
    "# disp_gpu_info() \n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Training.ipynb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33ac6e",
   "metadata": {},
   "source": [
    "## Create Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee652c57",
   "metadata": {},
   "source": [
    "### Parse Input Args  - Read YAML config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42bb98b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T02:58:24.224998Z",
     "start_time": "2022-03-29T02:58:24.186934Z"
    }
   },
   "outputs": [],
   "source": [
    "# RESUME_MODEL_CKPT = 'model_train_ep_25_seed_0088'\n",
    "\n",
    "## For RESTARTING\n",
    "##\n",
    "# input_args = \" --config yamls/chembl_3task_train.yaml \" \\\n",
    "#              \" --resume \" \\\n",
    "#              \" --exp_id      330i85cg\" \\\n",
    "#              \" --exp_name    0308_1204\" \\\n",
    "#              \" --exp_desc    Train with dropout 0.5\" \\\n",
    "#              \" --seed_idx    0 \"\\\n",
    "#              \" --batch_size  128\" \\\n",
    "#              \" --lambda_sparsity  0.01\"\\\n",
    "#              \" --lambda_sharing   0.01\" \n",
    "## get command line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd3a7f00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T02:58:24.268388Z",
     "start_time": "2022-03-29T02:58:24.228625Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [],
   "source": [
    "##  For Initiating \n",
    "##\n",
    "input_args = \" --config yamls/chembl_3task_train.yaml \" \\\n",
    "             \" --exp_desc    6 lyrs,dropout 0.5, weight 105 bch/ep policy 105 bch/ep \" \\\n",
    "             \" --warmup_epochs       350 \" \\\n",
    "             \" --hidden_size         1600 \" \\\n",
    "             \" --tail_hidden_size    1600 \" \\\n",
    "             \" --seed_idx             0\" \\\n",
    "             \" --batch_size         128\" \\\n",
    "             \" --task_lr          0.001\" \\\n",
    "             \" --backbone_lr      0.001\" \\\n",
    "             \" --policy_lr        0.001\" \\\n",
    "             \" --lambda_sparsity   0.02\" \\\n",
    "             \" --lambda_sharing    0.01\" \\\n",
    "               \" --folder_sfx    noplcy\"                       \n",
    "#              \" --hidden_size   100 100 100 100 100 100\" \\\n",
    "#              \" --tail_hidden_size  100 \" \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc14177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T02:58:25.125030Z",
     "start_time": "2022-03-29T02:58:24.274283Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  command line parms : \n",
      "------------------------\n",
      " config...................  yamls/chembl_3task_train.yaml\n",
      " exp_id...................  None\n",
      " exp_name.................  None\n",
      " folder_sfx...............  noplcy\n",
      " exp_desc.................  6 lyrs,dropout 0.5, weight 105 bch/ep policy 105 bch/ep\n",
      " hidden_sizes.............  [1600]\n",
      " tail_hidden_size.........  1600\n",
      " warmup_epochs............  350\n",
      " training_epochs..........  None\n",
      " seed_idx.................  0\n",
      " batch_size...............  128\n",
      " backbone_lr..............  0.001\n",
      " task_lr..................  0.001\n",
      " policy_lr................  0.001\n",
      " decay_lr_rate............  None\n",
      " decay_lr_freq............  None\n",
      " lambda_sparsity..........  0.02\n",
      " lambda_sharing...........  0.01\n",
      " gpu_ids..................  [0]\n",
      " resume...................  False\n",
      " cpu......................  False\n",
      "\n",
      "\n",
      "\n",
      "##################################################\n",
      "################### READ YAML ####################\n",
      "##################################################\n",
      "\n",
      "\n",
      " log_dir              create folder:  ../experiments/AdaSparseChem/1600x1_0329_0458_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      " result_dir           folder exists:  ../experiments/AdaSparseChem/1600x1_0329_0458_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      " checkpoint_dir       folder exists:  ../experiments/AdaSparseChem/1600x1_0329_0458_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " experiment name       : 0329_0458_noplcy \n",
      " experiment id         : 14lubvbu \n",
      " folder_name           : 1600x1_0329_0458_plr0.001_sp0.02_sh0.01_lr0.001_noplcy \n",
      " experiment description: 6 lyrs,dropout 0.5, weight 105 bch/ep policy 105 bch/ep\n",
      " Random seeds          : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      " Random  seed used     : 88 \n",
      " log folder            : ../experiments/AdaSparseChem/1600x1_0329_0458_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      " checkpoint folder     : ../experiments/AdaSparseChem/1600x1_0329_0458_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      " Gpu ids               : [0]\n",
      " Seed index            : 0\n",
      " policy_iter           : best\n",
      " Data Split ratios     : [0.725, 0.225, 0.05]\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "        project_name : AdaSparseChem\n",
      "              exp_id : 14lubvbu\n",
      "            exp_name : 0329_0458_noplcy\n",
      "          exp_folder : 1600x1_0329_0458_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      "     exp_description : 6 lyrs,dropout 0.5, weight 105 bch/ep policy 105 bch/ep\n",
      "          folder_sfx : noplcy\n",
      "         random_seed : 88\n",
      "           seed_list : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      "                 cpu : False\n",
      "             gpu_ids : [0]\n",
      "            backbone : SparseChem\n",
      "               tasks : ['class', 'class', 'class']\n",
      "     tasks_num_class : [5, 5, 5]\n",
      "             lambdas : [1, 1, 1]\n",
      "        policy_model : task-specific\n",
      "             verbose : False\n",
      "       backbone_orig : ResNet18\n",
      "          tasks_orig : ['seg', 'sn']\n",
      "     input_size_freq : None\n",
      "          input_size : 32000\n",
      " first_non_linearity : relu\n",
      "middle_non_linearity : relu\n",
      "  last_non_linearity : relu\n",
      "      middle_dropout : 0.5\n",
      "        last_dropout : 0.5\n",
      "   class_output_size : None\n",
      "    regr_output_size : None\n",
      "              policy : True\n",
      "           is_sparse : True\n",
      "          is_sharing : True\n",
      "diff_sparsity_weights : False\n",
      "          skip_layer : 0\n",
      "       is_curriculum : False\n",
      "    curriculum_speed : 3\n",
      "              fix_BN : False\n",
      "     retrain_from_pl : False\n",
      "\n",
      "train\n",
      "-----\n",
      "          batch_size : 128\n",
      "       warmup_epochs : 350\n",
      "     training_epochs : 250\n",
      "         total_iters : 25000\n",
      "       warm_up_iters : None\n",
      "             task_lr : 0.001\n",
      "         backbone_lr : 0.001\n",
      "       decay_lr_rate : 0.75\n",
      "       decay_lr_freq : 40\n",
      "policy_decay_lr_rate : 0.75\n",
      "policy_decay_lr_freq : 50\n",
      "           policy_lr : 0.001\n",
      "     lambda_sparsity : 0.02\n",
      "      lambda_sharing : 0.01\n",
      "        lambda_tasks : 1\n",
      "         init_method : random\n",
      "           init_temp : 4\n",
      "          decay_temp : 0.965\n",
      "     decay_temp_freq : 16\n",
      "     init_neg_logits : None\n",
      "       hard_sampling : False\n",
      "            val_freq : 500\n",
      "          print_freq : -1\n",
      "           val_iters : -1\n",
      "              resume : False\n",
      "      retrain_resume : False\n",
      "         policy_iter : best\n",
      "          which_iter : warmup\n",
      "\n",
      "paths\n",
      "-----\n",
      "             log_dir : ../experiments/AdaSparseChem/1600x1_0329_0458_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      "          result_dir : ../experiments/AdaSparseChem/1600x1_0329_0458_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      "      checkpoint_dir : ../experiments/AdaSparseChem/1600x1_0329_0458_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      "\n",
      "dataload\n",
      "--------\n",
      "             dataset : Chembl_23_mini\n",
      "            dataroot : /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic\n",
      "                   x : chembl_23mini_x.npy\n",
      "      x_split_ratios : [0.725, 0.225, 0.05]\n",
      "             folding : chembl_23mini_folds.npy\n",
      "         fold_inputs : 32000\n",
      "     input_transform : None\n",
      "             y_tasks : ['chembl_23mini_adashare_y1_bin_sparse.npy', 'chembl_23mini_adashare_y2_bin_sparse.npy', 'chembl_23mini_adashare_y3_bin_sparse.npy']\n",
      "            y_censor : None\n",
      "       weights_class : None\n",
      "              crop_h : 321\n",
      "              crop_w : 321\n",
      "   min_samples_class : 5\n",
      "             fold_va : 0\n",
      "             fold_te : None\n",
      "\n",
      "SC\n",
      "--\n",
      "      normalize_loss : None\n",
      "        hidden_sizes : [1600]\n",
      "    tail_hidden_size : 1600\n",
      "        exp_name_pfx : 0329_0458\n"
     ]
    }
   ],
   "source": [
    "opt, ns = initialize(input_args, build_folders = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bfa8d",
   "metadata": {},
   "source": [
    "### Setup Dataloader and Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c631eb67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T02:58:26.864156Z",
     "start_time": "2022-03-29T02:58:25.136309Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############### CREATE DATALOADERS ###############\n",
      "##################################################\n",
      "\n",
      " trainset.y_class                                   :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " trainset1.y_class                                  :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " trainset2.y_class                                  :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " valset.y_class                                     :  [(4137, 5), (4137, 5), (4137, 5)]  \n",
      " testset.y_class                                    :  [(920, 5), (920, 5), (920, 5)]  \n",
      "                                 \n",
      " size of training set 0 (warm up)                   :  13331 \n",
      " size of training set 1 (network parms)             :  13331 \n",
      " size of training set 2 (policy weights)            :  13331 \n",
      " size of validation set                             :  4137 \n",
      " size of test set                                   :  920 \n",
      "                               Total                :  45050 \n",
      "                                 \n",
      " lenght (# batches) in training 0 (warm up)         :  105 \n",
      " lenght (# batches) in training 1 (network parms)   :  105 \n",
      " lenght (# batches) in training 2 (policy weights)  :  105 \n",
      " lenght (# batches) in validation dataset           :  33 \n",
      " lenght (# batches) in test dataset                 :  29 \n",
      "                                \n",
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      " device is  cuda:0\n",
      "--------------------------------------------------------\n",
      "* SparseChemEnv_Dev environment successfully created\n",
      "-------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dldrs = init_dataloaders(opt)\n",
    "\n",
    "disp_dataloader_info(dldrs)\n",
    "\n",
    "environ = init_environment(ns, opt, is_train = True, policy_learning = False, display_cfg = False)\n",
    "\n",
    "# ********************************************************************\n",
    "# **************** define optimizer and schedulers *******************\n",
    "# ********************************************************************                                \n",
    "environ.define_optimizer(policy_learning=False)\n",
    "environ.define_scheduler(policy_learning=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "677fa3f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T02:58:26.953314Z",
     "start_time": "2022-03-29T02:58:26.871073Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.optimizers['weights'].param_groups[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320fdeee",
   "metadata": {},
   "source": [
    "###  Weights and Biases Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03c2469c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T02:58:31.547327Z",
     "start_time": "2022-03-29T02:58:26.957905Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkbardool\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14lubvbu 0329_0458_noplcy AdaSparseChem\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kbardool/kusanagi/AdaSparseChem/wandb/run-20220329_045827-14lubvbu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"http://localhost:8080/kbardool/AdaSparseChem/runs/14lubvbu\" target=\"_blank\">0329_0458_noplcy</a></strong> to <a href=\"http://localhost:8080/kbardool/AdaSparseChem\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PROJECT NAME: AdaSparseChem\n",
      " RUN ID      : 14lubvbu \n",
      " RUN NAME    : 0329_0458_noplcy\n",
      " PROJECT NAME: AdaSparseChem\n",
      " RUN ID      : 14lubvbu \n",
      " RUN NAME    : 0329_0458_noplcy\n"
     ]
    }
   ],
   "source": [
    "init_wandb(ns, opt, environment = environ)\n",
    "\n",
    "print(f\" PROJECT NAME: {ns.wandb_run.project}\\n\"\n",
    "      f\" RUN ID      : {ns.wandb_run.id} \\n\"\n",
    "      f\" RUN NAME    : {ns.wandb_run.name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d949180d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T02:58:31.636801Z",
     "start_time": "2022-03-29T02:58:31.553124Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d738062",
   "metadata": {},
   "source": [
    "### Initiate / Resume Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd2a36e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T02:58:31.710752Z",
     "start_time": "2022-03-29T02:58:31.640769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############### Initiate Training  ###############\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "if opt['train']['resume']:\n",
    "    RESUME_MODEL_CKPT = \"\"\n",
    "    RESUME_METRICS_CKPT = \"\"    \n",
    "    print(opt['train']['which_iter'])\n",
    "    print(opt['paths']['checkpoint_dir'])\n",
    "    print(RESUME_MODEL_CKPT)\n",
    "    # opt['train']['resume'] = True\n",
    "    # opt['train']['which_iter'] = 'warmup_ep_40_seed_0088'\n",
    "    print_separator('Resume training')\n",
    "    loaded_iter, loaded_epoch = environ.load_checkpoint(RESUME_MODEL_CKPT, path = opt['paths']['checkpoint_dir'], verbose = True)\n",
    "    print(loaded_iter, loaded_epoch)    \n",
    "#     current_iter = environ.load_checkpoint(opt['train']['which_iter'])\n",
    "    environ.networks['mtl-net'].reset_logits()\n",
    "    val_metrics = load_from_pickle(opt['paths']['checkpoint_dir'], RESUME_METRICS_CKPT)\n",
    "    # training_prep(ns, opt, environ, dldrs, epoch = loaded_epoch, iter = loaded_iter )\n",
    "\n",
    "else:\n",
    "    print_separator('Initiate Training ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7774f",
   "metadata": {},
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8b6afdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T02:58:31.905971Z",
     "start_time": "2022-03-29T02:58:31.716247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cuda available [0]\n",
      " set print_freq to length of train loader: 105\n",
      " set eval_iters to length of val loader  : 33\n"
     ]
    }
   ],
   "source": [
    "training_prep(ns, opt, environ, dldrs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ea212ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T02:58:31.985546Z",
     "start_time": "2022-03-29T02:58:31.909535Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:18.146907Z",
     "iopub.status.busy": "2022-01-07T22:44:18.145721Z",
     "iopub.status.idle": "2022-01-07T22:44:18.191126Z",
     "shell.execute_reply": "2022-01-07T22:44:18.189994Z",
     "shell.execute_reply.started": "2022-01-07T22:44:18.146867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Num_blocks                : 1                                \n",
      "\n",
      " batch size                : 128 \n",
      " batches/ Weight trn epoch : 105 \n",
      " batches/ Policy trn epoch : 105                                 \n",
      "\n",
      " Print Frequency           : -1 \n",
      " Config Val Frequency      : 500 \n",
      " Config Val Iterations     : -1 \n",
      " Val iterations            : 33 \n",
      " which_iter                : warmup \n",
      " train_resume              : False                                 \n",
      " \n",
      " fix BN parms              : False \n",
      " Task LR                   : 0.001 \n",
      " Backbone LR               : 0.001                                 \n",
      "\n",
      " Sharing  regularization   : 0.01 \n",
      " Sparsity regularization   : 0.02 \n",
      " Task     regularization   : 1                                 \n",
      "\n",
      " Current epoch             : 0  \n",
      " Warm-up epochs            : 350 \n",
      " Training epochs           : 250\n"
     ]
    }
   ],
   "source": [
    "disp_info_1(ns, opt, environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61bc6107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T02:58:32.060911Z",
     "start_time": "2022-03-29T02:58:31.989169Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:18.146907Z",
     "iopub.status.busy": "2022-01-07T22:44:18.145721Z",
     "iopub.status.idle": "2022-01-07T22:44:18.191126Z",
     "shell.execute_reply": "2022-01-07T22:44:18.189994Z",
     "shell.execute_reply.started": "2022-01-07T22:44:18.146867Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    folder: 1600x1_0329_0458_plr0.001_sp0.02_sh0.01_lr0.001_noplcy\n",
      "    layers: 1 [1600] \n",
      "    \n",
      "    middle dropout         : 0.5\n",
      "    last dropout           : 0.5\n",
      "    diff_sparsity_weights  : False\n",
      "    skip_layer             : 0\n",
      "    is_curriculum          : False\n",
      "    curriculum_speed       : 3\n",
      "    \n",
      "    task_lr                : 0.001\n",
      "    backbone_lr            : 0.001\n",
      "    decay_lr_rate          : 0.75\n",
      "    decay_lr_freq          : 40\n",
      "    \n",
      "    policy_lr              : 0.001\n",
      "    policy_decay_lr_rate   : 0.75\n",
      "    policy_decay_lr_freq   : 50\n",
      "    lambda_sparsity        : 0.02\n",
      "    lambda_sharing         : 0.01\n",
      "    lambda_tasks           : 1\n",
      "    \n",
      "    Gumbel init_temp       : 4\n",
      "    Gumbel decay_temp      : 0.965\n",
      "    Gumbel decay_temp_freq : 16\n",
      "    Logit init_method      : random\n",
      "    Logit init_neg_logits  : None\n",
      "    Logit hard_sampling    : False\n",
      "    Warm-up epochs         : 350\n",
      "    training epochs        : 250\n",
      "    Data split ratios      : [0.725, 0.225, 0.05]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(environ.disp_for_excel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278d6d1",
   "metadata": {},
   "source": [
    "## Warmup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92380a48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T02:58:32.135720Z",
     "start_time": "2022-03-29T02:58:32.064418Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 0\n",
      "--------------------------------------------------------------------------\n",
      " Last Epoch: 0   # of warm-up epochs to do:  350 - Run epochs 1 to 350\n",
      "-------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# environ.display_trained_policy(ns.current_epoch,out=sys.stdout)\n",
    "# ns.stop_epoch_warmup = 10\n",
    "# ns.warmup_epochs = 10\n",
    "# ns.check_for_improvment_wait = 0\n",
    "print(ns.warmup_epochs, ns.current_epoch)\n",
    "print_heading(f\" Last Epoch: {ns.current_epoch}   # of warm-up epochs to do:  {ns.warmup_epochs} - Run epochs {ns.current_epoch+1} to {ns.current_epoch + ns.warmup_epochs}\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8be9d65b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T07:34:24.837485Z",
     "start_time": "2022-03-29T02:58:32.140099Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      " Last Epoch: 0   # of warm-up epochs to do:  350 - Run epochs 1 to 350\n",
      "-------------------------------------------------------------------------- \n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "    1 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    9.8691   4.1555e-02   1.9403e-05    9.9107 |   0.67669   0.65897   0.65717   0.65871 |   10.1496   4.1555e-02   1.9403e-05    10.1912 |  46.8 |\n",
      "Previous best_epoch:     0   best iter:     0,   best_value: 0.00000\n",
      "New      best_epoch:     1   best iter:   105,   best_value: 0.65897\n",
      "    2 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    9.5726   4.1555e-02   1.9403e-05    9.6142 |   0.65873   0.68739   0.68286   0.68721 |    9.8788   4.1555e-02   1.9403e-05     9.9204 |  48.5 |        \n",
      "Previous best_epoch:     1   best iter:   105,   best_value: 0.65897\n",
      "New      best_epoch:     2   best iter:   210,   best_value: 0.68739\n",
      "    3 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    9.2388   4.1555e-02   1.9403e-05    9.2803 |   0.64010   0.70158   0.69779   0.70141 |    9.5993   4.1555e-02   1.9403e-05     9.6409 |  45.9 |        \n",
      "Previous best_epoch:     2   best iter:   210,   best_value: 0.68739\n",
      "New      best_epoch:     3   best iter:   315,   best_value: 0.70158\n",
      "    4 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    8.2870   4.1555e-02   1.9403e-05    8.3285 |   0.62668   0.71280   0.71033   0.71263 |    9.3948   4.1555e-02   1.9403e-05     9.4363 |  47.1 |        \n",
      "Previous best_epoch:     3   best iter:   315,   best_value: 0.70158\n",
      "New      best_epoch:     4   best iter:   420,   best_value: 0.71280\n",
      "    5 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    8.0674   4.1555e-02   1.9403e-05    8.1089 |   0.61420   0.72393   0.72220   0.72376 |    9.2166   4.1555e-02   1.9403e-05     9.2582 |  45.6 |        \n",
      "Previous best_epoch:     4   best iter:   420,   best_value: 0.71280\n",
      "New      best_epoch:     5   best iter:   525,   best_value: 0.72393\n",
      "    6 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    8.3569   4.1555e-02   1.9403e-05    8.3984 |   0.60414   0.73332   0.73207   0.73316 |    9.0598   4.1555e-02   1.9403e-05     9.1014 |  46.0 |        \n",
      "Previous best_epoch:     5   best iter:   525,   best_value: 0.72393\n",
      "New      best_epoch:     6   best iter:   630,   best_value: 0.73332\n",
      "    7 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    7.1983   4.1555e-02   1.9403e-05    7.2399 |   0.59561   0.74135   0.74047   0.74120 |    8.9330   4.1555e-02   1.9403e-05     8.9746 |  45.0 |        \n",
      "Previous best_epoch:     6   best iter:   630,   best_value: 0.73332\n",
      "New      best_epoch:     7   best iter:   735,   best_value: 0.74135\n",
      "    8 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    7.3935   4.1555e-02   1.9403e-05    7.4350 |   0.58875   0.74880   0.74808   0.74867 |    8.8318   4.1555e-02   1.9403e-05     8.8733 |  46.4 |        \n",
      "Previous best_epoch:     7   best iter:   735,   best_value: 0.74135\n",
      "New      best_epoch:     8   best iter:   840,   best_value: 0.74880\n",
      "    9 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    7.2228   4.1555e-02   1.9403e-05    7.2643 |   0.58429   0.75562   0.75480   0.75550 |    8.7634   4.1555e-02   1.9403e-05     8.8050 |  44.8 |        \n",
      "Previous best_epoch:     8   best iter:   840,   best_value: 0.74880\n",
      "New      best_epoch:     9   best iter:   945,   best_value: 0.75562\n",
      "   10 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    6.8065   4.1555e-02   1.9403e-05    6.8481 |   0.57957   0.76193   0.76092   0.76182 |    8.6984   4.1555e-02   1.9403e-05     8.7400 |  46.9 |        \n",
      "Previous best_epoch:     9   best iter:   945,   best_value: 0.75562\n",
      "New      best_epoch:    10   best iter:  1050,   best_value: 0.76193\n",
      "   11 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    6.7622   4.1555e-02   1.9403e-05    6.8038 |   0.57439   0.76730   0.76648   0.76719 |    8.6081   4.1555e-02   1.9403e-05     8.6496 |  44.5 |        \n",
      "Previous best_epoch:    10   best iter:  1050,   best_value: 0.76193\n",
      "New      best_epoch:    11   best iter:  1155,   best_value: 0.76730\n",
      "   12 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    6.5346   4.1555e-02   1.9403e-05    6.5761 |   0.56992   0.77307   0.77206   0.77296 |    8.5563   4.1555e-02   1.9403e-05     8.5978 |  46.6 |        \n",
      "Previous best_epoch:    11   best iter:  1155,   best_value: 0.76730\n",
      "New      best_epoch:    12   best iter:  1260,   best_value: 0.77307\n",
      "   13 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    6.3414   4.1555e-02   1.9403e-05    6.3829 |   0.56686   0.77743   0.77653   0.77732 |    8.4974   4.1555e-02   1.9403e-05     8.5390 |  45.1 |        \n",
      "Previous best_epoch:    12   best iter:  1260,   best_value: 0.77307\n",
      "New      best_epoch:    13   best iter:  1365,   best_value: 0.77743\n",
      "   14 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    5.8509   4.1555e-02   1.9403e-05    5.8925 |   0.56265   0.78151   0.78048   0.78141 |    8.4324   4.1555e-02   1.9403e-05     8.4740 |  46.4 |        \n",
      "Previous best_epoch:    13   best iter:  1365,   best_value: 0.77743\n",
      "New      best_epoch:    14   best iter:  1470,   best_value: 0.78151\n",
      "   15 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    6.1283   4.1555e-02   1.9403e-05    6.1698 |   0.56133   0.78540   0.78427   0.78530 |    8.4245   4.1555e-02   1.9403e-05     8.4661 |  45.5 |        \n",
      "Previous best_epoch:    14   best iter:  1470,   best_value: 0.78151\n",
      "New      best_epoch:    15   best iter:  1575,   best_value: 0.78540\n",
      "   16 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    5.6823   4.1555e-02   1.9403e-05    5.7239 |   0.56243   0.78867   0.78730   0.78857 |    8.4286   4.1555e-02   1.9403e-05     8.4702 |  46.2 |        \n",
      "Previous best_epoch:    15   best iter:  1575,   best_value: 0.78540\n",
      "New      best_epoch:    16   best iter:  1680,   best_value: 0.78867\n",
      "   17 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    5.9571   4.1555e-02   1.9403e-05    5.9987 |   0.55557   0.79208   0.79098   0.79199 |    8.3337   4.1555e-02   1.9403e-05     8.3753 |  44.8 |        \n",
      "Previous best_epoch:    16   best iter:  1680,   best_value: 0.78867\n",
      "New      best_epoch:    17   best iter:  1785,   best_value: 0.79208\n",
      "   18 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    6.0607   4.1555e-02   1.9403e-05    6.1023 |   0.55493   0.79582   0.79461   0.79573 |    8.3358   4.1555e-02   1.9403e-05     8.3774 |  46.6 |        \n",
      "Previous best_epoch:    17   best iter:  1785,   best_value: 0.79208\n",
      "New      best_epoch:    18   best iter:  1890,   best_value: 0.79582\n",
      "   19 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    5.2901   4.1555e-02   1.9403e-05    5.3317 |   0.55304   0.79873   0.79745   0.79865 |    8.2854   4.1555e-02   1.9403e-05     8.3270 |  45.1 |        \n",
      "Previous best_epoch:    18   best iter:  1890,   best_value: 0.79582\n",
      "New      best_epoch:    19   best iter:  1995,   best_value: 0.79873\n",
      "   20 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    5.4756   4.1555e-02   1.9403e-05    5.5172 |   0.55198   0.80114   0.79988   0.80105 |    8.2719   4.1555e-02   1.9403e-05     8.3135 |  46.3 |        \n",
      "Previous best_epoch:    19   best iter:  1995,   best_value: 0.79873\n",
      "New      best_epoch:    20   best iter:  2100,   best_value: 0.80114\n",
      "   21 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    5.1358   4.1555e-02   1.9403e-05    5.1774 |   0.55092   0.80352   0.80232   0.80344 |    8.2651   4.1555e-02   1.9403e-05     8.3066 |  44.8 |        \n",
      "Previous best_epoch:    20   best iter:  2100,   best_value: 0.80114\n",
      "New      best_epoch:    21   best iter:  2205,   best_value: 0.80352\n",
      "   22 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    4.4840   4.1555e-02   1.9403e-05    4.5256 |   0.54589   0.80599   0.80465   0.80591 |    8.1878   4.1555e-02   1.9403e-05     8.2293 |  47.3 |        \n",
      "Previous best_epoch:    21   best iter:  2205,   best_value: 0.80352\n",
      "New      best_epoch:    22   best iter:  2310,   best_value: 0.80599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   23 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    5.1086   4.1555e-02   1.9403e-05    5.1502 |   0.55225   0.80759   0.80655   0.80751 |    8.2928   4.1555e-02   1.9403e-05     8.3344 |  45.2 |        \n",
      "Previous best_epoch:    22   best iter:  2310,   best_value: 0.80599\n",
      "New      best_epoch:    23   best iter:  2415,   best_value: 0.80759\n",
      "   24 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    4.3138   4.1555e-02   1.9403e-05    4.3554 |   0.54752   0.80930   0.80806   0.80922 |    8.2133   4.1555e-02   1.9403e-05     8.2549 |  46.4 |        \n",
      "Previous best_epoch:    23   best iter:  2415,   best_value: 0.80759\n",
      "New      best_epoch:    24   best iter:  2520,   best_value: 0.80930\n",
      "   25 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.8359   4.1555e-02   1.9403e-05    3.8775 |   0.54834   0.81094   0.80963   0.81085 |    8.2249   4.1555e-02   1.9403e-05     8.2665 |  45.1 |        \n",
      "Previous best_epoch:    24   best iter:  2520,   best_value: 0.80930\n",
      "New      best_epoch:    25   best iter:  2625,   best_value: 0.81094\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "   26 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    4.6569   4.1555e-02   1.9403e-05    4.6984 |   0.54392   0.81304   0.81215   0.81296 |    8.1366   4.1555e-02   1.9403e-05     8.1782 |  45.5 |\n",
      "Previous best_epoch:    25   best iter:  2625,   best_value: 0.81094\n",
      "New      best_epoch:    26   best iter:  2730,   best_value: 0.81304\n",
      "   27 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    4.4930   4.1555e-02   1.9403e-05    4.5345 |   0.54984   0.81420   0.81346   0.81411 |    8.2474   4.1555e-02   1.9403e-05     8.2890 |  45.1 |        \n",
      "Previous best_epoch:    26   best iter:  2730,   best_value: 0.81304\n",
      "New      best_epoch:    27   best iter:  2835,   best_value: 0.81420\n",
      "   28 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    4.1691   4.1555e-02   1.9403e-05    4.2107 |   0.54802   0.81590   0.81515   0.81582 |    8.2224   4.1555e-02   1.9403e-05     8.2639 |  47.3 |        \n",
      "Previous best_epoch:    27   best iter:  2835,   best_value: 0.81420\n",
      "New      best_epoch:    28   best iter:  2940,   best_value: 0.81590\n",
      "   29 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    4.3799   4.1555e-02   1.9403e-05    4.4215 |   0.54953   0.81758   0.81652   0.81750 |    8.2336   4.1555e-02   1.9403e-05     8.2752 |  45.0 |        \n",
      "Previous best_epoch:    28   best iter:  2940,   best_value: 0.81590\n",
      "New      best_epoch:    29   best iter:  3045,   best_value: 0.81758\n",
      "   30 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    4.9542   4.1555e-02   1.9403e-05    4.9958 |   0.55267   0.81827   0.81723   0.81819 |    8.2899   4.1555e-02   1.9403e-05     8.3315 |  46.5 |        \n",
      "Previous best_epoch:    29   best iter:  3045,   best_value: 0.81758\n",
      "New      best_epoch:    30   best iter:  3150,   best_value: 0.81827\n",
      "   31 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.5883   4.1555e-02   1.9403e-05    3.6299 |   0.55501   0.81874   0.81773   0.81866 |    8.3211   4.1555e-02   1.9403e-05     8.3627 |  44.4 |        \n",
      "Previous best_epoch:    30   best iter:  3150,   best_value: 0.81827\n",
      "New      best_epoch:    31   best iter:  3255,   best_value: 0.81874\n",
      "   32 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.5320   4.1555e-02   1.9403e-05    3.5735 |   0.55120   0.82065   0.81975   0.82057 |    8.2666   4.1555e-02   1.9403e-05     8.3081 |  47.4 |        \n",
      "Previous best_epoch:    31   best iter:  3255,   best_value: 0.81874\n",
      "New      best_epoch:    32   best iter:  3360,   best_value: 0.82065\n",
      "   33 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.6168   4.1555e-02   1.9403e-05    3.6584 |   0.55147   0.82147   0.82056   0.82139 |    8.2588   4.1555e-02   1.9403e-05     8.3004 |  45.3 |        \n",
      "Previous best_epoch:    32   best iter:  3360,   best_value: 0.82065\n",
      "New      best_epoch:    33   best iter:  3465,   best_value: 0.82147\n",
      "   34 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.4977   4.1555e-02   1.9403e-05    3.5393 |   0.55679   0.82257   0.82157   0.82249 |    8.3748   4.1555e-02   1.9403e-05     8.4163 |  47.2 |        \n",
      "Previous best_epoch:    33   best iter:  3465,   best_value: 0.82147\n",
      "New      best_epoch:    34   best iter:  3570,   best_value: 0.82257\n",
      "   35 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.4617   4.1555e-02   1.9403e-05    3.5032 |   0.55599   0.82297   0.82247   0.82289 |    8.3410   4.1555e-02   1.9403e-05     8.3826 |  45.2 |        \n",
      "Previous best_epoch:    34   best iter:  3570,   best_value: 0.82257\n",
      "New      best_epoch:    35   best iter:  3675,   best_value: 0.82297\n",
      "   36 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    4.0135   4.1555e-02   1.9403e-05    4.0551 |   0.56044   0.82370   0.82289   0.82362 |    8.4031   4.1555e-02   1.9403e-05     8.4447 |  45.8 |        \n",
      "Previous best_epoch:    35   best iter:  3675,   best_value: 0.82297\n",
      "New      best_epoch:    36   best iter:  3780,   best_value: 0.82370\n",
      "   37 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.8850   4.1555e-02   1.9403e-05    3.9266 |   0.56797   0.82413   0.82313   0.82405 |    8.5244   4.1555e-02   1.9403e-05     8.5659 |  45.4 |        \n",
      "Previous best_epoch:    36   best iter:  3780,   best_value: 0.82370\n",
      "New      best_epoch:    37   best iter:  3885,   best_value: 0.82413\n",
      "   38 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.7206   4.1555e-02   1.9403e-05    3.7622 |   0.56730   0.82511   0.82444   0.82504 |    8.4943   4.1555e-02   1.9403e-05     8.5359 |  47.1 |        \n",
      "Previous best_epoch:    37   best iter:  3885,   best_value: 0.82413\n",
      "New      best_epoch:    38   best iter:  3990,   best_value: 0.82511\n",
      "   39 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    2.9858   4.1555e-02   1.9403e-05    3.0274 |   0.56624   0.82544   0.82466   0.82536 |    8.4819   4.1555e-02   1.9403e-05     8.5234 |  45.8 |        \n",
      "Previous best_epoch:    38   best iter:  3990,   best_value: 0.82511\n",
      "New      best_epoch:    39   best iter:  4095,   best_value: 0.82544\n",
      "   40 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    2.8485   4.1555e-02   1.9403e-05    2.8901 |   0.56725   0.82589   0.82528   0.82581 |    8.5072   4.1555e-02   1.9403e-05     8.5488 |  47.4 |        \n",
      "Previous best_epoch:    39   best iter:  4095,   best_value: 0.82544\n",
      "New      best_epoch:    40   best iter:  4200,   best_value: 0.82589\n",
      "   41 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.3352   4.1555e-02   1.9403e-05    3.3768 |   0.57267   0.82616   0.82551   0.82608 |    8.5758   4.1555e-02   1.9403e-05     8.6174 |  44.7 |        \n",
      "Previous best_epoch:    40   best iter:  4200,   best_value: 0.82589\n",
      "New      best_epoch:    41   best iter:  4305,   best_value: 0.82616\n",
      "   42 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.6231   4.1555e-02   1.9403e-05    3.6647 |   0.58067   0.82593   0.82519   0.82585 |    8.7154   4.1555e-02   1.9403e-05     8.7570 |  47.1 |        \n",
      "   43 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    2.8182   4.1555e-02   1.9403e-05    2.8597 |   0.57905   0.82652   0.82556   0.82644 |    8.6827   4.1555e-02   1.9403e-05     8.7243 |  46.0 |        \n",
      "Previous best_epoch:    41   best iter:  4305,   best_value: 0.82616\n",
      "New      best_epoch:    43   best iter:  4515,   best_value: 0.82652\n",
      "   44 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.3531   4.1555e-02   1.9403e-05    3.3947 |   0.58777   0.82670   0.82599   0.82662 |    8.7920   4.1555e-02   1.9403e-05     8.8336 |  46.2 |        \n",
      "Previous best_epoch:    43   best iter:  4515,   best_value: 0.82652\n",
      "New      best_epoch:    44   best iter:  4620,   best_value: 0.82670\n",
      "   45 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.1048   4.1555e-02   1.9403e-05    3.1464 |   0.59002   0.82683   0.82638   0.82675 |    8.8650   4.1555e-02   1.9403e-05     8.9066 |  45.5 |        \n",
      "Previous best_epoch:    44   best iter:  4620,   best_value: 0.82670\n",
      "New      best_epoch:    45   best iter:  4725,   best_value: 0.82683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   46 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.4770   4.1555e-02   1.9403e-05    3.5186 |   0.59043   0.82706   0.82664   0.82699 |    8.8640   4.1555e-02   1.9403e-05     8.9056 |  46.1 |        \n",
      "Previous best_epoch:    45   best iter:  4725,   best_value: 0.82683\n",
      "New      best_epoch:    46   best iter:  4830,   best_value: 0.82706\n",
      "   47 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.3765   4.1555e-02   1.9403e-05    3.4180 |   0.59101   0.82766   0.82700   0.82759 |    8.8687   4.1555e-02   1.9403e-05     8.9103 |  46.6 |        \n",
      "Previous best_epoch:    46   best iter:  4830,   best_value: 0.82706\n",
      "New      best_epoch:    47   best iter:  4935,   best_value: 0.82766\n",
      "   48 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    2.9140   4.1555e-02   1.9403e-05    2.9555 |   0.59881   0.82846   0.82781   0.82838 |    8.9854   4.1555e-02   1.9403e-05     9.0270 |  47.0 |        \n",
      "Previous best_epoch:    47   best iter:  4935,   best_value: 0.82766\n",
      "New      best_epoch:    48   best iter:  5040,   best_value: 0.82846\n",
      "   49 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    2.5250   4.1555e-02   1.9403e-05    2.5665 |   0.60051   0.82815   0.82755   0.82808 |    9.0098   4.1555e-02   1.9403e-05     9.0513 |  45.6 |        \n",
      "   50 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    2.8524   4.1555e-02   1.9403e-05    2.8939 |   0.60514   0.82831   0.82799   0.82823 |    9.0816   4.1555e-02   1.9403e-05     9.1232 |  47.1 |        \n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "   51 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    3.1552   4.1555e-02   1.9403e-05    3.1967 |   0.61169   0.82854   0.82763   0.82846 |    9.2125   4.1555e-02   1.9403e-05     9.2541 |  44.9 |\n",
      "Previous best_epoch:    48   best iter:  5040,   best_value: 0.82846\n",
      "New      best_epoch:    51   best iter:  5355,   best_value: 0.82854\n",
      "   52 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    2.7469   4.1555e-02   1.9403e-05    2.7885 |   0.61535   0.82882   0.82817   0.82874 |    9.2114   4.1555e-02   1.9403e-05     9.2529 |  47.1 |        \n",
      "Previous best_epoch:    51   best iter:  5355,   best_value: 0.82854\n",
      "New      best_epoch:    52   best iter:  5460,   best_value: 0.82882\n",
      "   53 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    2.2992   4.1555e-02   1.9403e-05    2.3407 |   0.62588   0.82850   0.82780   0.82842 |    9.3996   4.1555e-02   1.9403e-05     9.4411 |  45.5 |        \n",
      "   54 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    2.0851   4.1555e-02   1.9403e-05    2.1266 |   0.62740   0.82875   0.82832   0.82867 |    9.3963   4.1555e-02   1.9403e-05     9.4379 |  47.1 |        \n",
      "   55 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    1.9302   4.1555e-02   1.9403e-05    1.9718 |   0.62952   0.82894   0.82822   0.82886 |    9.4267   4.1555e-02   1.9403e-05     9.4683 |  45.7 |        \n",
      "Previous best_epoch:    52   best iter:  5460,   best_value: 0.82882\n",
      "New      best_epoch:    55   best iter:  5775,   best_value: 0.82894\n",
      "   56 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    2.6465   4.1555e-02   1.9403e-05    2.6881 |   0.63455   0.82895   0.82834   0.82887 |    9.5465   4.1555e-02   1.9403e-05     9.5881 |  45.9 |        \n",
      "Previous best_epoch:    55   best iter:  5775,   best_value: 0.82894\n",
      "New      best_epoch:    56   best iter:  5880,   best_value: 0.82895\n",
      "   57 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    1.8951   4.1555e-02   1.9403e-05    1.9367 |   0.64042   0.82883   0.82800   0.82875 |    9.6325   4.1555e-02   1.9403e-05     9.6741 |  45.6 |        \n",
      "   58 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    1.8300   4.1555e-02   1.9403e-05    1.8716 |   0.63827   0.82940   0.82880   0.82932 |    9.5694   4.1555e-02   1.9403e-05     9.6110 |  47.0 |        \n",
      "Previous best_epoch:    56   best iter:  5880,   best_value: 0.82895\n",
      "New      best_epoch:    58   best iter:  6090,   best_value: 0.82940\n",
      "   59 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    1.5760   4.1555e-02   1.9403e-05    1.6176 |   0.64587   0.82890   0.82831   0.82883 |    9.7029   4.1555e-02   1.9403e-05     9.7444 |  45.7 |        \n",
      "   60 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    1.8942   4.1555e-02   1.9403e-05    1.9358 |   0.65141   0.82907   0.82840   0.82899 |    9.7327   4.1555e-02   1.9403e-05     9.7743 |  47.7 |        \n",
      "   61 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    2.8829   4.1555e-02   1.9403e-05    2.9245 |   0.65502   0.82928   0.82851   0.82921 |    9.8114   4.1555e-02   1.9403e-05     9.8529 |  45.6 |        \n",
      "   62 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    1.9741   4.1555e-02   1.9403e-05    2.0157 |   0.66346   0.82908   0.82841   0.82901 |    9.9665   4.1555e-02   1.9403e-05    10.0081 |  47.4 |        \n",
      "   63 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    1.8702   4.1555e-02   1.9403e-05    1.9118 |   0.67053   0.82836   0.82805   0.82829 |   10.0603   4.1555e-02   1.9403e-05    10.1019 |  46.2 |        \n",
      "   64 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    1.9907   4.1555e-02   1.9403e-05    2.0323 |   0.67256   0.82886   0.82820   0.82879 |   10.0889   4.1555e-02   1.9403e-05    10.1305 |  47.6 |        \n",
      "   65 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    1.8720   4.1555e-02   1.9403e-05    1.9136 |   0.67870   0.82862   0.82820   0.82855 |   10.1658   4.1555e-02   1.9403e-05    10.2073 |  46.1 |        \n",
      "   66 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    2.3402   4.1555e-02   1.9403e-05    2.3818 |   0.68547   0.82871   0.82798   0.82864 |   10.2836   4.1555e-02   1.9403e-05    10.3252 |  46.7 |        \n",
      "   67 |   1.00e-03   1.00e-03   1.00e-03  4.000e+00 |    1.4836   4.1555e-02   1.9403e-05    1.5252 |   0.68805   0.82818   0.82763   0.82811 |   10.3368   4.1555e-02   1.9403e-05    10.3784 |  45.8 |        \n",
      "Epoch    67: reducing learning rate of group 0 to 7.5000e-04.\n",
      "Epoch    67: reducing learning rate of group 1 to 7.5000e-04.\n",
      "   68 |   7.50e-04   7.50e-04   1.00e-03  4.000e+00 |    1.4701   4.1555e-02   1.9403e-05    1.5117 |   0.69568   0.82836   0.82754   0.82828 |   10.4227   4.1555e-02   1.9403e-05    10.4643 |  47.5 |        \n",
      "   69 |   7.50e-04   7.50e-04   1.00e-03  4.000e+00 |    1.8361   4.1555e-02   1.9403e-05    1.8777 |   0.69782   0.82839   0.82756   0.82831 |   10.5049   4.1555e-02   1.9403e-05    10.5465 |  45.7 |        \n",
      "   70 |   7.50e-04   7.50e-04   1.00e-03  4.000e+00 |    1.9108   4.1555e-02   1.9403e-05    1.9524 |   0.70790   0.82822   0.82739   0.82814 |   10.5951   4.1555e-02   1.9403e-05    10.6367 |  47.0 |        \n",
      "   71 |   7.50e-04   7.50e-04   1.00e-03  4.000e+00 |    1.6631   4.1555e-02   1.9403e-05    1.7046 |   0.70576   0.82871   0.82799   0.82864 |   10.5863   4.1555e-02   1.9403e-05    10.6279 |  45.0 |        \n",
      "   72 |   7.50e-04   7.50e-04   1.00e-03  4.000e+00 |    1.3150   4.1555e-02   1.9403e-05    1.3566 |   0.71399   0.82845   0.82770   0.82838 |   10.7261   4.1555e-02   1.9403e-05    10.7676 |  47.6 |        \n",
      "   73 |   7.50e-04   7.50e-04   1.00e-03  4.000e+00 |    1.6580   4.1555e-02   1.9403e-05    1.6996 |   0.71523   0.82849   0.82765   0.82842 |   10.7221   4.1555e-02   1.9403e-05    10.7636 |  46.2 |        \n",
      "   74 |   7.50e-04   7.50e-04   1.00e-03  4.000e+00 |    1.7771   4.1555e-02   1.9403e-05    1.8187 |   0.72011   0.82860   0.82769   0.82852 |   10.8292   4.1555e-02   1.9403e-05    10.8707 |  47.1 |        \n",
      "   75 |   7.50e-04   7.50e-04   1.00e-03  4.000e+00 |    1.4642   4.1555e-02   1.9403e-05    1.5058 |   0.72092   0.82890   0.82815   0.82882 |   10.7955   4.1555e-02   1.9403e-05    10.8371 |  46.4 |        \n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "   76 |   7.50e-04   7.50e-04   1.00e-03  4.000e+00 |    1.4141   4.1555e-02   1.9403e-05    1.4556 |   0.72077   0.82862   0.82798   0.82854 |   10.7697   4.1555e-02   1.9403e-05    10.8112 |  46.4 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   77 |   7.50e-04   7.50e-04   1.00e-03  4.000e+00 |    1.3626   4.1555e-02   1.9403e-05    1.4042 |   0.72813   0.82834   0.82776   0.82826 |   10.8989   4.1555e-02   1.9403e-05    10.9405 |  46.4 |        \n",
      "Epoch    77: reducing learning rate of group 0 to 7.5000e-04.\n",
      "   78 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.3274   4.1555e-02   1.9403e-05    1.3690 |   0.72873   0.82876   0.82815   0.82868 |   10.8982   4.1555e-02   1.9403e-05    10.9397 |  47.3 |        \n",
      "   79 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.6056   4.1555e-02   1.9403e-05    1.6472 |   0.73286   0.82880   0.82793   0.82872 |   10.9903   4.1555e-02   1.9403e-05    11.0319 |  46.9 |        \n",
      "   80 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.5573   4.1555e-02   1.9403e-05    1.5988 |   0.73942   0.82859   0.82780   0.82852 |   11.0750   4.1555e-02   1.9403e-05    11.1166 |  48.0 |        \n",
      "   81 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.4888   4.1555e-02   1.9403e-05    1.5304 |   0.74720   0.82793   0.82718   0.82785 |   11.2167   4.1555e-02   1.9403e-05    11.2583 |  45.5 |        \n",
      "   82 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.6751   4.1555e-02   1.9403e-05    1.7167 |   0.74919   0.82828   0.82765   0.82820 |   11.2303   4.1555e-02   1.9403e-05    11.2719 |  48.2 |        \n",
      "   83 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.1994   4.1555e-02   1.9403e-05    1.2410 |   0.75420   0.82807   0.82736   0.82799 |   11.2856   4.1555e-02   1.9403e-05    11.3272 |  46.2 |        \n",
      "   84 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.2743   4.1555e-02   1.9403e-05    1.3159 |   0.75309   0.82797   0.82741   0.82789 |   11.3084   4.1555e-02   1.9403e-05    11.3500 |  47.0 |        \n",
      "   85 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.1458   4.1555e-02   1.9403e-05    1.1874 |   0.76018   0.82820   0.82739   0.82812 |   11.3967   4.1555e-02   1.9403e-05    11.4382 |  46.1 |        \n",
      "   86 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.1748   4.1555e-02   1.9403e-05    1.2164 |   0.76242   0.82768   0.82705   0.82761 |   11.4436   4.1555e-02   1.9403e-05    11.4852 |  47.1 |        \n",
      "   87 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.7631   4.1555e-02   1.9403e-05    1.8047 |   0.76392   0.82799   0.82726   0.82791 |   11.4575   4.1555e-02   1.9403e-05    11.4990 |  46.2 |        \n",
      "   88 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.0527   4.1555e-02   1.9403e-05    1.0943 |   0.77467   0.82771   0.82707   0.82763 |   11.6611   4.1555e-02   1.9403e-05    11.7027 |  47.5 |        \n",
      "   89 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.2934   4.1555e-02   1.9403e-05    1.3350 |   0.77200   0.82844   0.82734   0.82836 |   11.5868   4.1555e-02   1.9403e-05    11.6283 |  46.4 |        \n",
      "   90 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.7969   4.1555e-02   1.9403e-05    1.8385 |   0.78090   0.82786   0.82699   0.82778 |   11.7058   4.1555e-02   1.9403e-05    11.7474 |  47.2 |        \n",
      "   91 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.6283   4.1555e-02   1.9403e-05    1.6699 |   0.78591   0.82805   0.82715   0.82797 |   11.7724   4.1555e-02   1.9403e-05    11.8140 |  46.0 |        \n",
      "   92 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.1176   4.1555e-02   1.9403e-05    1.1592 |   0.78411   0.82817   0.82731   0.82810 |   11.7395   4.1555e-02   1.9403e-05    11.7811 |  47.9 |        \n",
      "   93 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.0145   4.1555e-02   1.9403e-05    1.0560 |   0.79436   0.82781   0.82666   0.82773 |   11.8842   4.1555e-02   1.9403e-05    11.9258 |  47.1 |        \n",
      "   94 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.2932   4.1555e-02   1.9403e-05    1.3348 |   0.79884   0.82750   0.82652   0.82742 |   11.9804   4.1555e-02   1.9403e-05    12.0219 |  47.5 |        \n",
      "   95 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.0615   4.1555e-02   1.9403e-05    1.1030 |   0.79752   0.82766   0.82671   0.82759 |   11.9513   4.1555e-02   1.9403e-05    11.9929 |  46.1 |        \n",
      "   96 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.0660   4.1555e-02   1.9403e-05    1.1076 |   0.80542   0.82728   0.82643   0.82720 |   12.0968   4.1555e-02   1.9403e-05    12.1384 |  46.8 |        \n",
      "   97 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.2825   4.1555e-02   1.9403e-05    1.3240 |   0.81051   0.82701   0.82628   0.82694 |   12.1945   4.1555e-02   1.9403e-05    12.2361 |  46.4 |        \n",
      "   98 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.4421   4.1555e-02   1.9403e-05    1.4837 |   0.81333   0.82711   0.82601   0.82704 |   12.2088   4.1555e-02   1.9403e-05    12.2504 |  48.0 |        \n",
      "   99 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    0.9468   4.1555e-02   1.9403e-05    0.9884 |   0.81438   0.82696   0.82615   0.82689 |   12.2646   4.1555e-02   1.9403e-05    12.3061 |  46.3 |        \n",
      "  100 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    0.8643   4.1555e-02   1.9403e-05    0.9059 |   0.81741   0.82715   0.82621   0.82707 |   12.2529   4.1555e-02   1.9403e-05    12.2945 |  48.3 |        \n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "  101 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.2143   4.1555e-02   1.9403e-05    1.2559 |   0.82355   0.82744   0.82653   0.82736 |   12.3841   4.1555e-02   1.9403e-05    12.4256 |  45.9 |\n",
      "  102 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.1048   4.1555e-02   1.9403e-05    1.1463 |   0.83050   0.82728   0.82624   0.82721 |   12.4023   4.1555e-02   1.9403e-05    12.4439 |  48.7 |        \n",
      "  103 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.1821   4.1555e-02   1.9403e-05    1.2236 |   0.83185   0.82698   0.82611   0.82690 |   12.4473   4.1555e-02   1.9403e-05    12.4888 |  47.0 |        \n",
      "  104 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.2752   4.1555e-02   1.9403e-05    1.3168 |   0.83162   0.82704   0.82609   0.82696 |   12.4766   4.1555e-02   1.9403e-05    12.5182 |  47.4 |        \n",
      "  105 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.0446   4.1555e-02   1.9403e-05    1.0862 |   0.84299   0.82660   0.82604   0.82652 |   12.6571   4.1555e-02   1.9403e-05    12.6987 |  45.8 |        \n",
      "  106 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.0326   4.1555e-02   1.9403e-05    1.0741 |   0.84173   0.82652   0.82574   0.82645 |   12.6308   4.1555e-02   1.9403e-05    12.6724 |  46.5 |        \n",
      "  107 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    0.9453   4.1555e-02   1.9403e-05    0.9868 |   0.84370   0.82684   0.82597   0.82676 |   12.6798   4.1555e-02   1.9403e-05    12.7214 |  46.2 |        \n",
      "  108 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    0.6126   4.1555e-02   1.9403e-05    0.6542 |   0.85039   0.82667   0.82583   0.82659 |   12.7744   4.1555e-02   1.9403e-05    12.8160 |  47.9 |        \n",
      "  109 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.2331   4.1555e-02   1.9403e-05    1.2746 |   0.85434   0.82686   0.82617   0.82678 |   12.8177   4.1555e-02   1.9403e-05    12.8593 |  46.4 |        \n",
      "  110 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.0688   4.1555e-02   1.9403e-05    1.1104 |   0.85700   0.82694   0.82604   0.82686 |   12.8527   4.1555e-02   1.9403e-05    12.8943 |  47.3 |        \n",
      "  111 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    1.0002   4.1555e-02   1.9403e-05    1.0418 |   0.86214   0.82626   0.82551   0.82618 |   12.9244   4.1555e-02   1.9403e-05    12.9659 |  45.5 |        \n",
      "  112 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    0.8263   4.1555e-02   1.9403e-05    0.8678 |   0.86746   0.82647   0.82572   0.82640 |   13.0008   4.1555e-02   1.9403e-05    13.0424 |  47.7 |        \n",
      "  113 |   7.50e-04   7.50e-04   7.50e-04  4.000e+00 |    0.7673   4.1555e-02   1.9403e-05    0.8089 |   0.86791   0.82655   0.82573   0.82648 |   12.9949   4.1555e-02   1.9403e-05    13.0364 |  46.8 |        \n",
      "Epoch   113: reducing learning rate of group 0 to 5.6250e-04.\n",
      "Epoch   113: reducing learning rate of group 1 to 5.6250e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  114 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.8418   4.1555e-02   1.9403e-05    0.8834 |   0.87335   0.82664   0.82580   0.82656 |   13.0944   4.1555e-02   1.9403e-05    13.1360 |  48.3 |        \n",
      "  115 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.7038   4.1555e-02   1.9403e-05    0.7454 |   0.87209   0.82672   0.82578   0.82664 |   13.0370   4.1555e-02   1.9403e-05    13.0786 |  46.1 |        \n",
      "  116 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.8204   4.1555e-02   1.9403e-05    0.8620 |   0.87561   0.82681   0.82579   0.82674 |   13.1968   4.1555e-02   1.9403e-05    13.2384 |  47.2 |        \n",
      "  117 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.8884   4.1555e-02   1.9403e-05    0.9299 |   0.87462   0.82676   0.82602   0.82668 |   13.1670   4.1555e-02   1.9403e-05    13.2086 |  48.6 |        \n",
      "  118 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    1.1316   4.1555e-02   1.9403e-05    1.1732 |   0.88240   0.82663   0.82567   0.82656 |   13.2455   4.1555e-02   1.9403e-05    13.2871 |  48.2 |        \n",
      "  119 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    1.0630   4.1555e-02   1.9403e-05    1.1046 |   0.88849   0.82653   0.82550   0.82645 |   13.3669   4.1555e-02   1.9403e-05    13.4085 |  46.7 |        \n",
      "  120 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.9641   4.1555e-02   1.9403e-05    1.0056 |   0.89018   0.82648   0.82554   0.82640 |   13.3461   4.1555e-02   1.9403e-05    13.3877 |  47.7 |        \n",
      "  121 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.7904   4.1555e-02   1.9403e-05    0.8320 |   0.89068   0.82634   0.82535   0.82626 |   13.4060   4.1555e-02   1.9403e-05    13.4475 |  46.1 |        \n",
      "  122 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.8583   4.1555e-02   1.9403e-05    0.8999 |   0.89403   0.82595   0.82507   0.82587 |   13.4294   4.1555e-02   1.9403e-05    13.4710 |  48.3 |        \n",
      "  123 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.6929   4.1555e-02   1.9403e-05    0.7345 |   0.90002   0.82594   0.82499   0.82586 |   13.5207   4.1555e-02   1.9403e-05    13.5623 |  47.3 |        \n",
      "  124 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.7832   4.1555e-02   1.9403e-05    0.8247 |   0.89977   0.82632   0.82534   0.82624 |   13.4642   4.1555e-02   1.9403e-05    13.5057 |  48.4 |        \n",
      "  125 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.7051   4.1555e-02   1.9403e-05    0.7467 |   0.90157   0.82620   0.82499   0.82612 |   13.5379   4.1555e-02   1.9403e-05    13.5795 |  46.6 |        \n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "  126 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.6674   4.1555e-02   1.9403e-05    0.7090 |   0.90289   0.82643   0.82527   0.82635 |   13.5790   4.1555e-02   1.9403e-05    13.6206 |  47.3 |\n",
      "  127 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.8955   4.1555e-02   1.9403e-05    0.9371 |   0.90841   0.82585   0.82484   0.82577 |   13.6289   4.1555e-02   1.9403e-05    13.6705 |  46.8 |        \n",
      "  128 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.6486   4.1555e-02   1.9403e-05    0.6902 |   0.90911   0.82599   0.82516   0.82591 |   13.5984   4.1555e-02   1.9403e-05    13.6400 |  48.1 |        \n",
      "  129 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.6600   4.1555e-02   1.9403e-05    0.7016 |   0.91342   0.82589   0.82502   0.82581 |   13.6837   4.1555e-02   1.9403e-05    13.7253 |  46.3 |        \n",
      "  130 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.6918   4.1555e-02   1.9403e-05    0.7334 |   0.91503   0.82601   0.82501   0.82594 |   13.6881   4.1555e-02   1.9403e-05    13.7297 |  47.7 |        \n",
      "  131 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.7002   4.1555e-02   1.9403e-05    0.7418 |   0.91438   0.82614   0.82513   0.82607 |   13.7182   4.1555e-02   1.9403e-05    13.7598 |  45.4 |        \n",
      "  132 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.5992   4.1555e-02   1.9403e-05    0.6408 |   0.92240   0.82576   0.82485   0.82568 |   13.8149   4.1555e-02   1.9403e-05    13.8565 |  48.7 |        \n",
      "  133 |   5.63e-04   5.63e-04   7.50e-04  4.000e+00 |    0.8398   4.1555e-02   1.9403e-05    0.8813 |   0.92043   0.82615   0.82514   0.82607 |   13.8167   4.1555e-02   1.9403e-05    13.8583 |  46.7 |        \n",
      "Epoch   133: reducing learning rate of group 0 to 5.6250e-04.\n",
      "  134 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.5544   4.1555e-02   1.9403e-05    0.5960 |   0.92187   0.82605   0.82500   0.82597 |   13.8515   4.1555e-02   1.9403e-05    13.8931 |  47.8 |        \n",
      "  135 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.6284   4.1555e-02   1.9403e-05    0.6700 |   0.92598   0.82588   0.82503   0.82580 |   13.8960   4.1555e-02   1.9403e-05    13.9376 |  46.3 |        \n",
      "  136 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.6236   4.1555e-02   1.9403e-05    0.6652 |   0.92795   0.82558   0.82461   0.82551 |   13.9499   4.1555e-02   1.9403e-05    13.9915 |  47.1 |        \n",
      "  137 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.9209   4.1555e-02   1.9403e-05    0.9625 |   0.93161   0.82562   0.82472   0.82554 |   13.9464   4.1555e-02   1.9403e-05    13.9880 |  46.1 |        \n",
      "  138 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.6306   4.1555e-02   1.9403e-05    0.6722 |   0.93244   0.82547   0.82463   0.82540 |   13.9954   4.1555e-02   1.9403e-05    14.0370 |  48.9 |        \n",
      "  139 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.5807   4.1555e-02   1.9403e-05    0.6223 |   0.94551   0.82564   0.82473   0.82557 |   14.1659   4.1555e-02   1.9403e-05    14.2075 |  47.1 |        \n",
      "  140 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.5807   4.1555e-02   1.9403e-05    0.6223 |   0.93750   0.82562   0.82470   0.82555 |   14.0414   4.1555e-02   1.9403e-05    14.0830 |  47.7 |        \n",
      "  141 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.8429   4.1555e-02   1.9403e-05    0.8844 |   0.94153   0.82535   0.82438   0.82528 |   14.1222   4.1555e-02   1.9403e-05    14.1638 |  45.0 |        \n",
      "  142 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    1.1385   4.1555e-02   1.9403e-05    1.1800 |   0.94614   0.82562   0.82456   0.82555 |   14.1766   4.1555e-02   1.9403e-05    14.2182 |  47.7 |        \n",
      "  143 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.7960   4.1555e-02   1.9403e-05    0.8376 |   0.95053   0.82556   0.82453   0.82548 |   14.2459   4.1555e-02   1.9403e-05    14.2874 |  46.3 |        \n",
      "  144 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.6581   4.1555e-02   1.9403e-05    0.6997 |   0.94736   0.82539   0.82442   0.82531 |   14.2427   4.1555e-02   1.9403e-05    14.2843 |  47.5 |        \n",
      "  145 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.6295   4.1555e-02   1.9403e-05    0.6711 |   0.95538   0.82523   0.82434   0.82515 |   14.3580   4.1555e-02   1.9403e-05    14.3996 |  46.2 |        \n",
      "  146 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.6463   4.1555e-02   1.9403e-05    0.6879 |   0.95450   0.82541   0.82435   0.82533 |   14.4147   4.1555e-02   1.9403e-05    14.4563 |  46.7 |        \n",
      "  147 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.9450   4.1555e-02   1.9403e-05    0.9866 |   0.95518   0.82531   0.82440   0.82523 |   14.3153   4.1555e-02   1.9403e-05    14.3569 |  46.2 |        \n",
      "  148 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.7499   4.1555e-02   1.9403e-05    0.7915 |   0.95391   0.82523   0.82435   0.82515 |   14.2935   4.1555e-02   1.9403e-05    14.3351 |  47.7 |        \n",
      "  149 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.5470   4.1555e-02   1.9403e-05    0.5885 |   0.96339   0.82498   0.82425   0.82490 |   14.3964   4.1555e-02   1.9403e-05    14.4380 |  46.6 |        \n",
      "  150 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.4256   4.1555e-02   1.9403e-05    0.4671 |   0.96158   0.82512   0.82429   0.82504 |   14.4261   4.1555e-02   1.9403e-05    14.4677 |  47.8 |        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "  151 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.5912   4.1555e-02   1.9403e-05    0.6327 |   0.96657   0.82517   0.82430   0.82509 |   14.4999   4.1555e-02   1.9403e-05    14.5415 |  50.4 |\n",
      "  152 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.7657   4.1555e-02   1.9403e-05    0.8073 |   0.96670   0.82533   0.82448   0.82526 |   14.4791   4.1555e-02   1.9403e-05    14.5206 |  48.0 |        \n",
      "  153 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.4771   4.1555e-02   1.9403e-05    0.5187 |   0.96987   0.82525   0.82431   0.82517 |   14.5784   4.1555e-02   1.9403e-05    14.6199 |  46.7 |        \n",
      "  154 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.5815   4.1555e-02   1.9403e-05    0.6231 |   0.96966   0.82496   0.82423   0.82488 |   14.5166   4.1555e-02   1.9403e-05    14.5581 |  46.7 |        \n",
      "  155 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.6194   4.1555e-02   1.9403e-05    0.6610 |   0.97510   0.82486   0.82411   0.82478 |   14.6370   4.1555e-02   1.9403e-05    14.6785 |  46.3 |        \n",
      "  156 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.8607   4.1555e-02   1.9403e-05    0.9023 |   0.98089   0.82517   0.82418   0.82509 |   14.7344   4.1555e-02   1.9403e-05    14.7760 |  46.4 |        \n",
      "  157 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.4811   4.1555e-02   1.9403e-05    0.5226 |   0.97642   0.82503   0.82417   0.82495 |   14.6429   4.1555e-02   1.9403e-05    14.6845 |  45.8 |        \n",
      "  158 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.9421   4.1555e-02   1.9403e-05    0.9837 |   0.98280   0.82493   0.82401   0.82485 |   14.7640   4.1555e-02   1.9403e-05    14.8056 |  47.5 |        \n",
      "  159 |   5.63e-04   5.63e-04   5.63e-04  4.000e+00 |    0.6649   4.1555e-02   1.9403e-05    0.7065 |   0.98035   0.82474   0.82384   0.82467 |   14.6699   4.1555e-02   1.9403e-05    14.7115 |  46.1 |        \n",
      "Epoch   159: reducing learning rate of group 0 to 4.2188e-04.\n",
      "Epoch   159: reducing learning rate of group 1 to 4.2188e-04.\n",
      "  160 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.7416   4.1555e-02   1.9403e-05    0.7832 |   0.98505   0.82484   0.82399   0.82476 |   14.7672   4.1555e-02   1.9403e-05    14.8087 |  47.2 |        \n",
      "  161 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.9081   4.1555e-02   1.9403e-05    0.9496 |   0.98576   0.82512   0.82426   0.82504 |   14.7660   4.1555e-02   1.9403e-05    14.8076 |  45.4 |        \n",
      "  162 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.6758   4.1555e-02   1.9403e-05    0.7174 |   0.98636   0.82509   0.82428   0.82501 |   14.8343   4.1555e-02   1.9403e-05    14.8759 |  47.3 |        \n",
      "  163 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.7226   4.1555e-02   1.9403e-05    0.7642 |   0.99070   0.82497   0.82409   0.82489 |   14.8387   4.1555e-02   1.9403e-05    14.8802 |  45.9 |        \n",
      "  164 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.6364   4.1555e-02   1.9403e-05    0.6780 |   0.99105   0.82505   0.82415   0.82497 |   14.8777   4.1555e-02   1.9403e-05    14.9193 |  47.3 |        \n",
      "  165 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.4132   4.1555e-02   1.9403e-05    0.4548 |   0.99499   0.82493   0.82397   0.82485 |   14.9367   4.1555e-02   1.9403e-05    14.9783 |  45.9 |        \n",
      "  166 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.7787   4.1555e-02   1.9403e-05    0.8202 |   0.99947   0.82473   0.82382   0.82466 |   15.0238   4.1555e-02   1.9403e-05    15.0653 |  46.4 |        \n",
      "  167 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.6544   4.1555e-02   1.9403e-05    0.6960 |   0.99980   0.82469   0.82378   0.82461 |   14.9700   4.1555e-02   1.9403e-05    15.0116 |  45.8 |        \n",
      "  168 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.5818   4.1555e-02   1.9403e-05    0.6234 |   0.99814   0.82472   0.82376   0.82465 |   14.9874   4.1555e-02   1.9403e-05    15.0289 |  47.0 |        \n",
      "  169 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.6198   4.1555e-02   1.9403e-05    0.6614 |   1.00598   0.82438   0.82339   0.82430 |   15.0710   4.1555e-02   1.9403e-05    15.1126 |  45.8 |        \n",
      "  170 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.9863   4.1555e-02   1.9403e-05    1.0279 |   1.00240   0.82445   0.82364   0.82437 |   15.0798   4.1555e-02   1.9403e-05    15.1214 |  47.2 |        \n",
      "  171 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.3609   4.1555e-02   1.9403e-05    0.4025 |   1.00566   0.82435   0.82354   0.82427 |   15.0284   4.1555e-02   1.9403e-05    15.0700 |  45.3 |        \n",
      "  172 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.5541   4.1555e-02   1.9403e-05    0.5956 |   1.00517   0.82447   0.82354   0.82439 |   15.0407   4.1555e-02   1.9403e-05    15.0822 |  47.1 |        \n",
      "  173 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.5637   4.1555e-02   1.9403e-05    0.6053 |   1.01306   0.82423   0.82346   0.82415 |   15.1655   4.1555e-02   1.9403e-05    15.2071 |  46.2 |        \n",
      "  174 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.5013   4.1555e-02   1.9403e-05    0.5429 |   1.00808   0.82452   0.82368   0.82444 |   15.1203   4.1555e-02   1.9403e-05    15.1619 |  48.8 |        \n",
      "  175 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.7226   4.1555e-02   1.9403e-05    0.7642 |   1.01327   0.82429   0.82346   0.82421 |   15.1865   4.1555e-02   1.9403e-05    15.2281 |  46.1 |        \n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "  176 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.3747   4.1555e-02   1.9403e-05    0.4162 |   1.01417   0.82422   0.82336   0.82414 |   15.2490   4.1555e-02   1.9403e-05    15.2906 |  46.4 |\n",
      "  177 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.3646   4.1555e-02   1.9403e-05    0.4062 |   1.01569   0.82428   0.82340   0.82421 |   15.2439   4.1555e-02   1.9403e-05    15.2854 |  46.3 |        \n",
      "  178 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.5147   4.1555e-02   1.9403e-05    0.5563 |   1.02038   0.82437   0.82345   0.82429 |   15.3408   4.1555e-02   1.9403e-05    15.3824 |  47.4 |        \n",
      "  179 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.4822   4.1555e-02   1.9403e-05    0.5237 |   1.02022   0.82442   0.82364   0.82434 |   15.2182   4.1555e-02   1.9403e-05    15.2597 |  46.2 |        \n",
      "  180 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.5810   4.1555e-02   1.9403e-05    0.6226 |   1.02087   0.82442   0.82361   0.82434 |   15.3455   4.1555e-02   1.9403e-05    15.3871 |  47.0 |        \n",
      "  181 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.5649   4.1555e-02   1.9403e-05    0.6065 |   1.02034   0.82450   0.82360   0.82443 |   15.3141   4.1555e-02   1.9403e-05    15.3557 |  45.6 |        \n",
      "  182 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.4538   4.1555e-02   1.9403e-05    0.4954 |   1.02812   0.82411   0.82327   0.82403 |   15.3476   4.1555e-02   1.9403e-05    15.3892 |  47.5 |        \n",
      "  183 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.5301   4.1555e-02   1.9403e-05    0.5716 |   1.02837   0.82396   0.82313   0.82388 |   15.3805   4.1555e-02   1.9403e-05    15.4220 |  46.3 |        \n",
      "  184 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.4534   4.1555e-02   1.9403e-05    0.4950 |   1.03000   0.82415   0.82318   0.82407 |   15.4298   4.1555e-02   1.9403e-05    15.4714 |  47.3 |        \n",
      "  185 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.6030   4.1555e-02   1.9403e-05    0.6445 |   1.02980   0.82437   0.82338   0.82430 |   15.5885   4.1555e-02   1.9403e-05    15.6301 |  45.8 |        \n",
      "  186 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.3072   4.1555e-02   1.9403e-05    0.3488 |   1.02916   0.82437   0.82348   0.82429 |   15.4335   4.1555e-02   1.9403e-05    15.4750 |  46.6 |        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  187 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.5399   4.1555e-02   1.9403e-05    0.5815 |   1.03127   0.82421   0.82337   0.82413 |   15.4300   4.1555e-02   1.9403e-05    15.4716 |  46.5 |        \n",
      "  188 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.3201   4.1555e-02   1.9403e-05    0.3616 |   1.03139   0.82398   0.82322   0.82390 |   15.4474   4.1555e-02   1.9403e-05    15.4890 |  47.4 |        \n",
      "  189 |   4.22e-04   4.22e-04   5.63e-04  4.000e+00 |    0.5813   4.1555e-02   1.9403e-05    0.6228 |   1.03358   0.82403   0.82323   0.82395 |   15.5147   4.1555e-02   1.9403e-05    15.5562 |  46.0 |        \n",
      "Epoch   189: reducing learning rate of group 0 to 4.2188e-04.\n",
      "  190 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.4899   4.1555e-02   1.9403e-05    0.5315 |   1.03417   0.82395   0.82316   0.82388 |   15.5902   4.1555e-02   1.9403e-05    15.6318 |  47.3 |        \n",
      "  191 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.5708   4.1555e-02   1.9403e-05    0.6124 |   1.03797   0.82385   0.82299   0.82377 |   15.5895   4.1555e-02   1.9403e-05    15.6311 |  45.2 |        \n",
      "  192 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.5963   4.1555e-02   1.9403e-05    0.6379 |   1.04074   0.82360   0.82272   0.82352 |   15.6346   4.1555e-02   1.9403e-05    15.6762 |  47.0 |        \n",
      "  193 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.5345   4.1555e-02   1.9403e-05    0.5760 |   1.03851   0.82391   0.82308   0.82383 |   15.5485   4.1555e-02   1.9403e-05    15.5901 |  47.8 |        \n",
      "  194 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.7893   4.1555e-02   1.9403e-05    0.8309 |   1.04292   0.82379   0.82309   0.82371 |   15.6465   4.1555e-02   1.9403e-05    15.6881 |  47.6 |        \n",
      "  195 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.8109   4.1555e-02   1.9403e-05    0.8525 |   1.04657   0.82379   0.82297   0.82371 |   15.7118   4.1555e-02   1.9403e-05    15.7534 |  46.8 |        \n",
      "  196 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.5790   4.1555e-02   1.9403e-05    0.6206 |   1.04401   0.82415   0.82333   0.82407 |   15.6598   4.1555e-02   1.9403e-05    15.7014 |  46.8 |        \n",
      "  197 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.3194   4.1555e-02   1.9403e-05    0.3609 |   1.04596   0.82426   0.82338   0.82418 |   15.6709   4.1555e-02   1.9403e-05    15.7125 |  46.7 |        \n",
      "  198 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.3394   4.1555e-02   1.9403e-05    0.3810 |   1.04902   0.82375   0.82292   0.82367 |   15.7573   4.1555e-02   1.9403e-05    15.7989 |  48.2 |        \n",
      "  199 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.4596   4.1555e-02   1.9403e-05    0.5012 |   1.05055   0.82385   0.82305   0.82377 |   15.7734   4.1555e-02   1.9403e-05    15.8149 |  46.2 |        \n",
      "  200 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.4739   4.1555e-02   1.9403e-05    0.5155 |   1.05482   0.82406   0.82321   0.82398 |   15.7554   4.1555e-02   1.9403e-05    15.7970 |  47.3 |        \n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "  201 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.4582   4.1555e-02   1.9403e-05    0.4998 |   1.05463   0.82408   0.82320   0.82400 |   15.7515   4.1555e-02   1.9403e-05    15.7931 |  46.4 |\n",
      "  202 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.5445   4.1555e-02   1.9403e-05    0.5861 |   1.05286   0.82372   0.82302   0.82364 |   15.7455   4.1555e-02   1.9403e-05    15.7870 |  47.6 |        \n",
      "  203 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.6219   4.1555e-02   1.9403e-05    0.6635 |   1.05477   0.82387   0.82305   0.82379 |   15.8505   4.1555e-02   1.9403e-05    15.8920 |  46.4 |        \n",
      "  204 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.4631   4.1555e-02   1.9403e-05    0.5047 |   1.05989   0.82389   0.82305   0.82381 |   15.8916   4.1555e-02   1.9403e-05    15.9331 |  47.8 |        \n",
      "  205 |   4.22e-04   4.22e-04   4.22e-04  4.000e+00 |    0.4701   4.1555e-02   1.9403e-05    0.5117 |   1.05984   0.82349   0.82279   0.82341 |   15.9346   4.1555e-02   1.9403e-05    15.9762 |  45.9 |        \n",
      "Epoch   205: reducing learning rate of group 0 to 3.1641e-04.\n",
      "Epoch   205: reducing learning rate of group 1 to 3.1641e-04.\n",
      "  206 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.5614   4.1555e-02   1.9403e-05    0.6029 |   1.06209   0.82375   0.82300   0.82367 |   15.9571   4.1555e-02   1.9403e-05    15.9987 |  46.8 |        \n",
      "  207 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.4303   4.1555e-02   1.9403e-05    0.4719 |   1.05847   0.82388   0.82300   0.82380 |   15.8987   4.1555e-02   1.9403e-05    15.9402 |  46.5 |        \n",
      "  208 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.5650   4.1555e-02   1.9403e-05    0.6066 |   1.06315   0.82375   0.82294   0.82367 |   15.9031   4.1555e-02   1.9403e-05    15.9447 |  47.5 |        \n",
      "  209 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.6382   4.1555e-02   1.9403e-05    0.6798 |   1.06106   0.82364   0.82289   0.82356 |   15.9268   4.1555e-02   1.9403e-05    15.9684 |  46.2 |        \n",
      "  210 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.5857   4.1555e-02   1.9403e-05    0.6273 |   1.06567   0.82374   0.82291   0.82366 |   16.0305   4.1555e-02   1.9403e-05    16.0721 |  47.5 |        \n",
      "  211 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.5764   4.1555e-02   1.9403e-05    0.6179 |   1.06554   0.82385   0.82303   0.82377 |   16.0062   4.1555e-02   1.9403e-05    16.0478 |  45.3 |        \n",
      "  212 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.2756   4.1555e-02   1.9403e-05    0.3171 |   1.06654   0.82375   0.82287   0.82367 |   16.0174   4.1555e-02   1.9403e-05    16.0589 |  48.3 |        \n",
      "  213 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.5149   4.1555e-02   1.9403e-05    0.5564 |   1.06886   0.82382   0.82299   0.82374 |   16.0231   4.1555e-02   1.9403e-05    16.0646 |  47.0 |        \n",
      "  214 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3485   4.1555e-02   1.9403e-05    0.3901 |   1.07163   0.82384   0.82292   0.82376 |   16.0593   4.1555e-02   1.9403e-05    16.1008 |  47.5 |        \n",
      "  215 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.6200   4.1555e-02   1.9403e-05    0.6615 |   1.07157   0.82390   0.82302   0.82383 |   16.0858   4.1555e-02   1.9403e-05    16.1274 |  46.8 |        \n",
      "  216 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.5880   4.1555e-02   1.9403e-05    0.6296 |   1.07135   0.82376   0.82300   0.82368 |   16.0089   4.1555e-02   1.9403e-05    16.0505 |  46.7 |        \n",
      "  217 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.4646   4.1555e-02   1.9403e-05    0.5062 |   1.07255   0.82367   0.82283   0.82359 |   16.1245   4.1555e-02   1.9403e-05    16.1661 |  46.6 |        \n",
      "  218 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.4743   4.1555e-02   1.9403e-05    0.5159 |   1.07315   0.82362   0.82286   0.82354 |   16.0951   4.1555e-02   1.9403e-05    16.1367 |  48.5 |        \n",
      "  219 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.4798   4.1555e-02   1.9403e-05    0.5214 |   1.07380   0.82369   0.82290   0.82361 |   16.1022   4.1555e-02   1.9403e-05    16.1437 |  46.2 |        \n",
      "  220 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3322   4.1555e-02   1.9403e-05    0.3738 |   1.07797   0.82365   0.82282   0.82357 |   16.1667   4.1555e-02   1.9403e-05    16.2082 |  47.9 |        \n",
      "  221 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.4054   4.1555e-02   1.9403e-05    0.4470 |   1.07901   0.82365   0.82283   0.82357 |   16.1713   4.1555e-02   1.9403e-05    16.2129 |  45.8 |        \n",
      "  222 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.5354   4.1555e-02   1.9403e-05    0.5770 |   1.07659   0.82375   0.82294   0.82367 |   16.1236   4.1555e-02   1.9403e-05    16.1652 |  47.9 |        \n",
      "  223 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.5045   4.1555e-02   1.9403e-05    0.5461 |   1.08176   0.82351   0.82271   0.82343 |   16.1897   4.1555e-02   1.9403e-05    16.2313 |  46.5 |        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  224 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3619   4.1555e-02   1.9403e-05    0.4034 |   1.08369   0.82344   0.82263   0.82336 |   16.2951   4.1555e-02   1.9403e-05    16.3367 |  47.6 |        \n",
      "  225 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3893   4.1555e-02   1.9403e-05    0.4309 |   1.08637   0.82333   0.82255   0.82325 |   16.2770   4.1555e-02   1.9403e-05    16.3186 |  46.9 |        \n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "  226 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3523   4.1555e-02   1.9403e-05    0.3939 |   1.08169   0.82351   0.82275   0.82343 |   16.2517   4.1555e-02   1.9403e-05    16.2933 |  46.9 |\n",
      "  227 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.4420   4.1555e-02   1.9403e-05    0.4836 |   1.08799   0.82351   0.82273   0.82343 |   16.3089   4.1555e-02   1.9403e-05    16.3505 |  46.4 |        \n",
      "  228 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.6986   4.1555e-02   1.9403e-05    0.7402 |   1.08613   0.82345   0.82265   0.82337 |   16.2977   4.1555e-02   1.9403e-05    16.3393 |  47.7 |        \n",
      "  229 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.7002   4.1555e-02   1.9403e-05    0.7417 |   1.08629   0.82330   0.82251   0.82322 |   16.2788   4.1555e-02   1.9403e-05    16.3203 |  46.5 |        \n",
      "  230 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.5933   4.1555e-02   1.9403e-05    0.6349 |   1.09085   0.82325   0.82249   0.82317 |   16.3482   4.1555e-02   1.9403e-05    16.3898 |  47.8 |        \n",
      "  231 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3508   4.1555e-02   1.9403e-05    0.3924 |   1.09798   0.82308   0.82224   0.82300 |   16.4956   4.1555e-02   1.9403e-05    16.5372 |  46.0 |        \n",
      "  232 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3493   4.1555e-02   1.9403e-05    0.3909 |   1.08880   0.82319   0.82263   0.82311 |   16.2989   4.1555e-02   1.9403e-05    16.3405 |  48.5 |        \n",
      "  233 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.4863   4.1555e-02   1.9403e-05    0.5279 |   1.09387   0.82337   0.82270   0.82329 |   16.4184   4.1555e-02   1.9403e-05    16.4600 |  46.9 |        \n",
      "  234 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3256   4.1555e-02   1.9403e-05    0.3672 |   1.09060   0.82336   0.82267   0.82328 |   16.3895   4.1555e-02   1.9403e-05    16.4311 |  48.8 |        \n",
      "  235 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3974   4.1555e-02   1.9403e-05    0.4390 |   1.09223   0.82337   0.82263   0.82329 |   16.4144   4.1555e-02   1.9403e-05    16.4560 |  46.6 |        \n",
      "  236 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3501   4.1555e-02   1.9403e-05    0.3917 |   1.09323   0.82324   0.82261   0.82316 |   16.3750   4.1555e-02   1.9403e-05    16.4166 |  47.6 |        \n",
      "  237 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.4484   4.1555e-02   1.9403e-05    0.4899 |   1.09740   0.82310   0.82234   0.82302 |   16.4868   4.1555e-02   1.9403e-05    16.5284 |  47.8 |        \n",
      "  238 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3587   4.1555e-02   1.9403e-05    0.4003 |   1.09759   0.82317   0.82240   0.82309 |   16.4186   4.1555e-02   1.9403e-05    16.4601 |  47.9 |        \n",
      "  239 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3849   4.1555e-02   1.9403e-05    0.4265 |   1.09935   0.82316   0.82246   0.82308 |   16.5015   4.1555e-02   1.9403e-05    16.5431 |  47.5 |        \n",
      "  240 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.4850   4.1555e-02   1.9403e-05    0.5266 |   1.10013   0.82317   0.82249   0.82309 |   16.4723   4.1555e-02   1.9403e-05    16.5138 |  48.6 |        \n",
      "  241 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3843   4.1555e-02   1.9403e-05    0.4259 |   1.10316   0.82287   0.82219   0.82279 |   16.5691   4.1555e-02   1.9403e-05    16.6107 |  46.4 |        \n",
      "  242 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.5372   4.1555e-02   1.9403e-05    0.5788 |   1.10141   0.82310   0.82239   0.82302 |   16.5113   4.1555e-02   1.9403e-05    16.5529 |  48.8 |        \n",
      "  243 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3177   4.1555e-02   1.9403e-05    0.3593 |   1.10082   0.82310   0.82236   0.82302 |   16.5199   4.1555e-02   1.9403e-05    16.5614 |  47.2 |        \n",
      "  244 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.3688   4.1555e-02   1.9403e-05    0.4104 |   1.10360   0.82305   0.82230   0.82297 |   16.5093   4.1555e-02   1.9403e-05    16.5508 |  48.0 |        \n",
      "  245 |   3.16e-04   3.16e-04   4.22e-04  4.000e+00 |    0.5341   4.1555e-02   1.9403e-05    0.5757 |   1.10369   0.82288   0.82221   0.82280 |   16.5773   4.1555e-02   1.9403e-05    16.6189 |  46.4 |        \n",
      "Epoch   245: reducing learning rate of group 0 to 3.1641e-04.\n",
      "  246 |   3.16e-04   3.16e-04   3.16e-04  4.000e+00 |    0.5886   4.1555e-02   1.9403e-05    0.6302 |   1.10631   0.82308   0.82247   0.82300 |   16.6238   4.1555e-02   1.9403e-05    16.6654 |  46.9 |        \n",
      "  247 |   3.16e-04   3.16e-04   3.16e-04  4.000e+00 |    0.5142   4.1555e-02   1.9403e-05    0.5557 |   1.10607   0.82320   0.82248   0.82312 |   16.6175   4.1555e-02   1.9403e-05    16.6590 |  46.3 |        \n",
      "  248 |   3.16e-04   3.16e-04   3.16e-04  4.000e+00 |    0.3117   4.1555e-02   1.9403e-05    0.3533 |   1.10882   0.82314   0.82235   0.82305 |   16.6569   4.1555e-02   1.9403e-05    16.6985 |  47.7 |        \n",
      "  249 |   3.16e-04   3.16e-04   3.16e-04  4.000e+00 |    0.2953   4.1555e-02   1.9403e-05    0.3369 |   1.10731   0.82292   0.82226   0.82284 |   16.6478   4.1555e-02   1.9403e-05    16.6894 |  46.2 |        \n",
      "  250 |   3.16e-04   3.16e-04   3.16e-04  4.000e+00 |    0.3981   4.1555e-02   1.9403e-05    0.4396 |   1.11273   0.82298   0.82214   0.82290 |   16.6883   4.1555e-02   1.9403e-05    16.7298 |  47.6 |        \n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "  251 |   3.16e-04   3.16e-04   3.16e-04  4.000e+00 |    0.4084   4.1555e-02   1.9403e-05    0.4499 |   1.10999   0.82296   0.82230   0.82288 |   16.6037   4.1555e-02   1.9403e-05    16.6453 |  45.6 |\n",
      "Epoch   251: reducing learning rate of group 0 to 2.3730e-04.\n",
      "Epoch   251: reducing learning rate of group 1 to 2.3730e-04.\n",
      "  252 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.2914   4.1555e-02   1.9403e-05    0.3329 |   1.11440   0.82287   0.82223   0.82279 |   16.6820   4.1555e-02   1.9403e-05    16.7236 |  47.9 |        \n",
      "  253 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3834   4.1555e-02   1.9403e-05    0.4250 |   1.11189   0.82288   0.82221   0.82279 |   16.6907   4.1555e-02   1.9403e-05    16.7322 |  46.6 |        \n",
      "  254 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3379   4.1555e-02   1.9403e-05    0.3795 |   1.11495   0.82282   0.82211   0.82274 |   16.7507   4.1555e-02   1.9403e-05    16.7923 |  48.2 |        \n",
      "  255 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4328   4.1555e-02   1.9403e-05    0.4744 |   1.11691   0.82264   0.82196   0.82256 |   16.7798   4.1555e-02   1.9403e-05    16.8214 |  46.8 |        \n",
      "  256 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4183   4.1555e-02   1.9403e-05    0.4599 |   1.11691   0.82275   0.82212   0.82267 |   16.7604   4.1555e-02   1.9403e-05    16.8019 |  47.0 |        \n",
      "  257 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3609   4.1555e-02   1.9403e-05    0.4024 |   1.11568   0.82285   0.82218   0.82277 |   16.6805   4.1555e-02   1.9403e-05    16.7221 |  47.4 |        \n",
      "  258 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4268   4.1555e-02   1.9403e-05    0.4683 |   1.11760   0.82280   0.82213   0.82272 |   16.7713   4.1555e-02   1.9403e-05    16.8128 |  48.7 |        \n",
      "  259 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3905   4.1555e-02   1.9403e-05    0.4321 |   1.11956   0.82275   0.82208   0.82267 |   16.8275   4.1555e-02   1.9403e-05    16.8691 |  46.4 |        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  260 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.2311   4.1555e-02   1.9403e-05    0.2727 |   1.11860   0.82283   0.82205   0.82275 |   16.8015   4.1555e-02   1.9403e-05    16.8431 |  48.4 |        \n",
      "  261 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3546   4.1555e-02   1.9403e-05    0.3962 |   1.12035   0.82276   0.82205   0.82268 |   16.8001   4.1555e-02   1.9403e-05    16.8417 |  45.8 |        \n",
      "  262 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4139   4.1555e-02   1.9403e-05    0.4555 |   1.12096   0.82283   0.82206   0.82275 |   16.7874   4.1555e-02   1.9403e-05    16.8290 |  47.8 |        \n",
      "  263 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4977   4.1555e-02   1.9403e-05    0.5392 |   1.12094   0.82286   0.82209   0.82278 |   16.8410   4.1555e-02   1.9403e-05    16.8826 |  46.5 |        \n",
      "  264 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.6473   4.1555e-02   1.9403e-05    0.6888 |   1.12199   0.82285   0.82211   0.82277 |   16.7899   4.1555e-02   1.9403e-05    16.8315 |  47.3 |        \n",
      "  265 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3622   4.1555e-02   1.9403e-05    0.4038 |   1.12393   0.82280   0.82208   0.82272 |   16.8345   4.1555e-02   1.9403e-05    16.8760 |  46.1 |        \n",
      "  266 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.6376   4.1555e-02   1.9403e-05    0.6791 |   1.12288   0.82293   0.82217   0.82285 |   16.8439   4.1555e-02   1.9403e-05    16.8855 |  46.6 |        \n",
      "  267 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4192   4.1555e-02   1.9403e-05    0.4608 |   1.12501   0.82291   0.82213   0.82283 |   16.8375   4.1555e-02   1.9403e-05    16.8791 |  46.3 |        \n",
      "  268 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3584   4.1555e-02   1.9403e-05    0.4000 |   1.12539   0.82289   0.82214   0.82281 |   16.8788   4.1555e-02   1.9403e-05    16.9204 |  47.9 |        \n",
      "  269 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4783   4.1555e-02   1.9403e-05    0.5198 |   1.12501   0.82271   0.82202   0.82263 |   16.8521   4.1555e-02   1.9403e-05    16.8937 |  46.6 |        \n",
      "  270 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3940   4.1555e-02   1.9403e-05    0.4356 |   1.12607   0.82278   0.82205   0.82270 |   16.8924   4.1555e-02   1.9403e-05    16.9340 |  47.8 |        \n",
      "  271 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4507   4.1555e-02   1.9403e-05    0.4923 |   1.12617   0.82279   0.82201   0.82271 |   16.8424   4.1555e-02   1.9403e-05    16.8840 |  46.0 |        \n",
      "  272 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3757   4.1555e-02   1.9403e-05    0.4173 |   1.12957   0.82266   0.82186   0.82258 |   16.8918   4.1555e-02   1.9403e-05    16.9333 |  48.0 |        \n",
      "  273 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3612   4.1555e-02   1.9403e-05    0.4028 |   1.13011   0.82265   0.82181   0.82257 |   16.9999   4.1555e-02   1.9403e-05    17.0415 |  46.7 |        \n",
      "  274 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3830   4.1555e-02   1.9403e-05    0.4246 |   1.13062   0.82260   0.82183   0.82252 |   16.9987   4.1555e-02   1.9403e-05    17.0402 |  48.2 |        \n",
      "  275 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.5103   4.1555e-02   1.9403e-05    0.5519 |   1.13246   0.82280   0.82194   0.82272 |   17.0059   4.1555e-02   1.9403e-05    17.0475 |  46.4 |        \n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "  276 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3418   4.1555e-02   1.9403e-05    0.3834 |   1.13187   0.82268   0.82184   0.82260 |   17.0014   4.1555e-02   1.9403e-05    17.0430 |  46.9 |\n",
      "  277 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3427   4.1555e-02   1.9403e-05    0.3843 |   1.13553   0.82252   0.82165   0.82244 |   16.9753   4.1555e-02   1.9403e-05    17.0168 |  46.8 |        \n",
      "  278 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4179   4.1555e-02   1.9403e-05    0.4595 |   1.13422   0.82260   0.82174   0.82252 |   16.9793   4.1555e-02   1.9403e-05    17.0209 |  47.8 |        \n",
      "  279 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4419   4.1555e-02   1.9403e-05    0.4835 |   1.13469   0.82270   0.82181   0.82262 |   16.9999   4.1555e-02   1.9403e-05    17.0415 |  46.3 |        \n",
      "  280 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3575   4.1555e-02   1.9403e-05    0.3991 |   1.13408   0.82274   0.82188   0.82266 |   17.0005   4.1555e-02   1.9403e-05    17.0421 |  47.6 |        \n",
      "  281 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3094   4.1555e-02   1.9403e-05    0.3510 |   1.13450   0.82276   0.82192   0.82268 |   17.0058   4.1555e-02   1.9403e-05    17.0473 |  45.6 |        \n",
      "  282 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.5336   4.1555e-02   1.9403e-05    0.5752 |   1.13626   0.82268   0.82187   0.82260 |   17.0441   4.1555e-02   1.9403e-05    17.0857 |  47.9 |        \n",
      "  283 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4956   4.1555e-02   1.9403e-05    0.5372 |   1.13556   0.82289   0.82202   0.82281 |   17.0194   4.1555e-02   1.9403e-05    17.0609 |  46.2 |        \n",
      "  284 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3141   4.1555e-02   1.9403e-05    0.3556 |   1.13570   0.82294   0.82207   0.82286 |   17.0289   4.1555e-02   1.9403e-05    17.0705 |  48.0 |        \n",
      "  285 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4549   4.1555e-02   1.9403e-05    0.4965 |   1.13834   0.82272   0.82186   0.82264 |   17.0378   4.1555e-02   1.9403e-05    17.0794 |  46.6 |        \n",
      "  286 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4487   4.1555e-02   1.9403e-05    0.4902 |   1.13939   0.82273   0.82186   0.82265 |   17.1009   4.1555e-02   1.9403e-05    17.1425 |  46.8 |        \n",
      "  287 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.2630   4.1555e-02   1.9403e-05    0.3046 |   1.13939   0.82270   0.82185   0.82262 |   17.1145   4.1555e-02   1.9403e-05    17.1561 |  46.4 |        \n",
      "  288 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3380   4.1555e-02   1.9403e-05    0.3796 |   1.14048   0.82290   0.82200   0.82282 |   17.0449   4.1555e-02   1.9403e-05    17.0865 |  48.3 |        \n",
      "  289 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.5299   4.1555e-02   1.9403e-05    0.5714 |   1.14131   0.82277   0.82196   0.82269 |   17.1251   4.1555e-02   1.9403e-05    17.1667 |  46.3 |        \n",
      "  290 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.4737   4.1555e-02   1.9403e-05    0.5153 |   1.14243   0.82268   0.82181   0.82260 |   17.1683   4.1555e-02   1.9403e-05    17.2099 |  47.6 |        \n",
      "  291 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3127   4.1555e-02   1.9403e-05    0.3543 |   1.14136   0.82256   0.82176   0.82248 |   17.0971   4.1555e-02   1.9403e-05    17.1387 |  46.0 |        \n",
      "  292 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.5344   4.1555e-02   1.9403e-05    0.5760 |   1.14212   0.82268   0.82188   0.82260 |   17.1529   4.1555e-02   1.9403e-05    17.1945 |  47.8 |        \n",
      "  293 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.2877   4.1555e-02   1.9403e-05    0.3293 |   1.14357   0.82267   0.82183   0.82259 |   17.1493   4.1555e-02   1.9403e-05    17.1909 |  48.0 |        \n",
      "  294 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.5658   4.1555e-02   1.9403e-05    0.6074 |   1.14591   0.82261   0.82177   0.82253 |   17.2404   4.1555e-02   1.9403e-05    17.2820 |  48.3 |        \n",
      "  295 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.5446   4.1555e-02   1.9403e-05    0.5862 |   1.14608   0.82254   0.82173   0.82246 |   17.1894   4.1555e-02   1.9403e-05    17.2310 |  47.1 |        \n",
      "  296 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3154   4.1555e-02   1.9403e-05    0.3570 |   1.14219   0.82272   0.82192   0.82264 |   17.1365   4.1555e-02   1.9403e-05    17.1781 |  47.4 |        \n",
      "  297 |   2.37e-04   2.37e-04   3.16e-04  4.000e+00 |    0.3898   4.1555e-02   1.9403e-05    0.4313 |   1.14637   0.82248   0.82177   0.82240 |   17.2395   4.1555e-02   1.9403e-05    17.2810 |  46.6 |        \n",
      "Epoch   297: reducing learning rate of group 0 to 1.7798e-04.\n",
      "Epoch   297: reducing learning rate of group 1 to 1.7798e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  298 |   1.78e-04   1.78e-04   3.16e-04  4.000e+00 |    0.3717   4.1555e-02   1.9403e-05    0.4132 |   1.14520   0.82255   0.82182   0.82247 |   17.1644   4.1555e-02   1.9403e-05    17.2060 |  48.1 |        \n",
      "  299 |   1.78e-04   1.78e-04   3.16e-04  4.000e+00 |    0.4038   4.1555e-02   1.9403e-05    0.4454 |   1.14920   0.82259   0.82182   0.82251 |   17.2732   4.1555e-02   1.9403e-05    17.3148 |  46.5 |        \n",
      "  300 |   1.78e-04   1.78e-04   3.16e-04  4.000e+00 |    0.2379   4.1555e-02   1.9403e-05    0.2795 |   1.14675   0.82267   0.82191   0.82259 |   17.1464   4.1555e-02   1.9403e-05    17.1880 |  47.6 |        \n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "  301 |   1.78e-04   1.78e-04   3.16e-04  4.000e+00 |    0.2998   4.1555e-02   1.9403e-05    0.3414 |   1.14931   0.82257   0.82176   0.82249 |   17.2307   4.1555e-02   1.9403e-05    17.2723 |  46.0 |\n",
      "Epoch   301: reducing learning rate of group 0 to 2.3730e-04.\n",
      "  302 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2979   4.1555e-02   1.9403e-05    0.3395 |   1.14982   0.82247   0.82171   0.82239 |   17.2366   4.1555e-02   1.9403e-05    17.2782 |  49.2 |        \n",
      "  303 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3450   4.1555e-02   1.9403e-05    0.3866 |   1.14779   0.82258   0.82179   0.82250 |   17.1430   4.1555e-02   1.9403e-05    17.1846 |  46.5 |        \n",
      "  304 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2618   4.1555e-02   1.9403e-05    0.3034 |   1.15210   0.82251   0.82169   0.82243 |   17.2435   4.1555e-02   1.9403e-05    17.2851 |  47.3 |        \n",
      "  305 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3565   4.1555e-02   1.9403e-05    0.3981 |   1.15077   0.82258   0.82174   0.82250 |   17.2138   4.1555e-02   1.9403e-05    17.2554 |  46.1 |        \n",
      "  306 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3574   4.1555e-02   1.9403e-05    0.3989 |   1.15216   0.82259   0.82178   0.82251 |   17.2705   4.1555e-02   1.9403e-05    17.3121 |  46.8 |        \n",
      "  307 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2887   4.1555e-02   1.9403e-05    0.3302 |   1.14902   0.82274   0.82196   0.82266 |   17.2049   4.1555e-02   1.9403e-05    17.2464 |  47.5 |        \n",
      "  308 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2845   4.1555e-02   1.9403e-05    0.3261 |   1.15222   0.82253   0.82175   0.82245 |   17.1990   4.1555e-02   1.9403e-05    17.2406 |  47.8 |        \n",
      "  309 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3794   4.1555e-02   1.9403e-05    0.4209 |   1.15381   0.82243   0.82173   0.82235 |   17.2752   4.1555e-02   1.9403e-05    17.3168 |  46.0 |        \n",
      "  310 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2781   4.1555e-02   1.9403e-05    0.3197 |   1.15148   0.82250   0.82172   0.82242 |   17.2999   4.1555e-02   1.9403e-05    17.3414 |  47.3 |        \n",
      "  311 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2808   4.1555e-02   1.9403e-05    0.3224 |   1.15391   0.82239   0.82167   0.82231 |   17.3377   4.1555e-02   1.9403e-05    17.3792 |  45.3 |        \n",
      "  312 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3064   4.1555e-02   1.9403e-05    0.3480 |   1.15689   0.82235   0.82160   0.82226 |   17.3350   4.1555e-02   1.9403e-05    17.3766 |  47.3 |        \n",
      "  313 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.5145   4.1555e-02   1.9403e-05    0.5561 |   1.15629   0.82247   0.82165   0.82239 |   17.3370   4.1555e-02   1.9403e-05    17.3786 |  45.9 |        \n",
      "  314 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.4065   4.1555e-02   1.9403e-05    0.4481 |   1.15744   0.82250   0.82168   0.82242 |   17.3451   4.1555e-02   1.9403e-05    17.3867 |  47.5 |        \n",
      "  315 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2738   4.1555e-02   1.9403e-05    0.3154 |   1.15858   0.82245   0.82164   0.82237 |   17.3882   4.1555e-02   1.9403e-05    17.4298 |  46.0 |        \n",
      "  316 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3359   4.1555e-02   1.9403e-05    0.3775 |   1.15691   0.82252   0.82174   0.82244 |   17.3511   4.1555e-02   1.9403e-05    17.3927 |  46.5 |        \n",
      "  317 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3537   4.1555e-02   1.9403e-05    0.3953 |   1.15515   0.82267   0.82189   0.82259 |   17.2550   4.1555e-02   1.9403e-05    17.2966 |  45.9 |        \n",
      "  318 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2469   4.1555e-02   1.9403e-05    0.2885 |   1.15712   0.82266   0.82182   0.82258 |   17.3815   4.1555e-02   1.9403e-05    17.4231 |  47.5 |        \n",
      "  319 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.4098   4.1555e-02   1.9403e-05    0.4514 |   1.15974   0.82265   0.82179   0.82257 |   17.3682   4.1555e-02   1.9403e-05    17.4097 |  46.5 |        \n",
      "  320 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.5289   4.1555e-02   1.9403e-05    0.5705 |   1.15945   0.82240   0.82158   0.82232 |   17.4041   4.1555e-02   1.9403e-05    17.4457 |  47.7 |        \n",
      "  321 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2383   4.1555e-02   1.9403e-05    0.2799 |   1.16222   0.82235   0.82156   0.82227 |   17.4570   4.1555e-02   1.9403e-05    17.4985 |  45.6 |        \n",
      "  322 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2686   4.1555e-02   1.9403e-05    0.3102 |   1.16242   0.82239   0.82162   0.82231 |   17.4586   4.1555e-02   1.9403e-05    17.5001 |  47.9 |        \n",
      "  323 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3286   4.1555e-02   1.9403e-05    0.3702 |   1.16190   0.82252   0.82162   0.82244 |   17.4263   4.1555e-02   1.9403e-05    17.4679 |  46.3 |        \n",
      "  324 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2928   4.1555e-02   1.9403e-05    0.3344 |   1.16072   0.82249   0.82157   0.82241 |   17.3912   4.1555e-02   1.9403e-05    17.4328 |  47.5 |        \n",
      "  325 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.4544   4.1555e-02   1.9403e-05    0.4960 |   1.16471   0.82230   0.82142   0.82222 |   17.5821   4.1555e-02   1.9403e-05    17.6237 |  46.2 |        \n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |        \n",
      "  326 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.4464   4.1555e-02   1.9403e-05    0.4880 |   1.16179   0.82242   0.82153   0.82234 |   17.3595   4.1555e-02   1.9403e-05    17.4011 |  46.6 |\n",
      "  327 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3445   4.1555e-02   1.9403e-05    0.3861 |   1.16425   0.82234   0.82148   0.82226 |   17.5263   4.1555e-02   1.9403e-05    17.5679 |  52.4 |        \n",
      "  328 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2051   4.1555e-02   1.9403e-05    0.2467 |   1.16237   0.82236   0.82153   0.82228 |   17.3961   4.1555e-02   1.9403e-05    17.4377 |  47.5 |        \n",
      "  329 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3536   4.1555e-02   1.9403e-05    0.3952 |   1.16426   0.82249   0.82158   0.82241 |   17.4653   4.1555e-02   1.9403e-05    17.5069 |  45.9 |        \n",
      "  330 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.4509   4.1555e-02   1.9403e-05    0.4925 |   1.16497   0.82247   0.82157   0.82239 |   17.4186   4.1555e-02   1.9403e-05    17.4602 |  47.0 |        \n",
      "  331 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3791   4.1555e-02   1.9403e-05    0.4207 |   1.16622   0.82235   0.82150   0.82227 |   17.4965   4.1555e-02   1.9403e-05    17.5381 |  45.2 |        \n",
      "  332 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2177   4.1555e-02   1.9403e-05    0.2593 |   1.16621   0.82237   0.82152   0.82229 |   17.5080   4.1555e-02   1.9403e-05    17.5496 |  47.7 |        \n",
      "  333 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3850   4.1555e-02   1.9403e-05    0.4265 |   1.16762   0.82249   0.82159   0.82241 |   17.5039   4.1555e-02   1.9403e-05    17.5454 |  46.2 |        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  334 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2831   4.1555e-02   1.9403e-05    0.3247 |   1.16434   0.82261   0.82176   0.82253 |   17.4673   4.1555e-02   1.9403e-05    17.5089 |  47.3 |        \n",
      "  335 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3729   4.1555e-02   1.9403e-05    0.4145 |   1.16682   0.82247   0.82163   0.82239 |   17.4884   4.1555e-02   1.9403e-05    17.5299 |  45.8 |        \n",
      "  336 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2166   4.1555e-02   1.9403e-05    0.2582 |   1.16628   0.82244   0.82157   0.82236 |   17.5791   4.1555e-02   1.9403e-05    17.6207 |  48.3 |        \n",
      "  337 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3769   4.1555e-02   1.9403e-05    0.4185 |   1.16719   0.82247   0.82163   0.82239 |   17.4964   4.1555e-02   1.9403e-05    17.5380 |  48.0 |        \n",
      "  338 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3440   4.1555e-02   1.9403e-05    0.3855 |   1.16978   0.82248   0.82161   0.82240 |   17.5224   4.1555e-02   1.9403e-05    17.5640 |  50.3 |        \n",
      "  339 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2221   4.1555e-02   1.9403e-05    0.2637 |   1.16942   0.82235   0.82149   0.82227 |   17.5236   4.1555e-02   1.9403e-05    17.5652 |  50.1 |        \n",
      "  340 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3134   4.1555e-02   1.9403e-05    0.3550 |   1.17083   0.82240   0.82158   0.82232 |   17.5793   4.1555e-02   1.9403e-05    17.6209 |  50.6 |        \n",
      "  341 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.3289   4.1555e-02   1.9403e-05    0.3705 |   1.16921   0.82224   0.82145   0.82216 |   17.6012   4.1555e-02   1.9403e-05    17.6427 |  47.1 |        \n",
      "  342 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.2133   4.1555e-02   1.9403e-05    0.2549 |   1.17041   0.82227   0.82150   0.82219 |   17.4910   4.1555e-02   1.9403e-05    17.5326 |  50.4 |        \n",
      "  343 |   1.78e-04   1.78e-04   2.37e-04  4.000e+00 |    0.4137   4.1555e-02   1.9403e-05    0.4553 |   1.17054   0.82228   0.82151   0.82220 |   17.5397   4.1555e-02   1.9403e-05    17.5813 |  50.3 |        \n",
      "Epoch   343: reducing learning rate of group 0 to 1.3348e-04.\n",
      "Epoch   343: reducing learning rate of group 1 to 1.3348e-04.\n",
      "  344 |   1.33e-04   1.33e-04   2.37e-04  4.000e+00 |    0.2957   4.1555e-02   1.9403e-05    0.3373 |   1.17244   0.82224   0.82146   0.82216 |   17.6154   4.1555e-02   1.9403e-05    17.6569 |  49.1 |        \n",
      "  345 |   1.33e-04   1.33e-04   2.37e-04  4.000e+00 |    0.3148   4.1555e-02   1.9403e-05    0.3564 |   1.17327   0.82220   0.82147   0.82212 |   17.6053   4.1555e-02   1.9403e-05    17.6469 |  48.4 |        \n",
      "  346 |   1.33e-04   1.33e-04   2.37e-04  4.000e+00 |    0.4246   4.1555e-02   1.9403e-05    0.4661 |   1.17160   0.82227   0.82150   0.82219 |   17.5501   4.1555e-02   1.9403e-05    17.5916 |  48.2 |        \n",
      "  347 |   1.33e-04   1.33e-04   2.37e-04  4.000e+00 |    0.5959   4.1555e-02   1.9403e-05    0.6374 |   1.17338   0.82225   0.82145   0.82217 |   17.5723   4.1555e-02   1.9403e-05    17.6139 |  47.6 |        \n",
      "  348 |   1.33e-04   1.33e-04   2.37e-04  4.000e+00 |    0.3912   4.1555e-02   1.9403e-05    0.4328 |   1.17318   0.82237   0.82154   0.82229 |   17.6391   4.1555e-02   1.9403e-05    17.6807 |  49.4 |        \n",
      "  349 |   1.33e-04   1.33e-04   2.37e-04  4.000e+00 |    0.4605   4.1555e-02   1.9403e-05    0.5021 |   1.17171   0.82237   0.82157   0.82229 |   17.5514   4.1555e-02   1.9403e-05    17.5930 |  47.6 |        \n",
      "  350 |   1.33e-04   1.33e-04   2.37e-04  4.000e+00 |    0.3782   4.1555e-02   1.9403e-05    0.4198 |   1.17405   0.82225   0.82148   0.82217 |   17.6045   4.1555e-02   1.9403e-05    17.6460 |  49.3 |        \n",
      "[Final] ep:350  it:36750 -  Total Loss: 17.6460     \n",
      "Task: 17.6045   Sparsity: 4.15548e-02    Sharing: 1.94033e-05 \n",
      "\n",
      " epch: 350   softmax      s        softmax       s        softmax       s\n",
      " -----  ----------------- -    ----------------- -    ----------------- - \n",
      "   1    0.4999    0.5001  0    0.4996    0.5004  0    0.4997    0.5003  0\n",
      "\n",
      "\n",
      "\n",
      " epch: 350   logits       s          logits      s         logits       s\n",
      " -----  ----------------- -    ----------------  -    ----------------  - \n",
      "   1   -0.0008   -0.0003  0    0.0001    0.0018  0   -0.0009    0.0003  0\n",
      "\n",
      "\n",
      " save warmup val_metrics to :  model_warmup_ep_350\n",
      " save warmup checkpoint  to :  model_warmup_ep_350\n"
     ]
    }
   ],
   "source": [
    "# warmup_phase(ns,opt, environ, dldrs, epochs = 25)\n",
    "warmup_phase(ns,opt, environ, dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05b99542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T07:34:24.954147Z",
     "start_time": "2022-03-29T07:34:24.842969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 6090, 0.8293974608888801)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warmup_phase(ns,opt, environ, dldrs, epochs = 25)\n",
    "ns.best_epoch, ns.best_iter, ns.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3dc43cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T07:36:51.350183Z",
     "start_time": "2022-03-29T07:36:47.892723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1f0d7593d74f51a48c48b179f02eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.867 MB of 3.867 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_time</td><td>▄▃▂▄▁▃▁▄▅▅▅▆▅▄▆▄▄▅▄▃▃▄▃▅▆▅▆▇▅▃▅▃▅▅▅▄▅▄▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>350</td></tr><tr><td>train_time</td><td>49.3322</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0329_0458_noplcy</strong>: <a href=\"http://localhost:8080/kbardool/AdaSparseChem/runs/14lubvbu\" target=\"_blank\">http://localhost:8080/kbardool/AdaSparseChem/runs/14lubvbu</a><br/>Synced 7 W&B file(s), 1050 media file(s), 1054 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220329_045827-14lubvbu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ns.wandb_run.finish()\n",
    "\n",
    "ns.wandb_run.finish()\n",
    "\n",
    "# environ.losses\n",
    "\n",
    "# environ.val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea84c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04d238e8",
   "metadata": {},
   "source": [
    "#### display parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e75ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:47.732297Z",
     "start_time": "2022-03-28T04:02:47.639607Z"
    }
   },
   "outputs": [],
   "source": [
    "print( f\" Backbone Initial LR         : {environ.opt['train']['backbone_lr']:4f}      current LR : {environ.optimizers['alphas'].param_groups[0]['lr']} \\n\"\n",
    "       f\" Tasks    Initial LR         : {environ.opt['train']['task_lr']:4f}      current LR : {environ.optimizers['weights'].param_groups[0]['lr']}    \\n\"\n",
    "       f\" Policy   Initial LR         : {environ.opt['train']['policy_lr']:4f}      current LR : {environ.optimizers['weights'].param_groups[1]['lr']}  \\n\")\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db34fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:47.803657Z",
     "start_time": "2022-03-28T04:02:47.736497Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['policy_lr'] = 0.01\n",
    "# opt['train']['policy_lr']         = 0.01\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.1\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# environ.opt['train']['decay_temp_freq'] = 2\n",
    "# print(environ.optimizers['alphas'].param_groups)\n",
    "# print(environ.optimizers['weights'].param_groups)\n",
    "# print('current lr: ', environ.optimizers['alphas'].param_groups[0]['lr'],)\n",
    "# print('current lr: ', environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "# print('current lr: ', environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49645c",
   "metadata": {},
   "source": [
    "## Weight & Policy Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aade16",
   "metadata": {},
   "source": [
    "### Weight/Policy Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe24a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:47.867009Z",
     "start_time": "2022-03-28T04:02:47.807720Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.flag_warmup = True\n",
    "# num_train_layers = None \n",
    "# environ.opt['is_curriculum'] = True\n",
    "# environ.opt['curriculum_speed'] = 4\n",
    "# ns.num_train_layers = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365996be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:47.944530Z",
     "start_time": "2022-03-28T04:02:47.871259Z"
    }
   },
   "outputs": [],
   "source": [
    "if ns.flag_warmup:\n",
    "    print_heading( f\"** {timestring()} \\n\"\n",
    "                   f\"** Training epoch: {ns.current_epoch} iter: {ns.current_iter}   flag: {ns.flag} \\n\"\n",
    "                   f\"** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\\n\"\n",
    "                   f\"** Switch from Warm Up training to Alternate training Weights & Policy \\n\"\n",
    "                   f\"** Take checkpoint and block gradient flow through Policy net\", verbose=True)\n",
    "#     environ.define_optimizer(policy_learning=True)\n",
    "#     environ.define_scheduler(policy_learning=True)\n",
    "    ns.flag_warmup = False\n",
    "    ns.flag = 'update_weights'\n",
    "    environ.fix_alpha()\n",
    "    environ.free_weights(opt['fix_BN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc79e10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:48.024063Z",
     "start_time": "2022-03-28T04:02:47.950823Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.training_epochs = 250\n",
    "# environ.display_trained_policy(ns.current_epoch)\n",
    "# environ.display_trained_logits(ns.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d84a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T04:02:48.115175Z",
     "start_time": "2022-03-28T04:02:48.028324Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"ns.current_epoch           : {ns.current_epoch}\")\n",
    "print(f\"ns.training_epochs         : {ns.training_epochs} \\n\") \n",
    "print(f\"ns.current_iters           : {ns.current_iter}\")  \n",
    "print(f\"Batches in weight epoch    : {ns.stop_iter_w}\")\n",
    "print(f\"Batches in policy epoch    : {ns.stop_iter_a}\")\n",
    "print(f\"num_train_layers           : {ns.num_train_layers}\")\n",
    "print()\n",
    "print_loss(environ.val_metrics, title = f\"[e] Last ep:{ns.current_epoch}  it:{ns.current_iter}\")\n",
    "print()\n",
    "\n",
    "print_heading(f\" Last Epoch Completed : {ns.current_epoch}       # of epochs to run:  {ns.training_epochs} -->  epochs {ns.current_epoch+1} to {ns.training_epochs + ns.current_epoch}\"\n",
    "              f\"\\n policy_learning rate : {environ.opt['train']['policy_lr']} \"\n",
    "              f\"\\n lambda_sparsity      : {environ.opt['train']['lambda_sparsity']}\"\n",
    "              f\"\\n lambda_sharing       : {environ.opt['train']['lambda_sharing']}\"\n",
    "              f\"\\n curriculum training  : {opt['is_curriculum']}     cirriculum speed: {opt['curriculum_speed']}     num_training_layers : {ns.num_train_layers}\", \n",
    "              verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c71af",
   "metadata": {},
   "source": [
    "### Weight/Policy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ad7d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:27.891351Z",
     "start_time": "2022-03-28T04:02:48.119371Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# weight_policy_training(ns, opt, environ, dldrs, epochs = 100)\n",
    "weight_policy_training(ns, opt, environ, dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27779c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:28.065212Z",
     "start_time": "2022-03-28T05:13:27.897193Z"
    }
   },
   "outputs": [],
   "source": [
    "ns.best_epoch, ns.best_iter, ns.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be1060",
   "metadata": {},
   "source": [
    "### Close WandB run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f6dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.216421Z",
     "start_time": "2022-03-28T05:13:28.068834Z"
    }
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49cc3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.253924Z",
     "start_time": "2022-03-28T05:13:32.221329Z"
    }
   },
   "outputs": [],
   "source": [
    "# ns.best_epoch = 0\n",
    "# from utils.notebook_modules import wrapup_phase\n",
    "# wrapup_phase(ns, opt, environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570db82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.307351Z",
     "start_time": "2022-03-28T05:13:32.262822Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['policy_lr']       = 0.002\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.05\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# # environ.opt['train']['decay_temp_freq'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26efa07b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T05:13:32.344678Z",
     "start_time": "2022-03-28T05:13:32.310706Z"
    }
   },
   "outputs": [],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" \n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\\n\") \n",
    "\n",
    "print( f\" current_iters               : {ns.current_iter}   \\n\"\n",
    "       f\" current_epochs              : {ns.current_epoch}  \\n\" \n",
    "       f\" train_total_epochs          : {ns.training_epochs}\\n\" \n",
    "       f\" stop_epoch_training         : {ns.stop_epoch_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3dcb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86ac6b6a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Post Training Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de4040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T22:17:44.833671Z",
     "start_time": "2022-03-13T22:17:44.799394Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "# pp.pprint(environ.val_metrics)\n",
    "environ.num_layers, environ.networks['mtl-net'].num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ca92e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T23:23:43.744498Z",
     "start_time": "2022-03-10T23:23:43.696990Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.val_metrics['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e5cec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T17:44:36.218784Z",
     "start_time": "2022-02-21T17:44:36.063411Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "# environ.display_trained_policy(current_epoch)\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c1c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:32:52.580865Z",
     "start_time": "2022-03-06T00:32:52.554112Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_label   = 'model_train_ep_%d_seed_%04d' % (current_epoch, opt['random_seed'])\n",
    "# metrics_label = 'metrics_train_ep_%d_seed_%04d.pickle' % (current_epoch, opt['random_seed'])\n",
    "# environ.save_checkpoint(model_label, current_iter, current_epoch) \n",
    "# save_to_pickle(environ.val_metrics, environ.opt['paths']['checkpoint_dir'], metrics_label)\n",
    "# print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "# environ.display_trained_policy(current_epoch,out=[sys.stdout, environ.log_file])\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad3a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T22:48:27.014120Z",
     "start_time": "2022-02-20T22:48:26.982535Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_loss(current_iter, environ.losses, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")\n",
    "# print()\n",
    "# print_loss(current_iter, trn_losses, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")\n",
    "# print()\n",
    "# print_loss(current_iter, environ.val_metrics, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d5db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T20:31:45.254334Z",
     "start_time": "2022-03-01T20:31:45.116895Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.losses\n",
    "# environ.val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4dd81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T20:47:29.582501Z",
     "start_time": "2022-03-01T20:47:29.492581Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.batch_data\n",
    "# print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics, 0, out=[sys.stdout])\n",
    "# environ.display_parameters()\n",
    "\n",
    "# with np.printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', precision=7, formatter={'float': lambda x: f\"{x:12.5e}\"}):\n",
    "#     environ.print_logit_grads('gradients')\n",
    "\n",
    "# environ_params = environ.get_task_specific_parameters()\n",
    "# environ_params = environ.get_arch_parameters()\n",
    "# environ_params = environ.get_backbone_parameters()\n",
    "# print(environ_params)\n",
    "# for param in environ_params:\n",
    "#     print(param.grad.shape, '\\n', param.grad)\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c80c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:12:46.806056Z",
     "start_time": "2022-03-11T21:12:46.471801Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.display_trained_logits(ns.current_epoch)\n",
    "environ.display_trained_policy(ns.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d47dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:13:19.578964Z",
     "start_time": "2022-03-11T21:13:19.242252Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.display_test_sample_policy(ns.current_epoch, hard_sampling = True)\n",
    "environ.display_train_sample_policy(ns.current_epoch, hard_sampling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754b317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:33:19.474125Z",
     "start_time": "2022-03-06T00:33:19.447847Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.define_optimizer(policy_learning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e89541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T00:07:08.097708Z",
     "start_time": "2022-03-09T00:07:08.070721Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.optimizers['alphas'])\n",
    "print(environ.optimizers['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ecc91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T00:07:50.026992Z",
     "start_time": "2022-03-09T00:07:49.986101Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Policy  initial_lr : ', environ.optimizers['alphas'].param_groups[0]['initial_lr'], 'lr : ',environ.optimizers['alphas'].param_groups[0]['lr'])\n",
    "print('Weights initial_lr : ', environ.optimizers['weights'].param_groups[0]['initial_lr'], 'lr : ',environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "print('Weights initial_lr : ', environ.optimizers['weights'].param_groups[1]['initial_lr'], 'lr : ',environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1306e8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T22:31:50.425696Z",
     "start_time": "2022-03-10T22:31:50.396531Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wandb.run is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b8e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:10:03.751132Z",
     "start_time": "2022-03-05T23:10:03.724538Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# opt['exp_instance'] = '0218_1358'     \n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\"\n",
    "# print()\n",
    "# opt['exp_instance'] = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "# opt['exp_description'] = f\"No Alternating Weight/Policy - training all done with both weights and policy\"\n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2affee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T21:12:20.322227Z",
     "start_time": "2022-03-11T21:12:20.285961Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527bd00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:25:11.319751Z",
     "start_time": "2022-02-20T21:25:11.210062Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "p = environ.get_current_state(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919068f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:25:26.324030Z",
     "start_time": "2022-02-20T21:25:26.112782Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82a453",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Post Warm-up Training stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb74c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:45:43.999959Z",
     "start_time": "2022-02-01T12:45:43.862475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b47da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:36.700361Z",
     "start_time": "2022-02-01T12:46:36.367037Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].arch_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f0235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:37:10.158440Z",
     "start_time": "2022-01-28T16:37:09.742327Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p = environ.get_sample_policy(hard_sampling = False)\n",
    "print(p)\n",
    "p = environ.get_policy_prob()\n",
    "print(p)\n",
    "p = environ.get_policy_logits()\n",
    "print(p)\n",
    "\n",
    "# p = environ.get_current_policy()\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bddd44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:40:37.799917Z",
     "start_time": "2022-01-28T16:40:37.773177Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = softmax([0.0, 1])\n",
    "print(a)\n",
    "sampled = np.random.choice((1, 0), p=a)\n",
    "print(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8f376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:13:16.205889Z",
     "start_time": "2022-01-28T16:13:16.179303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.optimizers['weights'])\n",
    "print(environ.schedulers['weights'].get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf9c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:50.411465Z",
     "start_time": "2022-02-01T12:46:50.020540Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('losses.keys      : ', environ.losses.keys())\n",
    "print('losses[task]keys : ', environ.losses['task1'].keys())\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20950069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T22:57:02.151169Z",
     "start_time": "2022-01-15T22:57:02.056562Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print( environ.val_metrics.keys())\n",
    "# pp.pprint(val_metrics)\n",
    "print(type(environ.val_metrics['aggregated']))\n",
    "print()\n",
    "print(type(environ.val_metrics['task1']['classification_agg']))\n",
    "print()\n",
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6e311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.266303Z",
     "start_time": "2022-01-14T18:57:26.166878Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"val_metrics.pkl\", mode= 'wb') as f:\n",
    "#         pickle.dump(val_metrics, f)\n",
    "    \n",
    "# with open('val_metrics.pkl', 'rb') as f:    \n",
    "#     tst_val_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00a8aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.297444Z",
     "start_time": "2022-01-14T18:57:26.269323Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(environ.input.shape) \n",
    "# a = getattr(environ, 'task1_pred')\n",
    "# yc_data = environ.batch['task1_data']\n",
    "# print(yc_data.shape)\n",
    "# yc_ind = environ.batch['task1_ind']\n",
    "# print(yc_ind.shape)\n",
    "# yc_hat_all = getattr(environ, 'task1_pred')\n",
    "# print(yc_hat_all.shape)\n",
    "# yc_hat  = yc_hat_all[yc_ind[0], yc_ind[1]]\n",
    "# print(yc_hat_all.shape, yc_hat.shape)\n",
    "\n",
    "# \n",
    "# environ.losses\n",
    "# loss = {}\n",
    "# for key in environ.losses.keys():\n",
    "#     loss[key] = {}\n",
    "#     for subkey, v in environ.losses[key].items():\n",
    "#         print(f\" key:  {key}   subkey: {subkey} \")\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             loss[key][subkey] = v.data\n",
    "#             print(f\" Tensor  -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "#         else:\n",
    "#             loss[key][subkey] = v\n",
    "#             print(f\" integer -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "# pp.pprint(tst_val_metrics)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987f89f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.340792Z",
     "start_time": "2022-01-14T18:57:26.302528Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print('metrics.keys: ', environ.metrics.keys())\n",
    "# print('metrics[task].keys: ', environ.metrics['task1'].keys())\n",
    "# pp.pprint(environ.metrics['task1'])\n",
    "# pp.pprint(environ.losses['task1']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ae417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.373399Z",
     "start_time": "2022-01-14T18:57:26.345065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# title='Iteration'\n",
    "# for t_id, _ in enumerate(environ.tasks):\n",
    "#     task_key = f\"task{t_id+1}\"\n",
    "# #     print_heading(f\"{title}  {current_iter}  {task_key} : {val_metrics[task_key]['classification_agg']}\", verbose = True)\n",
    "\n",
    "#     for key, _  in val_metrics[task_key]['classification_agg'].items():\n",
    "#         print('%s/%-20s'%(task_key, key), val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print(f\"{task_key:s}/{key:20s}\", val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print()\n",
    "#             # print_current_errors(os.path.join(self.log_dir, 'loss.txt'), current_iter,key, loss[key], time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b73b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:48.162261Z",
     "start_time": "2022-01-07T22:52:48.140423Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.print_loss(current_iter, start_time, metrics = val_metrics['loss'], verbose=True)\n",
    "# print(opt['lambdas'])\n",
    "# p = (opt['lambdas'][0] * environ.losses['tasks']['task1'])\n",
    "# print(p)\n",
    "\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics , title='validation', verbose=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850378b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:47.661019Z",
     "start_time": "2022-01-07T22:52:47.639094Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(current_iter)\n",
    "# print_metrics_cr(current_iter, t1 - t0, None, val_metrics , True)\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics, title='validation', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a80b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:14:58.034384Z",
     "start_time": "2022-01-07T23:14:58.004850Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\" val_metric keys               : {val_metrics.keys()}\")\n",
    "print(f\" loss keys                     : {val_metrics['loss'].keys()}\")\n",
    "print(f\" task1 keys                    : {val_metrics['task1'].keys()}\")\n",
    "print(f\" task1 classification keys     : {val_metrics['task1']['classification'].keys()}\")\n",
    "print(f\" task1 classification_agg keys : {val_metrics['task1']['classification_agg'].keys()}\")\n",
    "print()\n",
    "print(f\" task1                       : {val_metrics['task1']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task2                       : {val_metrics['task2']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task3                       : {val_metrics['task3']['classification_agg']['loss']:5f}\")\n",
    "print(f\" loss                        : {val_metrics['loss']['total']:5f}\")\n",
    "print(f\" train_time                  : {val_metrics['train_time']:2f}\")\n",
    "print(f\" epoch                       : {val_metrics['epoch']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc43a6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Post Weight + Policy Training Stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65640cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:22:20.634818Z",
     "start_time": "2022-01-27T00:22:20.444566Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].backbone.layer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4374287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:30:31.940280Z",
     "start_time": "2022-01-26T19:30:31.910058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_blocks = 6\n",
    "num_policy_layers = 6\n",
    "gt =  torch.ones((num_blocks)).long()\n",
    "gt0 =  torch.zeros((num_blocks)).long()\n",
    "print(gt)\n",
    "print(gt0)\n",
    "\n",
    "loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "print(loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651bc43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:42:31.300891Z",
     "start_time": "2022-01-26T19:42:31.257774Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if environ.opt['diff_sparsity_weights'] and not environ.opt['is_sharing']:\n",
    "    print(' cond 1')\n",
    "    ## Assign higher weights to higher layers \n",
    "    loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "    print(f\"{task_key} sparsity error:  {2 * (loss_weights[-num_blocks:] * environ.cross_entropy2(logits[-num_blocks:], gt)).mean()})\")\n",
    "    print_dbg(f\" loss_weights :  {loss_weights}\", verbose = True)\n",
    "    print_dbg(f\" cross_entropy:  {environ.cross_entropy2(logits[-num_blocks:], gt)}  \", verbose = True)\n",
    "    print_dbg(f\" loss[sparsity][{task_key}]: {self.losses['sparsity'][task_key] } \", verbose = True)\n",
    "\n",
    "else:\n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between \\n Logits   : \\n{logits[-num_blocks:]} \\n and gt: \\n{gt} \\n\", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-num_blocks:], gt)}\")\n",
    "    \n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt[-1:])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt0[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt0[-1:])} \\n\")\n",
    "    \n",
    "    print('\\n cond 3')    \n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt[0:1])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt0[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt0[0:1])} \\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686cd05",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ee1b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:30.155045Z",
     "start_time": "2022-01-26T00:14:30.107095Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# flag = 'update_w'\n",
    "# environ.fix_alpha\n",
    "# environ.free_w(opt['fix_BN'])\n",
    "\n",
    "flag = 'update_alpha'\n",
    "environ.fix_weights()\n",
    "environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7996b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:31.184285Z",
     "start_time": "2022-01-25T23:43:31.159229Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f436ee6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:34.993711Z",
     "start_time": "2022-01-26T00:14:34.968623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") \n",
    "\n",
    "train_total_epochs += 5\n",
    "\n",
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334a0b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T17:15:02.216665Z",
     "start_time": "2022-01-25T17:15:01.848081Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - t0, None, environ.val_metrics , num_prints)      \n",
    "\n",
    "# num_prints += 1\n",
    "# t0 = time.time()\n",
    "\n",
    "# # Take check point\n",
    "# environ.save_checkpoint('latest', current_iter)\n",
    "# environ.train()\n",
    "# #-------------------------------------------------------\n",
    "# # END validation process\n",
    "# #-------------------------------------------------------       \n",
    "# flag = 'update_alpha'\n",
    "# environ.fix_w()\n",
    "# environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c4f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:08:57.366231Z",
     "start_time": "2022-01-08T01:08:57.295445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dilation = 2\n",
    "# kernel_size = np.asarray((3, 3))\n",
    "# upsampled_kernel_size = (kernel_size - 1) * (dilation - 1) + kernel_size\n",
    "# print(upsampled_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500c390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:39.763599Z",
     "start_time": "2022-01-25T23:43:39.728402Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.optimizers['weights'].param_groups[0]\n",
    "# for param_group in optimizer.param_groups:\n",
    "#     return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb71bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:41.628847Z",
     "start_time": "2022-01-25T23:43:41.602238Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.schedulers['weights'].get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7934862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:36:17.129535Z",
     "start_time": "2022-01-08T01:36:16.006144Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.optimizers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    current_state[k] = v.state_dict()\n",
    "pp.pprint(current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5faf7f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:40:22.032247Z",
     "start_time": "2022-01-08T01:40:22.006953Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.schedulers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    print(v.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd497e72",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Losses and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66169a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T16:34:44.555617Z",
     "start_time": "2022-02-09T16:34:44.507417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_losses = environ.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb8234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:35:11.758429Z",
     "start_time": "2022-02-10T03:35:11.278211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0301f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:21:49.107793Z",
     "start_time": "2022-02-10T03:21:49.084484Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498b6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:20:32.866010Z",
     "start_time": "2022-02-10T03:20:32.442919Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "pp.pprint(trn_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe30724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:34:21.945701Z",
     "start_time": "2022-02-10T03:34:21.411234Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d81167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:49.364883Z",
     "start_time": "2022-01-27T00:58:49.342931Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['Lambda_sharing'] = 0.5\n",
    "# opt['train']['Lambda_sharing'] = 0.5\n",
    "\n",
    "# environ.opt['train']['policy_lr'] = 0.001\n",
    "# opt['train']['policy_lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73aa06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T01:00:41.996410Z",
     "start_time": "2022-01-26T01:00:41.559006Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.losses.keys()\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ece74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:19:43.683550Z",
     "start_time": "2022-01-08T01:19:43.571450Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = environ.get_loss_dict()\n",
    "print(tmp.keys())\n",
    "pp.pprint(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac0256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:50.458223Z",
     "start_time": "2022-01-27T00:58:50.430889Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(opt['diff_sparsity_weights'])\n",
    "print(opt['is_sharing'])\n",
    "print(opt['diff_sparsity_weights'] and not opt['is_sharing'])\n",
    "print(environ.opt['train']['Lambda_sharing'])\n",
    "print(opt['train']['Lambda_sharing'])\n",
    "print(environ.opt['train']['Lambda_sparsity'])\n",
    "print(opt['train']['Lambda_sparsity'])\n",
    "print(environ.opt['train']['policy_lr'])\n",
    "print(opt['train']['policy_lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2d510",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Policy / Logit stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb628497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:35:14.041577Z",
     "start_time": "2022-02-08T20:35:14.018303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.special          import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eed454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:30.103364Z",
     "start_time": "2022-02-08T20:00:30.068021Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03b5cc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_task_logits(n)` Get logits for task group n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed8b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:56:35.652087Z",
     "start_time": "2022-02-08T20:56:35.327406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task_logits = environ.get_task_logits(1)\n",
    "print(task_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66fa5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_arch_parameters()`: Get last used logits from network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85521e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:31.101960Z",
     "start_time": "2022-02-08T20:00:30.757064Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b0bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:06.054699Z",
     "start_time": "2022-02-09T15:43:05.689327Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea1743",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_logits()`:  Get Policy Logits - returns same as `get_arch_parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb40c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:24.972390Z",
     "start_time": "2022-02-09T15:43:24.636629Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs = environ.get_policy_logits()\n",
    "for i in logs:\n",
    "    print(i, '\\n')\n",
    "# probs = softmax(logs, axis= -1)\n",
    "# for i in probs:\n",
    "#     print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080a364",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_prob()` : Gets the softmax of the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c75af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:29.733732Z",
     "start_time": "2022-02-09T15:43:29.699600Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "for i in policy_softmaxs:\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3160d9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = False)` : Calls test_sample_policy of network with random choices based on softmax of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f411444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:21:15.636722Z",
     "start_time": "2022-02-08T22:21:15.165456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "policies,logits = environ.get_sample_policy(hard_sampling = False)\n",
    "\n",
    "for l, p, s in zip(logits, policies, policy_softmaxs) :\n",
    "    for  l_row, p_row, s_row in zip(l, p, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802664ec",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = True)` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea65bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:59:40.790899Z",
     "start_time": "2022-02-08T20:59:40.726657Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "hard_policies, logits = environ.get_sample_policy(hard_sampling = True)\n",
    "\n",
    "for p,l,s in zip(hard_policies, logits, policy_softmaxs) :\n",
    "    for  p_row, l_row, s_row in zip(p, l, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c39cf",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fe096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:00:47.452220Z",
     "start_time": "2022-02-08T21:00:47.422902Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\" Layer    task 1      task 2      task 3\")\n",
    "print(f\" -----    ------      ------      ------\")\n",
    "for idx, (l1, l2, l3) in enumerate(zip(hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1}       {l2}       {l3}\")\n",
    "    \n",
    "\n",
    "    print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade0ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:39:39.936555Z",
     "start_time": "2022-02-08T22:39:39.911591Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_trained_policy(iter):\n",
    "\n",
    "    policy_softmaxs = environ.get_policy_prob()\n",
    "    policy_argmaxs = 1-np.argmax(policy_softmaxs, axis = -1)\n",
    "    print(f\"  Trained polcies at iteration: {iter} \")\n",
    "    print(f\"                   task 1                           task 2                         task 3        \")\n",
    "    print(f\" Layer       softmax        select          softmax        select          softmax        select   \")\n",
    "    print(f\" -----    ---------------   ------       ---------------   ------       ---------------   ------   \")\n",
    "    for idx, (l1,l2,l3,  p1,p2,p3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2], policy_argmaxs[0], policy_argmaxs[1], policy_argmaxs[2]),1):\n",
    "        print(f\"   {idx}      {l1[0]:.4f}   {l1[1]:.4f}   {p1:4d}    {l2[0]:11.4f}   {l2[1]:.4f}   {p2:4d}    {l3[0]:11.4f}   {l3[1]:.4f}   {p3:4d}\")\n",
    "\n",
    "    print()\n",
    "# print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec208dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:42:12.650813Z",
     "start_time": "2022-02-08T22:42:12.330169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display_trained_policy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec517e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:07:30.836214Z",
     "start_time": "2022-02-08T22:07:30.804575Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"                        POLICIES (SOFTMAX)                                       task 3          \")\n",
    "print(f\" Layer    task1              task2            task3 softmax         softmax         argmax         softmax         argmax   \")\n",
    "print(f\" -----    -------------     -------------     -------------   ------   \")\n",
    "for idx, (l1,l2,l3, h1,h2,h3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2],hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1[0]:.4f} {l1[1]:.4f}     {l2[0]:.4f} {l2[1]:.4f}     {l3[0]:.4f} {l3[1]:.4f}    {h3}\")\n",
    "    \n",
    "print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbeacb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:04:50.757406Z",
     "start_time": "2022-02-08T22:04:50.731736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(policy_softmaxs[2], np.argmax(1-policy_softmaxs[2], axis = -1))\n",
    "print(policy_softmaxs, np.argmax(policy_softmaxs, axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be0240",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_logits()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb7240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:19:06.155425Z",
     "start_time": "2022-02-08T21:19:06.118640Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits  = (environ.get_current_logits())\n",
    "for i in logits:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e84662",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_policy()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cfa24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:40:06.543376Z",
     "start_time": "2022-02-08T20:40:06.230711Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pols  = (environ.get_current_policy())\n",
    "\n",
    "for i in pols:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f556a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T18:27:33.593255Z",
     "start_time": "2022-01-27T18:27:33.553141Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792710e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `gumbel_softmax()`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265490e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:28:17.107529Z",
     "start_time": "2022-02-08T21:28:17.084910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', floatmode = 'maxprec_equal')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb0087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:35:11.617269Z",
     "start_time": "2022-02-08T21:35:11.569599Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.temp)\n",
    "# tau = environ.temp\n",
    "tau = 1\n",
    "for i in range(3): \n",
    "    logits_tensor = torch.tensor(logits[0])\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=tau, hard=False).cpu().numpy() \n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=tau, hard=True).cpu().numpy()\n",
    "    \n",
    "    for l, gs, gh in zip(lgts, gumbel_soft, gumbel_hard):\n",
    "        print(f\"   {l}   \\t {gs}            \\t {gh}\")\n",
    "#     print(lgts)\n",
    "#     print(gumbel_soft)\n",
    "#     print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5ef7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e0e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:21:35.524957Z",
     "start_time": "2022-02-08T21:21:35.488812Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for lgts in logits:\n",
    "    logits_tensor = torch.tensor(lgts)\n",
    "    print(lgts)\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=1, hard=False)\n",
    "    print(gumbel_soft)\n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=1, hard=True)\n",
    "    print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34a06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T20:49:37.643349Z",
     "start_time": "2022-02-03T20:49:37.580786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smax = scipy.special.softmax(logs, axis =1)\n",
    "# smax = np.array( \n",
    "# [[0.46973792, 0.530262  ],\n",
    "#  [0.45025694, 0.549743  ],\n",
    "#  [0.4443086 , 0.5556915 ],\n",
    "#  [0.4138397 , 0.58616036],\n",
    "#  [0.4140113 , 0.5859887 ],\n",
    "#  [0.42114905, 0.57885087]])\n",
    "\n",
    "print(smax.shape)\n",
    "print(smax)\n",
    "print(smax[0])\n",
    "print(smax[0].sum())\n",
    "print(np.random.choice((1,0), p =smax[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7de25c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:15:19.893888Z",
     "start_time": "2022-02-08T21:15:19.870899Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logs = np.array(\n",
    "[[0.33064184, 0.42053092],\n",
    " [0.3532089 , 0.52056104],\n",
    " [0.3888512 , 0.5680909 ],\n",
    " [0.42039296, 0.694217  ],\n",
    " [0.4519742 , 0.73311865],\n",
    " [0.48401102, 0.7522658 ]],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "399px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
