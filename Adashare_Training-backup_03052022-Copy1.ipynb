{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408f1261",
   "metadata": {},
   "source": [
    "## Initialization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d574cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T22:13:28.077169Z",
     "start_time": "2022-03-05T22:13:24.851409Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:08.233990Z",
     "iopub.status.busy": "2022-01-07T22:44:08.233053Z",
     "iopub.status.idle": "2022-01-07T22:44:08.273284Z",
     "shell.execute_reply": "2022-01-07T22:44:08.271908Z",
     "shell.execute_reply.started": "2022-01-07T22:44:08.233943Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./src', '/home/kbardool/kusanagi/AdaSparseChem', '/home/kbardool/miniconda3/envs/pyt-gpu/lib/python39.zip', '/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9', '/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/lib-dynload', '', '/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages', '/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions', '/home/kbardool/.ipython']\n",
      " Cuda is available  :  True\n",
      " CUDA device count  :  1\n",
      " CUDA current device:  0\n",
      " GPU Processes      : \n",
      " GPU:0\n",
      "no processes are running\n",
      "\n",
      " Device : cuda:0\n",
      "   name:        NVIDIA GeForce GTX 970M\n",
      "   capability:  (5, 2)\n",
      "   properties:  _CudaDeviceProperties(name='NVIDIA GeForce GTX 970M', major=5, minor=2, total_memory=3071MB, multi_processor_count=10)\n",
      "   Allocated :  0\n",
      "   Reserved  :  0\n",
      "\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | nan% |  1% |\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "# sys.path.insert(0, '/home/kbardool/kusanagi/AdaSparseChem/src')\n",
    "print(sys.path)\n",
    "import time\n",
    "import argparse\n",
    "import yaml\n",
    "import types\n",
    "import copy, pprint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy  as np\n",
    "import torch  \n",
    "import wandb\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader \n",
    "import scipy.sparse\n",
    "from scipy.special import softmax\n",
    " \n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "# from tqdm.notebook import trange, tqdm\n",
    "from tqdm     import tqdm,trange \n",
    "\n",
    "from envs.sparsechem_env_dev import SparseChemEnv_Dev\n",
    "# from utils.sparsechem_utils import load_sparse, load_task_weights, class_fold_counts, fold_and_transform_inputs, print_metrics_cr\n",
    "from dataloaders.chembl_dataloader_dev import ClassRegrSparseDataset_v3, ClassRegrSparseDataset, InfiniteDataLoader\n",
    "from utils.util import ( makedir, print_separator, create_path, print_yaml, print_yaml2, print_loss, should, \n",
    "                         fix_random_seed, read_yaml, timestring, print_heading, print_dbg, save_to_pickle, load_from_pickle,\n",
    "                         print_underline, write_config_report, display_config, get_command_line_args, is_notebook) \n",
    "\n",
    "print(' Cuda is available  : ', torch.cuda.is_available())\n",
    "print(' CUDA device count  : ', torch.cuda.device_count())\n",
    "print(' CUDA current device: ', torch.cuda.current_device())\n",
    "print(' GPU Processes      : \\n', torch.cuda.list_gpu_processes())\n",
    "print()\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\" Device : cuda:{i}\")\n",
    "    print('   name:       ', torch.cuda.get_device_name())\n",
    "    print('   capability: ', torch.cuda.get_device_capability())\n",
    "    print('   properties: ', torch.cuda.get_device_properties(i))\n",
    "    ## current GPU memory usage by tensors in bytes for a given device\n",
    "    print('   Allocated : ', torch.cuda.memory_allocated(i) ) \n",
    "    ## current GPU memory managed by caching allocator in bytes for a given device, in previous PyTorch versions the command was torch.cuda.memory_cached\n",
    "    print('   Reserved  : ', torch.cuda.memory_reserved(i) )   \n",
    "    print()\n",
    "\n",
    "gpu_usage()                             \n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=6, linewidth=132)\n",
    "# torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
    "pd.options.display.width = 132\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Adashare_Training.ipynb\"\n",
    "\n",
    "# sys.path.pop(0)\n",
    "# print(sys.path)\n",
    "# is_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33ac6e",
   "metadata": {},
   "source": [
    "## Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1d3b1478",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:11:19.339373Z",
     "start_time": "2022-03-06T00:11:19.271814Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.notebook_modules import initialize, init_dataloaders, init_environment, init_wandb, \\\n",
    "                                       training_prep, disp_dataloader_info,disp_info_1, disp_for_excel, warmup_phase, weight_policy_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee652c57",
   "metadata": {},
   "source": [
    "### Parse Input Args  - Read YAML config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fadddc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T22:13:30.677090Z",
     "start_time": "2022-03-05T22:13:30.651127Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [],
   "source": [
    "input_args = \" --config yamls/chembl_3task_train.yaml \" \\\n",
    "             \" --exp_id      14oarkpu\" \\\n",
    "             \" --exp_name    0304_1549\" \\\n",
    "             \" --exp_desc    Train with dropout 0.5\" \\\n",
    "             \" --seed_idx    0 \"\\\n",
    "             \" --batch_size  128\"\n",
    "# get command line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22d886d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:04:16.446800Z",
     "start_time": "2022-03-05T23:04:16.417400Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [],
   "source": [
    "input_args = \" --config yamls/chembl_3task_train.yaml \" \\\n",
    "             \" --exp_desc    Train with dropout 0.5\" \\\n",
    "             \" --seed_idx    0 \"\\\n",
    "             \" --batch_size  128\"\n",
    "# get command line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "29675ef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:09:39.196544Z",
     "start_time": "2022-03-05T23:09:39.002783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  command line parms : \n",
      "------------------------\n",
      " config...................  yamls/chembl_3task_train.yaml\n",
      " exp_id...................  None\n",
      " exp_name.................  None\n",
      " folder_sfx...............  None\n",
      " exp_desc.................  Train with dropout 0.5\n",
      " seed_idx.................  0\n",
      " batch_size...............  128\n",
      " backbone_lr..............  None\n",
      " task_lr..................  None\n",
      " decay_lr_rate............  None\n",
      " decay_lr_freq............  None\n",
      " gpu_ids..................  [0]\n",
      " cpu......................  False\n",
      "\n",
      "\n",
      "\n",
      "##################################################\n",
      "################### READ YAML ####################\n",
      "##################################################\n",
      "\n",
      "\n",
      " log_dir              create folder:  ../experiments/AdaSparseChem/50x6_0305_1509_plr0.01_sp0.0001_sh0.01\n",
      " result_dir           folder exists:  ../experiments/AdaSparseChem/50x6_0305_1509_plr0.01_sp0.0001_sh0.01\n",
      " checkpoint_dir       folder exists:  ../experiments/AdaSparseChem/50x6_0305_1509_plr0.01_sp0.0001_sh0.01\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " experiment name       : 0305_1509 \n",
      " experiment id         : 3lmm6sdm \n",
      " folder_name           : 50x6_0305_1509_plr0.01_sp0.0001_sh0.01 \n",
      " experiment description: Train with dropout 0.5\n",
      " Random seeds          : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      " Random  seed used     : 88 \n",
      " log folder            : ../experiments/AdaSparseChem/50x6_0305_1509_plr0.01_sp0.0001_sh0.01\n",
      " checkpoint folder     : ../experiments/AdaSparseChem/50x6_0305_1509_plr0.01_sp0.0001_sh0.01\n",
      " Gpu ids               : [0]\n",
      " Seed index            : 0\n",
      " policy_iter           : best\n",
      " Data Split ratios     : [0.725, 0.225, 0.05]\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "        project_name : AdaSparseChem\n",
      "              exp_id : 3lmm6sdm\n",
      "            exp_name : 0305_1509\n",
      "     exp_description : Train with dropout 0.5\n",
      "         random_seed : 88\n",
      "           seed_list : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      "            backbone : SparseChem\n",
      "               tasks : ['class', 'class', 'class']\n",
      "     tasks_num_class : [5, 5, 5]\n",
      "             lambdas : [1, 1, 1]\n",
      "        policy_model : task-specific\n",
      "             verbose : False\n",
      "       backbone_orig : ResNet18\n",
      "          tasks_orig : ['seg', 'sn']\n",
      "     input_size_freq : None\n",
      "          input_size : 32000\n",
      "        hidden_sizes : [50, 50, 50, 50, 50, 50]\n",
      "    tail_hidden_size : 50\n",
      " first_non_linearity : relu\n",
      "middle_non_linearity : relu\n",
      "  last_non_linearity : relu\n",
      "      middle_dropout : 0.5\n",
      "        last_dropout : 0.5\n",
      "   class_output_size : None\n",
      "    regr_output_size : None\n",
      "              policy : True\n",
      "           is_sparse : True\n",
      "          is_sharing : True\n",
      "diff_sparsity_weights : False\n",
      "          skip_layer : 0\n",
      "       is_curriculum : False\n",
      "    curriculum_speed : 3\n",
      "              fix_BN : False\n",
      "     retrain_from_pl : False\n",
      "\n",
      "train\n",
      "-----\n",
      "          batch_size : 128\n",
      "      warm_up_epochs : 10\n",
      "     training_epochs : 50\n",
      "         total_iters : 25000\n",
      "       warm_up_iters : None\n",
      "             task_lr : 0.001\n",
      "         backbone_lr : 0.001\n",
      "       decay_lr_rate : 0.85\n",
      "       decay_lr_freq : 2000\n",
      "policy_decay_lr_rate : 0.85\n",
      "policy_decay_lr_freq : 2200\n",
      "           policy_lr : 0.01\n",
      "     lambda_sparsity : 0.0001\n",
      "      lambda_sharing : 0.01\n",
      "        lambda_tasks : 1\n",
      "         init_method : random\n",
      "           init_temp : 4\n",
      "          decay_temp : 0.965\n",
      "     decay_temp_freq : 2\n",
      "     init_neg_logits : None\n",
      "       hard_sampling : False\n",
      "            val_freq : 500\n",
      "          print_freq : -1\n",
      "           val_iters : -1\n",
      "              resume : False\n",
      "      retrain_resume : False\n",
      "         policy_iter : best\n",
      "          which_iter : warmup\n",
      "\n",
      "paths\n",
      "-----\n",
      "             log_dir : ../experiments/AdaSparseChem/50x6_0305_1509_plr0.01_sp0.0001_sh0.01\n",
      "          result_dir : ../experiments/AdaSparseChem/50x6_0305_1509_plr0.01_sp0.0001_sh0.01\n",
      "      checkpoint_dir : ../experiments/AdaSparseChem/50x6_0305_1509_plr0.01_sp0.0001_sh0.01\n",
      "\n",
      "dataload\n",
      "--------\n",
      "             dataset : Chembl_23_mini\n",
      "            dataroot : /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic\n",
      "                   x : chembl_23mini_x.npy\n",
      "      x_split_ratios : [0.725, 0.225, 0.05]\n",
      "             folding : chembl_23mini_folds.npy\n",
      "         fold_inputs : 32000\n",
      "     input_transform : None\n",
      "             y_tasks : ['chembl_23mini_adashare_y1_bin_sparse.npy', 'chembl_23mini_adashare_y2_bin_sparse.npy', 'chembl_23mini_adashare_y3_bin_sparse.npy']\n",
      "            y_censor : None\n",
      "       weights_class : None\n",
      "              crop_h : 321\n",
      "              crop_w : 321\n",
      "   min_samples_class : 5\n",
      "             fold_va : 0\n",
      "             fold_te : None\n",
      "\n",
      "SC\n",
      "--\n",
      "         batch_ratio : 0.02\n",
      "      normalize_loss : None\n",
      "                 cpu : False\n",
      "             gpu_ids : [0]\n",
      "          folder_sfx : None\n",
      "          exp_folder : 50x6_0305_1509_plr0.01_sp0.0001_sh0.01\n"
     ]
    }
   ],
   "source": [
    "opt, ns = initialize(input_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194e6c24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T22:13:49.927644Z",
     "start_time": "2022-03-05T22:13:49.902525Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [],
   "source": [
    "# args = get_command_line_args(ns.input_args.split())\n",
    "    \n",
    "# print_underline(' command line parms : ', True)\n",
    "# for key, val in vars(args).items():\n",
    "#     print(f\" {key:.<25s}  {val}\")\n",
    "\n",
    "# # ********************************************************************\n",
    "# # ****************** create folders and print options ****************\n",
    "# # ********************************************************************\n",
    "# print_separator('READ YAML')\n",
    "\n",
    "# opt = read_yaml(args)\n",
    "\n",
    "# fix_random_seed(opt[\"random_seed\"])\n",
    "    \n",
    "# # opt['exp_instance'] = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "# # opt['exp_instance'] = '0218_1358'     \n",
    "# # opt['exp_description'] = f\"Retrain phase for 0218_1358\"\n",
    "# # folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\"\n",
    "\n",
    "# create_path(opt)    \n",
    "# print()\n",
    "# print_heading(f\" experiment name       : {opt['exp_name']} \\n\"\n",
    "#               f\" experiment id         : {opt['exp_id']} \\n\"\n",
    "#               f\" folder_name           : {opt['exp_folder']} \\n\"\n",
    "#               f\" experiment description: {opt['exp_description']}\\n\"\n",
    "#               f\" Random seeds          : {opt['seed_list']}\\n\"\n",
    "#               f\" Random  seed used     : {opt['random_seed']} \\n\"\n",
    "#               f\" log folder            : {opt['paths']['log_dir']}\\n\"\n",
    "#               f\" checkpoint folder     : {opt['paths']['checkpoint_dir']}\"\n",
    "#               f\" Gpu ids               : {opt['gpu_ids']}\"\n",
    "#               f\" Seed index            : {args.seed_idx}\"\n",
    "#               f\" policy_iter           : {opt['train']['policy_iter']}\"\n",
    "#               f\" Data Split ratios     : {opt['dataload']['x_split_ratios']}\", verbose = True)\n",
    "\n",
    "# ns.config_filename = 'run_config_seed_%04d.txt' % (opt['random_seed'])\n",
    "# write_config_report(opt, filename = ns.config_filename)    \n",
    "# # display_config(opt)\n",
    "# ns.best_results = {}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "deb61013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:10:00.645170Z",
     "start_time": "2022-03-05T23:10:00.596140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace(args=Namespace(config='yamls/chembl_3task_train.yaml', exp_id=None, exp_name=None, folder_sfx=None, exp_desc='Train with dropout 0.5', seed_idx=0, batch_size=128, backbone_lr=None, task_lr=None, decay_lr_rate=None, decay_lr_freq=None, gpu_ids=[0], cpu=False),\n",
      "          config_filename='run_config_seed_0088.txt')\n",
      "dict_keys(['args', 'config_filename'])\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(ns)\n",
    "\n",
    "print(ns.__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d3145218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:10:03.751132Z",
     "start_time": "2022-03-05T23:10:03.724538Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [],
   "source": [
    "# opt['exp_instance'] = '0218_1358'     \n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\"\n",
    "# print()\n",
    "# opt['exp_instance'] = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "# opt['exp_description'] = f\"No Alternating Weight/Policy - training all done with both weights and policy\"\n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bfa8d",
   "metadata": {},
   "source": [
    "### Setup Dataloader and Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "df9b5286",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:10:08.630645Z",
     "start_time": "2022-03-05T23:10:07.972698Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############### CREATE DATALOADERS ###############\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "dldrs = init_dataloaders(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "702b2b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:10:10.097587Z",
     "start_time": "2022-03-05T23:10:10.050587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 105\n"
     ]
    }
   ],
   "source": [
    "print(opt['train']['weight_iter_alternate'] , opt['train']['alpha_iter_alternate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a5f1c75e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:10:27.226328Z",
     "start_time": "2022-03-05T23:10:27.194295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['args', 'config_filename'])\n",
      "dict_keys(['trainset0', 'trainset1', 'trainset2', 'valset', 'testset', 'warmup_trn_loader', 'weight_trn_loader', 'policy_trn_loader', 'val_loader', 'test_loader'])\n"
     ]
    }
   ],
   "source": [
    "print(ns.__dict__.keys())\n",
    "print(dldrs.__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e97db369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:10:46.209986Z",
     "start_time": "2022-03-05T23:10:45.810292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "############# CREATE THE ENVIRONMENT #############\n",
      "##################################################\n",
      " device is  cuda:0\n",
      "--------------------------------------------------------\n",
      "* SparseChemEnv_Dev environment successfully created\n",
      "-------------------------------------------------------- \n",
      "\n",
      " cuda available [0]\n"
     ]
    }
   ],
   "source": [
    "environ = init_environment(ns, opt, is_train = True, policy_learning = False, display_cfg = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2358fa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T22:17:47.703682Z",
     "start_time": "2022-03-05T22:17:47.678689Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    }
   },
   "outputs": [],
   "source": [
    "# # ********************************************************************\n",
    "# # ********************Create the environment *************************\n",
    "# # ********************************************************************\n",
    "# # create the model and the pretrain model\n",
    "# print_separator('CREATE THE ENVIRONMENT')\n",
    "# environ = SparseChemEnv_Dev(log_dir          = opt['paths']['log_dir'], \n",
    "#                             checkpoint_dir   = opt['paths']['checkpoint_dir'], \n",
    "#                             exp_name         = opt['exp_name'],\n",
    "#                             tasks_num_class  = opt['tasks_num_class'], \n",
    "#                             init_neg_logits  = opt['train']['init_neg_logits'], \n",
    "#                             device           = opt['gpu_ids'][0],\n",
    "#                             init_temperature = opt['train']['init_temp'], \n",
    "#                             temperature_decay= opt['train']['decay_temp'], \n",
    "#                             is_train         = True,\n",
    "#                             opt              = opt, \n",
    "#                             verbose          = opt['verbose'])\n",
    "# environ.define_optimizer(policy_learning=False)\n",
    "# environ.define_scheduler(policy_learning=False)\n",
    "\n",
    "# cfg = environ.print_configuration()\n",
    "# # print(cfg)\n",
    "# write_config_report(opt, cfg, filename = config_filename, mode = 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320fdeee",
   "metadata": {},
   "source": [
    "###  Weights and Biases Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2b32a405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:21:28.382274Z",
     "start_time": "2022-03-05T23:21:26.738703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3lmm6sdm 0305_1509 AdaSparseChem\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kbardool/kusanagi/AdaSparseChem/wandb/run-20220305_152126-3lmm6sdm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"http://localhost:8080/kbardool/AdaSparseChem/runs/3lmm6sdm\" target=\"_blank\">0305_1509</a></strong> to <a href=\"http://localhost:8080/kbardool/AdaSparseChem\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PROJECT NAME: AdaSparseChem\n",
      " RUN ID      : 3lmm6sdm \n",
      " RUN NAME    : 0305_1509\n"
     ]
    }
   ],
   "source": [
    "# init_wandb(ns, opt, environment = environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e6cca52e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:21:32.538001Z",
     "start_time": "2022-03-05T23:21:32.474580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['args', 'config_filename', 'wandb_run', 'print_freq', 'eval_iters', 'stop_iter_w', 'stop_iter_a', 'flag', 'current_epoch', 'current_iter', 'best_results', 'best_metrics', 'best_value', 'best_iter', 'p_epoch', 'w_epoch', 'flag_warmup', 'num_prints', 'num_blocks', 'warm_up_epochs', 'train_total_epochs', 'curriculum_speed', 'stop_epoch_warmup'])\n",
      "AdaSparseChem\n",
      "<wandb.sdk.wandb_run.Run object at 0x7f9498194160>\n"
     ]
    }
   ],
   "source": [
    "# print(ns.__dict__.keys())\n",
    "# print(ns.wandb_run.project)\n",
    "# print(ns.wandb_run)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3d2dc273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:21:33.355645Z",
     "start_time": "2022-03-05T23:21:33.291147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PROJECT NAME: AdaSparseChem\n",
      " RUN ID      : 3lmm6sdm \n",
      " RUN NAME    : 0305_1509\n"
     ]
    }
   ],
   "source": [
    "print(f\" PROJECT NAME: {ns.wandb_run.project}\\n\"\n",
    "      f\" RUN ID      : {ns.wandb_run.id} \\n\"\n",
    "      f\" RUN NAME    : {ns.wandb_run.name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "069ba312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T22:05:37.697663Z",
     "start_time": "2022-03-05T22:05:37.644317Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(opt['exp_id'], opt['exp_name'], opt['project_name']) # , opt['exp_instance'])\n",
    "# # opt['exp_id'] = wandb.util.generate_id()\n",
    "\n",
    "# run = wandb.init(project=opt['project_name'], entity=\"kbardool\", resume=\"allow\", id = opt['exp_id'], name = opt['exp_name'])\n",
    " \n",
    "# print(f\"PROJECT NAME: {wandb.run.project} RUN ID:  {wandb.run.id}    RUN NAME: {wandb.run.name}\") \n",
    "\n",
    "# # # wandb.init(id='1q3dt2en' )\n",
    "# # assert wandb.run is None, \"Run is still running\"\n",
    "\n",
    "# wandb.config = opt.copy()\n",
    "# wandb.watch(environ.networks['mtl-net'], log='all', log_freq=10)     ###  Weights and Biases Initialization \n",
    "\n",
    "# # wandb_run_name = opt['exp_instance']\n",
    "# # wandb_run_id = wandb.util.generate_id()\n",
    "# # print(wandb.run.id, wandb.run.name) \n",
    "# # print(opt['exp_uid'], opt['exp_instance'])\n",
    "# # run = wandb.init(project=\"AdaSparseChem\", entity=\"kbardool\", resume=\"allow\", id = opt['exp_id'], name = opt['exp_instance'])\n",
    "\n",
    "# # wandb.config = opt.copy()\n",
    "# # wandb.watch(environ.networks['mtl-net'], log='all', log_freq=10)\n",
    "# environ.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8d531996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:14:41.223610Z",
     "start_time": "2022-03-05T23:14:37.852712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c4674746544e9d861093791a4fac78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.152 MB of 1.152 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0305_1509</strong>: <a href=\"http://localhost:8080/kbardool/AdaSparseChem/runs/3lmm6sdm\" target=\"_blank\">http://localhost:8080/kbardool/AdaSparseChem/runs/3lmm6sdm</a><br/>Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220305_151144-3lmm6sdm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d738062",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Initiate / Resume Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32da8774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T01:26:20.486164Z",
     "start_time": "2022-03-05T01:26:19.010055Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup\n",
      "=> loading snapshot from ../experiments/AdaSparseChem/50x6_0304_1549_plr0.01_sp0.0001_sh0.01/warmup_ep_40_seed_0088_model.pth.tar\n",
      "   Loading to GPU cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(opt['train']['which_iter'])\n",
    "a = environ.load_checkpoint('warmup_ep_40_seed_0088', path = '../experiments/AdaSparseChem/50x6_0304_1549_plr0.01_sp0.0001_sh0.01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b36142",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8743e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4262d69b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T01:26:20.643981Z",
     "start_time": "2022-03-05T01:26:20.489740Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:27.458746Z",
     "iopub.status.busy": "2022-01-07T22:44:27.457640Z",
     "iopub.status.idle": "2022-01-07T22:44:27.491358Z",
     "shell.execute_reply": "2022-01-07T22:44:27.490019Z",
     "shell.execute_reply.started": "2022-01-07T22:44:27.458686Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "################ Resume training #################\n",
      "##################################################\n",
      "=> loading snapshot from ../experiments/AdaSparseChem/50x6_0304_1549_plr0.01_sp0.0001_sh0.01/warmup_ep_40_seed_0088_model.pth.tar\n",
      "   Loading to GPU cuda:0\n"
     ]
    }
   ],
   "source": [
    "opt['train']['resume'] = True\n",
    "opt['train']['which_iter'] = 'warmup_ep_40_seed_0088'\n",
    "if opt['train']['resume']:\n",
    "    print_separator('Resume training')\n",
    "    current_iter = environ.load_checkpoint(opt['train']['which_iter'])\n",
    "    environ.networks['mtl-net'].reset_logits()\n",
    "else:\n",
    "    print_separator('Initiate Training ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5508b4",
   "metadata": {},
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0dccff20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:21:40.471077Z",
     "start_time": "2022-03-05T23:21:40.404229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "-1\n",
      "-1 eval_iters:  33\n"
     ]
    }
   ],
   "source": [
    "print(opt['gpu_ids'])\n",
    "print(opt['train']['print_freq'])\n",
    "print(opt['train']['val_iters'],  'eval_iters: ', ns.eval_iters )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c06e0766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:21:40.836854Z",
     "start_time": "2022-03-05T23:21:40.785536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " set print_freq to length of train loader: 105\n",
      " set eval_iters to length of val loader  : 33\n"
     ]
    }
   ],
   "source": [
    "training_prep(ns, opt, environ, dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6f5ee22f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:21:41.988652Z",
     "start_time": "2022-03-05T23:21:41.932074Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:27.458746Z",
     "iopub.status.busy": "2022-01-07T22:44:27.457640Z",
     "iopub.status.idle": "2022-01-07T22:44:27.491358Z",
     "shell.execute_reply": "2022-01-07T22:44:27.490019Z",
     "shell.execute_reply.started": "2022-01-07T22:44:27.458686Z"
    }
   },
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     print(' cuda available', gpu_ids)   \n",
    "#     environ.cuda(gpu_ids)\n",
    "# else:\n",
    "#     print(' cuda not available')\n",
    "#     environ.cpu()\n",
    "\n",
    "# if opt['train']['print_freq'] == -1:\n",
    "#     print(f\" set print_freq to length of train loader: {len(warmup_trn_loader)}\")\n",
    "#     opt['train']['print_freq']    = len(warmup_trn_loader)\n",
    "\n",
    "# if opt['train']['val_iters'] == -1:\n",
    "#     print(f\" set eval_iters to length of val loader  : {len(val_loader)}\")\n",
    "#     eval_iters    = len(val_loader)    \n",
    "# else:\n",
    "#     eval_iters    = opt['train']['val_iters']\n",
    " \n",
    "# stop_iter_w = opt['train']['weight_iter_alternate']\n",
    "# stop_iter_a = opt['train']['alpha_iter_alternate'] \n",
    "    \n",
    "# # Fix Alpha -     \n",
    "# flag           = 'update_w'\n",
    "# environ.fix_alpha()\n",
    "# environ.free_weights(opt['fix_BN'])\n",
    "\n",
    "# current_epoch  = 0\n",
    "# current_iter   = 0\n",
    "# # current_iter_w = 0 \n",
    "# # current_iter_a = 0\n",
    "\n",
    "# best_metrics   = None\n",
    "# best_value     = 0 \n",
    "# best_iter      = 0\n",
    "\n",
    "# p_epoch        = 0\n",
    "# w_epoch        = 0\n",
    "\n",
    "\n",
    "# flag_warmup    = True\n",
    "\n",
    "# num_prints     = 0\n",
    "# num_blocks     = sum(environ.networks['mtl-net'].layers)\n",
    "# warm_up_epochs     = opt['train']['warm_up_epochs']\n",
    "# train_total_epochs = opt['train']['training_epochs']\n",
    "# curriculum_speed   = opt['curriculum_speed'] \n",
    "\n",
    "# stop_epoch_warmup  = current_epoch + warm_up_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b0efe7",
   "metadata": {},
   "source": [
    "## Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b766952d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:21:42.891563Z",
     "start_time": "2022-03-05T23:21:42.823809Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " trainset.y_class                                   :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " trainset1.y_class                                  :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " trainset2.y_class                                  :  [(13331, 5), (13331, 5), (13331, 5)] \n",
      " valset.y_class                                     :  [(4137, 5), (4137, 5), (4137, 5)]  \n",
      " testset.y_class                                    :  [(920, 5), (920, 5), (920, 5)]  \n",
      "                                 \n",
      " size of training set 0 (warm up)                   :  13331 \n",
      " size of training set 1 (network parms)             :  13331 \n",
      " size of training set 2 (policy weights)            :  13331 \n",
      " size of validation set                             :  4137 \n",
      " size of test set                                   :  920 \n",
      "                               Total                :  45050 \n",
      "                                 \n",
      " lenght (# batches) in training 0 (warm up)         :  105 \n",
      " lenght (# batches) in training 1 (network parms)   :  105 \n",
      " lenght (# batches) in training 2 (policy weights)  :  105 \n",
      " lenght (# batches) in validation dataset           :  33 \n",
      " lenght (# batches) in test dataset                 :  29 \n",
      "                                \n"
     ]
    }
   ],
   "source": [
    "disp_dataloader_info(dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5ea212ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:21:43.438460Z",
     "start_time": "2022-03-05T23:21:43.367248Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:18.146907Z",
     "iopub.status.busy": "2022-01-07T22:44:18.145721Z",
     "iopub.status.idle": "2022-01-07T22:44:18.191126Z",
     "shell.execute_reply": "2022-01-07T22:44:18.189994Z",
     "shell.execute_reply.started": "2022-01-07T22:44:18.146867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Num_blocks                : 6                                \n",
      "\n",
      " # batches in Weight training epoch : 105 \n",
      " # batches in Policy training epoch : 105 \n",
      " batch size                : 128 \n",
      " Total iterations          : 25000 \n",
      " Warm-up iterations        : None \n",
      " Warm-up epochs            : 10 \n",
      " Warm-up stop              : 10 \n",
      " train_total_epochs        : 50                                 \n",
      "\n",
      " Print Frequency           : -1 \n",
      " Validation Frequency      : 500 \n",
      " Validation Iterations     : -1 \n",
      " eval_iters                : 33 \n",
      " which_iter                : warmup \n",
      " train_resume              : False                                 \n",
      "                                 \n",
      " \n",
      " fix BN parms              : False \n",
      " Backbone LR               : 0.001 \n",
      " Backbone LR               : 0.001                                 \n",
      "\n",
      " Sharing  regularization   : 0.01 \n",
      " Sparsity regularization   : 0.0001 \n",
      " Task     regularization   : 1 \n",
      " Last Epoch                : 0  \n",
      " # of warm-up epochs to do : 10 \n",
      " stop_iter_w               : 105\n"
     ]
    }
   ],
   "source": [
    "disp_info_1(ns, opt, environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "61bc6107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:21:43.803051Z",
     "start_time": "2022-03-05T23:21:43.741130Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:18.146907Z",
     "iopub.status.busy": "2022-01-07T22:44:18.145721Z",
     "iopub.status.idle": "2022-01-07T22:44:18.191126Z",
     "shell.execute_reply": "2022-01-07T22:44:18.189994Z",
     "shell.execute_reply.started": "2022-01-07T22:44:18.146867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " folder: 50x6_0305_1509_plr0.01_sp0.0001_sh0.01 \n",
      " layers: [50, 50, 50, 50, 50, 50]                                \n",
      " \n",
      " middle dropout         : 0.5 \n",
      " last dropout           : 0.5 \n",
      " diff_sparsity_weights  : False \n",
      " skip_layer             : 0 \n",
      " is_curriculum          : False \n",
      " curriculum_speed       : 3                               \n",
      " \n",
      " decay_lr_rate          : 0.85 \n",
      " decay_lr_freq          : 2000 \n",
      " policy_decay_lr_rate   : 0.85 \n",
      " policy_decay_lr_freq   : 2200                               \n",
      " \n",
      " policy_lr              : 0.01 \n",
      " lambda_sparsity        : 0.0001 \n",
      " lambda_sharing         : 0.01                               \n",
      " \n",
      " lambda_tasks           : 1 \n",
      " init_temp              : 4 \n",
      " decay_temp             : 0.965 \n",
      " decay_temp_freq        : 2 \n",
      " init_method            : random \n",
      " init_neg_logits        : None \n",
      " hard_sampling          : False \n",
      " Warm-up epochs         : 10 \n",
      " training epochs        : 50\n"
     ]
    }
   ],
   "source": [
    "disp_for_excel(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278d6d1",
   "metadata": {},
   "source": [
    "## Warmup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "92380a48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:21:45.890973Z",
     "start_time": "2022-03-05T23:21:45.841483Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# environ.display_trained_policy(current_epoch,out=[sys.stdout, environ.log_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0c670ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:21:46.434468Z",
     "start_time": "2022-03-05T23:21:46.365810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0\n",
      "40 0\n"
     ]
    }
   ],
   "source": [
    "print(ns.stop_epoch_warmup, ns.current_epoch)\n",
    "ns.stop_epoch_warmup = 40\n",
    "print(ns.stop_epoch_warmup, ns.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "451112f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:21:48.413729Z",
     "start_time": "2022-03-05T23:21:48.348698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Last Epoch: 0   # of warm-up epochs to do:  10 - Run epochs 1 to 40\n"
     ]
    }
   ],
   "source": [
    "print(f\" Last Epoch: {ns.current_epoch}   # of warm-up epochs to do:  {ns.warm_up_epochs} - Run epochs {ns.current_epoch+1} to {ns.stop_epoch_warmup}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1e66971e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:36:12.521733Z",
     "start_time": "2022-03-05T23:21:49.116212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "    1 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |   10.3296   2.0791e+00   1.9979e-02   12.4288 |   0.68932   0.57139   0.57369   0.57097 |   10.3409   2.0791e+00   1.9979e-02    12.4401 |  18.9 |\n",
      "    2 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |   10.0835   2.0791e+00   1.9979e-02   12.1826 |   0.68340   0.62562   0.62452   0.62533 |   10.2509   2.0791e+00   1.9979e-02    12.3501 |  21.5 |\n",
      "    3 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    9.6564   2.0791e+00   1.9979e-02   11.7555 |   0.67119   0.65147   0.65721   0.65119 |   10.0698   2.0791e+00   1.9979e-02    12.1689 |  20.8 |\n",
      "    4 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    9.3069   2.0791e+00   1.9979e-02   11.4061 |   0.65921   0.66746   0.67416   0.66721 |    9.8827   2.0791e+00   1.9979e-02    11.9819 |  20.9 |\n",
      "    5 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.7478   2.0791e+00   1.9979e-02   10.8469 |   0.64829   0.68931   0.69187   0.68908 |    9.7227   2.0791e+00   1.9979e-02    11.8218 |  21.1 |\n",
      "    6 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    8.3234   2.0791e+00   1.9979e-02   10.4225 |   0.63650   0.70131   0.70564   0.70110 |    9.5464   2.0791e+00   1.9979e-02    11.6455 |  21.2 |\n",
      "    7 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.9815   2.0791e+00   1.9979e-02   10.0806 |   0.62176   0.71930   0.72289   0.71913 |    9.3313   2.0791e+00   1.9979e-02    11.4305 |  21.6 |\n",
      "    8 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    7.1601   2.0791e+00   1.9979e-02    9.2592 |   0.60888   0.73539   0.73843   0.73522 |    9.1269   2.0791e+00   1.9979e-02    11.2260 |  21.9 |\n",
      "    9 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.6598   2.0791e+00   1.9979e-02    8.7590 |   0.59773   0.74750   0.75048   0.74734 |    8.9620   2.0791e+00   1.9979e-02    11.0611 |  20.9 |\n",
      "   10 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    6.0244   2.0791e+00   1.9979e-02    8.1235 |   0.58663   0.75689   0.76101   0.75674 |    8.7972   2.0791e+00   1.9979e-02    10.8963 |  21.6 |\n",
      "   11 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.7534   2.0791e+00   1.9979e-02    7.8525 |   0.58073   0.76571   0.76998   0.76555 |    8.7094   2.0791e+00   1.9979e-02    10.8085 |  21.4 |\n",
      "   12 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    5.0993   2.0791e+00   1.9979e-02    7.1984 |   0.57502   0.77330   0.77718   0.77314 |    8.6302   2.0791e+00   1.9979e-02    10.7293 |  21.0 |\n",
      "   13 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.6453   2.0791e+00   1.9979e-02    6.7444 |   0.57276   0.78016   0.78324   0.78002 |    8.5861   2.0791e+00   1.9979e-02    10.6853 |  22.3 |\n",
      "   14 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    4.2645   2.0791e+00   1.9979e-02    6.3636 |   0.57377   0.78477   0.78795   0.78464 |    8.6083   2.0791e+00   1.9979e-02    10.7074 |  21.3 |\n",
      "   15 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.7522   2.0791e+00   1.9979e-02    5.8513 |   0.57408   0.78811   0.79095   0.78798 |    8.6113   2.0791e+00   1.9979e-02    10.7104 |  20.3 |\n",
      "   16 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.6430   2.0791e+00   1.9979e-02    5.7421 |   0.58141   0.78804   0.79172   0.78789 |    8.7271   2.0791e+00   1.9979e-02    10.8262 |  19.8 |\n",
      "   17 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.2795   2.0791e+00   1.9979e-02    5.3786 |   0.58499   0.79073   0.79486   0.79061 |    8.7929   2.0791e+00   1.9979e-02    10.8920 |  24.5 |\n",
      "   18 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    3.1780   2.0791e+00   1.9979e-02    5.2771 |   0.59015   0.79421   0.79790   0.79409 |    8.8536   2.0791e+00   1.9979e-02    10.9527 |  21.3 |\n",
      "   19 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    3.0562   2.0791e+00   1.9979e-02    5.1553 |   0.60250   0.79435   0.79745   0.79423 |    9.0571   2.0791e+00   1.9979e-02    11.1563 |  21.8 |\n",
      "   20 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    2.4018   2.0791e+00   1.9979e-02    4.5009 |   0.61383   0.79457   0.79818   0.79445 |    9.1852   2.0791e+00   1.9979e-02    11.2843 |  21.0 |\n",
      "   21 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    2.2500   2.0791e+00   1.9979e-02    4.3491 |   0.61795   0.79632   0.80003   0.79621 |    9.2884   2.0791e+00   1.9979e-02    11.3875 |  21.4 |\n",
      "   22 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    2.0703   2.0791e+00   1.9979e-02    4.1695 |   0.62942   0.79590   0.79980   0.79579 |    9.4459   2.0791e+00   1.9979e-02    11.5451 |  21.3 |\n",
      "   23 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    1.9102   2.0791e+00   1.9979e-02    4.0094 |   0.64524   0.79561   0.79900   0.79550 |    9.6648   2.0791e+00   1.9979e-02    11.7639 |  21.6 |\n",
      "   24 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    2.0347   2.0791e+00   1.9979e-02    4.1338 |   0.65283   0.79691   0.80042   0.79680 |    9.7999   2.0791e+00   1.9979e-02    11.8990 |  22.6 |\n",
      "   25 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    1.6760   2.0791e+00   1.9979e-02    3.7752 |   0.66505   0.79728   0.80058   0.79717 |    9.9750   2.0791e+00   1.9979e-02    12.0741 |  21.5 |\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   26 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    1.7651   2.0791e+00   1.9979e-02    3.8642 |   0.67904   0.79727   0.80064   0.79716 |   10.1954   2.0791e+00   1.9979e-02    12.2945 |  21.4 |\n",
      "   27 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    1.5233   2.0791e+00   1.9979e-02    3.6224 |   0.68984   0.79638   0.80030   0.79627 |   10.3310   2.0791e+00   1.9979e-02    12.4301 |  22.1 |\n",
      "   28 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    1.4429   2.0791e+00   1.9979e-02    3.5420 |   0.70370   0.79751   0.80014   0.79740 |   10.5498   2.0791e+00   1.9979e-02    12.6489 |  21.5 |\n",
      "   29 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    1.4763   2.0791e+00   1.9979e-02    3.5754 |   0.71881   0.79738   0.80036   0.79727 |   10.7799   2.0791e+00   1.9979e-02    12.8790 |  21.4 |\n",
      "   30 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    1.4355   2.0791e+00   1.9979e-02    3.5346 |   0.73060   0.79752   0.79960   0.79741 |   10.9673   2.0791e+00   1.9979e-02    13.0664 |  22.1 |\n",
      "   31 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    1.3836   2.0791e+00   1.9979e-02    3.4827 |   0.74115   0.79772   0.80046   0.79761 |   11.1462   2.0791e+00   1.9979e-02    13.2453 |  21.3 |\n",
      "   32 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    1.2684   2.0791e+00   1.9979e-02    3.3675 |   0.75568   0.79734   0.80037   0.79723 |   11.3361   2.0791e+00   1.9979e-02    13.4352 |  21.6 |\n",
      "   33 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    1.2880   2.0791e+00   1.9979e-02    3.3871 |   0.76294   0.79894   0.80146   0.79884 |   11.4083   2.0791e+00   1.9979e-02    13.5074 |  21.0 |\n",
      "   34 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    0.9403   2.0791e+00   1.9979e-02    3.0395 |   0.77738   0.79896   0.80112   0.79886 |   11.6933   2.0791e+00   1.9979e-02    13.7924 |  20.4 |\n",
      "   35 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    1.0486   2.0791e+00   1.9979e-02    3.1478 |   0.79146   0.79831   0.80067   0.79820 |   11.8523   2.0791e+00   1.9979e-02    13.9514 |  21.6 |\n",
      "   36 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    0.9695   2.0791e+00   1.9979e-02    3.0686 |   0.80471   0.79880   0.80166   0.79869 |   12.0689   2.0791e+00   1.9979e-02    14.1680 |  21.6 |\n",
      "   37 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    0.9221   2.0791e+00   1.9979e-02    3.0212 |   0.81274   0.79932   0.80149   0.79921 |   12.1980   2.0791e+00   1.9979e-02    14.2971 |  21.6 |\n",
      "   38 |   8.50e-04   8.50e-04   1.00e-02  4.000e+00 |    0.9531   2.0791e+00   1.9979e-02    3.0522 |   0.82700   0.79947   0.80167   0.79937 |   12.4350   2.0791e+00   1.9979e-02    14.5341 |  20.9 |\n",
      "   39 |   7.22e-04   7.22e-04   1.00e-02  4.000e+00 |    0.7699   2.0791e+00   1.9979e-02    2.8690 |   0.83921   0.79901   0.80162   0.79891 |   12.5659   2.0791e+00   1.9979e-02    14.6650 |  20.5 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   40 |   7.22e-04   7.22e-04   1.00e-02  4.000e+00 |    0.8751   2.0791e+00   1.9979e-02    2.9742 |   0.85439   0.79894   0.80125   0.79884 |   12.8435   2.0791e+00   1.9979e-02    14.9426 |  21.4 |\n",
      "[Final] ep:40  it:4200 -  Total Loss: 14.9426     \n",
      "Task: 12.8435   Sparsity: 2.07915e+00    Sharing: 1.99785e-02 \n",
      "\n",
      " epch:  40   softmax       sel        softmax        sel        softmax        sel \n",
      " -----  -----------------  ---    -----------------  ---    -----------------  --- \n",
      "   1    0.4997     0.5003   0     0.4994     0.5006   0     0.5000     0.5000   1\n",
      "   2    0.4998     0.5002   0     0.5003     0.4997   1     0.5006     0.4994   1\n",
      "   3    0.4993     0.5007   0     0.5007     0.4993   1     0.5004     0.4996   1\n",
      "   4    0.5002     0.4998   1     0.4999     0.5001   0     0.5001     0.4999   1\n",
      "   5    0.4991     0.5009   0     0.4996     0.5004   0     0.5002     0.4998   1\n",
      "   6    0.4993     0.5007   0     0.5005     0.4995   1     0.4998     0.5002   0\n",
      "\n",
      "\n",
      "\n",
      " epch:  40   logits        sel          logits       sel         logits        sel \n",
      " -----  -----------------  ---    ----------------   ---    ----------------   --- \n",
      "   1   -0.0008     0.0003   0    -0.0014     0.0009   0    -0.0001    -0.0003   1\n",
      "   2    0.0005     0.0014   0     0.0006    -0.0008   1     0.0006    -0.0017   1\n",
      "   3   -0.0002     0.0025   0     0.0028    -0.0001   1     0.0002    -0.0013   1\n",
      "   4    0.0017     0.0007   1     0.0005     0.0007   0     0.0003    -0.0002   1\n",
      "   5   -0.0019     0.0016   0    -0.0008     0.0006   0     0.0001    -0.0006   1\n",
      "   6   -0.0000     0.0029   0     0.0014    -0.0007   1    -0.0007     0.0001   0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warmup_phase(ns,opt, environ, dldrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b6541a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:42:59.613949Z",
     "start_time": "2022-03-05T23:42:59.494773Z"
    }
   },
   "outputs": [],
   "source": [
    "# line_count = 0\n",
    "\n",
    "# while current_epoch < stop_epoch_warmup:\n",
    "#     start_time = time.time()\n",
    "#     current_epoch+=1\n",
    "#     #-----------------------------------------\n",
    "#     # Train & Update the network weights\n",
    "#     #-----------------------------------------   \n",
    "#     with trange(+1, stop_iter_w+1 , initial = 0 , total = stop_iter_w, position=0, file=sys.stdout,\n",
    "#                 leave= False, desc=f\" Warmup Epoch {current_epoch}/{stop_epoch_warmup}\") as t_warmup :\n",
    "#         for _ in t_warmup:\n",
    "#             current_iter += 1            \n",
    "\n",
    "#             environ.train()    \n",
    "#             batch = next(warmup_trn_loader)            \n",
    "#             environ.set_inputs(batch, warmup_trn_loader.dataset.input_size)\n",
    "#             environ.optimize(opt['lambdas'], \n",
    "#                              is_policy=False, \n",
    "#                              flag='update_w', \n",
    "#                              verbose = False)\n",
    "        \n",
    "#             t_warmup.set_postfix({'curr_iter':current_iter, \n",
    "#                                   'Loss': f\"{environ.losses['total']['total'].item():.4f}\"})\n",
    "\n",
    "#         trn_losses = environ.losses\n",
    "#         environ.print_trn_metrics(current_epoch, current_iter, start_time, title = f\"[Warmup Trn]\")\n",
    "#         wandb.log(environ.losses)\n",
    "\n",
    "#         ##--------------------------------------------------------------- \n",
    "#         ## validation\n",
    "#         ##--------------------------------------------------------------- \n",
    "#         val_metrics = environ.evaluate(val_loader,\n",
    "#                                        is_policy       = False, \n",
    "#                                        num_train_layers= None,\n",
    "#                                        eval_iters      = eval_iters, \n",
    "#                                        progress        = True,\n",
    "#                                        leave           = False,\n",
    "#                                        verbose         = False)\n",
    "\n",
    "#         environ.print_val_metrics(current_epoch, current_iter, start_time, title = f\"[Warmup Val]\")    \n",
    "#         print_metrics_cr(current_epoch,  time.time() - start_time, trn_losses, environ.val_metrics, line_count, \n",
    "#                          out=[sys.stdout, environ.log_file], to_tqdm = True) \n",
    "#         line_count += 1\n",
    "#         wandb.log(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d585bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7e24c5c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:43:28.118862Z",
     "start_time": "2022-03-05T23:43:28.060201Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# environ.save_checkpoint('warmup', current_iter, current_epoch)   \n",
    "# print_loss(environ.val_metrics, f\"\\n[e] Warmup epoch:{current_epoch}    iter:{current_iter}\")\n",
    "# environ.display_trained_policy(ns.current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521962b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T18:39:56.827896Z",
     "start_time": "2022-02-24T18:39:56.753183Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc89302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e22e75ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:43:31.694231Z",
     "start_time": "2022-03-05T23:43:31.629319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone Learning Rate      : 0.001\n",
      " Tasks    Learning Rate      : 0.001\n",
      " Policy   Learning Rate      : 0.01\n",
      "\n",
      " Sparsity regularization     : 0.0001\n",
      " Sharing  regularization     : 0.01 \n",
      "\n",
      " Tasks    regularization     : 1   \n",
      " Gumbel Temp                 : 4.0000         \n",
      " Gumbel Temp decay           : 2\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2db34fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T00:07:26.408466Z",
     "start_time": "2022-03-05T00:07:26.350990Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['policy_lr']       = 0.01\n",
    "# opt['train']['policy_lr']       = 0.01\n",
    "# environ.opt['train']['lambda_sparsity'] = 0.1\n",
    "# environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# environ.opt['train']['decay_temp_freq'] = 2\n",
    "# print(environ.optimizers['alphas'].param_groups)\n",
    "# print(environ.optimizers['alphas'].param_groups[0]['initial_lr'],environ.optimizers['alphas'].param_groups[0]['lr'],)\n",
    "# print(environ.optimizers['weights'].param_groups[0]['initial_lr'], environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "# print(environ.optimizers['weights'].param_groups[1]['initial_lr'], environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49645c",
   "metadata": {},
   "source": [
    "## Weight & Policy Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aade16",
   "metadata": {},
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a814a0f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:47:14.361235Z",
     "start_time": "2022-03-05T23:47:14.291623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches in weight epoch (stop_iter_w): 105\n",
      "Batches in policy epoch (stop_iter_a): 105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if ns.flag_warmup:\n",
    "    print_heading( f\"** {timestring()} \\n\"\n",
    "                   f\"** Training epoch: {ns.current_epoch} iter: {ns.current_iter}   flag: {ns.flag} \\n\"\n",
    "                   f\"** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\\n\"\n",
    "                   f\"** Switch from Warm Up training to Alternate training Weights & Policy \\n\"\n",
    "                   f\"** Take checkpoint and block gradient flow through Policy net\", verbose=True)\n",
    "    environ.define_optimizer(policy_learning=True)\n",
    "    environ.define_scheduler(policy_learning=True)\n",
    "    ns.flag_warmup = False\n",
    "    ns.flag = 'update_w'\n",
    "    environ.fix_alpha()\n",
    "    environ.free_weights(opt['fix_BN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "33503635",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:54:07.310568Z",
     "start_time": "2022-03-05T23:54:07.252448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 50\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "# current_epoch = 40\n",
    "print(ns.current_epoch,ns.train_total_epochs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8593384c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:55:26.513540Z",
     "start_time": "2022-03-05T23:55:26.458512Z"
    }
   },
   "outputs": [],
   "source": [
    "# num_train_layers = None \n",
    "# environ.opt['is_curriculum'] = True\n",
    "# environ.opt['curriculum_speed'] = 4\n",
    "ns.num_train_layers = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c0bc96b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:09:05.742004Z",
     "start_time": "2022-03-06T00:09:05.677778Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_total_epochs = 10\n",
    "# stop_epoch_training = current_epoch +train_total_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "753d84a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:09:00.507447Z",
     "start_time": "2022-03-06T00:09:00.436994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_epoch           : 40\n",
      "current_iters           : 4200\n",
      "train_total_epochs      : 50\n",
      "stop_epoch_training     : 90\n",
      "Batches in weight epoch : 105\n",
      "Batches in policy epoch : 105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"current_epoch           : {ns.current_epoch}\") \n",
    "print(f\"current_iters           : {ns.current_iter}\")  \n",
    "print(f\"train_total_epochs      : {ns.train_total_epochs}\") \n",
    "print(f\"stop_epoch_training     : {ns.stop_epoch_training}\")\n",
    "print(f\"Batches in weight epoch : {ns.stop_iter_w}\")\n",
    "print(f\"Batches in policy epoch : {ns.stop_iter_a}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "67886cb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:49:41.089717Z",
     "start_time": "2022-03-05T23:49:41.035222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[e] Last epoch:40  it:4200 -  Total Loss: 14.9426     \n",
      "Task: 12.8435   Sparsity: 2.07915e+00    Sharing: 1.99785e-02 \n"
     ]
    }
   ],
   "source": [
    "print_loss(environ.val_metrics, title = f\"[e] Last epoch:{ns.current_epoch}  it:{ns.current_iter}\")\n",
    "# environ.display_trained_policy(ns.current_epoch)\n",
    "# environ.display_trained_logits(ns.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2fcd6751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:12:14.742210Z",
     "start_time": "2022-03-06T00:12:14.682036Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed : 40   # of epochs to run:  50 -->  epochs 41 to 50\n",
      " policy_learning rate : 0.01 \n",
      " lambda_sparsity      : 0.0001\n",
      " lambda_sharing       : 0.01\n",
      " curriculum training  : False     cirriculum speed: 3     num_training_layers : None\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_heading(f\" Last Epoch Completed : {ns.current_epoch}   # of epochs to run:  {ns.train_total_epochs} -->  epochs {ns.current_epoch+1} to {ns.stop_epoch_training}\"\n",
    "              f\"\\n policy_learning rate : {environ.opt['train']['policy_lr']} \"\n",
    "              f\"\\n lambda_sparsity      : {environ.opt['train']['lambda_sparsity']}\"\n",
    "              f\"\\n lambda_sharing       : {environ.opt['train']['lambda_sharing']}\"\n",
    "              f\"\\n curriculum training  : {opt['is_curriculum']}     cirriculum speed: {opt['curriculum_speed']}     num_training_layers : {ns.num_train_layers}\", \n",
    "              verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc5b23",
   "metadata": {},
   "source": [
    "### Weight/Policy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8a10f80f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:29:50.043721Z",
     "start_time": "2022-03-06T00:21:35.049706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      " Last Epoch Completed : 42   # of epochs to run:  50 -->  epochs 43 to 52 \n",
      " policy_learning rate : 0.01      \n",
      " lambda_sparsity      : 0.0001\n",
      " lambda_sharing       : 0.01 \n",
      " curriculum training  : False     cirriculum speed: 3     num_training_layers : None\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   43 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    0.8420   3.1854e+00   2.9997e-02    4.0574 |   0.86447   0.79700   0.79988   0.79690 |   12.9681   3.1974e+00   3.2340e-02    16.1978 |  23.4 |\n",
      "   44 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    0.5892   3.1974e+00   3.2340e-02    3.8190 |   0.87367   0.79698   0.80042   0.79688 |   13.0986   3.1974e+00   3.2340e-02    16.3284 |  24.6 |\n",
      "   44 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    0.6388   4.0989e+00   3.2195e-02    4.7698 |   0.87891   0.79635   0.79981   0.79626 |   13.1985   4.1067e+00   3.3324e-02    17.3386 |  26.8 |\n",
      " decay gumbel softmax to 3.86\n",
      "   45 |   1.00e-03   1.00e-03   1.00e-02  3.860e+00 |    0.6551   4.1067e+00   3.3324e-02    4.7951 |   0.89904   0.79701   0.79999   0.79691 |   13.4901   4.1067e+00   3.3324e-02    17.6301 |  24.1 |\n",
      "   45 |   1.00e-03   1.00e-03   1.00e-02  3.860e+00 |    0.7904   4.9173e+00   3.6866e-02    5.7445 |   0.91145   0.79764   0.80031   0.79755 |   13.6744   4.9208e+00   3.4353e-02    18.6295 |  27.8 |\n",
      "\n",
      "[e] Policy training epoch:45  it:4936 -  Total Loss: 18.6295     \n",
      "Task: 13.6744   Sparsity: 4.92075e+00    Sharing: 3.43531e-02 \n",
      "\n",
      " epch:  45   softmax       sel        softmax        sel        softmax        sel \n",
      " -----  -----------------  ---    -----------------  ---    -----------------  --- \n",
      "   1    0.6518     0.3482   1     0.6444     0.3556   1     0.6733     0.3267   1\n",
      "   2    0.7106     0.2894   1     0.7470     0.2530   1     0.7310     0.2690   1\n",
      "   3    0.8380     0.1620   1     0.7963     0.2037   1     0.8141     0.1859   1\n",
      "   4    0.8159     0.1841   1     0.8244     0.1756   1     0.8313     0.1687   1\n",
      "   5    0.8902     0.1098   1     0.8746     0.1254   1     0.8642     0.1358   1\n",
      "   6    0.8761     0.1239   1     0.8559     0.1441   1     0.8308     0.1692   1\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   46 |   1.00e-03   1.00e-03   1.00e-02  3.860e+00 |    0.6959   4.9208e+00   3.4353e-02    5.6510 |   0.91760   0.79660   0.79962   0.79651 |   13.7376   4.9208e+00   3.4353e-02    18.6927 |  25.4 |\n",
      "   46 |   1.00e-03   1.00e-03   1.00e-02  3.860e+00 |    0.7607   5.3693e+00   3.9761e-02    6.1698 |   0.91648   0.79737   0.80010   0.79727 |   13.7738   5.3723e+00   3.4071e-02    19.1802 |  28.8 |\n",
      " decay gumbel softmax to 3.7249\n",
      "   47 |   1.00e-03   1.00e-03   1.00e-02  3.725e+00 |    0.7062   5.3723e+00   3.4071e-02    6.1126 |   0.91927   0.79712   0.79973   0.79702 |   13.8316   5.3723e+00   3.4071e-02    19.2380 |  23.6 |\n",
      "   47 |   1.00e-03   1.00e-03   1.00e-02  3.725e+00 |    0.7103   5.5572e+00   2.7259e-02    6.2948 |   0.91871   0.79743   0.79999   0.79734 |   13.7862   5.5585e+00   2.9048e-02    19.3738 |  26.3 |\n",
      "   48 |   1.00e-03   1.00e-03   1.00e-02  3.725e+00 |    0.7819   5.5585e+00   2.9048e-02    6.3694 |   0.92149   0.79732   0.80004   0.79722 |   13.8090   5.5585e+00   2.9048e-02    19.3965 |  24.5 |\n",
      "   48 |   1.00e-03   1.00e-03   1.00e-02  3.725e+00 |    0.7753   5.6992e+00   3.1739e-02    6.5063 |   0.92473   0.79729   0.80017   0.79719 |   13.8435   5.7036e+00   2.7191e-02    19.5744 |  27.3 |\n",
      " decay gumbel softmax to 3.5945284999999996\n",
      "   49 |   1.00e-03   1.00e-03   1.00e-02  3.595e+00 |    0.7295   5.7036e+00   2.7191e-02    6.4603 |   0.93043   0.79770   0.80016   0.79761 |   13.9039   5.7036e+00   2.7191e-02    19.6347 |  25.1 |\n",
      "   49 |   1.00e-03   1.00e-03   1.00e-02  3.595e+00 |    0.7311   5.8787e+00   3.5046e-02    6.6448 |   0.92766   0.79743   0.80015   0.79733 |   13.9019   5.8802e+00   3.4531e-02    19.8167 |  26.9 |\n",
      "   50 |   1.00e-03   1.00e-03   1.00e-02  3.595e+00 |    1.1884   5.8802e+00   3.4532e-02    7.1031 |   0.92784   0.79773   0.80023   0.79763 |   13.9288   5.8802e+00   3.4531e-02    19.8435 |  23.0 |\n",
      "   50 |   1.00e-03   1.00e-03   1.00e-02  3.595e+00 |    0.5759   5.8635e+00   3.6376e-02    6.4758 |   0.92806   0.79758   0.80037   0.79748 |   13.8968   5.8631e+00   5.2533e-02    19.8123 |  27.1 |\n",
      " decay gumbel softmax to 3.4687200024999996\n",
      "\n",
      "[e] Policy training epoch:50  it:5986 -  Total Loss: 19.8123     \n",
      "Task: 13.8968   Sparsity: 5.86305e+00    Sharing: 5.25331e-02 \n",
      "\n",
      " epch:  50   softmax       sel        softmax        sel        softmax        sel \n",
      " -----  -----------------  ---    -----------------  ---    -----------------  --- \n",
      "   1    0.6263     0.3737   1     0.6291     0.3709   1     0.6040     0.3960   1\n",
      "   2    0.7501     0.2499   1     0.7531     0.2469   1     0.7056     0.2944   1\n",
      "   3    0.9155     0.0845   1     0.8080     0.1920   1     0.8482     0.1518   1\n",
      "   4    0.8790     0.1210   1     0.8465     0.1535   1     0.8427     0.1573   1\n",
      "   5    0.9531     0.0469   1     0.9468     0.0532   1     0.9146     0.0854   1\n",
      "   6    0.9470     0.0530   1     0.9318     0.0682   1     0.9046     0.0954   1\n",
      "\n",
      "\n",
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   51 |   1.00e-03   1.00e-03   1.00e-02  3.469e+00 |    0.9033   5.8631e+00   5.2533e-02    6.8189 |   0.93929   0.79715   0.79986   0.79705 |   14.0762   5.8631e+00   5.2533e-02    19.9918 |  24.7 |\n",
      "   51 |   1.00e-03   1.00e-03   1.00e-02  3.469e+00 |    0.6084   6.1114e+00   3.8171e-02    6.7579 |   0.93806   0.79731   0.79989   0.79721 |   14.0882   6.1109e+00   3.0661e-02    20.2298 |  28.1 |\n",
      "   52 |   1.00e-03   1.00e-03   1.00e-02  3.469e+00 |    0.7121   6.1109e+00   3.0661e-02    6.8537 |   0.94115   0.79761   0.80023   0.79752 |   14.1227   6.1109e+00   3.0661e-02    20.2642 |  26.7 |\n",
      "   52 |   1.00e-03   1.00e-03   1.00e-02  3.469e+00 |    0.6142   6.1188e+00   2.6461e-02    6.7595 |   0.93929   0.79740   0.80014   0.79730 |   14.1093   6.1202e+00   3.1772e-02    20.2613 |  26.5 |\n",
      " decay gumbel softmax to 3.3473148024124995\n",
      "[Final] ep:52  it:6406 -  Total Loss: 20.2613     \n",
      "Task: 14.1093   Sparsity: 6.12019e+00    Sharing: 3.17720e-02 \n",
      "\n",
      " epch:  52   softmax       sel        softmax        sel        softmax        sel \n",
      " -----  -----------------  ---    -----------------  ---    -----------------  --- \n",
      "   1    0.6098     0.3902   1     0.6373     0.3627   1     0.6365     0.3635   1\n",
      "   2    0.7754     0.2246   1     0.7450     0.2550   1     0.6998     0.3002   1\n",
      "   3    0.9121     0.0879   1     0.8494     0.1506   1     0.8834     0.1166   1\n",
      "   4    0.8774     0.1226   1     0.8688     0.1312   1     0.8675     0.1325   1\n",
      "   5    0.9494     0.0506   1     0.9567     0.0433   1     0.9286     0.0714   1\n",
      "   6    0.9514     0.0486   1     0.9357     0.0643   1     0.9208     0.0792   1\n",
      "\n",
      "\n",
      "\n",
      " epch:  52   logits        sel          logits       sel         logits        sel \n",
      " -----  -----------------  ---    ----------------   ---    ----------------   --- \n",
      "   1    0.1309    -0.3156   1     0.1346    -0.4291   1     0.1304    -0.4296   1\n",
      "   2    0.2477    -0.9911   1     0.2471    -0.8251   1     0.2462    -0.6001   1\n",
      "   3    0.4757    -1.8642   1     0.4748    -1.2547   1     0.4745    -1.5508   1\n",
      "   4    0.4599    -1.5085   1     0.4594    -1.4308   1     0.4600    -1.4189   1\n",
      "   5    0.7330    -2.1997   1     0.7341    -2.3609   1     0.7318    -1.8328   1\n",
      "   6    0.6880    -2.2857   1     0.6942    -1.9836   1     0.6943    -1.7586   1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weight_policy_training(ns, opt, environ, dldrs, epochs = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b87364e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T00:13:49.228500Z",
     "start_time": "2022-03-06T00:13:49.164823Z"
    }
   },
   "outputs": [],
   "source": [
    "# while current_epoch < stop_epoch_training:\n",
    "#     current_epoch+=1\n",
    "\n",
    "#     #-----------------------------------------------------------------------------------------------------------\n",
    "#     # Set number of layers to train based on cirriculum_speed and p_epoch (number of epochs of policy training)\n",
    "#     # e.g., When curriculum_speed == 3, num_train_layers is incremented  after every 3 policy training epochs\n",
    "#     #-----------------------------------------------------------------------------------------------------------\n",
    "#     num_train_layers = (p_epoch // opt['curriculum_speed']) + 1  if opt['is_curriculum'] else None\n",
    "    \n",
    "#     #-----------------------------------------\n",
    "#     # Train & Update the network weights\n",
    "#     #-----------------------------------------\n",
    "#     if flag == 'update_w':\n",
    "#         start_time = time.time()\n",
    "#         environ.train()\n",
    "        \n",
    "#         with trange(+1, stop_iter_w+1 , initial = 0, total = stop_iter_w,  file=sys.stdout,\n",
    "#                      position=0, ncols = 132, leave= leave, desc=f\"Ep: {current_epoch} [weights]\") as t_weights :\n",
    "            \n",
    "#             for _ in t_weights:    \n",
    "#                 current_iter += 1\n",
    "\n",
    "#                 batch = next(weight_trn_loader)\n",
    "#                 environ.set_inputs(batch, weight_trn_loader.dataset.input_size)\n",
    "#                 environ.optimize(opt['lambdas'], \n",
    "#                                  is_policy=opt['policy'], \n",
    "#                                  flag=flag, \n",
    "#                                  num_train_layers=num_train_layers,\n",
    "#                                  hard_sampling=opt['train']['hard_sampling'],\n",
    "#                                  verbose = False)\n",
    "\n",
    "#                 t_weights.set_postfix({'it' : current_iter, \n",
    "#                                        'Lss': f\"{environ.losses['losses']['total'].item():.4f}\" , \n",
    "#                                        'Spr': f\"{environ.losses['sparsity']['total'].item():.4e}\",  \n",
    "#                                        'Shr': f\"{environ.losses['sharing']['total'].item():.4e}\",\n",
    "#                                        'lyr': f\"{num_train_layers}\"})    \n",
    " \n",
    "#         trn_losses = environ.losses\n",
    "#         environ.print_trn_metrics(current_epoch, current_iter, start_time, title = f\"[Weight Trn]\", to_display = False)\n",
    "#         wandb.log(environ.losses)\n",
    "                      \n",
    "#         #--------------------------------------------------------------------\n",
    "#         # validation process (here current_iter_w and stop_iter_w are equal)\n",
    "#         #--------------------------------------------------------------------\n",
    "#         val_metrics = environ.evaluate(val_loader,  is_policy=opt['policy'],\n",
    "#                                        num_train_layers=num_train_layers, hard_sampling=opt['train']['hard_sampling'],\n",
    "#                                        eval_iters = eval_iters, progress = True, leave = leave, verbose = False)  \n",
    "\n",
    "#         environ.print_val_metrics(current_epoch, current_iter, start_time, title = f\"[Weight Val]\", verbose = False)\n",
    "#         print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics, line_count, out=[sys.stdout, environ.log_file]) \n",
    "#         line_count +=1\n",
    "#         wandb.log(environ.val_metrics)\n",
    "\n",
    "#         #------------------------------------------------------------------------ \n",
    "#         #  Save Best Checkpoint Code (saved below and in sparsechem_env_dev.py)\n",
    "#         #----------------------------------------------------------------------- \n",
    "#         # Take check point:     environ.save_checkpoint('latest_weights', current_iter)\n",
    "#         #-----------------------------------------------------------------------\n",
    "#         # END validation process \n",
    "#         #-----------------------------------------------------------------------\n",
    "#         flag = 'update_alpha'\n",
    "#         environ.fix_weights()\n",
    "#         environ.free_alpha()\n",
    "        \n",
    "# #         environ.display_trained_policy(current_epoch,out=[sys.stdout])\n",
    "\n",
    "#     #-----------------------------------------\n",
    "#     # Policy Training  \n",
    "#     #-----------------------------------------\n",
    "#     if flag == 'update_alpha':\n",
    "#         start_time = time.time()        \n",
    "#         environ.train()\n",
    "        \n",
    "#         with trange( +1, stop_iter_a+1 , initial = 0, total = stop_iter_a,   file=sys.stdout,\n",
    "#                      position=0, dynamic_ncols = True, leave= leave, desc=f\"Ep:{current_epoch} [policy] \") as t_policy :\n",
    "#             for _ in t_policy:    \n",
    "#                 current_iter += 1\n",
    "#                 batch = next(policy_trn_loader)\n",
    "\n",
    "#                 environ.set_inputs(batch, policy_trn_loader.dataset.input_size)\n",
    "\n",
    "#                 environ.optimize(opt['lambdas'], is_policy=opt['policy'],  \n",
    "#                                  flag=flag, num_train_layers=num_train_layers,\n",
    "#                                  hard_sampling=opt['train']['hard_sampling'], verbose = False)\n",
    "                \n",
    "#                 t_policy.set_postfix({'it' : current_iter,\n",
    "#                                       'Lss': f\"{environ.losses['losses']['total'].item():.4f}\",\n",
    "#                                       'Spr': f\"{environ.losses['sparsity']['total'].item():.4e}\",\n",
    "#                                       'Shr': f\"{environ.losses['sharing']['total'].item():.4e}\",\n",
    "#                                       'lyr': f\"{num_train_layers}\"})    \n",
    "# #                                       ,'row_ids':f\"{batch['row_id'][0]}-{batch['row_id'][-1]}\"})\n",
    "\n",
    "#         # print loss results - here current_iter_w and stop_iter_w are equal\n",
    "#         trn_losses = environ.losses\n",
    "#         environ.print_trn_metrics(current_epoch, current_iter, start_time, title = f\"[Policy Trn]\")\n",
    "#         wandb.log(environ.losses)\n",
    "        \n",
    "#         #--------------------------------------------------------------------\n",
    "#         # validation process (here current_iter_a and stop_iter_a are equal)\n",
    "#         #--------------------------------------------------------------------        \n",
    "#         val_metrics = environ.evaluate(val_loader, is_policy=opt['policy'],\n",
    "#                                        num_train_layers=num_train_layers, hard_sampling=opt['train']['hard_sampling'],\n",
    "#                                        eval_iters = eval_iters, progress = True, leave = False, verbose = False)  \n",
    "\n",
    "#         environ.print_val_metrics(current_epoch, current_iter, start_time, title = f\"[Policy Val]\", verbose = False)\n",
    "#         print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics, line_count, out=[sys.stdout, environ.log_file])      \n",
    "#         line_count +=1\n",
    "#         wandb.log(environ.val_metrics)\n",
    "#         #-----------------------------------------------------------------------\n",
    "#         # END validation process \n",
    "#         #-----------------------------------------------------------------------    \n",
    "        \n",
    "#         p_epoch += 1        \n",
    "#         if should(p_epoch, opt['train']['decay_temp_freq']):\n",
    "#             environ.decay_temperature()\n",
    "#             print(f\" decay gumbel softmax to {environ.gumbel_temperature}\")\n",
    "        \n",
    "#         flag = 'update_w'\n",
    "#         environ.fix_alpha()\n",
    "#         environ.free_weights(opt['fix_BN'])\n",
    "        \n",
    "#     environ.display_trained_policy(current_epoch,out=[sys.stdout, environ.log_file])\n",
    "# #         environ.display_trained_logits(current_epoch)        \n",
    "# #         print_loss(current_epoc, current_iter, environ.val_metrics, title = f\"[Policy trn]  ep:{current_epoch}   it:{current_iter}\")\n",
    "    \n",
    "#     #-----------------------------------------\n",
    "#     # End Policy Training  \n",
    "#     #----------------------------------------- \n",
    "#     if should(current_epoch, 5):\n",
    "#         environ.save_checkpoint('model_latest_weights_policy', current_iter)        \n",
    "#         print_loss(environ.val_metrics, title = f\"\\n[e] Policy training epoch:{current_epoch}  it:{current_iter}\")\n",
    "#         environ.display_trained_policy(current_epoch,out=[sys.stdout, environ.log_file])\n",
    "#         environ.log_file.flush()\n",
    "#         line_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1563b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
    "   41 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    0.8728   2.0798e+00   2.2045e-02    2.9746 |   0.79093   0.79385   0.79872   0.79374 |   11.8822   2.0798e+00   2.2045e-02    13.9840 |  21.3 |\n",
    "   41 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    0.8624   3.3384e+00   2.4459e-02    4.2252 |   0.83149   0.79523   0.79952   0.79511 |   12.4564   3.3486e+00   2.5304e-02    15.8303 |  24.7 |\n",
    "\n",
    " epch:  41   softmax       sel        softmax        sel        softmax        sel \n",
    " -----  -----------------  ---    -----------------  ---    -----------------  --- \n",
    "   1    0.6458     0.3542   1     0.6070     0.3930   1     0.5805     0.4195   1\n",
    "   2    0.6702     0.3298   1     0.6470     0.3530   1     0.6384     0.3616   1\n",
    "   3    0.7101     0.2899   1     0.6877     0.3123   1     0.7061     0.2939   1\n",
    "   4    0.7079     0.2921   1     0.6889     0.3111   1     0.6832     0.3168   1\n",
    "   5    0.6939     0.3061   1     0.6880     0.3120   1     0.6562     0.3438   1\n",
    "   6    0.7013     0.2987   1     0.6764     0.3236   1     0.6851     0.3149   1\n",
    "\n",
    "\n",
    "   42 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    0.7771   3.3486e+00   2.5304e-02    4.1511 |   0.83653   0.79496   0.79934   0.79485 |   12.5565   3.3486e+00   2.5304e-02    15.9304 |  22.3 |\n",
    "   42 |   1.00e-03   1.00e-03   1.00e-02  4.000e+00 |    0.8742   4.3501e+00   3.0319e-02    5.2546 |   0.86560   0.79615   0.80054   0.79604 |   12.9552   4.3551e+00   2.6973e-02    17.3373 |  26.0 |\n",
    " decay gumbel softmax to 3.86\n",
    "\n",
    " epch:  42   softmax       sel        softmax        sel        softmax        sel \n",
    " -----  -----------------  ---    -----------------  ---    -----------------  --- \n",
    "   1    0.6727     0.3273   1     0.6672     0.3328   1     0.6010     0.3990   1\n",
    "   2    0.7368     0.2632   1     0.7413     0.2587   1     0.7077     0.2923   1\n",
    "   3    0.8078     0.1922   1     0.8050     0.1950   1     0.7959     0.2041   1\n",
    "   4    0.8129     0.1871   1     0.8185     0.1815   1     0.8087     0.1913   1\n",
    "   5    0.7898     0.2102   1     0.7883     0.2117   1     0.7289     0.2711   1\n",
    "   6    0.8033     0.1967   1     0.7912     0.2088   1     0.7895     0.2105   1\n",
    "\n",
    "\n",
    "   43 |   1.00e-03   1.00e-03   1.00e-02  3.860e+00 |    1.0659   4.3551e+00   2.6973e-02    5.4481 |   0.85030   0.79606   0.80014   0.79596 |   12.7389   4.3551e+00   2.6973e-02    17.1210 |  22.3 |\n",
    "   43 |   1.00e-03   1.00e-03   1.00e-02  3.860e+00 |    0.8035   5.0357e+00   2.5471e-02    5.8647 |   0.88083   0.79652   0.80068   0.79641 |   13.2055   5.0398e+00   2.5324e-02    18.2706 |  25.9 |\n",
    "\n",
    " epch:  43   softmax       sel        softmax        sel        softmax        sel \n",
    " -----  -----------------  ---    -----------------  ---    -----------------  --- \n",
    "   1    0.6780     0.3220   1     0.6618     0.3382   1     0.6301     0.3699   1\n",
    "   2    0.7836     0.2164   1     0.7349     0.2651   1     0.7357     0.2643   1\n",
    "   3    0.8825     0.1175   1     0.8691     0.1309   1     0.8280     0.1720   1\n",
    "   4    0.8726     0.1274   1     0.8646     0.1354   1     0.8581     0.1419   1\n",
    "   5    0.8440     0.1560   1     0.8456     0.1544   1     0.7950     0.2050   1\n",
    "   6    0.8380     0.1620   1     0.8524     0.1476   1     0.8421     0.1579   1\n",
    "\n",
    "\n",
    "   44 |   1.00e-03   1.00e-03   1.00e-02  3.860e+00 |    0.8932   5.0398e+00   2.5324e-02    5.9583 |   0.89359   0.79644   0.80050   0.79634 |   13.3804   5.0398e+00   2.5324e-02    18.4455 |  22.4 |\n",
    "   44 |   1.00e-03   1.00e-03   1.00e-02  3.860e+00 |    0.5556   5.3640e+00   3.5313e-02    5.9550 |   0.89871   0.79618   0.80029   0.79607 |   13.4941   5.3614e+00   2.5808e-02    18.8814 |  25.9 |\n",
    " decay gumbel softmax to 3.7249\n",
    "\n",
    " epch:  44   softmax       sel        softmax        sel        softmax        sel \n",
    " -----  -----------------  ---    -----------------  ---    -----------------  --- \n",
    "   1    0.6587     0.3413   1     0.6316     0.3684   1     0.5749     0.4251   1\n",
    "   2    0.8027     0.1973   1     0.7663     0.2337   1     0.7475     0.2525   1\n",
    "   3    0.8963     0.1037   1     0.8871     0.1129   1     0.8511     0.1489   1\n",
    "   4    0.9030     0.0970   1     0.9038     0.0962   1     0.8964     0.1036   1\n",
    "   5    0.8662     0.1338   1     0.8678     0.1322   1     0.8120     0.1880   1\n",
    "   6    0.8525     0.1475   1     0.8732     0.1268   1     0.8357     0.1643   1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d96d311d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T20:02:27.055909Z",
     "start_time": "2022-03-05T20:02:26.639160Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Final] ep:60  it:4200 -  Total Loss: 20.7877     \n",
      "Task: 14.1191   Sparsity: 6.63991e+00    Sharing: 2.87537e-02 \n",
      "\n",
      " epch:  60   softmax       sel        softmax        sel        softmax        sel \n",
      " -----  -----------------  ---    -----------------  ---    -----------------  --- \n",
      "   1    0.6732     0.3268   1     0.6369     0.3631   1     0.5632     0.4368   1\n",
      "   2    0.8367     0.1633   1     0.8318     0.1682   1     0.7858     0.2142   1\n",
      "   3    0.9442     0.0558   1     0.9399     0.0601   1     0.8721     0.1279   1\n",
      "   4    0.9570     0.0430   1     0.9632     0.0368   1     0.9441     0.0559   1\n",
      "   5    0.9136     0.0864   1     0.9303     0.0697   1     0.8721     0.1279   1\n",
      "   6    0.9061     0.0939   1     0.9375     0.0625   1     0.9047     0.0953   1\n",
      "\n",
      "\n",
      "\n",
      " epch:  60   logits        sel          logits       sel         logits        sel \n",
      " -----  -----------------  ---    ----------------   ---    ----------------   --- \n",
      "   1    0.1796    -0.5430   1     0.1820    -0.3801   1     0.1805    -0.0735   1\n",
      "   2    0.4971    -1.1369   1     0.4941    -1.1043   1     0.4945    -0.8055   1\n",
      "   3    0.8833    -1.9448   1     0.8838    -1.8667   1     0.8841    -1.0355   1\n",
      "   4    1.0964    -2.0064   1     1.0968    -2.1683   1     1.0935    -1.7324   1\n",
      "   5    0.8017    -1.5564   1     0.8030    -1.7878   1     0.8035    -1.1164   1\n",
      "   6    0.8298    -1.4369   1     0.8292    -1.8780   1     0.8323    -1.4188   1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_label   = 'model_train_ep_%d_seed_%04d' % (current_epoch, opt['random_seed'])\n",
    "metrics_label = 'metrics_train_ep_%d_seed_%04d.pickle' % (current_epoch, opt['random_seed'])\n",
    "environ.save_checkpoint(model_label, current_iter, current_epoch) \n",
    "save_to_pickle(environ.val_metrics, environ.opt['paths']['checkpoint_dir'], metrics_label)\n",
    "print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "environ.display_trained_policy(current_epoch,out=[sys.stdout, environ.log_file])\n",
    "environ.display_trained_logits(current_epoch)\n",
    "environ.log_file.flush()\n",
    "\n",
    "\n",
    "# environ.save_checkpoint('best_weights_policy_2', current_iter, current_epoch) \n",
    "# print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "# environ.display_trained_policy(current_epoch,out=[sys.stdout, environ.log_file])\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49cc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946c616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff8b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f1656da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T02:24:41.755527Z",
     "start_time": "2022-03-02T02:24:41.573076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone Learning Rate      : 0.001\n",
      " Tasks    Learning Rate      : 0.001\n",
      " Policy   Learning Rate      : 0.002\n",
      "\n",
      " Sparsity regularization     : 0.1\n",
      " Sharing  regularization     : 0.01 \n",
      "\n",
      " Tasks    regularization     : 1   \n",
      " Gumbel Temp                 : 0.2764         \n",
      " Gumbel Temp decay           : 2\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c570db82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T02:24:42.383142Z",
     "start_time": "2022-03-02T02:24:42.291656Z"
    }
   },
   "outputs": [],
   "source": [
    "environ.opt['train']['policy_lr']       = 0.002\n",
    "environ.opt['train']['lambda_sparsity'] = 0.1\n",
    "environ.opt['train']['lambda_sharing']  = 0.01\n",
    "# environ.opt['train']['lambda_tasks']    = 1.0\n",
    "# # environ.opt['train']['decay_temp_freq'] = 2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "26efa07b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T02:24:42.962923Z",
     "start_time": "2022-03-02T02:24:42.851901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backbone Learning Rate      : 0.001\n",
      " Tasks    Learning Rate      : 0.001\n",
      " Policy   Learning Rate      : 0.002\n",
      "\n",
      " Sparsity regularization     : 0.1\n",
      " Sharing  regularization     : 0.01 \n",
      "\n",
      " Tasks    regularization     : 1   \n",
      " Gumbel Temp                 : 0.2764         \n",
      " Gumbel Temp decay           : 2\n",
      "\n",
      " current_iters               : 32550\n",
      " current_epochs              : 160\n",
      " train_total_epochs          : 10\n",
      " stop_epoch_training         : 160\n"
     ]
    }
   ],
   "source": [
    "print( f\" Backbone Learning Rate      : {environ.opt['train']['backbone_lr']}\\n\"\n",
    "       f\" Tasks    Learning Rate      : {environ.opt['train']['task_lr']}\\n\"\n",
    "       f\" Policy   Learning Rate      : {environ.opt['train']['policy_lr']}\\n\")\n",
    "\n",
    "\n",
    "print( f\" Sparsity regularization     : {environ.opt['train']['lambda_sparsity']}\\n\"\n",
    "       f\" Sharing  regularization     : {environ.opt['train']['lambda_sharing']} \\n\\n\"\n",
    "       f\" Tasks    regularization     : {environ.opt['train']['lambda_tasks']}   \\n\"\n",
    "       f\" Gumbel Temp                 : {environ.gumbel_temperature:.4f}         \\n\" #\n",
    "       f\" Gumbel Temp decay           : {environ.opt['train']['decay_temp_freq']}\") #\n",
    "\n",
    "print()\n",
    "print( f\" current_iters               : {current_iter}\")  \n",
    "print( f\" current_epochs              : {current_epoch}\") \n",
    "print( f\" train_total_epochs          : {train_total_epochs}\") \n",
    "print( f\" stop_epoch_training         : {stop_epoch_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de4040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T23:42:38.875913Z",
     "start_time": "2022-02-16T23:42:38.820249Z"
    }
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "# pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e5cec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T17:44:36.218784Z",
     "start_time": "2022-02-21T17:44:36.063411Z"
    }
   },
   "outputs": [],
   "source": [
    "# print_loss(environ.val_metrics, title = f\"[Final] ep:{current_epoch}  it:{current_iter}\",)\n",
    "# environ.display_trained_policy(current_epoch)\n",
    "# environ.display_trained_logits(current_epoch)\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad3a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T22:48:27.014120Z",
     "start_time": "2022-02-20T22:48:26.982535Z"
    }
   },
   "outputs": [],
   "source": [
    "# print_loss(current_iter, environ.losses, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")\n",
    "# print()\n",
    "# print_loss(current_iter, trn_losses, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")\n",
    "# print()\n",
    "# print_loss(current_iter, environ.val_metrics, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20edbdd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T20:37:56.499455Z",
     "start_time": "2022-03-01T20:37:56.093472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | BckBone LR   Heads LR  Policy LR Gumbl Temp |  trn loss     trn spar     trn shar   trn ttl |   bceloss  avg prec    aucroc     aucpr |  val loss     val spar     val shar    val ttl |  time |\n",
      "   90 |   5.22e-04   5.22e-04   6.14e-03  9.968e-01 |    2.3488   2.3753e+00   2.9361e-02    4.7535 |   0.66047   0.80706   0.81083   0.80696 |    9.8989   2.3745e+00   3.2183e-02    12.3056 |2719.3 |\n"
     ]
    }
   ],
   "source": [
    "print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics, 0, out=[sys.stdout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d5db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T20:31:45.254334Z",
     "start_time": "2022-03-01T20:31:45.116895Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.losses\n",
    "\n",
    "environ.val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59c4dd81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T20:47:29.582501Z",
     "start_time": "2022-03-01T20:47:29.492581Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.batch_data\n",
    "\n",
    "# environ.display_parameters()\n",
    "\n",
    "# with np.printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', precision=7, formatter={'float': lambda x: f\"{x:12.5e}\"}):\n",
    "#     environ.print_logit_grads('gradients')\n",
    "\n",
    "# environ_params = environ.get_task_specific_parameters()\n",
    "# environ_params = environ.get_arch_parameters()\n",
    "# environ_params = environ.get_backbone_parameters()\n",
    "# print(environ_params)\n",
    "# for param in environ_params:\n",
    "#     print(param.grad.shape, '\\n', param.grad)\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c80c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T07:39:25.496225Z",
     "start_time": "2022-02-21T07:39:25.439137Z"
    }
   },
   "outputs": [],
   "source": [
    "environ.display_trained_logits(current_epoch)\n",
    "environ.display_trained_policy(current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d47dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T17:25:12.503617Z",
     "start_time": "2022-02-22T17:25:12.162406Z"
    }
   },
   "outputs": [],
   "source": [
    "environ.display_test_sample_policy(current_epoch, hard_sampling = True)\n",
    "environ.display_train_sample_policy(current_epoch, hard_sampling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8754b317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T18:43:49.293386Z",
     "start_time": "2022-02-24T18:43:49.253007Z"
    }
   },
   "outputs": [],
   "source": [
    "    environ.define_optimizer(policy_learning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e89541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:30:31.566158Z",
     "start_time": "2022-02-25T21:30:31.242033Z"
    }
   },
   "outputs": [],
   "source": [
    "print(environ.optimizers['alphas'])\n",
    "print(environ.optimizers['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1ecc91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T00:37:03.507813Z",
     "start_time": "2022-02-26T00:37:03.462964Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  initial_lr :  0.01 lr :  0.0072250000000000005\n",
      "Weights initial_lr :  0.001 lr :  0.0007224999999999999\n",
      "Weights initial_lr :  0.001 lr :  0.0007224999999999999\n"
     ]
    }
   ],
   "source": [
    "print('Policy  initial_lr : ', environ.optimizers['alphas'].param_groups[0]['initial_lr'], 'lr : ',environ.optimizers['alphas'].param_groups[0]['lr'])\n",
    "print('Weights initial_lr : ', environ.optimizers['weights'].param_groups[0]['initial_lr'], 'lr : ',environ.optimizers['weights'].param_groups[0]['lr'])\n",
    "print('Weights initial_lr : ', environ.optimizers['weights'].param_groups[1]['initial_lr'], 'lr : ',environ.optimizers['weights'].param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "96d8af9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T03:13:25.272902Z",
     "start_time": "2022-03-03T03:13:14.880317Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of wandb.apis.normalize failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 855, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/apis/normalize.py\", line 14, in <module>\n",
      "    from wandb_gql.client import RetryError\n",
      "ModuleNotFoundError: No module named 'wandb_gql'\n",
      "]\n",
      "[autoreload of wandb.sdk.internal.internal_api failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 855, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/internal/internal_api.py\", line 1, in <module>\n",
      "    from wandb_gql import Client, gql  # type: ignore\n",
      "ModuleNotFoundError: No module named 'wandb_gql'\n",
      "]\n",
      "[autoreload of wandb.old.summary failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 855, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/old/summary.py\", line 9, in <module>\n",
      "    from wandb_gql import gql\n",
      "ModuleNotFoundError: No module named 'wandb_gql'\n",
      "]\n",
      "[autoreload of wandb.apis.public failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 855, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/apis/public.py\", line 39, in <module>\n",
      "    from wandb_gql import Client, gql\n",
      "ModuleNotFoundError: No module named 'wandb_gql'\n",
      "]\n",
      "[autoreload of wandb.sdk.wandb_config failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 317, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 280, in update_instances\n",
      "    ref.__class__ = new\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_config.py\", line 148, in __setitem__\n",
      "    with wandb.sdk.lib.telemetry.context() as tel:\n",
      "AttributeError: module 'wandb.sdk.lib' has no attribute 'telemetry'\n",
      "]\n",
      "[autoreload of wandb.sdk.wandb_settings failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 317, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 280, in update_instances\n",
      "    ref.__class__ = new\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_settings.py\", line 974, in __setattr__\n",
      "    raise TypeError(f\"Please use update() to update attribute `{key}` value\")\n",
      "TypeError: Please use update() to update attribute `__class__` value\n",
      "]\n",
      "[autoreload of wandb.proto.wandb_base_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 855, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/proto/wandb_base_pb2.py\", line 16, in <module>\n",
      "    DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/google/protobuf/descriptor.py\", line 982, in __new__\n",
      "    return _message.default_pool.AddSerializedFile(serialized_pb)\n",
      "TypeError: Couldn't build proto file into descriptor pool!\n",
      "Invalid proto descriptor for file \"wandb/proto/wandb_base.proto\":\n",
      "  wandb/proto/wandb_base.proto: A file with this name is already in the pool.\n",
      "\n",
      "]\n",
      "[autoreload of wandb.proto.wandb_telemetry_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 855, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/proto/wandb_telemetry_pb2.py\", line 17, in <module>\n",
      "    DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/google/protobuf/descriptor.py\", line 982, in __new__\n",
      "    return _message.default_pool.AddSerializedFile(serialized_pb)\n",
      "TypeError: Couldn't build proto file into descriptor pool!\n",
      "Invalid proto descriptor for file \"wandb/proto/wandb_telemetry.proto\":\n",
      "  wandb/proto/wandb_telemetry.proto: A file with this name is already in the pool.\n",
      "\n",
      "]\n",
      "[autoreload of wandb.proto.wandb_internal_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 855, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/proto/wandb_internal_pb2.py\", line 19, in <module>\n",
      "    DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/google/protobuf/descriptor.py\", line 982, in __new__\n",
      "    return _message.default_pool.AddSerializedFile(serialized_pb)\n",
      "TypeError: Couldn't build proto file into descriptor pool!\n",
      "Invalid proto descriptor for file \"wandb/proto/wandb_internal.proto\":\n",
      "  wandb/proto/wandb_internal.proto: A file with this name is already in the pool.\n",
      "\n",
      "]\n",
      "[autoreload of wandb.sdk.interface.interface failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 855, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\", line 65, in <module>\n",
      "    class InterfaceBase(object):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\", line 520, in InterfaceBase\n",
      "    def _publish_partial_history(self, history: pb.PartialHistoryRequest) -> None:\n",
      "AttributeError: module 'wandb.proto.wandb_internal_pb2' has no attribute 'PartialHistoryRequest'\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of wandb.sdk.interface.interface_shared failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 855, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 30, in <module>\n",
      "    class InterfaceShared(InterfaceBase):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 58, in InterfaceShared\n",
      "    self, partial_history: pb.PartialHistoryRequest\n",
      "AttributeError: module 'wandb.proto.wandb_internal_pb2' has no attribute 'PartialHistoryRequest'\n",
      "]\n",
      "Exception in thread MsgRouterThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/threading.py\", line 954, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/threading.py\", line 892, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/interface/router.py\", line 69, in message_loop\n",
      "    msg = self._read_message()\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/interface/router_queue.py\", line 35, in _read_message\n",
      "    tracelog.log_message_dequeue(msg, self._response_queue)\n",
      "NameError: name 'debug_log' is not defined\n",
      "[autoreload of wandb.sdk.wandb_run failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 317, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 280, in update_instances\n",
      "    ref.__class__ = new\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 491, in __setattr__\n",
      "    super(Run, self).__setattr__(attr, value)\n",
      "TypeError: super(type, obj): obj must be an instance or subtype of type\n",
      "]\n",
      "[autoreload of watchdog failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/importlib/__init__.py\", line 168, in reload\n",
      "    raise ModuleNotFoundError(f\"spec not found for the module {name!r}\", name=name)\n",
      "ModuleNotFoundError: spec not found for the module 'watchdog'\n",
      "]\n",
      "[autoreload of wandb failed: Traceback (most recent call last):\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 855, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/__init__.py\", line 31, in <module>\n",
      "    wandb.wandb_lib = wandb_sdk.lib\n",
      "AttributeError: module 'wandb.sdk' has no attribute 'lib'\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._resume_backend at 0x7f6cc229d310> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'info'"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Attribute _telemetry_obj_dirty is not supported on Run object.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3978/2127913808.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(exit_code, quiet)\u001b[0m\n\u001b[1;32m   2865\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rendering history\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2867\u001b[0;31m             sampled_history = {\n\u001b[0m\u001b[1;32m   2868\u001b[0m                 item.key: wandb.util.downsample(\n\u001b[1;32m   2869\u001b[0m                     \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_float\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_quiet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtelemetry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m             \u001b[0mtel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"finishing run {self.path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[0;31m# detach jupyter hooks / others that needs to happen before backend shutdown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/lib/telemetry.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exctype, excinst, exctb)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_telemetry_callback\u001b[0;34m(self, telem_obj)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_telemetry_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtelem_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtelemetry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTelemetryRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtelem_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_obj_dirty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_telemetry_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, attr, value)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_frozen\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attribute {} is not supported on Run object.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Attribute _telemetry_obj_dirty is not supported on Run object."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7f6cc2173670> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pause_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;31m# Attempt to save the code on every execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60ed5d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Post Training Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d2affee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:42:27.261326Z",
     "start_time": "2022-02-25T21:42:23.247820Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21319... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f498a73a6a4fe5923a0cdfd1f59b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.49MB of 0.49MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">0225_1207</strong>: <a href=\"http://localhost:8080/kbardool/AdaSparseChem/runs/2as296zs\" target=\"_blank\">http://localhost:8080/kbardool/AdaSparseChem/runs/2as296zs</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220225_120707-2as296zs/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Upgrade to the 0.9.49 version of W&B Local to get the latest features. Learn more: http://wandb.me/local-upgrade\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527bd00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:25:11.319751Z",
     "start_time": "2022-02-20T21:25:11.210062Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "p = environ.get_current_state(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919068f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:25:26.324030Z",
     "start_time": "2022-02-20T21:25:26.112782Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82a453",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Post Warm-up Training stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb74c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:45:43.999959Z",
     "start_time": "2022-02-01T12:45:43.862475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b47da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:36.700361Z",
     "start_time": "2022-02-01T12:46:36.367037Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].arch_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f0235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:37:10.158440Z",
     "start_time": "2022-01-28T16:37:09.742327Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p = environ.get_sample_policy(hard_sampling = False)\n",
    "print(p)\n",
    "p = environ.get_policy_prob()\n",
    "print(p)\n",
    "p = environ.get_policy_logits()\n",
    "print(p)\n",
    "\n",
    "# p = environ.get_current_policy()\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bddd44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:40:37.799917Z",
     "start_time": "2022-01-28T16:40:37.773177Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = softmax([0.0, 1])\n",
    "print(a)\n",
    "sampled = np.random.choice((1, 0), p=a)\n",
    "print(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8f376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:13:16.205889Z",
     "start_time": "2022-01-28T16:13:16.179303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.optimizers['weights'])\n",
    "print(environ.schedulers['weights'].get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf9c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:50.411465Z",
     "start_time": "2022-02-01T12:46:50.020540Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('losses.keys      : ', environ.losses.keys())\n",
    "print('losses[task]keys : ', environ.losses['task1'].keys())\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20950069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T22:57:02.151169Z",
     "start_time": "2022-01-15T22:57:02.056562Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print( environ.val_metrics.keys())\n",
    "# pp.pprint(val_metrics)\n",
    "print(type(environ.val_metrics['aggregated']))\n",
    "print()\n",
    "print(type(environ.val_metrics['task1']['classification_agg']))\n",
    "print()\n",
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6e311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.266303Z",
     "start_time": "2022-01-14T18:57:26.166878Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"val_metrics.pkl\", mode= 'wb') as f:\n",
    "#         pickle.dump(val_metrics, f)\n",
    "    \n",
    "# with open('val_metrics.pkl', 'rb') as f:    \n",
    "#     tst_val_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00a8aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.297444Z",
     "start_time": "2022-01-14T18:57:26.269323Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(environ.input.shape) \n",
    "# a = getattr(environ, 'task1_pred')\n",
    "# yc_data = environ.batch['task1_data']\n",
    "# print(yc_data.shape)\n",
    "# yc_ind = environ.batch['task1_ind']\n",
    "# print(yc_ind.shape)\n",
    "# yc_hat_all = getattr(environ, 'task1_pred')\n",
    "# print(yc_hat_all.shape)\n",
    "# yc_hat  = yc_hat_all[yc_ind[0], yc_ind[1]]\n",
    "# print(yc_hat_all.shape, yc_hat.shape)\n",
    "\n",
    "# \n",
    "# environ.losses\n",
    "# loss = {}\n",
    "# for key in environ.losses.keys():\n",
    "#     loss[key] = {}\n",
    "#     for subkey, v in environ.losses[key].items():\n",
    "#         print(f\" key:  {key}   subkey: {subkey} \")\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             loss[key][subkey] = v.data\n",
    "#             print(f\" Tensor  -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "#         else:\n",
    "#             loss[key][subkey] = v\n",
    "#             print(f\" integer -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "# pp.pprint(tst_val_metrics)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987f89f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.340792Z",
     "start_time": "2022-01-14T18:57:26.302528Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print('metrics.keys: ', environ.metrics.keys())\n",
    "# print('metrics[task].keys: ', environ.metrics['task1'].keys())\n",
    "# pp.pprint(environ.metrics['task1'])\n",
    "# pp.pprint(environ.losses['task1']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ae417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.373399Z",
     "start_time": "2022-01-14T18:57:26.345065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# title='Iteration'\n",
    "# for t_id, _ in enumerate(environ.tasks):\n",
    "#     task_key = f\"task{t_id+1}\"\n",
    "# #     print_heading(f\"{title}  {current_iter}  {task_key} : {val_metrics[task_key]['classification_agg']}\", verbose = True)\n",
    "\n",
    "#     for key, _  in val_metrics[task_key]['classification_agg'].items():\n",
    "#         print('%s/%-20s'%(task_key, key), val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print(f\"{task_key:s}/{key:20s}\", val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print()\n",
    "#             # print_current_errors(os.path.join(self.log_dir, 'loss.txt'), current_iter,key, loss[key], time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b73b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:48.162261Z",
     "start_time": "2022-01-07T22:52:48.140423Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.print_loss(current_iter, start_time, metrics = val_metrics['loss'], verbose=True)\n",
    "# print(opt['lambdas'])\n",
    "# p = (opt['lambdas'][0] * environ.losses['tasks']['task1'])\n",
    "# print(p)\n",
    "\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics , title='validation', verbose=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850378b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:47.661019Z",
     "start_time": "2022-01-07T22:52:47.639094Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(current_iter)\n",
    "# print_metrics_cr(current_iter, t1 - t0, None, val_metrics , True)\n",
    "# environ.print_val_metrics(current_iter, start_time, val_metrics, title='validation', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a80b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:14:58.034384Z",
     "start_time": "2022-01-07T23:14:58.004850Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\" val_metric keys               : {val_metrics.keys()}\")\n",
    "print(f\" loss keys                     : {val_metrics['loss'].keys()}\")\n",
    "print(f\" task1 keys                    : {val_metrics['task1'].keys()}\")\n",
    "print(f\" task1 classification keys     : {val_metrics['task1']['classification'].keys()}\")\n",
    "print(f\" task1 classification_agg keys : {val_metrics['task1']['classification_agg'].keys()}\")\n",
    "print()\n",
    "print(f\" task1                       : {val_metrics['task1']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task2                       : {val_metrics['task2']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task3                       : {val_metrics['task3']['classification_agg']['loss']:5f}\")\n",
    "print(f\" loss                        : {val_metrics['loss']['total']:5f}\")\n",
    "print(f\" train_time                  : {val_metrics['train_time']:2f}\")\n",
    "print(f\" epoch                       : {val_metrics['epoch']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc43a6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Post Weight + Policy Training Stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65640cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:22:20.634818Z",
     "start_time": "2022-01-27T00:22:20.444566Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].backbone.layer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4374287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:30:31.940280Z",
     "start_time": "2022-01-26T19:30:31.910058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_blocks = 6\n",
    "num_policy_layers = 6\n",
    "gt =  torch.ones((num_blocks)).long()\n",
    "gt0 =  torch.zeros((num_blocks)).long()\n",
    "print(gt)\n",
    "print(gt0)\n",
    "\n",
    "loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "print(loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651bc43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:42:31.300891Z",
     "start_time": "2022-01-26T19:42:31.257774Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if environ.opt['diff_sparsity_weights'] and not environ.opt['is_sharing']:\n",
    "    print(' cond 1')\n",
    "    ## Assign higher weights to higher layers \n",
    "    loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "    print(f\"{task_key} sparsity error:  {2 * (loss_weights[-num_blocks:] * environ.cross_entropy2(logits[-num_blocks:], gt)).mean()})\")\n",
    "    print_dbg(f\" loss_weights :  {loss_weights}\", verbose = True)\n",
    "    print_dbg(f\" cross_entropy:  {environ.cross_entropy2(logits[-num_blocks:], gt)}  \", verbose = True)\n",
    "    print_dbg(f\" loss[sparsity][{task_key}]: {self.losses['sparsity'][task_key] } \", verbose = True)\n",
    "\n",
    "else:\n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between \\n Logits   : \\n{logits[-num_blocks:]} \\n and gt: \\n{gt} \\n\", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-num_blocks:], gt)}\")\n",
    "    \n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt[-1:])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt0[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt0[-1:])} \\n\")\n",
    "    \n",
    "    print('\\n cond 3')    \n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt[0:1])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt0[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt0[0:1])} \\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686cd05",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ee1b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:30.155045Z",
     "start_time": "2022-01-26T00:14:30.107095Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# flag = 'update_w'\n",
    "# environ.fix_alpha\n",
    "# environ.free_w(opt['fix_BN'])\n",
    "\n",
    "flag = 'update_alpha'\n",
    "environ.fix_weights()\n",
    "environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7996b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:31.184285Z",
     "start_time": "2022-01-25T23:43:31.159229Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.networks['mtl-net'].num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f436ee6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:34.993711Z",
     "start_time": "2022-01-26T00:14:34.968623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") \n",
    "\n",
    "train_total_epochs += 5\n",
    "\n",
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334a0b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T17:15:02.216665Z",
     "start_time": "2022-01-25T17:15:01.848081Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - t0, None, environ.val_metrics , num_prints)      \n",
    "\n",
    "# num_prints += 1\n",
    "# t0 = time.time()\n",
    "\n",
    "# # Take check point\n",
    "# environ.save_checkpoint('latest', current_iter)\n",
    "# environ.train()\n",
    "# #-------------------------------------------------------\n",
    "# # END validation process\n",
    "# #-------------------------------------------------------       \n",
    "# flag = 'update_alpha'\n",
    "# environ.fix_w()\n",
    "# environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c4f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:08:57.366231Z",
     "start_time": "2022-01-08T01:08:57.295445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dilation = 2\n",
    "# kernel_size = np.asarray((3, 3))\n",
    "# upsampled_kernel_size = (kernel_size - 1) * (dilation - 1) + kernel_size\n",
    "# print(upsampled_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500c390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:39.763599Z",
     "start_time": "2022-01-25T23:43:39.728402Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.optimizers['weights'].param_groups[0]\n",
    "# for param_group in optimizer.param_groups:\n",
    "#     return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb71bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:41.628847Z",
     "start_time": "2022-01-25T23:43:41.602238Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.schedulers['weights'].get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7934862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:36:17.129535Z",
     "start_time": "2022-01-08T01:36:16.006144Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.optimizers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    current_state[k] = v.state_dict()\n",
    "pp.pprint(current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5faf7f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:40:22.032247Z",
     "start_time": "2022-01-08T01:40:22.006953Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.schedulers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    print(v.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd497e72",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Losses and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66169a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T16:34:44.555617Z",
     "start_time": "2022-02-09T16:34:44.507417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_losses = environ.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb8234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:35:11.758429Z",
     "start_time": "2022-02-10T03:35:11.278211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0301f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:21:49.107793Z",
     "start_time": "2022-02-10T03:21:49.084484Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498b6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:20:32.866010Z",
     "start_time": "2022-02-10T03:20:32.442919Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "pp.pprint(trn_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe30724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:34:21.945701Z",
     "start_time": "2022-02-10T03:34:21.411234Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d81167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:49.364883Z",
     "start_time": "2022-01-27T00:58:49.342931Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['Lambda_sharing'] = 0.5\n",
    "# opt['train']['Lambda_sharing'] = 0.5\n",
    "\n",
    "# environ.opt['train']['policy_lr'] = 0.001\n",
    "# opt['train']['policy_lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73aa06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T01:00:41.996410Z",
     "start_time": "2022-01-26T01:00:41.559006Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "environ.losses.keys()\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ece74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:19:43.683550Z",
     "start_time": "2022-01-08T01:19:43.571450Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = environ.get_loss_dict()\n",
    "print(tmp.keys())\n",
    "pp.pprint(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac0256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:50.458223Z",
     "start_time": "2022-01-27T00:58:50.430889Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(opt['diff_sparsity_weights'])\n",
    "print(opt['is_sharing'])\n",
    "print(opt['diff_sparsity_weights'] and not opt['is_sharing'])\n",
    "print(environ.opt['train']['Lambda_sharing'])\n",
    "print(opt['train']['Lambda_sharing'])\n",
    "print(environ.opt['train']['Lambda_sparsity'])\n",
    "print(opt['train']['Lambda_sparsity'])\n",
    "print(environ.opt['train']['policy_lr'])\n",
    "print(opt['train']['policy_lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2d510",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Policy / Logit stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb628497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:35:14.041577Z",
     "start_time": "2022-02-08T20:35:14.018303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.special          import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eed454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:30.103364Z",
     "start_time": "2022-02-08T20:00:30.068021Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03b5cc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_task_logits(n)` Get logits for task group n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed8b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:56:35.652087Z",
     "start_time": "2022-02-08T20:56:35.327406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task_logits = environ.get_task_logits(1)\n",
    "print(task_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66fa5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_arch_parameters()`: Get last used logits from network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85521e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:31.101960Z",
     "start_time": "2022-02-08T20:00:30.757064Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b0bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:06.054699Z",
     "start_time": "2022-02-09T15:43:05.689327Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea1743",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_logits()`:  Get Policy Logits - returns same as `get_arch_parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb40c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:24.972390Z",
     "start_time": "2022-02-09T15:43:24.636629Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs = environ.get_policy_logits()\n",
    "for i in logs:\n",
    "    print(i, '\\n')\n",
    "# probs = softmax(logs, axis= -1)\n",
    "# for i in probs:\n",
    "#     print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080a364",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_prob()` : Gets the softmax of the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c75af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:29.733732Z",
     "start_time": "2022-02-09T15:43:29.699600Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "for i in policy_softmaxs:\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3160d9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = False)` : Calls test_sample_policy of network with random choices based on softmax of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f411444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:21:15.636722Z",
     "start_time": "2022-02-08T22:21:15.165456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "policies,logits = environ.get_sample_policy(hard_sampling = False)\n",
    "\n",
    "for l, p, s in zip(logits, policies, policy_softmaxs) :\n",
    "    for  l_row, p_row, s_row in zip(l, p, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802664ec",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = True)` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea65bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:59:40.790899Z",
     "start_time": "2022-02-08T20:59:40.726657Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "hard_policies, logits = environ.get_sample_policy(hard_sampling = True)\n",
    "\n",
    "for p,l,s in zip(hard_policies, logits, policy_softmaxs) :\n",
    "    for  p_row, l_row, s_row in zip(p, l, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c39cf",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fe096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:00:47.452220Z",
     "start_time": "2022-02-08T21:00:47.422902Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\" Layer    task 1      task 2      task 3\")\n",
    "print(f\" -----    ------      ------      ------\")\n",
    "for idx, (l1, l2, l3) in enumerate(zip(hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1}       {l2}       {l3}\")\n",
    "    \n",
    "\n",
    "    print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade0ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:39:39.936555Z",
     "start_time": "2022-02-08T22:39:39.911591Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_trained_policy(iter):\n",
    "\n",
    "    policy_softmaxs = environ.get_policy_prob()\n",
    "    policy_argmaxs = 1-np.argmax(policy_softmaxs, axis = -1)\n",
    "    print(f\"  Trained polcies at iteration: {iter} \")\n",
    "    print(f\"                   task 1                           task 2                         task 3        \")\n",
    "    print(f\" Layer       softmax        select          softmax        select          softmax        select   \")\n",
    "    print(f\" -----    ---------------   ------       ---------------   ------       ---------------   ------   \")\n",
    "    for idx, (l1,l2,l3,  p1,p2,p3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2], policy_argmaxs[0], policy_argmaxs[1], policy_argmaxs[2]),1):\n",
    "        print(f\"   {idx}      {l1[0]:.4f}   {l1[1]:.4f}   {p1:4d}    {l2[0]:11.4f}   {l2[1]:.4f}   {p2:4d}    {l3[0]:11.4f}   {l3[1]:.4f}   {p3:4d}\")\n",
    "\n",
    "    print()\n",
    "# print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec208dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:42:12.650813Z",
     "start_time": "2022-02-08T22:42:12.330169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display_trained_policy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec517e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:07:30.836214Z",
     "start_time": "2022-02-08T22:07:30.804575Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"                        POLICIES (SOFTMAX)                                       task 3          \")\n",
    "print(f\" Layer    task1              task2            task3 softmax         softmax         argmax         softmax         argmax   \")\n",
    "print(f\" -----    -------------     -------------     -------------   ------   \")\n",
    "for idx, (l1,l2,l3, h1,h2,h3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2],hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1[0]:.4f} {l1[1]:.4f}     {l2[0]:.4f} {l2[1]:.4f}     {l3[0]:.4f} {l3[1]:.4f}    {h3}\")\n",
    "    \n",
    "print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbeacb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:04:50.757406Z",
     "start_time": "2022-02-08T22:04:50.731736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(policy_softmaxs[2], np.argmax(1-policy_softmaxs[2], axis = -1))\n",
    "print(policy_softmaxs, np.argmax(policy_softmaxs, axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be0240",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_logits()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb7240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:19:06.155425Z",
     "start_time": "2022-02-08T21:19:06.118640Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits  = (environ.get_current_logits())\n",
    "for i in logits:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e84662",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_policy()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cfa24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:40:06.543376Z",
     "start_time": "2022-02-08T20:40:06.230711Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pols  = (environ.get_current_policy())\n",
    "\n",
    "for i in pols:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f556a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T18:27:33.593255Z",
     "start_time": "2022-01-27T18:27:33.553141Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792710e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `gumbel_softmax()`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265490e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:28:17.107529Z",
     "start_time": "2022-02-08T21:28:17.084910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', floatmode = 'maxprec_equal')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb0087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:35:11.617269Z",
     "start_time": "2022-02-08T21:35:11.569599Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(environ.temp)\n",
    "# tau = environ.temp\n",
    "tau = 1\n",
    "for i in range(3): \n",
    "    logits_tensor = torch.tensor(logits[0])\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=tau, hard=False).cpu().numpy() \n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=tau, hard=True).cpu().numpy()\n",
    "    \n",
    "    for l, gs, gh in zip(lgts, gumbel_soft, gumbel_hard):\n",
    "        print(f\"   {l}   \\t {gs}            \\t {gh}\")\n",
    "#     print(lgts)\n",
    "#     print(gumbel_soft)\n",
    "#     print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5ef7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e0e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:21:35.524957Z",
     "start_time": "2022-02-08T21:21:35.488812Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for lgts in logits:\n",
    "    logits_tensor = torch.tensor(lgts)\n",
    "    print(lgts)\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=1, hard=False)\n",
    "    print(gumbel_soft)\n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=1, hard=True)\n",
    "    print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34a06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T20:49:37.643349Z",
     "start_time": "2022-02-03T20:49:37.580786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smax = scipy.special.softmax(logs, axis =1)\n",
    "# smax = np.array( \n",
    "# [[0.46973792, 0.530262  ],\n",
    "#  [0.45025694, 0.549743  ],\n",
    "#  [0.4443086 , 0.5556915 ],\n",
    "#  [0.4138397 , 0.58616036],\n",
    "#  [0.4140113 , 0.5859887 ],\n",
    "#  [0.42114905, 0.57885087]])\n",
    "\n",
    "print(smax.shape)\n",
    "print(smax)\n",
    "print(smax[0])\n",
    "print(smax[0].sum())\n",
    "print(np.random.choice((1,0), p =smax[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7de25c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:15:19.893888Z",
     "start_time": "2022-02-08T21:15:19.870899Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logs = np.array(\n",
    "[[0.33064184, 0.42053092],\n",
    " [0.3532089 , 0.52056104],\n",
    " [0.3888512 , 0.5680909 ],\n",
    " [0.42039296, 0.694217  ],\n",
    " [0.4519742 , 0.73311865],\n",
    " [0.48401102, 0.7522658 ]],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "399px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
