{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d574cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:31.006282Z",
     "start_time": "2022-01-14T20:16:29.058120Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:08.233990Z",
     "iopub.status.busy": "2022-01-07T22:44:08.233053Z",
     "iopub.status.idle": "2022-01-07T22:44:08.273284Z",
     "shell.execute_reply": "2022-01-07T22:44:08.271908Z",
     "shell.execute_reply.started": "2022-01-07T22:44:08.233943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import time\n",
    "import argparse\n",
    "import yaml\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "# import tqdm.notebook.trange as tnrange\n",
    "import copy, pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader \n",
    "import scipy.sparse\n",
    "from time import sleep\n",
    "from scipy.special import softmax\n",
    " \n",
    "from datetime import datetime\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    " # from tqdm import trange, tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from dev.sparsechem_utils_dev import load_sparse, load_task_weights, class_fold_counts, fold_and_transform_inputs\n",
    "from dev.sparsechem_utils_dev import print_metrics_cr\n",
    "from dev.chembl_dataloader_dev import ClassRegrSparseDataset_v3, ClassRegrSparseDataset, InfiniteDataLoader\n",
    "from utils.util import ( makedir, print_separator, create_path, print_yaml, print_yaml2, should, \n",
    "                         fix_random_seed, read_yaml_from_input, timestring, print_heading, print_dbg, \n",
    "                         print_underline, write_parms_report, get_command_line_args)\n",
    "from dev.sparsechem_env_dev import SparseChemEnv_Dev\n",
    "from dev.train_dev import evaluate\n",
    "\n",
    "# torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions( linewidth=132)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe56f6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:31.828552Z",
     "start_time": "2022-01-14T20:16:31.010329Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:10.627259Z",
     "iopub.status.busy": "2022-01-07T22:44:10.626952Z",
     "iopub.status.idle": "2022-01-07T22:44:11.043381Z",
     "shell.execute_reply": "2022-01-07T22:44:11.042421Z",
     "shell.execute_reply.started": "2022-01-07T22:44:10.627221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cuda is available  :  True\n",
      " CUDA device count  :  1\n",
      " CUDA current device:  0\n",
      " GPU Processes      :  GPU:0\n",
      "no processes are running\n",
      "\n",
      " Device : cuda:0\n",
      "   name:        NVIDIA GeForce GTX 970M\n",
      "   capability:  (5, 2)\n",
      "   properties:  _CudaDeviceProperties(name='NVIDIA GeForce GTX 970M', major=5, minor=2, total_memory=3071MB, multi_processor_count=10)\n",
      "   Allocated :  0\n",
      "   Reserved  :  0\n",
      "\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | nan% |  1% |\n"
     ]
    }
   ],
   "source": [
    "print(' Cuda is available  : ', torch.cuda.is_available())\n",
    "print(' CUDA device count  : ', torch.cuda.device_count())\n",
    "print(' CUDA current device: ', torch.cuda.current_device())\n",
    "print(' GPU Processes      : ', torch.cuda.list_gpu_processes())\n",
    "print()\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\" Device : cuda:{i}\")\n",
    "    print('   name:       ', torch.cuda.get_device_name())\n",
    "    print('   capability: ', torch.cuda.get_device_capability())\n",
    "    print('   properties: ', torch.cuda.get_device_properties(i))\n",
    "    ## current GPU memory usage by tensors in bytes for a given device\n",
    "    print('   Allocated : ', torch.cuda.memory_allocated(i) ) \n",
    "    ## current GPU memory managed by caching allocator in bytes for a given device, in previous PyTorch versions the command was torch.cuda.memory_cached\n",
    "    print('   Reserved  : ', torch.cuda.memory_reserved(i) )   \n",
    "    print()\n",
    "\n",
    "gpu_usage()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05032bf4",
   "metadata": {},
   "source": [
    "## Read yaml config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a7bb1dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:31.880131Z",
     "start_time": "2022-01-14T20:16:31.833001Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " command line parms :  {'config': 'yamls/adashare/chembl_2task.yml', 'exp_instance': None, 'exp_ids': [0], 'batch_size': 9999, 'backbone_lr': None, 'task_lr': None, 'decay_lr_rate': None, 'decay_lr_freq': None, 'gpus': [0], 'cpu': True}\n",
      "Namespace(config='yamls/adashare/chembl_2task.yml', exp_instance=None, exp_ids=[0], batch_size=9999, backbone_lr=None, task_lr=None, decay_lr_rate=None, decay_lr_freq=None, gpus=[0], cpu=True)\n",
      "\n",
      "0114_1216\n"
     ]
    }
   ],
   "source": [
    "input_args = \" --config yamls/adashare/chembl_2task.yml --cpu --batch_size 09999\".split()\n",
    "# get command line arguments\n",
    "args = get_command_line_args(input_args)\n",
    "print(args)\n",
    "\n",
    "print()\n",
    "\n",
    "if args.exp_instance is None:\n",
    "    args.exp_instance = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "    \n",
    "print(args.exp_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13447e2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:31.931129Z",
     "start_time": "2022-01-14T20:16:31.886003Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "####################READ YAML#####################\n",
      "##################################################\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " experiment name       : SparseChem \n",
      " experiment instance   : 0114_1216 \n",
      " folder_name           : 0114_1216_bs256_lr0.001_dr0.10_df2000 \n",
      " experiment description: Run small network without any policy (only warmup)  \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_separator('READ YAML')\n",
    "\n",
    "opt, gpu_ids, _ = read_yaml_from_input(args)\n",
    "\n",
    "fix_random_seed(opt[\"seed\"][0])\n",
    "\n",
    "opt['exp_description'] = f\"Run small network without any policy (only warmup)  \\n\"\n",
    "\n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\"\n",
    "\n",
    "print_heading(f\" experiment name       : {opt['exp_name']} \\n\"\n",
    "              f\" experiment instance   : {opt['exp_instance']} \\n\"\n",
    "              f\" folder_name           : {opt['paths']['exp_folder']} \\n\"\n",
    "              f\" experiment description: {opt['exp_description']}\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99a6a63d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:31.966733Z",
     "start_time": "2022-01-14T20:16:31.934769Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(opt['exp_instance'])\n",
    "# print(opt['paths']['exp_folder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d33640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:32.038194Z",
     "start_time": "2022-01-14T20:16:31.972070Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Create folder ../experiments/SparseChem/0114_1216_bs256_lr0.001_dr0.10_df2000\n",
      "            exp_name : SparseChem\n",
      "        exp_instance : 0114_1216\n",
      "     exp_description : Run small network without any policy (only warmup)  \n",
      "\n",
      "                seed : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      "            backbone : SparseChem\n",
      "       backbone_orig : ResNet18\n",
      "          orig_tasks : ['seg', 'sn']\n",
      "               tasks : ['class', 'class', 'class']\n",
      "     tasks_num_class : [5, 5, 5]\n",
      "             lambdas : [1, 1, 1]\n",
      "        policy_model : task-specific\n",
      "             verbose : False\n",
      "     input_size_freq : None\n",
      "          input_size : 32000\n",
      "        hidden_sizes : [25, 25, 25, 25, 25, 25]\n",
      "    tail_hidden_size : 25\n",
      " first_non_linearity : relu\n",
      "middle_non_linearity : relu\n",
      "      middle_dropout : 0.2\n",
      "  last_non_linearity : relu\n",
      "        last_dropout : 0.2\n",
      "   class_output_size : None\n",
      "    regr_output_size : None\n",
      "              policy : True\n",
      "     init_neg_logits : None\n",
      "           is_sparse : True\n",
      "diff_sparsity_weights : True\n",
      "          is_sharing : True\n",
      "          skip_layer : 0\n",
      "       is_curriculum : True\n",
      "    curriculum_speed : 20\n",
      "              fix_BN : False\n",
      "     retrain_from_pl : False\n",
      "\n",
      "paths\n",
      "-----\n",
      "      experiment_dir : ../experiments/SparseChem\n",
      "             log_dir : ../experiments/SparseChem\n",
      "          result_dir : ../experiments/SparseChem\n",
      "      checkpoint_dir : ../experiments/SparseChem\n",
      "          exp_folder : 0114_1216_bs256_lr0.001_dr0.10_df2000\n",
      "\n",
      "dataload\n",
      "--------\n",
      "             dataset : Chembl_23_mini\n",
      "            dataroot : /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic\n",
      "                   x : chembl_23mini_x.npy\n",
      "      x_split_ratios : [0.75, 0.001, 0.001, 0.248]\n",
      "             folding : chembl_23mini_folds.npy\n",
      "       weights_class : None\n",
      "         fold_inputs : 32000\n",
      "     input_transform : None\n",
      "             y_tasks : ['chembl_23mini_adashare_y1_bin_sparse.npy', 'chembl_23mini_adashare_y2_bin_sparse.npy', 'chembl_23mini_adashare_y3_bin_sparse.npy']\n",
      "            y_censor : None\n",
      "             fold_te : None\n",
      "              crop_h : 321\n",
      "              crop_w : 321\n",
      "   min_samples_class : 5\n",
      "             fold_va : 0\n",
      "\n",
      "train\n",
      "-----\n",
      "          batch_size : 256\n",
      "             task_lr : 0.001\n",
      "         backbone_lr : 0.001\n",
      "       decay_lr_rate : 0.1\n",
      "       decay_lr_freq : 2000\n",
      "         total_iters : 15000\n",
      "       warm_up_iters : 15000\n",
      "           policy_lr : 0.0001\n",
      "               reg_w : 0.05\n",
      "     Lambda_sparsity : 0.05\n",
      "       reg_w_hamming : 0.1\n",
      "      Lambda_sharing : 0.1\n",
      "          print_freq : -1\n",
      "            val_freq : 500\n",
      "           init_temp : 5\n",
      "          decay_temp : 0.965\n",
      "     decay_temp_freq : 100\n",
      "              resume : False\n",
      "      retrain_resume : False\n",
      "         policy_iter : best\n",
      "          which_iter : warmup\n",
      "         init_method : equal\n",
      "       hard_sampling : False\n",
      "\n",
      "SC\n",
      "--\n",
      "         batch_ratio : 0.02\n",
      "      normalize_loss : None\n",
      "\n",
      "test\n",
      "----\n",
      "          which_iter : best\n",
      "                 cpu : True\n"
     ]
    }
   ],
   "source": [
    "# for line in lines: \n",
    "create_path(opt)    \n",
    "\n",
    "# print yaml on the screen\n",
    "for line in print_yaml2(opt):\n",
    "    print(line)\n",
    "\n",
    "write_parms_report(opt)    \n",
    "\n",
    "log_dir        =  os.path.join(opt['paths']['log_dir'], opt['paths']['exp_folder'])\n",
    "checkpoint_dir =  os.path.join(opt['paths']['checkpoint_dir'], opt['paths']['exp_folder'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bfa8d",
   "metadata": {},
   "source": [
    "## Chembl Dataloader V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c17b578f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:32.825950Z",
     "start_time": "2022-01-14T20:16:32.040827Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset  = ClassRegrSparseDataset_v3(opt, split_ratios = opt['dataload']['x_split_ratios'], ratio_index = 0, verbose = False)\n",
    "trainset1 = ClassRegrSparseDataset_v3(opt, split_ratios = opt['dataload']['x_split_ratios'], ratio_index = 1)\n",
    "trainset2 = ClassRegrSparseDataset_v3(opt, split_ratios = opt['dataload']['x_split_ratios'], ratio_index = 2)\n",
    "valset    = ClassRegrSparseDataset_v3(opt, split_ratios = opt['dataload']['x_split_ratios'], ratio_index = 3)\n",
    "\n",
    "\n",
    "train_loader  = InfiniteDataLoader(trainset , batch_size=opt['train']['batch_size'], num_workers = 2, pin_memory=True, collate_fn=trainset.collate, shuffle=False)\n",
    "val_loader    = InfiniteDataLoader(valset   , batch_size=opt['train']['batch_size'], num_workers = 1, pin_memory=True, collate_fn=valset.collate  , shuffle=False)\n",
    "train1_loader = InfiniteDataLoader(trainset1, batch_size=opt['train']['batch_size'], num_workers = 2, pin_memory=True, collate_fn=trainset1.collate, shuffle=False)\n",
    "train2_loader = InfiniteDataLoader(trainset2, batch_size=opt['train']['batch_size'], num_workers = 2, pin_memory=True, collate_fn=trainset2.collate, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f4f21",
   "metadata": {},
   "source": [
    "## Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c09986",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:33.041929Z",
     "start_time": "2022-01-14T20:16:32.833680Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:18.146907Z",
     "iopub.status.busy": "2022-01-07T22:44:18.145721Z",
     "iopub.status.idle": "2022-01-07T22:44:18.191126Z",
     "shell.execute_reply": "2022-01-07T22:44:18.189994Z",
     "shell.execute_reply.started": "2022-01-07T22:44:18.146867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trainset.y_class                       :  [(13791, 5), (13791, 5), (13791, 5)]\n",
      " trainset1.y_class                      :  [(18, 5), (18, 5), (18, 5)]\n",
      " trainset2.y_class                      :  [(18, 5), (18, 5), (18, 5)]\n",
      " valset.y_class                         :  [(4561, 5), (4561, 5), (4561, 5)] \n",
      "\n",
      " size of training set 0 (warm up)       :  13791\n",
      " size of training set 1 (network parms) :  18\n",
      " size of training set 2 (policy weights):  18\n",
      " size of validation set                 :  4561\n",
      "                               Total    :  18388\n",
      "\n",
      " batch size                             :  256\n",
      "\n",
      " # batches training 0 (warm up)         :  54\n",
      " # batches training 1 (network parms)   :  1\n",
      " # batches training 2 (policy weights)  :  1\n",
      " # batches validation dataset           :  18\n",
      "\n",
      "\n",
      " batch size                             : 256 \n",
      " backbone                               : SparseChem \n",
      " paths.log_dir                          : ../experiments/SparseChem \n",
      " paths.checkpoint_dir                   : ../experiments/SparseChem \n",
      " experiment name                        : SparseChem \n",
      " tasks_num_class                        : ([5, 5, 5],) \n",
      " Hidden sizes                           : [25, 25, 25, 25, 25, 25] \n",
      " init_neg_logits                        : (None,) \n",
      " device id                              : 0 \n",
      " init temp                              : (5,) \n",
      " decay temp                             : 0.965 \n",
      " fix BN parms                           : False \n",
      " skip_layer                             : 0 \n",
      " train.init_method                      : equal \n",
      " Total iterations                       : 15000 \n",
      " Warm-up iterations                     : 15000 \n",
      " Print Frequency                        : -1 \n",
      " Validation Frequency                   : 500 \n",
      " \n",
      " Weight iter alternate                  : 1 \n",
      " Alpha  iter alternate                  : 1\n"
     ]
    }
   ],
   "source": [
    "opt['train']['weight_iter_alternate'] = opt['train'].get('weight_iter_alternate', len(train1_loader))\n",
    "opt['train']['alpha_iter_alternate']  = opt['train'].get('alpha_iter_alternate'  , len(train2_loader))\n",
    "\n",
    "\n",
    "print(f\" trainset.y_class                       :  {[ i.shape  for i in trainset.y_class_list]}\")\n",
    "print(f\" trainset1.y_class                      :  {[ i.shape  for i in trainset1.y_class_list]}\")\n",
    "print(f\" trainset2.y_class                      :  {[ i.shape  for i in trainset2.y_class_list]}\")\n",
    "print(f\" valset.y_class                         :  {[ i.shape  for i in valset.y_class_list  ]} \")\n",
    "print()\n",
    "\n",
    "print(f' size of training set 0 (warm up)       :  {len(trainset)}')\n",
    "print(f' size of training set 1 (network parms) :  {len(trainset1)}')\n",
    "print(f' size of training set 2 (policy weights):  {len(trainset2)}')\n",
    "print(f' size of validation set                 :  {len(valset)}')\n",
    "print(f'                               Total    :  {len(trainset)+len(trainset1)+len(trainset2)+len(valset)}')\n",
    "print()\n",
    "print(f\" batch size                             :  {opt['train']['batch_size']}\")\n",
    "print()\n",
    "print(f\" # batches training 0 (warm up)         :  {len(train_loader)}\")\n",
    "print(f\" # batches training 1 (network parms)   :  {len(train1_loader)}\")\n",
    "print(f\" # batches training 2 (policy weights)  :  {len(train2_loader)}\")\n",
    "print(f\" # batches validation dataset           :  {len(val_loader)}\")\n",
    "print()\n",
    "print(\n",
    "    f\"\\n batch size                             : {opt['train']['batch_size']}\", \n",
    "    f\"\\n backbone                               : {opt['backbone']}\",\n",
    "    f\"\\n paths.log_dir                          : {opt['paths']['log_dir']}\", \n",
    "    f\"\\n paths.checkpoint_dir                   : {opt['paths']['checkpoint_dir']}\", \n",
    "    f\"\\n experiment name                        : {opt['exp_name']}\",\n",
    "    f\"\\n tasks_num_class                        : {opt['tasks_num_class'],}\",\n",
    "    f\"\\n Hidden sizes                           : {opt['hidden_sizes']}\",     \n",
    "    f\"\\n init_neg_logits                        : {opt['init_neg_logits'],}\",\n",
    "    f\"\\n device id                              : {gpu_ids[0]}\",\n",
    "    f\"\\n init temp                              : {opt['train']['init_temp'],}\",\n",
    "    f\"\\n decay temp                             : {opt['train']['decay_temp']}\",\n",
    "    f\"\\n fix BN parms                           : {opt['fix_BN']}\",\n",
    "    f\"\\n skip_layer                             : {opt['skip_layer']}\",\n",
    "    f\"\\n train.init_method                      : {opt['train']['init_method']}\",\n",
    "    f\"\\n Total iterations                       : {opt['train']['total_iters']}\",\n",
    "    f\"\\n Warm-up iterations                     : {opt['train']['warm_up_iters']}\",\n",
    "    f\"\\n Print Frequency                        : {opt['train']['print_freq']}\",\n",
    "    f\"\\n Validation Frequency                   : {opt['train']['val_freq']} \\n\",\n",
    "    f\"\\n Weight iter alternate                  : {opt['train']['weight_iter_alternate'] }\",\n",
    "    f\"\\n Alpha  iter alternate                  : {opt['train']['alpha_iter_alternate'] }\")\n",
    "# print('\\n\\n Opt file \\n ------------ \\n')\n",
    "# pp.pprint(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf868bb",
   "metadata": {},
   "source": [
    "### Create model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3293d4b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:33.153952Z",
     "start_time": "2022-01-14T20:16:33.049775Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:21.499081Z",
     "iopub.status.busy": "2022-01-07T22:44:21.498215Z",
     "iopub.status.idle": "2022-01-07T22:44:21.604241Z",
     "shell.execute_reply": "2022-01-07T22:44:21.602711Z",
     "shell.execute_reply.started": "2022-01-07T22:44:21.499039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "* SparseChemEnv_Dev  Initializtion - verbose: False\n",
      "------------------------------------------------------- \n",
      "\n",
      "------------------------------------------------------------\n",
      "SparseChemEnv_Dev.super() init()  Start - verbose: False\n",
      "------------------------------------------------------------ \n",
      "\n",
      " log_dir        :  ../experiments/SparseChem/0114_1216_bs256_lr0.001_dr0.10_df2000 \n",
      " checkpoint_dir :  ../experiments/SparseChem/0114_1216_bs256_lr0.001_dr0.10_df2000 \n",
      " exp_name       :  SparseChem \n",
      " tasks_num_class:  [5, 5, 5] \n",
      " device         :  cuda:0 \n",
      " device id      :  0 \n",
      " dataset        :  Chembl_23_mini \n",
      " tasks          :  ['class', 'class', 'class'] \n",
      "\n",
      "--------------------------------------------------\n",
      "SparseChemEnv_Dev.super() init()  end\n",
      "-------------------------------------------------- \n",
      "\n",
      " is_train       :  True \n",
      " init_neg_logits:  None \n",
      " init temp      :  5 \n",
      " decay temp     :  0.965 \n",
      " input_size     :  32000 \n",
      " normalize loss :  None \n",
      " num_tasks      :  3 \n",
      " policys        :  [None, None, None]\n",
      "--------------------------------------------------------\n",
      "* SparseChemEnv_Dev environment successfully created\n",
      "-------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "environ = SparseChemEnv_Dev(log_dir = log_dir, \n",
    "                            checkpoint_dir = checkpoint_dir, \n",
    "                            exp_name = opt['exp_name'],\n",
    "                            tasks_num_class = opt['tasks_num_class'], \n",
    "                            init_neg_logits = opt['init_neg_logits'], \n",
    "                            device = gpu_ids[0],\n",
    "                            init_temperature = opt['train']['init_temp'], \n",
    "                            temperature_decay= opt['train']['decay_temp'], \n",
    "                            is_train=True,\n",
    "                            opt=opt, \n",
    "                            verbose = False)\n",
    "\n",
    "cfg = environ.print_configuration()\n",
    "write_parms_report(opt, cfg, mode = 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07462f4d",
   "metadata": {},
   "source": [
    "## Warmup Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d738062",
   "metadata": {},
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7498ab15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:33.229972Z",
     "start_time": "2022-01-14T20:16:33.159738Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:25.814333Z",
     "iopub.status.busy": "2022-01-07T22:44:25.813544Z",
     "iopub.status.idle": "2022-01-07T22:44:25.847331Z",
     "shell.execute_reply": "2022-01-07T22:44:25.845489Z",
     "shell.execute_reply.started": "2022-01-07T22:44:25.814290Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tasks_num_class         : ([5, 5, 5],) \n",
      " init_neg_logits         : (None,) \n",
      " device id               : 0 \n",
      " init temp               : (5,) \n",
      " decay temp              : 0.965 \n",
      " fix BN parms            : False \n",
      " skip_layer              : 0 \n",
      "\n",
      " train.init_method       : equal \n",
      " Total iterations        : 15000 \n",
      " Warm-up iterations      : 15000 \n",
      " Print Frequency         : -1 \n",
      " Validation Frequency    : 500 \n",
      " Weight iter alternate   : 1 \n",
      " Alpha  iter alternate   : 1 \n",
      " Network[mtl_net].layers : [1, 1, 1, 1] \n",
      " Num_blocks              : 4\n"
     ]
    }
   ],
   "source": [
    "print( \n",
    "    f\"\\n tasks_num_class         : {opt['tasks_num_class'],}\",\n",
    "    f\"\\n init_neg_logits         : {opt['init_neg_logits'],}\",\n",
    "    f\"\\n device id               : {gpu_ids[0]}\",\n",
    "    f\"\\n init temp               : {opt['train']['init_temp'],}\",\n",
    "    f\"\\n decay temp              : {opt['train']['decay_temp']}\",\n",
    "    f\"\\n fix BN parms            : {opt['fix_BN']}\",\n",
    "    f\"\\n skip_layer              : {opt['skip_layer']}\",\n",
    "    f\"\\n\"\n",
    "    f\"\\n train.init_method       : {opt['train']['init_method']}\",\n",
    "    f\"\\n Total iterations        : {opt['train']['total_iters']}\",\n",
    "    f\"\\n Warm-up iterations      : {opt['train']['warm_up_iters']}\",\n",
    "    f\"\\n Print Frequency         : {opt['train']['print_freq']}\",\n",
    "    f\"\\n Validation Frequency    : {opt['train']['val_freq']}\",\n",
    "    f\"\\n Weight iter alternate   : {opt['train']['weight_iter_alternate'] }\",\n",
    "    f\"\\n Alpha  iter alternate   : {opt['train']['alpha_iter_alternate'] }\",\n",
    "    f\"\\n Network[mtl_net].layers : {environ.networks['mtl-net'].layers}\",\n",
    "    f\"\\n Num_blocks              : {sum(environ.networks['mtl-net'].layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "251f3adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:36.136679Z",
     "start_time": "2022-01-14T20:16:33.236954Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:27.458746Z",
     "iopub.status.busy": "2022-01-07T22:44:27.457640Z",
     "iopub.status.idle": "2022-01-07T22:44:27.491358Z",
     "shell.execute_reply": "2022-01-07T22:44:27.490019Z",
     "shell.execute_reply.started": "2022-01-07T22:44:27.458686Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate Training \n",
      "cuda available [0]\n",
      "\n",
      "\n",
      " set print_freq to length of train loader: 54\n"
     ]
    }
   ],
   "source": [
    "environ.define_optimizer(policy_learning=False)\n",
    "environ.define_scheduler(policy_learning=False)\n",
    "# Fix Alpha - \n",
    "environ.fix_alpha()\n",
    "environ.free_w(opt['fix_BN'])\n",
    "\n",
    "if opt['train']['resume']:\n",
    "    print('Resume training')\n",
    "    current_iter = environ.load(opt['train']['which_iter'])\n",
    "    environ.networks['mtl-net'].reset_logits()\n",
    "else:\n",
    "    print('Initiate Training ')\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda available', gpu_ids)   \n",
    "    environ.cuda(gpu_ids)\n",
    "else:\n",
    "    print('cuda not available')\n",
    "    environ.cpu()\n",
    "print('\\n')\n",
    "\n",
    "current_iter   = 0\n",
    "current_iter_w = 0 \n",
    "current_iter_a = 0\n",
    "flag         = 'update_w'\n",
    "best_value   = 0 \n",
    "best_iter    = 0\n",
    "p_epoch      = 0\n",
    "best_metrics = None\n",
    "flag_warmup  = True\n",
    "eval_iter    = -1\n",
    "num_prints   = 0\n",
    "\n",
    "num_blocks = sum(environ.networks['mtl-net'].layers)\n",
    "\n",
    "if opt['train']['print_freq'] == -1:\n",
    "    print(f\" set print_freq to length of train loader: {len(train_loader)}\")\n",
    "    opt['train']['print_freq']    = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d6aac59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:36.300876Z",
     "start_time": "2022-01-14T20:16:36.146375Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:31.240717Z",
     "iopub.status.busy": "2022-01-07T22:44:31.240386Z",
     "iopub.status.idle": "2022-01-07T22:44:31.264367Z",
     "shell.execute_reply": "2022-01-07T22:44:31.262797Z",
     "shell.execute_reply.started": "2022-01-07T22:44:31.240692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which_iter          : warmup\n",
      "train_resume        : False\n",
      "\n",
      "Length train_loader : 54\n",
      "Length val_loader   : 18\n",
      "\n",
      "total_iters         : 15000\n",
      "warm_up_iters       : 15000\n",
      "\n",
      "val_freq            : 500\n",
      "print_freq          : 54\n",
      "\n",
      "batch_size          : 256\n",
      "Backbone LR         : 0.001\n",
      "LR decay rate       : 0.1\n",
      "LR decay frequency  : 2000\n",
      "\n",
      " output folder      : 0114_1216_bs256_lr0.001_dr0.10_df2000\n"
     ]
    }
   ],
   "source": [
    "# opt['train']['warm_up_iters'] = 15000\n",
    "# opt['train']['print_freq'] =1\n",
    "# opt['train']['weight_iter_alternate'] = 10R1\n",
    "# opt['train']['alpha_iter_alternate']  = 10\n",
    "# opt['train']['warm_up_iters'] = 200\n",
    "# opt['train']['val_freq']   = 50\n",
    "# opt['train']['val_freq']      = 500\n",
    "\n",
    "print(f\"which_iter          : {opt['train']['which_iter']}\")\n",
    "print(f\"train_resume        : {opt['train']['resume']}\")\n",
    "print()\n",
    "print(f\"Length train_loader : {len(train_loader)}\")\n",
    "print(f\"Length val_loader   : {len(val_loader)}\")\n",
    "print()\n",
    "print(f\"total_iters         : {opt['train']['total_iters']}\")  \n",
    "print(f\"warm_up_iters       : {opt['train']['warm_up_iters']}\")   \n",
    "print()\n",
    "print(f\"val_freq            : {opt['train']['val_freq']     }\")      \n",
    "print(f\"print_freq          : {opt['train']['print_freq']  }\")\n",
    "print()\n",
    "print(f\"batch_size          : {opt['train']['batch_size']   }\")         \n",
    "print(f\"Backbone LR         : {opt['train']['backbone_lr']   }\")        \n",
    "print(f\"LR decay rate       : {opt['train']['decay_lr_rate']   }\")        \n",
    "print(f\"LR decay frequency  : {opt['train']['decay_lr_freq']   }\")        \n",
    "print()\n",
    "print(f\" output folder      : {opt['paths']['exp_folder']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e42d110",
   "metadata": {},
   "source": [
    "### Warm-up Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f349c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:39.995041Z",
     "start_time": "2022-01-14T20:16:39.971264Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:32.955710Z",
     "iopub.status.busy": "2022-01-07T22:44:32.954619Z",
     "iopub.status.idle": "2022-01-07T22:44:32.980934Z",
     "shell.execute_reply": "2022-01-07T22:44:32.979443Z",
     "shell.execute_reply.started": "2022-01-07T22:44:32.955675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(current_iter)\n",
    "#     stop_iter  = current_iter + 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d6cc691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:16:40.877210Z",
     "start_time": "2022-01-14T20:16:40.853146Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:35.007879Z",
     "iopub.status.busy": "2022-01-07T22:44:35.007527Z",
     "iopub.status.idle": "2022-01-07T22:44:35.034650Z",
     "shell.execute_reply": "2022-01-07T22:44:35.033033Z",
     "shell.execute_reply.started": "2022-01-07T22:44:35.007855Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Last iteration: 0  # of warm-up iterations to do:15000 - Run  from 1 to 15000\n"
     ]
    }
   ],
   "source": [
    "stop_iter  = current_iter + opt['train']['warm_up_iters']\n",
    "print(f\" Last iteration: {current_iter}  # of warm-up iterations to do:{opt['train']['warm_up_iters']} - Run  from {current_iter+1} to {stop_iter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0bfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8663432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T20:52:24.542675Z",
     "start_time": "2022-01-14T20:16:44.796346Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:38.657578Z",
     "iopub.status.busy": "2022-01-07T22:44:38.657285Z",
     "iopub.status.idle": "2022-01-07T22:45:02.893150Z",
     "shell.execute_reply": "2022-01-07T22:45:02.891381Z",
     "shell.execute_reply.started": "2022-01-07T22:44:38.657539Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Last iteration: 0  # of warm-up iterations to do:15000 - Run  from 1 to 15000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47728c68c7c4e41a7c3be01e01c6314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | logloss bceloss  aucroc   aucpr  f1_max| t1 loss t2 loss t3 lossttl loss|tr_time|\n",
      "500   | logloss 0.62028 0.72502 0.72719 0.71290|  3.1552  3.0094  3.1384  9.3030|  68.9|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  | logloss 0.60467 0.76837 0.77106 0.73363|  2.9895  3.0357  3.0425  9.0678|  73.4|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500  | logloss 0.65194 0.77397 0.77336 0.73743|  3.3595  3.1873  3.2306  9.7774|  72.9|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000  | logloss 0.71621 0.77561 0.77557 0.73870|  3.6767  3.5094  3.5542 10.7404|  76.1|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500  | logloss 0.72524 0.77685 0.77610 0.73913|  3.7479  3.5351  3.5926 10.8756|  71.0|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000  | logloss 0.73856 0.77652 0.77540 0.73873|  3.8349  3.5892  3.6505 11.0747|  70.9|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500  | logloss 0.74805 0.77663 0.77563 0.73830|  3.8942  3.6311  3.6912 11.2165|  70.4|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000  | logloss 0.76054 0.77649 0.77552 0.73840|  3.9746  3.6816  3.7472 11.4034|  69.9|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500  | logloss 0.76115 0.77656 0.77558 0.73842|  3.9783  3.6833  3.7509 11.4124|  70.0|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000  | logloss 0.76290 0.77651 0.77549 0.73839|  3.9891  3.6900  3.7596 11.4387|  69.7|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500  | logloss 0.76415 0.77655 0.77557 0.73841|  3.9954  3.6960  3.7661 11.4575|  73.3|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000  | logloss 0.76595 0.77656 0.77561 0.73827|  4.0040  3.7057  3.7746 11.4844|  74.0|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500  | logloss 0.76602 0.77656 0.77561 0.73831|  4.0043  3.7057  3.7755 11.4854|  72.8|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000  | logloss 0.76609 0.77655 0.77559 0.73830|  4.0039  3.7059  3.7766 11.4864|  72.4|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500  | logloss 0.76623 0.77655 0.77559 0.73831|  4.0045  3.7068  3.7772 11.4886|  75.8|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000  | logloss 0.76636 0.77656 0.77560 0.73836|  4.0055  3.7071  3.7780 11.4906|  78.6|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500  | logloss 0.76639 0.77656 0.77559 0.73834|  4.0057  3.7071  3.7781 11.4910|  69.0|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000  | logloss 0.76643 0.77656 0.77559 0.73834|  4.0061  3.7072  3.7783 11.4915|  69.5|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9500  | logloss 0.76646 0.77656 0.77559 0.73835|  4.0063  3.7073  3.7784 11.4920|  69.5|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 | logloss 0.76649 0.77656 0.77560 0.73835|  4.0065  3.7074  3.7785 11.4924|  70.6|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | logloss bceloss  aucroc   aucpr  f1_max| t1 loss t2 loss t3 lossttl loss|tr_time|\n",
      "10500 | logloss 0.76649 0.77656 0.77560 0.73835|  4.0065  3.7074  3.7785 11.4924|  69.8|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000 | logloss 0.76649 0.77656 0.77560 0.73835|  4.0065  3.7074  3.7785 11.4924|  70.5|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11500 | logloss 0.76649 0.77656 0.77560 0.73835|  4.0065  3.7074  3.7785 11.4924|  70.1|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000 | logloss 0.76649 0.77656 0.77560 0.73835|  4.0065  3.7074  3.7785 11.4924|  71.1|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500 | logloss 0.76649 0.77656 0.77560 0.73835|  4.0065  3.7074  3.7785 11.4924|  69.9|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000 | logloss 0.76649 0.77656 0.77560 0.73835|  4.0065  3.7074  3.7785 11.4924|  69.6|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13500 | logloss 0.76649 0.77656 0.77560 0.73835|  4.0065  3.7074  3.7785 11.4924|  69.5|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000 | logloss 0.76649 0.77656 0.77560 0.73835|  4.0065  3.7074  3.7785 11.4924|  70.7|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14500 | logloss 0.76649 0.77656 0.77560 0.73835|  4.0065  3.7074  3.7785 11.4924|  69.1|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000 | logloss 0.76649 0.77656 0.77560 0.73835|  4.0065  3.7074  3.7785 11.4924|  70.9|\n"
     ]
    }
   ],
   "source": [
    "##---------------------------------------------------------------     \n",
    "## part one: warm up\n",
    "##---------------------------------------------------------------\n",
    "num_prints = 0\n",
    "print(f\" Last iteration: {current_iter}  # of warm-up iterations to do:{opt['train']['warm_up_iters']} - Run  from {current_iter+1} to {stop_iter}\")\n",
    "t0 = time.time()\n",
    "\n",
    "with trange(current_iter+1, stop_iter+1 , initial = current_iter, total = stop_iter, position=0, leave= True, desc=\"training\") as t_warmup :\n",
    "    \n",
    "    for current_iter in t_warmup:\n",
    "        start_time = time.time()\n",
    "        environ.train()\n",
    "        batch = next(train_loader)    \n",
    "    \n",
    "#         print_heading(f\" {timestring()} - WARMUP Training iter {current_iter}/{opt['train']['warm_up_iters']} \", verbose = False)\n",
    "\n",
    "        environ.set_inputs(batch, train_loader.dataset.input_size)\n",
    "\n",
    "        environ.optimize(opt['lambdas'], \n",
    "                         is_policy=False, \n",
    "                         flag='update_w', \n",
    "                         verbose = False)\n",
    "        \n",
    "        t_warmup.set_postfix({'curr_iter':current_iter, \n",
    "                              'Loss': f\"{environ.losses['total']['total'].item():.4f}\" , \n",
    "                              'row_ids':f\"{batch['row_id'][0]}-{batch['row_id'][-1]}\"})\n",
    "\n",
    "        if should(current_iter, opt['train']['print_freq']):\n",
    "            environ.print_loss(current_iter, start_time, verbose = False)\n",
    "\n",
    "#         print(f\"**  {timestring()}  iteration: {current_iter}  Complete - Loss: {environ.losses['total']['total']:.4f}\" )\n",
    "\n",
    "        ##--------------------------------------------------------------- \n",
    "        # validation\n",
    "        ##--------------------------------------------------------------- \n",
    "        if should(current_iter, opt['train']['val_freq']):\n",
    "            print_dbg(f\"**  {timestring()}  START VALIDATION iteration: {current_iter}    Validation freq {opt['train']['val_freq']}\") \n",
    "\n",
    "            num_seg_class = opt['tasks_num_class'][opt['tasks'].index('seg')] if 'seg' in opt['tasks'] else -1\n",
    "            val_metrics = evaluate(environ, \n",
    "                                   val_loader, \n",
    "                                   opt['tasks'], \n",
    "                                   is_policy=False, \n",
    "                                   num_train_layers=None,\n",
    "                                   eval_iter = eval_iter, \n",
    "                                   progress=True,\n",
    "                                   leave = False,\n",
    "                                   verbose = False)\n",
    "\n",
    "            environ.print_metrics(current_iter, start_time, val_metrics, title='validation')\n",
    "            environ.save_checkpoint('warmup', current_iter)\n",
    "            \n",
    "            print_metrics_cr(current_iter, time.time() - t0, None, val_metrics, num_prints)\n",
    "            num_prints += 1            \n",
    "            t0 = time.time()\n",
    "            print()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6605cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4359e814",
   "metadata": {},
   "source": [
    "### Post Warm-up Training stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd3c7b30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T21:32:58.099353Z",
     "start_time": "2022-01-13T21:32:57.692543Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses.keys :  dict_keys(['parms', 'task1', 'task2', 'task3'])\n",
      "losses[task]keys :  dict_keys(['cls_loss', 'cls_loss_mean'])\n",
      "{   'parms': {   'gumbel_temp': 5,\n",
      "                 'lr_0': 1.0000000000000002e-06,\n",
      "                 'lr_1': 1.0000000000000002e-06},\n",
      "    'task1': {   'cls_loss': tensor(4.5776, device='cuda:0', dtype=torch.float64),\n",
      "                 'cls_loss_mean': tensor(0.9155, device='cuda:0', dtype=torch.float64)},\n",
      "    'task2': {   'cls_loss': tensor(3.7255, device='cuda:0', dtype=torch.float64),\n",
      "                 'cls_loss_mean': tensor(0.7451, device='cuda:0', dtype=torch.float64)},\n",
      "    'task3': {   'cls_loss': tensor(5.4301, device='cuda:0', dtype=torch.float64),\n",
      "                 'cls_loss_mean': tensor(1.0860, device='cuda:0', dtype=torch.float64)}}\n"
     ]
    }
   ],
   "source": [
    "print('losses.keys      : ', environ.losses.keys())\n",
    "print('losses[task]keys : ', environ.losses['task1'].keys())\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d4b8e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T03:21:09.086777Z",
     "start_time": "2022-01-14T03:21:08.995721Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'loss_mean', 'task1', 'task2', 'task3', 'loss_aggregated', 'train_time', 'epoch'])\n",
      "{   'epoch': 20,\n",
      "    'loss': {   'task1': 3.4728868553618577,\n",
      "                'task2': 3.4479531633693505,\n",
      "                'task3': 3.470910336423501,\n",
      "                'total': 10.39175035515471},\n",
      "    'loss_aggregated': roc_auc_score     0.564752\n",
      "auc_pr            0.569393\n",
      "avg_prec_score    0.569769\n",
      "f1_max            0.675643\n",
      "p_f1_max          0.416170\n",
      "kappa             0.053352\n",
      "kappa_max         0.110656\n",
      "p_kappa_max       0.506664\n",
      "bceloss           0.692846\n",
      "dtype: float64,\n",
      "    'loss_mean': {   'task1': 0.6945773710723714,\n",
      "                     'task2': 0.6895906326738702,\n",
      "                     'task3': 0.6941820672847003,\n",
      "                     'total': 2.0783500710309424},\n",
      "    'task1': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.624813  0.580625        0.580911  0.622941  0.488947  0.039262   \n",
      "1          0.510657  0.440550        0.440997  0.593886  0.516762  0.004158   \n",
      "2          0.532284  0.546964        0.547342  0.673071  0.420608  0.025385   \n",
      "3          0.617051  0.586130        0.586447  0.655808  0.448596  0.130755   \n",
      "4          0.585042  0.586591        0.586885  0.683104  0.360267  0.133074   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.214520     0.534235  0.689787  \n",
      "1      0.042201     0.584124  0.723610  \n",
      "2      0.067228     0.531821  0.690733  \n",
      "3      0.176131     0.488338  0.685254  \n",
      "4      0.139186     0.509885  0.683920  ,\n",
      "                 'classification_agg': {   'auc_pr': 0.5481720895820631,\n",
      "                                           'avg_prec_score': 0.5485164716697374,\n",
      "                                           'bceloss': 0.6946609258651734,\n",
      "                                           'f1_max': 0.6457620890929407,\n",
      "                                           'kappa': 0.06652684361008195,\n",
      "                                           'kappa_max': 0.1278530420795324,\n",
      "                                           'logloss': 0.0054823033016017046,\n",
      "                                           'p_f1_max': 0.44703611135482796,\n",
      "                                           'p_kappa_max': 0.5296807587146759,\n",
      "                                           'roc_auc_score': 0.5739694830625268,\n",
      "                                           'sc_loss': 3.4728868553618577}},\n",
      "    'task2': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.514823  0.545747        0.546040  0.694630  0.445809  0.000523   \n",
      "1          0.542576  0.566114        0.566622  0.691567  0.393436  0.066365   \n",
      "2          0.564743  0.554560        0.554904  0.659211  0.304477  0.073088   \n",
      "3          0.534256  0.549973        0.550499  0.687166  0.406282  0.043412   \n",
      "4          0.577333  0.604984        0.605165  0.670884  0.415392  0.121700   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.049624     0.468551  0.692878  \n",
      "1      0.069269     0.500187  0.688589  \n",
      "2      0.091075     0.447509  0.687218  \n",
      "3      0.059735     0.488154  0.693143  \n",
      "4      0.129209     0.513912  0.686653  ,\n",
      "                 'classification_agg': {   'auc_pr': 0.5642756241763394,\n",
      "                                           'avg_prec_score': 0.5646461202556846,\n",
      "                                           'bceloss': 0.6896960973739624,\n",
      "                                           'f1_max': 0.6806917755476137,\n",
      "                                           'kappa': 0.06101755920380761,\n",
      "                                           'kappa_max': 0.07978244951156063,\n",
      "                                           'logloss': 0.005442942945902067,\n",
      "                                           'p_f1_max': 0.3930791020393372,\n",
      "                                           'p_kappa_max': 0.48366234898567206,\n",
      "                                           'roc_auc_score': 0.5467463549679178,\n",
      "                                           'sc_loss': 3.4479531633693505}},\n",
      "    'task3': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.596356  0.649471        0.649891  0.745286  0.379486  0.009947   \n",
      "1          0.538755  0.559864        0.560369  0.696485  0.405639  0.018723   \n",
      "2          0.622304  0.612494        0.612753  0.658909  0.491313  0.082079   \n",
      "3          0.530017  0.567680        0.568072  0.716700  0.365744  0.001515   \n",
      "4          0.580263  0.589153        0.589638  0.684995  0.399795  0.050292   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.164024     0.423688  0.711948  \n",
      "1      0.069880     0.540532  0.688883  \n",
      "2      0.187426     0.556059  0.685274  \n",
      "3      0.089237     0.461759  0.698096  \n",
      "4      0.111100     0.551209  0.686704  ,\n",
      "                 'classification_agg': {   'auc_pr': 0.5957322222904313,\n",
      "                                           'avg_prec_score': 0.5961447510924626,\n",
      "                                           'bceloss': 0.694180965423584,\n",
      "                                           'f1_max': 0.7004747111902365,\n",
      "                                           'kappa': 0.03251122025572644,\n",
      "                                           'kappa_max': 0.12433348907409156,\n",
      "                                           'logloss': 0.0054791831664655136,\n",
      "                                           'p_f1_max': 0.40839544534683236,\n",
      "                                           'p_kappa_max': 0.506649398803711,\n",
      "                                           'roc_auc_score': 0.5735389540991538,\n",
      "                                           'sc_loss': 3.470910336423501}},\n",
      "    'train_time': 5.165820360183716}\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print( val_metrics.keys())\n",
    "# pp.pprint(val_metrics)\n",
    "print(type(val_metrics['aggregated']))\n",
    "print()\n",
    "print(type(val_metrics['task1']['classification_agg']))\n",
    "print()\n",
    "pp.pprint(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce42477c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.266303Z",
     "start_time": "2022-01-14T18:57:26.166878Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"val_metrics.pkl\", mode= 'wb') as f:\n",
    "#         pickle.dump(val_metrics, f)\n",
    "    \n",
    "# with open('val_metrics.pkl', 'rb') as f:    \n",
    "#     tst_val_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "797b6487",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.297444Z",
     "start_time": "2022-01-14T18:57:26.269323Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(environ.input.shape) \n",
    "# a = getattr(environ, 'task1_pred')\n",
    "# yc_data = environ.batch['task1_data']\n",
    "# print(yc_data.shape)\n",
    "# yc_ind = environ.batch['task1_ind']\n",
    "# print(yc_ind.shape)\n",
    "# yc_hat_all = getattr(environ, 'task1_pred')\n",
    "# print(yc_hat_all.shape)\n",
    "# yc_hat  = yc_hat_all[yc_ind[0], yc_ind[1]]\n",
    "# print(yc_hat_all.shape, yc_hat.shape)\n",
    "\n",
    "# \n",
    "# environ.losses\n",
    "# loss = {}\n",
    "# for key in environ.losses.keys():\n",
    "#     loss[key] = {}\n",
    "#     for subkey, v in environ.losses[key].items():\n",
    "#         print(f\" key:  {key}   subkey: {subkey} \")\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             loss[key][subkey] = v.data\n",
    "#             print(f\" Tensor  -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "#         else:\n",
    "#             loss[key][subkey] = v\n",
    "#             print(f\" integer -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "# pp.pprint(tst_val_metrics)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2d6ab42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.340792Z",
     "start_time": "2022-01-14T18:57:26.302528Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    }
   },
   "outputs": [],
   "source": [
    "# print('metrics.keys: ', environ.metrics.keys())\n",
    "# print('metrics[task].keys: ', environ.metrics['task1'].keys())\n",
    "# pp.pprint(environ.metrics['task1'])\n",
    "# pp.pprint(environ.losses['task1']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ddcaed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.373399Z",
     "start_time": "2022-01-14T18:57:26.345065Z"
    }
   },
   "outputs": [],
   "source": [
    "# title='Iteration'\n",
    "# for t_id, _ in enumerate(environ.tasks):\n",
    "#     task_key = f\"task{t_id+1}\"\n",
    "# #     print_heading(f\"{title}  {current_iter}  {task_key} : {val_metrics[task_key]['classification_agg']}\", verbose = True)\n",
    "\n",
    "#     for key, _  in val_metrics[task_key]['classification_agg'].items():\n",
    "#         print('%s/%-20s'%(task_key, key), val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print(f\"{task_key:s}/{key:20s}\", val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print()\n",
    "#             # print_current_errors(os.path.join(self.log_dir, 'loss.txt'), current_iter,key, loss[key], time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a669b0aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:48.162261Z",
     "start_time": "2022-01-07T22:52:48.140423Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.print_loss(current_iter, start_time, metrics = val_metrics['loss'], verbose=True)\n",
    "# print(opt['lambdas'])\n",
    "# p = (opt['lambdas'][0] * environ.losses['tasks']['task1'])\n",
    "# print(p)\n",
    "\n",
    "# environ.print_metrics(current_iter, start_time, val_metrics , title='validation', verbose=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e3de0c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:47.661019Z",
     "start_time": "2022-01-07T22:52:47.639094Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(current_iter)\n",
    "# print_metrics_cr(current_iter, t1 - t0, None, val_metrics , True)\n",
    "# environ.print_metrics(current_iter, start_time, val_metrics, title='validation', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2da239bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:14:58.034384Z",
     "start_time": "2022-01-07T23:14:58.004850Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_metric keys              :  dict_keys(['loss', 'task1', 'task2', 'task3', 'train_time', 'epoch'])\n",
      "loss keys                    :  dict_keys(['total', 'task1', 'task2', 'task3'])\n",
      "task1 keys                   :  dict_keys(['classification', 'classification_agg'])\n",
      "task1 classification keys    :  Index(['roc_auc_score', 'auc_pr', 'avg_prec_score', 'f1_max', 'p_f1_max',\n",
      "       'kappa', 'kappa_max', 'p_kappa_max', 'bceloss'],\n",
      "      dtype='object') \n",
      "\n",
      "task1 classification_agg keys:  dict_keys(['roc_auc_score', 'auc_pr', 'avg_prec_score', 'f1_max', 'p_f1_max', 'kappa', 'kappa_max', 'p_kappa_max', 'bceloss', 'loss', 'logloss', 'num_tasks_total', 'weights']) \n",
      "\n",
      "\n",
      " task1     : 3.452184\n",
      " task2     : 3.415023\n",
      " task3     : 3.465614\n",
      " loss      : 10.332821\n",
      " train_time: 2.327263\n",
      " epoch     : 400\n"
     ]
    }
   ],
   "source": [
    "print(f\" val_metric keys               : {val_metrics.keys()}\")\n",
    "print(f\" loss keys                     : {val_metrics['loss'].keys()}\")\n",
    "print(f\" task1 keys                    : {val_metrics['task1'].keys()}\")\n",
    "print(f\" task1 classification keys     : {val_metrics['task1']['classification'].keys()}\")\n",
    "print(f\" task1 classification_agg keys : {val_metrics['task1']['classification_agg'].keys()}\")\n",
    "print()\n",
    "print(f\" task1                       : {val_metrics['task1']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task2                       : {val_metrics['task2']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task3                       : {val_metrics['task3']['classification_agg']['loss']:5f}\")\n",
    "print(f\" loss                        : {val_metrics['loss']['total']:5f}\")\n",
    "print(f\" train_time                  : {val_metrics['train_time']:2f}\")\n",
    "print(f\" epoch                       : {val_metrics['epoch']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49645c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Weight & Policy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "443db2fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:15:00.118689Z",
     "start_time": "2022-01-07T23:15:00.095543Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(environ.optimizers)\n",
    "# pp.pprint(environ.schedulers['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5013601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:15:00.402996Z",
     "start_time": "2022-01-07T23:15:00.330518Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:13.390485Z",
     "iopub.status.busy": "2022-01-07T22:49:13.389634Z",
     "iopub.status.idle": "2022-01-07T22:49:13.441270Z",
     "shell.execute_reply": "2022-01-07T22:49:13.439724Z",
     "shell.execute_reply.started": "2022-01-07T22:49:13.390444Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------\n",
      " ** 2022-01-08 12:32:48:395515 - Training current iteration 400  flag: update_w \n",
      "----------------------------------------------------------------------------------- \n",
      "\n",
      "------------------------------------------------------------\n",
      " ** Set optimizer and scheduler to policy_learning = True\n",
      "------------------------------------------------------------ \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " ** Switch from Warm Up training to Alternate training Weights & Policy \n",
      "   Take checkpoint and block gradient flow through Policy net\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_heading(f\"** {timestring()} - Training current iteration {current_iter}  flag: {flag} \", verbose = True)    \n",
    "\n",
    "current_iter_w = 0 \n",
    "current_iter_a = 0 \n",
    "batch_idx_a = 0 \n",
    "batch_idx_w = 0 \n",
    "curr_epoch  = 0 \n",
    "\n",
    "\n",
    "if flag_warmup:\n",
    "    print_heading(f\"** Set optimizer and scheduler to policy_learning = True\", verbose = True)\n",
    "    environ.define_optimizer(policy_learning=True)\n",
    "    environ.define_scheduler(policy_learning=True)\n",
    "    flag_warmup = False\n",
    "\n",
    "if current_iter == opt['train']['warm_up_iters']:\n",
    "    print_heading(f\"** Switch from Warm Up training to Alternate training Weights & Policy \\n\"\n",
    "                  f\"   Take checkpoint and block gradient flow through Policy net\", verbose=True)\n",
    "    environ.save_checkpoint('warmup', current_iter)\n",
    "    environ.fix_alpha()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea8b8473",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:15:00.848805Z",
     "start_time": "2022-01-07T23:15:00.796540Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:16.084885Z",
     "iopub.status.busy": "2022-01-07T22:49:16.084628Z",
     "iopub.status.idle": "2022-01-07T22:49:16.119033Z",
     "shell.execute_reply": "2022-01-07T22:49:16.117523Z",
     "shell.execute_reply.started": "2022-01-07T22:49:16.084860Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt['train']['print_freq']         100\n",
      "opt['train']['hard_sampling']      False\n",
      "opt['policy']                      True\n",
      "opt['tasks']                       ['class', 'class', 'class']\n",
      "weight_iter_alternate:             101\n",
      "alpha_iter_alternate :             101\n",
      "\n",
      "total_iters                        12000\n",
      "current_iter                       400\n",
      "\n",
      "current_iter_w                     0\n",
      "current_iter_a                     0\n",
      "batch_idx_w                        0\n",
      "\n",
      "curr_epochs                        0\n",
      "train_total_epochs                 10\n",
      "\n",
      "flag                               update_w\n"
     ]
    }
   ],
   "source": [
    "# batch_enumerator1 = enumerate(train1_loader,1)  \n",
    "# batch_enumerator2 = enumerate(train2_loader,1)  \n",
    "\n",
    "train_total_epochs = 10\n",
    "\n",
    "print(f\"opt['train']['print_freq']         {opt['train']['print_freq']}\")\n",
    "print(f\"opt['train']['hard_sampling']      {opt['train']['hard_sampling']}\")\n",
    "print(f\"opt['policy']                      {opt['policy']}\")\n",
    "print(f\"opt['tasks']                       {opt['tasks']}\")\n",
    "print(f\"weight_iter_alternate:             {opt['train']['weight_iter_alternate']}\")\n",
    "print(f\"alpha_iter_alternate :             {opt['train']['alpha_iter_alternate']}\")\n",
    "print()\n",
    "print(f\"total_iters                        {opt['train']['total_iters']}\")  \n",
    "print(f\"current_iter                       {current_iter  }\")\n",
    "print()\n",
    "print(f\"current_iter_w                     {current_iter_w}\")\n",
    "print(f\"current_iter_a                     {current_iter_a}\")\n",
    "print(f\"batch_idx_w                        {batch_idx_w}\")\n",
    "print()\n",
    "print(f\"curr_epochs                        {curr_epoch}\") \n",
    "print(f\"train_total_epochs                 {train_total_epochs}\") \n",
    "print()\n",
    "print(f\"flag                               {flag          }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0dd50bb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:43:20.842524Z",
     "start_time": "2022-01-07T23:43:20.818706Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# curr_epoch = 0\n",
    "# train_total_epochs = 55\n",
    "train_total_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dcbfcbc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:43:21.367115Z",
     "start_time": "2022-01-07T23:43:21.328772Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_iters         : 20600\n",
      "curr_epochs           : 100\n",
      "train_total_epochs    : 200\n"
     ]
    }
   ],
   "source": [
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"curr_epochs           : {curr_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860a16e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67347dd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T00:00:44.528818Z",
     "start_time": "2022-01-07T23:43:22.509963Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e868d9ba65843d88db006b828aa72bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Alternate Weight/Policy training:  50%|#####     | 101/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2461169d544cfeb893642e28c39c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 102 weight training:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20178/1936481496.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'print_freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     \u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"[c]Weight training epoch:{curr_epoch} iteration:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#         print(f\" d - curr_epoch: {curr_epoch}   current_iter: {current_iter}    current_iter_w: {current_iter_w}   stop_iter_w: {stop_iter_w}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kusanagi/AdaSparseChem/dev/base_env_dev.py\u001b[0m in \u001b[0;36mprint_loss\u001b[0;34m(self, current_iter, start_time, metrics, title, verbose)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Iteration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# loss = {'metrics': metrics}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kusanagi/AdaSparseChem/dev/base_env_dev.py\u001b[0m in \u001b[0;36mget_loss_dict\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0mprint_dbg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  key:  {key}   subkey: {subkey}  value: {v:.4f}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "num_prints = 0 \n",
    "verbose = False\n",
    "t = tqdm(initial = curr_epoch, total=train_total_epochs, desc=f\" Alternate Weight/Policy training\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "while curr_epoch < train_total_epochs:\n",
    "    curr_epoch+=1\n",
    "    t.update(1)\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # Train & Update the network weights\n",
    "    #-----------------------------------------\n",
    "    if flag == 'update_w':\n",
    "        current_iter_w  = 0 \n",
    "        stop_iter_w =   opt['train']['weight_iter_alternate']\n",
    "\n",
    "        with trange(+1, stop_iter_w+1 , initial = current_iter_w, total = stop_iter_w, \n",
    "                     position=0, leave= False, desc=f\"Epoch {curr_epoch} weight training\") as t_weights :\n",
    "            \n",
    "            for current_iter_w in t_weights:    \n",
    "                current_iter += 1\n",
    "\n",
    "                start_time = time.time()\n",
    "                environ.train()\n",
    "                \n",
    "                batch = next(train1_loader)\n",
    "                environ.set_inputs(batch, train1_loader.dataset.input_size)\n",
    "\n",
    "                ##----------------------------------------------------------------------\n",
    "                ## Set number of layers to train based on cirriculum_speed \n",
    "                ## and p_epoch (number of epochs of policy training)\n",
    "                ## When curriculum_speed == 3, a num_train_layers is incremented \n",
    "                ## after completion of every 3 policy training epochs\n",
    "                ##----------------------------------------------------------------------\n",
    "                if opt['is_curriculum']:\n",
    "                    num_train_layers = p_epoch // opt['curriculum_speed'] + 1\n",
    "                else:\n",
    "                    num_train_layers = None\n",
    "\n",
    "                environ.optimize(opt['lambdas'], \n",
    "                                 is_policy=opt['policy'], \n",
    "                                 flag=flag, \n",
    "                                 num_train_layers=num_train_layers,\n",
    "                                 hard_sampling=opt['train']['hard_sampling'],\n",
    "                                 verbose = False)\n",
    "\n",
    "                t_weights.set_postfix({'iter': current_iter, 'Loss': f\"{environ.losses['total']['total'].item():.4f}\" , \n",
    "                                       'row_ids':f\"{batch['row_id'][0]}-{batch['row_id'][-1]}\"})\n",
    "                \n",
    "                if should(current_iter, opt['train']['print_freq']):\n",
    "                    environ.print_loss(current_iter, start_time, title = f\"[c]Weight training epoch:{curr_epoch} iteration:\", verbose = True)\n",
    "\n",
    "#         print(f\" d - curr_epoch: {curr_epoch}   current_iter: {current_iter}    current_iter_w: {current_iter_w}   stop_iter_w: {stop_iter_w}\")\n",
    "\n",
    "        #-------------------------------------------------------\n",
    "        # validation process\n",
    "        #------------------------------------------------------- \n",
    "#       if should(current_iter_w, opt['train']['weight_iter_alternate']): \n",
    "        if (current_iter_w >= stop_iter_w):\n",
    "            environ.print_loss(current_iter, start_time, title = f\"[e]Weight training epoch:{curr_epoch} iteration:\", verbose = True)\n",
    "            environ.eval()\n",
    "\n",
    "            val_metrics = eval_dev(environ, \n",
    "                                  val_loader, \n",
    "                                  opt['tasks'], \n",
    "                                  policy=opt['policy'],\n",
    "                                  num_train_layers=num_train_layers, \n",
    "                                  hard_sampling=opt['train']['hard_sampling'],\n",
    "                                  eval_iter = -1)        \n",
    "\n",
    "#             environ.print_loss(current_iter, start_time, title = f\"[v]Weight training epoch:{curr_epoch} iteration:\", verbose = True)\n",
    "            environ.print_metrics(current_iter, start_time, val_metrics, title = f\"[v]Weight training epoch:{curr_epoch} iteration:\", verbose = False)\n",
    "            \n",
    "            ## printing a new header every 20 lines\n",
    "\n",
    "            print_metrics_cr(curr_epoch, time.time() - t0, None, val_metrics , num_prints)      \n",
    "            num_prints += 1\n",
    "            t0 = time.time()\n",
    "            \n",
    "            # Take check point\n",
    "            environ.save_checkpoint('latest', current_iter)\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "#\n",
    "#            #----------------------------------------------------------------------------------------------\n",
    "#            # if number of iterations completed after the warm up phase is greater than the number of \n",
    "#            # (weight/policy alternations) x (cirriculum speed) x (number of layers to be policy trained)\n",
    "#            #\n",
    "#            # check metrics for improvement, and issue a checkpoint if necessary\n",
    "#            #----------------------------------------------------------------------------------------------\n",
    "# \n",
    "#             if current_iter - opt['train']['warm_up_iters'] >= num_blocks * opt['curriculum_speed'] * \\\n",
    "#                     (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate']):\n",
    "#                 new_value = 0\n",
    "#                 print(f\"  {current_iter - opt['train']['warm_up_iters']} IS GREATER THAN \"\n",
    "#                        f\" {num_blocks * opt['curriculum_speed'] * (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate'])} -- \"\n",
    "#                        f\"  evaluate progress and make checkpoint if necessary.\" )            \n",
    "# \n",
    "#                 ## compare validation metrics against reference metrics.\n",
    "#                 \n",
    "#                 for k in refer_metrics.keys():\n",
    "#                     if k in val_metrics.keys():\n",
    "#                         for kk in val_metrics[k].keys():\n",
    "#                             if not kk in refer_metrics[k].keys():\n",
    "#                                 continue\n",
    "#                             if (k == 'sn' and kk in ['Angle Mean', 'Angle Median']) or (\n",
    "#                                     k == 'depth' and not kk.startswith('sigma')) or (kk == 'err'):\n",
    "#                                 value = refer_metrics[k][kk] / val_metrics[k][kk]\n",
    "#                             else:\n",
    "#                                 value = val_metrics[k][kk] / refer_metrics[k][kk]\n",
    "#                             value = value / len(list(set(val_metrics[k].keys()) & set(refer_metrics[k].keys())))\n",
    "#                             new_value += value\n",
    "# \n",
    "#                 print('Best Value %.4f  New value: %.4f' % new_value)\n",
    "# \n",
    "#                 ## if results have improved, save these results and issue a checkpoint\n",
    "# \n",
    "#                 if (new_value > best_value):\n",
    "#                     print('Previous best iter: %d, best_value: %.4f' % (best_iter, best_value), best_metrics)\n",
    "#                     best_value = new_value\n",
    "#                     best_metrics = val_metrics\n",
    "#                     best_iter = current_iter\n",
    "#                     environ.save_checkpoint('best', current_iter)\n",
    "#                     print('New      best iter: %d, best_value: %.4f' % (best_iter, best_value), best_metrics)                         \n",
    "#                     print('Best Value %.4f  New value: %.4f' % new_value)\n",
    "#\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "            environ.train()\n",
    "            #-------------------------------------------------------\n",
    "            # END validation process\n",
    "            #-------------------------------------------------------       \n",
    "            flag = 'update_alpha'\n",
    "            environ.fix_w()\n",
    "            environ.free_alpha()\n",
    "    #-------------------------------------------------------\n",
    "    # end weight training iteration\n",
    "    #-------------------------------------------------------               \n",
    "\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # Train & Update the  policy \n",
    "    #-----------------------------------------\n",
    "    if flag == 'update_alpha':\n",
    "        current_iter_a = 0\n",
    "        stop_iter_a = opt['train']['alpha_iter_alternate']\n",
    "\n",
    "        with trange( +1, stop_iter_a+1 , initial = 0, total = stop_iter_a, \n",
    "                     position=0, leave= False, desc=f\"Epoch {curr_epoch} policy training\") as t_policy :\n",
    "            for current_iter_a in t_policy:    \n",
    "                current_iter += 1\n",
    "\n",
    "                batch = next(train2_loader)\n",
    "                environ.set_inputs(batch, train2_loader.dataset.input_size)\n",
    "\n",
    "                if opt['is_curriculum']:\n",
    "                    num_train_layers = (p_epoch // opt['curriculum_speed']) + 1\n",
    "                else:\n",
    "                    num_train_layers = None\n",
    "\n",
    "                print_dbg(f\" num_train_layers  : {num_train_layers}\", verbose = False)\n",
    "\n",
    "                environ.optimize(opt['lambdas'], \n",
    "                                 is_policy=opt['policy'], \n",
    "                                 flag=flag, \n",
    "                                 num_train_layers=num_train_layers,\n",
    "                                 hard_sampling=opt['train']['hard_sampling'],\n",
    "                                 verbose = False)\n",
    "                \n",
    "                t_policy.set_postfix({'iteration': current_iter, 'Loss': f\"{environ.losses['total']['total'].item():.4f}\" , \n",
    "                                      'row_ids':f\"{batch['row_id'][0]}-{batch['row_id'][-1]}\"})\n",
    "                \n",
    "                if should(current_iter, opt['train']['print_freq']):\n",
    "                    environ.print_loss(current_iter, start_time, title = f\"[c]Policy training epoch:{curr_epoch} iteration:\", verbose=True)\n",
    "#                     environ.resize_results()\n",
    "#                     environ.visual_policy(current_iter)\n",
    "\n",
    "        if( current_iter_a >= stop_iter_a):            \n",
    "            environ.print_loss(current_iter, start_time, title = f\"[e]Policy training epoch:{curr_epoch} iteration:\", verbose=True)\n",
    "            flag = 'update_w'\n",
    "            environ.fix_alpha()\n",
    "            environ.free_w(opt['fix_BN'])\n",
    "            environ.decay_temperature()\n",
    "\n",
    "            # print the distribution\n",
    "            print_dbg(np.concatenate(environ.get_policy_prob(), axis=-1), verbose = False)\n",
    "            \n",
    "            p_epoch += 1\n",
    "            print_dbg(f\"** p_epoch incremented: {p_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70ae98e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T00:52:04.096664Z",
     "start_time": "2022-01-08T00:52:03.391454Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.49429607, 0.50570387],\n",
       "        [0.41874295, 0.58125705],\n",
       "        [0.36423224, 0.6357677 ],\n",
       "        [0.35090193, 0.64909816]], dtype=float32),\n",
       " array([[0.47767437, 0.52232575],\n",
       "        [0.42561013, 0.5743899 ],\n",
       "        [0.36186078, 0.6381392 ],\n",
       "        [0.32504362, 0.6749565 ]], dtype=float32),\n",
       " array([[0.482358  , 0.5176419 ],\n",
       "        [0.4386291 , 0.56137097],\n",
       "        [0.3968838 , 0.6031162 ],\n",
       "        [0.3329986 , 0.6670013 ]], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.get_policy_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff4ae7f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1418081981208155"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aa133f4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:08:57.366231Z",
     "start_time": "2022-01-08T01:08:57.295445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dilation = 2\n",
    "# kernel_size = np.asarray((3, 3))\n",
    "# upsampled_kernel_size = (kernel_size - 1) * (dilation - 1) + kernel_size\n",
    "# print(upsampled_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ecceb943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:09:09.084406Z",
     "start_time": "2022-01-08T01:09:09.060848Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': [Parameter containing:\n",
       "  tensor([[ 0.0800,  0.0051, -0.1250,  0.0351,  0.0504, -0.0745, -0.2902,  0.1308, -0.1071, -0.1518,  0.1789, -0.1324,  0.0987,\n",
       "           -0.1741, -0.4123,  0.1891,  0.0486, -0.2707,  0.1530,  0.0564, -0.0468, -0.0995,  0.2201, -0.1887,  0.0582,  0.2382,\n",
       "           -0.1516,  0.0251, -0.2729,  0.3212, -0.0769,  0.0788, -0.3097,  0.0631,  0.0423, -0.0516,  0.1535,  0.0506, -0.1826,\n",
       "            0.2992],\n",
       "          [-0.0962, -0.0139,  0.0584, -0.1527,  0.0107,  0.0350,  0.2339, -0.0274,  0.0570,  0.0608, -0.0893,  0.1807,  0.0060,\n",
       "            0.1492,  0.0426, -0.1930, -0.2432,  0.2835, -0.0589, -0.0352,  0.0498, -0.0519, -0.2233, -0.1339,  0.2161, -0.0861,\n",
       "           -0.4572,  0.2499, -0.1028,  0.2406,  0.0900,  0.1479, -0.0364,  0.0859,  0.0045,  0.1033,  0.1973, -0.2724, -0.0319,\n",
       "            0.2184],\n",
       "          [-0.1150,  0.2470,  0.0115, -0.1706,  0.0171,  0.0549,  0.1986,  0.0339,  0.1069, -0.2308, -0.1000, -0.1046,  0.0725,\n",
       "           -0.0088, -0.2527, -0.0865, -0.3401, -0.0200,  0.3557, -0.4023,  0.0766,  0.0330,  0.0434,  0.2808, -0.0199,  0.1858,\n",
       "            0.4047, -0.1863, -0.1903,  0.1431,  0.3313,  0.0394, -0.3658,  0.0770,  0.0711,  0.0256, -0.1488, -0.0523,  0.1159,\n",
       "            0.0120],\n",
       "          [-0.0209, -0.0312,  0.1506, -0.0012, -0.1686,  0.2715,  0.0825, -0.4356, -0.0962, -0.1211,  0.1803, -0.1688,  0.0133,\n",
       "           -0.0890, -0.1193, -0.1326, -0.2460,  0.1625,  0.1573,  0.1264, -0.1458, -0.2660, -0.1035,  0.1257, -0.1659,  0.0805,\n",
       "            0.1533,  0.1402, -0.2018, -0.0252, -0.0925,  0.2706,  0.2398,  0.2795,  0.0768,  0.0846, -0.0754,  0.0307,  0.0984,\n",
       "            0.0878],\n",
       "          [-0.0749, -0.0116, -0.0537,  0.0434, -0.3054, -0.0702,  0.2344,  0.1712, -0.2290,  0.3892, -0.1884, -0.0565,  0.0397,\n",
       "           -0.2683, -0.0985, -0.1468, -0.1235, -0.4361, -0.0707,  0.0031, -0.2501,  0.0418, -0.0426,  0.3056, -0.2140, -0.0035,\n",
       "            0.1284, -0.0525,  0.1086,  0.2379,  0.3222,  0.1394,  0.2889,  0.1582, -0.2404, -0.0229, -0.1522,  0.1202,  0.0899,\n",
       "           -0.0469]], device='cuda:0', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1457, -0.0445, -0.0901,  0.0934,  0.0335], device='cuda:0', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2414,  0.0265,  0.0188,  0.0882, -0.1351, -0.2479,  0.1349, -0.2273, -0.0433,  0.0527,  0.0637,  0.0178, -0.1019,\n",
       "            0.1385, -0.2702, -0.0014,  0.0596, -0.0425, -0.2000,  0.0270,  0.1038, -0.0664,  0.1432,  0.1490,  0.2161,  0.1624,\n",
       "            0.1354, -0.2592,  0.0906,  0.0845, -0.0799,  0.0632, -0.3490, -0.3668,  0.3272,  0.0203,  0.1017, -0.1130, -0.2042,\n",
       "            0.2612],\n",
       "          [-0.3642, -0.0601,  0.0531,  0.0892, -0.1135,  0.2315, -0.1625,  0.0071,  0.1493,  0.0579,  0.1936,  0.3129,  0.1672,\n",
       "            0.1343,  0.2185,  0.3332, -0.0744,  0.0704, -0.0137,  0.0094,  0.0802,  0.0495,  0.0594, -0.2016, -0.3397, -0.1716,\n",
       "           -0.0252,  0.0123, -0.1133,  0.1283,  0.0968, -0.1958, -0.1241,  0.3351,  0.0582, -0.2279,  0.0824, -0.2149, -0.2339,\n",
       "           -0.0464],\n",
       "          [-0.1976,  0.1971,  0.1812, -0.1694, -0.2277,  0.1656, -0.0270, -0.1019, -0.0831,  0.1223, -0.1570,  0.1662,  0.1979,\n",
       "           -0.0234, -0.2405, -0.1615, -0.0488, -0.1213, -0.0285, -0.1841, -0.0049, -0.2015, -0.0480,  0.0190,  0.0977,  0.2293,\n",
       "           -0.0331,  0.1180, -0.1136,  0.2553,  0.0701,  0.2582,  0.2136, -0.0081,  0.1625,  0.0671,  0.0527, -0.0874,  0.2708,\n",
       "           -0.0450],\n",
       "          [-0.0145,  0.2273,  0.0369, -0.0757,  0.0215,  0.0132, -0.0393,  0.0446,  0.1999,  0.3046, -0.1304,  0.1287, -0.0669,\n",
       "            0.1408, -0.0321, -0.2565, -0.3590, -0.1408,  0.1553,  0.0344, -0.2893,  0.3799, -0.2601, -0.0222, -0.1016, -0.1034,\n",
       "            0.2233, -0.2250,  0.2216,  0.2190,  0.1252, -0.1986, -0.0389, -0.0162, -0.1601,  0.0746,  0.2600,  0.0155, -0.0655,\n",
       "            0.0754],\n",
       "          [-0.1999,  0.0285, -0.1157,  0.0988, -0.4710, -0.1114,  0.1069, -0.1225,  0.2076,  0.2355,  0.0284,  0.3269, -0.0702,\n",
       "           -0.0815,  0.0436,  0.1573,  0.2510,  0.0198, -0.0246,  0.3002,  0.0960,  0.0710, -0.3474,  0.2722, -0.0494,  0.1666,\n",
       "           -0.3937,  0.0482, -0.1424, -0.0156, -0.0102, -0.0206, -0.2247, -0.0702, -0.2204, -0.0401, -0.3021,  0.1273, -0.0951,\n",
       "           -0.1126]], device='cuda:0', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1372, -0.1462, -0.1287, -0.0912,  0.1353], device='cuda:0', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-7.8776e-02,  3.2070e-01,  9.5512e-02, -1.6822e-01, -1.3882e-01,  3.0330e-01,  7.9411e-02,  9.2494e-02,  6.5047e-02,\n",
       "            6.9948e-02, -6.7040e-03, -1.5941e-01,  3.5294e-02,  1.5654e-01, -2.2588e-01, -2.9623e-01,  2.2140e-01,  2.9230e-01,\n",
       "           -1.2977e-01, -1.5640e-01, -2.7311e-01, -8.1215e-03,  2.7525e-01,  1.7660e-01, -1.5184e-01, -4.4047e-02, -1.4662e-01,\n",
       "            6.3010e-02,  1.7356e-01, -1.6516e-01, -2.3557e-03, -5.9126e-02, -4.0466e-01,  7.5102e-02,  4.4548e-02,  1.5976e-01,\n",
       "            7.9867e-02,  3.2007e-01, -3.8207e-02, -2.8297e-01],\n",
       "          [-5.8589e-02, -3.6527e-02,  7.2966e-02,  1.1062e-01, -1.2367e-01, -1.0441e-01, -8.0063e-02,  2.3685e-01, -2.0158e-01,\n",
       "           -1.9505e-01, -1.8927e-01, -1.5269e-01, -2.5210e-03,  1.8923e-01,  2.5335e-02,  3.9100e-02, -1.1658e-01,  5.9215e-02,\n",
       "           -2.2396e-01,  1.0931e-01, -1.9209e-01, -7.9822e-02, -1.0642e-01, -7.8017e-02,  2.4390e-01,  3.0419e-01, -2.2456e-01,\n",
       "           -1.0345e-01,  2.0049e-01,  1.3631e-01,  3.8865e-02, -4.6637e-02, -2.1880e-01,  1.5554e-01,  8.0814e-02,  1.3915e-01,\n",
       "            2.1646e-01,  2.3872e-01, -3.8260e-02,  5.3572e-02],\n",
       "          [ 5.6381e-02, -8.3169e-02,  1.1865e-01, -1.0236e-01, -2.3658e-01,  2.3555e-01,  5.2097e-02, -1.7277e-01,  1.5553e-01,\n",
       "            3.0703e-01,  7.3348e-02,  2.4426e-01, -2.3043e-02, -1.0073e-01, -1.5559e-01,  1.3444e-01, -2.6896e-01,  4.4921e-02,\n",
       "            6.0172e-02, -3.5985e-02,  1.1668e-01, -1.5632e-01, -6.5979e-02, -2.2116e-01,  2.0715e-02,  8.9060e-02,  1.0769e-01,\n",
       "            2.3763e-01,  8.9163e-02,  2.4237e-01, -2.4480e-01,  1.1909e-01, -1.2013e-01, -3.2743e-01, -4.4384e-02,  1.5877e-01,\n",
       "            1.3331e-02, -1.7347e-01,  1.7028e-01,  6.6160e-02],\n",
       "          [-6.3271e-02, -3.5448e-01,  1.3363e-01, -1.4534e-01,  1.2299e-01,  1.4109e-01, -1.3386e-01, -5.7759e-05, -2.0807e-01,\n",
       "            4.5600e-01,  4.8151e-02,  1.8875e-01,  1.8827e-01,  2.4882e-01,  3.2633e-02, -1.1254e-01, -3.2353e-02, -1.2369e-01,\n",
       "            1.3376e-01,  1.8190e-01,  9.8875e-02, -1.8401e-01,  1.5062e-02, -1.2302e-02,  6.0444e-03,  2.7141e-02,  7.7008e-02,\n",
       "            8.6371e-02, -2.0230e-01,  3.1445e-02,  2.2210e-01, -1.2176e-01, -3.5307e-01, -1.2096e-01, -4.4982e-01, -1.5877e-01,\n",
       "           -4.9785e-02,  4.0072e-02,  2.2763e-01,  2.4344e-01],\n",
       "          [-2.6074e-02, -2.3715e-01,  1.0002e-01, -8.5733e-02, -9.0628e-02, -2.5279e-01, -1.1125e-01,  2.4577e-01, -2.1160e-02,\n",
       "            3.0423e-01,  1.4831e-01, -1.6713e-01, -1.3751e-01,  3.1000e-01,  4.9296e-02, -2.7765e-02, -9.8118e-02,  2.6264e-01,\n",
       "            9.7576e-02,  7.0825e-02,  8.0630e-02, -7.4195e-02,  2.9098e-02,  2.9917e-01,  3.9210e-02,  1.3244e-02, -2.8451e-02,\n",
       "            7.0856e-02, -9.9718e-02, -2.1618e-01,  3.8070e-02, -1.1237e-01,  1.3603e-01, -9.0670e-02, -4.3502e-01,  2.2241e-01,\n",
       "           -2.9643e-01,  4.7129e-02, -3.8410e-02,  1.0289e-01]], device='cuda:0', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1001,  0.1572,  0.1407,  0.0728, -0.1881], device='cuda:0', requires_grad=True)],\n",
       " 'lr': 0.0001,\n",
       " 'momentum': 0.9,\n",
       " 'dampening': 0,\n",
       " 'weight_decay': 0.0001,\n",
       " 'nesterov': False}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.optimizers['weights'].param_groups[0]\n",
    "# for param_group in optimizer.param_groups:\n",
    "#     return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4338b92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:15:18.576545Z",
     "start_time": "2022-01-08T01:15:18.550384Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.5e-05, 2.5e-05]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.schedulers['weights'].get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "424781ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:18:38.271776Z",
     "start_time": "2022-01-08T01:18:37.894182Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'sharing': {   'total': tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)},\n",
      "    'sparsity': {   'task1_logits': tensor(0.5147, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
      "                    'task2_logits': tensor(0.5195, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
      "                    'task3_logits': tensor(0.4978, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
      "                    'total': tensor(0.0766, device='cuda:0', grad_fn=<MulBackward0>)},\n",
      "    'task1': {   'total': tensor(3.3657, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)},\n",
      "    'task2': {   'total': tensor(3.5906, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)},\n",
      "    'task3': {   'total': tensor(3.2182, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)},\n",
      "    'tasks': {   'task1': tensor(3.3657, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>),\n",
      "                 'task2': tensor(3.5906, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>),\n",
      "                 'task3': tensor(3.2182, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>),\n",
      "                 'total': tensor(10.1745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)},\n",
      "    'total': {   'total': tensor(10.2513, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)}}\n"
     ]
    }
   ],
   "source": [
    "environ.losses.keys()\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "24354e05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:19:43.683550Z",
     "start_time": "2022-01-08T01:19:43.571450Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['task1', 'task2', 'task3', 'tasks', 'total', 'sharing', 'sparsity'])\n",
      "{   'sharing': {'total': tensor(0.0002, device='cuda:0')},\n",
      "    'sparsity': {   'task1_logits': tensor(0.5147, device='cuda:0'),\n",
      "                    'task2_logits': tensor(0.5195, device='cuda:0'),\n",
      "                    'task3_logits': tensor(0.4978, device='cuda:0'),\n",
      "                    'total': tensor(0.0766, device='cuda:0')},\n",
      "    'task1': {'total': tensor(3.3657, device='cuda:0', dtype=torch.float64)},\n",
      "    'task2': {'total': tensor(3.5906, device='cuda:0', dtype=torch.float64)},\n",
      "    'task3': {'total': tensor(3.2182, device='cuda:0', dtype=torch.float64)},\n",
      "    'tasks': {   'task1': tensor(3.3657, device='cuda:0', dtype=torch.float64),\n",
      "                 'task2': tensor(3.5906, device='cuda:0', dtype=torch.float64),\n",
      "                 'task3': tensor(3.2182, device='cuda:0', dtype=torch.float64),\n",
      "                 'total': tensor(10.1745, device='cuda:0', dtype=torch.float64)},\n",
      "    'total': {'total': tensor(10.2513, device='cuda:0', dtype=torch.float64)}}\n"
     ]
    }
   ],
   "source": [
    "tmp = environ.get_loss_dict()\n",
    "print(tmp.keys())\n",
    "pp.pprint(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "980e5ce3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:22:22.714409Z",
     "start_time": "2022-01-08T01:22:22.395164Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.2513, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['task1']['total']+tmp['task2']['total']+tmp['task3']['total']+tmp['sharing']['total']+tmp['sparsity']['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f17d45c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:34:26.770937Z",
     "start_time": "2022-01-08T01:34:26.747415Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17713"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e39d2493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:36:17.129535Z",
     "start_time": "2022-01-08T01:36:16.006144Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state dict for weights = SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.0001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      "\n",
      "Parameter Group 1\n",
      "    dampening: 0\n",
      "    lr: 0.0001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "state dict for alphas = Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "{   'alphas': {   'param_groups': [   {   'amsgrad': False,\n",
      "                                          'betas': (0.9, 0.999),\n",
      "                                          'eps': 1e-08,\n",
      "                                          'lr': 0.0001,\n",
      "                                          'params': [0, 1, 2],\n",
      "                                          'weight_decay': 0.0005}],\n",
      "                  'state': {   0: {   'exp_avg': tensor([[ 0.0607, -0.0007],\n",
      "        [-0.0428, -0.0069],\n",
      "        [-0.1218,  0.0138],\n",
      "        [ 0.0086,  0.0238]], device='cuda:0'),\n",
      "                                      'exp_avg_sq': tensor([[0.0523, 0.0112],\n",
      "        [0.1734, 0.0073],\n",
      "        [0.3830, 0.0086],\n",
      "        [0.6783, 0.0108]], device='cuda:0'),\n",
      "                                      'step': 8613},\n",
      "                               1: {   'exp_avg': tensor([[ 0.0535, -0.0901],\n",
      "        [-0.0352, -0.0387],\n",
      "        [ 0.1020, -0.0073],\n",
      "        [-0.0796, -0.0576]], device='cuda:0'),\n",
      "                                      'exp_avg_sq': tensor([[0.0549, 0.0120],\n",
      "        [0.1729, 0.0070],\n",
      "        [0.3925, 0.0042],\n",
      "        [0.6830, 0.0098]], device='cuda:0'),\n",
      "                                      'step': 8613},\n",
      "                               2: {   'exp_avg': tensor([[-0.0127, -0.0090],\n",
      "        [ 0.1781, -0.0526],\n",
      "        [ 0.0248, -0.0095],\n",
      "        [ 0.1182, -0.0113]], device='cuda:0'),\n",
      "                                      'exp_avg_sq': tensor([[0.0501, 0.0096],\n",
      "        [0.1758, 0.0075],\n",
      "        [0.3727, 0.0086],\n",
      "        [0.6747, 0.0059]], device='cuda:0'),\n",
      "                                      'step': 8613}}},\n",
      "    'weights': {   'param_groups': [   {   'dampening': 0,\n",
      "                                           'lr': 0.0001,\n",
      "                                           'momentum': 0.9,\n",
      "                                           'nesterov': False,\n",
      "                                           'params': [0, 1, 2, 3, 4, 5],\n",
      "                                           'weight_decay': 0.0001},\n",
      "                                       {   'dampening': 0,\n",
      "                                           'lr': 0.0001,\n",
      "                                           'momentum': 0.9,\n",
      "                                           'nesterov': False,\n",
      "                                           'params': [   6,\n",
      "                                                         7,\n",
      "                                                         8,\n",
      "                                                         9,\n",
      "                                                         10,\n",
      "                                                         11,\n",
      "                                                         12,\n",
      "                                                         13,\n",
      "                                                         14,\n",
      "                                                         15],\n",
      "                                           'weight_decay': 0.0001}],\n",
      "                   'state': {   0: {   'momentum_buffer': tensor([[-5.4482e-01, -2.7512e-01,  4.6711e-02, -4.5902e-01, -2.5247e-01, -2.1980e-01,  9.4069e-02, -1.7776e-01, -2.0681e-01,\n",
      "         -1.0892e-01, -2.7464e-01,  9.3985e-03, -3.7082e-01, -2.7459e-01,  3.1315e-01, -2.4067e-01, -2.3865e-01, -2.0458e-01,\n",
      "         -3.9198e-01, -1.3971e-01, -2.2085e-01,  2.9561e-01, -3.2675e-01, -4.4961e-01, -2.5565e-01, -1.9292e-01,  2.3961e-02,\n",
      "         -1.4747e-01, -2.0461e-01, -2.9271e-01, -1.2636e-01, -3.2118e-01, -1.3085e-02, -3.2467e-01,  7.6504e-02, -3.8073e-01,\n",
      "         -3.4652e-01, -4.8136e-01, -1.0855e-01, -4.6362e-01],\n",
      "        [ 7.5279e-02,  5.0053e-01, -6.5901e-02,  4.2624e-01, -1.1979e-01,  1.3010e-01, -5.5052e-03,  6.0068e-02,  1.6456e-01,\n",
      "          6.9727e-02,  5.5028e-01,  7.4976e-02,  2.0544e-01, -1.8356e-01,  5.8646e-03,  3.8858e-01,  5.8229e-01, -6.4714e-02,\n",
      "         -9.7311e-02,  1.5540e-02,  2.6569e-01,  1.2685e-01,  3.5929e-01,  6.1809e-02,  6.5516e-02,  1.7281e-01,  2.4054e-01,\n",
      "          2.5444e-01,  8.1368e-02,  1.7834e-01,  6.4536e-01,  2.9524e-01,  5.1240e-02,  1.0327e-01,  5.0252e-01, -1.2009e-01,\n",
      "          5.2004e-01,  3.6589e-01,  2.5036e-02,  1.1756e-01],\n",
      "        [-2.6041e-02,  3.7978e-01, -2.9577e-02,  1.2583e-01, -1.9533e-01,  1.3204e-01, -2.4134e-01, -2.2500e-01,  1.1932e-01,\n",
      "         -2.8338e-02, -1.2620e-01,  4.1562e-02, -1.4164e-01,  1.0466e-02, -7.2124e-03, -1.7311e-01, -1.0594e-02, -1.1018e-01,\n",
      "         -4.0215e-01,  2.2231e-01, -3.5036e-01, -1.2274e-01, -2.5909e-01, -4.9505e-01,  2.7185e-01, -6.1372e-02, -3.2376e-01,\n",
      "         -4.9975e-01,  4.8624e-01, -2.4463e-03, -5.9059e-02, -2.9173e-02, -8.6035e-02,  2.1797e-02, -3.9157e-02, -1.6863e-01,\n",
      "          5.4898e-01,  1.9727e-01, -1.3099e-01,  2.3543e-01],\n",
      "        [ 2.3553e-01,  3.4450e-01, -7.3627e-02,  4.6605e-01,  4.3280e-02, -6.7811e-02,  7.9972e-02,  5.1132e-01, -2.0549e-02,\n",
      "          3.1941e-01,  7.4393e-01,  8.0956e-01,  5.7910e-02, -5.3678e-02,  2.2120e-01,  8.8379e-01,  8.9871e-01, -1.4795e-01,\n",
      "         -2.7687e-02,  3.6311e-01,  4.9540e-01,  3.6264e-01,  3.9721e-01,  3.3454e-01,  5.2051e-01,  1.9513e-01,  3.0391e-01,\n",
      "          1.0195e-01, -1.7816e-01,  5.9080e-01,  1.0638e+00, -2.2466e-01,  1.3106e-01,  2.6890e-01,  4.8539e-01, -1.6549e-01,\n",
      "          1.6727e-01,  1.9687e-01, -5.7773e-02,  6.5643e-04],\n",
      "        [-1.4043e+00, -4.7333e-01, -2.1537e-01, -6.8192e-01, -4.0019e-01, -3.0406e-01, -3.6066e-01, -8.0768e-01, -3.2529e-02,\n",
      "         -6.8346e-01, -1.1644e+00, -8.0557e-01, -7.2629e-01, -6.1576e-02, -2.6680e-01, -1.1771e+00, -9.3424e-01, -3.5853e-01,\n",
      "         -5.4122e-01, -5.1141e-01, -6.5359e-01, -5.1459e-01, -8.0336e-01, -8.5221e-01, -5.7714e-01, -4.6222e-01, -6.1317e-01,\n",
      "         -8.5647e-01,  1.8005e-02, -1.0541e+00, -1.6143e+00, -3.8753e-01, -6.1965e-01, -6.0904e-01, -6.1653e-01, -3.2613e-01,\n",
      "         -4.6098e-01, -5.1365e-01, -5.4302e-01, -6.4716e-01]], device='cuda:0')},\n",
      "                                1: {   'momentum_buffer': tensor([-0.0579,  0.2361, -0.0467,  0.4477, -0.6013], device='cuda:0')},\n",
      "                                2: {   'momentum_buffer': tensor([[-0.2612, -0.1668, -0.0060, -0.4843,  0.0824,  0.2120, -0.0110, -0.2463,  0.0614, -0.1931, -0.0739, -0.3940, -0.1723,\n",
      "         -0.0844, -0.0420, -0.3581, -0.3555,  0.1027,  0.3321, -0.2004,  0.0719, -0.1718, -0.1382, -0.2087, -0.4006,  0.1659,\n",
      "         -0.0612,  0.2602, -0.3789, -0.5442, -0.6798, -0.0991,  0.1144,  0.0608, -0.3799,  0.1046, -0.5230, -0.1794,  0.2387,\n",
      "         -0.3948],\n",
      "        [-0.7644, -0.4455,  0.1079, -0.6770, -0.0285, -0.0317, -0.0798, -0.5369, -0.1481, -0.5042, -0.6391, -0.6097, -0.4634,\n",
      "         -0.3808, -0.4200, -0.5469, -0.9528, -0.0851,  0.2172, -0.3774, -0.0737, -0.6040, -0.4646, -0.6076, -0.3767,  0.0727,\n",
      "         -0.1834,  0.3338, -0.3549, -0.7231, -1.1620,  0.0138, -0.1620, -0.3471, -0.4770,  0.0757, -0.6643, -0.6895,  0.0787,\n",
      "         -0.4058],\n",
      "        [ 0.2805, -0.0582,  0.1003,  0.0825,  0.2279, -0.3497,  0.1211,  0.5327,  0.0040,  0.5895,  0.3208,  0.3248,  0.1391,\n",
      "          0.3223,  0.3612,  0.3953, -0.0528,  0.2579,  0.6889,  0.3003,  0.2949,  0.3943,  0.3399,  0.3902,  0.2274,  0.1454,\n",
      "          0.2639,  0.4317,  0.0282,  0.2718,  0.7873,  0.1240, -0.0545, -0.0371, -0.2902,  0.1248,  0.0531,  0.4477,  0.1740,\n",
      "          0.3522],\n",
      "        [-0.1528, -0.1209,  0.0156, -0.2532, -0.0495, -0.1200,  0.2843, -0.2697,  0.0212, -0.3180, -0.1699,  0.0696, -0.0441,\n",
      "         -0.2312,  0.0227,  0.0530,  0.4047, -0.4066,  0.1157, -0.0749,  0.0571, -0.2684,  0.0121,  0.2005, -0.0978,  0.0283,\n",
      "          0.1963, -0.2490, -0.3016, -0.0356,  0.0103,  0.0743,  0.2626,  0.0507, -0.0169, -0.3918, -0.1736,  0.0629, -0.0922,\n",
      "         -0.0151],\n",
      "        [-0.1752,  0.0017, -0.0910, -0.4192, -0.1514,  0.1885, -0.0909, -0.2453,  0.0872, -0.2964, -0.3132, -0.5285, -0.0679,\n",
      "         -0.0362, -0.2413, -0.5825, -0.5508,  0.1931, -0.0183, -0.3240, -0.0980, -0.0574, -0.3542, -0.1842, -0.1074,  0.2090,\n",
      "         -0.1148,  0.0744, -0.1232, -0.2965, -0.8092,  0.1216,  0.0491,  0.0700,  0.0853,  0.0258,  0.0286, -0.4716,  0.1206,\n",
      "         -0.0628]], device='cuda:0')},\n",
      "                                3: {   'momentum_buffer': tensor([-0.1741, -0.3002,  0.2925,  0.2971, -0.3722], device='cuda:0')},\n",
      "                                4: {   'momentum_buffer': tensor([[-0.0849, -0.1597,  0.2053, -0.1966, -0.0118, -0.2330, -0.0241, -0.6122, -0.2113, -0.3294, -0.2063, -0.3181,  0.0481,\n",
      "         -0.4093, -0.4637, -0.7161, -0.4272, -0.1147,  0.2656, -0.4111,  0.0617, -0.3495, -0.3421, -0.1997,  0.0105,  0.0609,\n",
      "         -0.0572,  0.1777, -0.0505, -0.6948, -0.4959,  0.2197,  0.1054, -0.3540, -0.4853,  0.2524, -0.3534, -0.1041,  0.0436,\n",
      "         -0.0729],\n",
      "        [-0.2884, -0.0777, -0.1561, -0.0193, -0.2145,  0.1506,  0.0461, -0.1056,  0.1115,  0.0735,  0.0143, -0.1489, -0.1132,\n",
      "         -0.1654, -0.0719, -0.0780,  0.0905, -0.1635,  0.0411,  0.0230, -0.1094,  0.2141,  0.2209,  0.2538, -0.2747, -0.0911,\n",
      "          0.2328, -0.0246, -0.2137,  0.0164,  0.4605,  0.0623,  0.1916,  0.0445,  0.2819,  0.0821, -0.2006,  0.0480, -0.2465,\n",
      "         -0.0939],\n",
      "        [-0.3999, -0.1251, -0.2381, -0.1985, -0.1385, -0.0977, -0.1711, -0.1430, -0.2113, -0.3605, -0.0474, -0.3035,  0.0633,\n",
      "         -0.0959, -0.1873, -0.3301, -0.1024, -0.2385, -0.4791, -0.1046, -0.2390, -0.2179, -0.3163, -0.2241, -0.5092,  0.1025,\n",
      "         -0.1386, -0.4020, -0.2547, -0.1484, -0.6128, -0.2314, -0.0788,  0.2300, -0.0069, -0.2817, -0.1210, -0.0113, -0.4520,\n",
      "         -0.2268],\n",
      "        [ 0.2257,  0.3765,  0.1650, -0.1478,  0.0906,  0.1179,  0.1602, -0.1910,  0.4880, -0.0549, -0.0863,  0.1077,  0.3084,\n",
      "          0.1151, -0.0719, -0.2795,  0.0179,  0.6149,  0.4591, -0.0565, -0.0812,  0.2760, -0.0342,  0.0169,  0.0639, -0.0015,\n",
      "          0.0713,  0.1656,  0.2635,  0.0067, -0.1705,  0.2555,  0.2492, -0.0994,  0.1673,  0.3523,  0.3903,  0.0610,  0.2200,\n",
      "          0.0149],\n",
      "        [ 0.4827,  0.3845,  0.2594,  0.7605,  0.4389,  0.4478,  0.4341,  0.6531,  0.1451,  0.5494,  0.8218,  0.7176,  0.2111,\n",
      "          0.1574,  0.5871,  1.1305,  0.7570,  0.1728,  0.4147,  0.5044,  0.3479,  0.4095,  0.6468,  0.4890,  0.3662,  0.0461,\n",
      "          0.3462,  0.2534,  0.3233,  0.7041,  1.0300,  0.2806,  0.3191,  0.6002,  0.5828,  0.2223,  0.5332,  0.5004,  0.1183,\n",
      "          0.3750]], device='cuda:0')},\n",
      "                                5: {   'momentum_buffer': tensor([-0.3636,  0.1302, -0.1584, -0.0355,  0.4779], device='cuda:0')},\n",
      "                                6: {   'momentum_buffer': tensor([[ 1.5304e-01, -5.9271e-03,  4.8917e-01,  ..., -2.2712e-01, -1.2944e-01, -1.5610e-01],\n",
      "        [ 2.3775e-02, -9.0718e-03,  2.1647e-02,  ...,  3.9088e-02,  2.5611e-02, -2.9572e-02],\n",
      "        [ 1.6747e-02, -1.2741e-02,  1.7129e-02,  ...,  1.8492e-02, -8.0235e-03, -2.1392e-02],\n",
      "        ...,\n",
      "        [-3.1285e-06, -2.0295e-06,  7.8620e-06,  ...,  1.1699e-06,  3.7180e-07,  5.9421e-07],\n",
      "        [ 7.3640e-06, -1.7594e-05,  7.4498e-05,  ..., -2.5983e-05,  1.2307e-05,  3.2505e-05],\n",
      "        [-9.6068e-06, -8.5949e-06,  1.0171e-05,  ..., -6.1072e-06, -8.3978e-07, -6.7925e-06]], device='cuda:0')},\n",
      "                                7: {   'momentum_buffer': tensor([ 0.3887, -0.0579,  0.3107,  0.1551,  0.8331, -0.1376, -0.3844, -0.0353,  0.4420, -0.5766,  0.0788, -0.0751, -0.1867,\n",
      "         0.1001, -0.3312, -0.2118, -0.3287, -0.0677,  0.3000, -0.2234,  0.1245, -0.1919, -0.2328,  0.3670,  0.0290, -0.1925,\n",
      "         0.4300, -0.1144, -0.4987, -0.1107, -0.3611,  0.4313, -0.4842,  0.6604,  0.0137,  0.0144,  0.2782, -0.2992, -0.2614,\n",
      "        -0.2438], device='cuda:0')},\n",
      "                                8: {   'momentum_buffer': tensor([[ 1.5098e-01,  6.8066e-02, -1.1790e-01,  ...,  9.2484e-02, -4.3672e-02,  6.0582e-02],\n",
      "        [-2.7928e-02, -3.8709e-02,  1.1351e-02,  ...,  1.4022e-02,  1.4181e-02, -2.3581e-02],\n",
      "        [ 1.2368e-05,  1.6269e-04, -2.8662e-04,  ..., -4.4968e-05, -1.8164e-04, -3.3822e-04],\n",
      "        ...,\n",
      "        [-4.0677e-02,  2.7337e-02,  1.5571e-02,  ..., -4.8724e-02, -3.2856e-02, -1.0650e-02],\n",
      "        [ 1.6598e-01,  9.5019e-02, -4.6000e-02,  ...,  6.4921e-02,  3.7100e-02,  8.7817e-02],\n",
      "        [-8.4905e-03,  2.2479e-02, -2.5620e-03,  ..., -7.5068e-03, -5.1343e-03, -1.6064e-02]], device='cuda:0')},\n",
      "                                9: {   'momentum_buffer': tensor([ 3.4776e-01, -3.5319e-02,  1.0072e-04,  3.8190e-03,  4.6922e-01, -1.4719e-02, -1.9333e-01, -1.0430e-01, -4.9097e-02,\n",
      "        -3.4282e-01, -1.2632e-01,  1.1640e-01,  1.4245e-01,  3.9221e-01, -1.5241e-01,  1.0361e-01,  2.8693e-01, -3.8438e-02,\n",
      "         5.4297e-01,  2.2322e-02,  2.2954e-01, -2.4616e-01,  8.4137e-02,  2.5481e-01, -9.6045e-02,  4.1123e-02,  1.7366e-01,\n",
      "        -3.3607e-02, -7.8799e-02, -8.1003e-02, -1.5968e-01,  1.4050e-01,  7.0586e-02,  2.4685e-01,  8.4280e-02,  1.2348e-01,\n",
      "        -1.0331e-01, -9.8404e-02,  2.8721e-01, -3.6698e-02], device='cuda:0')},\n",
      "                                10: {   'momentum_buffer': tensor([[ 0.0122, -0.0239, -0.0222,  ...,  0.0248,  0.0130, -0.0082],\n",
      "        [ 0.0409, -0.0863, -0.0585,  ...,  0.0649, -0.0058,  0.0468],\n",
      "        [ 0.0525,  0.0079, -0.0112,  ...,  0.0785,  0.0505,  0.0502],\n",
      "        ...,\n",
      "        [ 0.2707,  0.1044, -0.0254,  ...,  0.1337,  0.0744,  0.0592],\n",
      "        [ 0.0154,  0.0331,  0.0019,  ...,  0.0142, -0.0596, -0.0396],\n",
      "        [-0.0857,  0.0114, -0.0162,  ..., -0.0332, -0.1018, -0.0657]], device='cuda:0')},\n",
      "                                11: {   'momentum_buffer': tensor([ 0.0760, -0.0063,  0.1234, -0.0805,  0.1407, -0.0494,  0.0783,  0.1751, -0.0619, -0.1029,  0.0626, -0.1621,  0.0215,\n",
      "         0.0589,  0.0777, -0.0114,  0.0356,  0.0869,  0.1138,  0.0837,  0.0116, -0.0266,  0.1767,  0.2595,  0.0828, -0.0264,\n",
      "         0.1041,  0.0221,  0.0534, -0.0933,  0.0266, -0.0506, -0.0109, -0.0572, -0.0290,  0.0525, -0.0016,  0.2201, -0.0559,\n",
      "        -0.0764], device='cuda:0')},\n",
      "                                12: {   'momentum_buffer': tensor([[ 0.0542,  0.0008, -0.0059,  ...,  0.0547,  0.0933,  0.0654],\n",
      "        [-0.0124, -0.0217, -0.0174,  ...,  0.0780, -0.0404,  0.0119],\n",
      "        [-0.0024, -0.0011, -0.0005,  ...,  0.0003, -0.0004, -0.0003],\n",
      "        ...,\n",
      "        [ 0.0027,  0.0664,  0.0873,  ...,  0.0592,  0.0687,  0.0510],\n",
      "        [ 0.0913,  0.0534, -0.0025,  ...,  0.0306, -0.0440,  0.0299],\n",
      "        [-0.0215,  0.0202, -0.0636,  ..., -0.0170, -0.0338, -0.0677]], device='cuda:0')},\n",
      "                                13: {   'momentum_buffer': tensor([ 0.1389, -0.0492, -0.0026, -0.1231, -0.0199,  0.0288,  0.0002,  0.0369,  0.0689,  0.0349, -0.0123, -0.0443, -0.0297,\n",
      "         0.0026,  0.0345,  0.0489,  0.0253,  0.0764,  0.0739,  0.0602, -0.0033,  0.0222, -0.0743,  0.0255,  0.0509,  0.1373,\n",
      "         0.0104,  0.0234, -0.0108,  0.0034, -0.0159,  0.0054,  0.0429,  0.0476, -0.0150, -0.0057, -0.0413,  0.0307,  0.0383,\n",
      "        -0.0091], device='cuda:0')},\n",
      "                                14: {   'momentum_buffer': tensor([[ 0.1029,  0.0980,  0.0202,  ...,  0.1078,  0.0647,  0.0686],\n",
      "        [ 0.1083,  0.0676,  0.0507,  ...,  0.1634,  0.0056,  0.0213],\n",
      "        [ 0.0021, -0.0008, -0.0076,  ...,  0.0037, -0.0008, -0.0021],\n",
      "        ...,\n",
      "        [ 0.0117,  0.0903,  0.0301,  ..., -0.0045,  0.0020,  0.0292],\n",
      "        [ 0.0616,  0.0727, -0.0032,  ...,  0.0555,  0.0145,  0.0146],\n",
      "        [-0.0441, -0.0322, -0.0147,  ...,  0.0057, -0.0240, -0.0302]], device='cuda:0')},\n",
      "                                15: {   'momentum_buffer': tensor([ 0.0819,  0.0197, -0.0006, -0.0349,  0.0058,  0.0291, -0.0123, -0.0388, -0.0164, -0.0855,  0.0779,  0.0347, -0.0715,\n",
      "        -0.0225,  0.0360,  0.0105, -0.0919,  0.2164,  0.0061,  0.0852,  0.1488, -0.1035,  0.0128, -0.0246,  0.1463,  0.0421,\n",
      "         0.0069, -0.0251,  0.0041, -0.0824, -0.1332, -0.0114, -0.0141,  0.0515,  0.0716,  0.0047, -0.0701, -0.0178,  0.0446,\n",
      "        -0.0167], device='cuda:0')}}}}\n"
     ]
    }
   ],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.optimizers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    current_state[k] = v.state_dict()\n",
    "pp.pprint(current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b8b87b1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:40:22.032247Z",
     "start_time": "2022-01-08T01:40:22.006953Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state dict for weights = <torch.optim.lr_scheduler.StepLR object at 0x7f90c01c0ca0>\n",
      "{'step_size': 4000, 'gamma': 0.5, 'base_lrs': [0.0001, 0.0001], 'last_epoch': 9100, '_step_count': 9101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [2.5e-05, 2.5e-05]}\n"
     ]
    }
   ],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.schedulers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    print(v.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240104e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Warm-up:  validation - Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c3eaa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:41:10.772791Z",
     "start_time": "2021-12-15T20:41:05.690320Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# validation\n",
    "if should(current_iter, opt['train']['val_freq']):\n",
    "    print(f\"**  {timestring()}  START VALIDATION iteration: {current_iter} \")    \n",
    "\n",
    "    environ.eval()     # set to evaluation mode (train = False)\n",
    "    num_seg_class = opt['tasks_num_class'][opt['tasks'].index('seg')] if 'seg' in opt['tasks'] else -1\n",
    "    val_metrics = eval_dev(environ, \n",
    "                          val_loader, \n",
    "                          opt['tasks'], \n",
    "                          policy=False, \n",
    "                          num_train_layers=None, \n",
    "                          eval_iter = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac77c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:41:11.489480Z",
     "start_time": "2021-12-15T20:41:11.461278Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_metrics.keys()\n",
    "val_metrics['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ad14d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:41:55.074366Z",
     "start_time": "2021-12-15T20:41:55.029329Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in val_metrics:\n",
    "    print(f'\\n {i} \\n -----------------')\n",
    "    print(val_metrics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d951d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:37:44.423495Z",
     "start_time": "2021-12-15T20:37:44.400109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    for t_id, task in enumerate(environ.tasks):\n",
    "        task_key = f\"task{t_id+1}\"    \n",
    "        environ.print_loss(current_iter, start_time, val_metrics[task_key][\"classification_agg\"], title='validation')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5783f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:36:43.503203Z",
     "start_time": "2021-12-15T20:36:43.371900Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    environ.save_checkpoint('latest', current_iter)\n",
    "\n",
    "    print(f\"** {timestring()} - END VALIDATION iteration:  {current_iter} \")                \n",
    "    environ.train()    # set to training mode (train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3074d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T22:26:36.573475Z",
     "start_time": "2021-12-12T22:26:36.455074Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for i in val_metrics.keys():\n",
    "#     print(i, type(val_metrics[i]))\n",
    "#     for k in val_metrics[i].keys():\n",
    "#         print(i,k, type(val_metrics[i][k]))\n",
    "#         if isinstance(val_metrics[i][k], pd.core.series.Series):\n",
    "#             print(f\"val_metrics[{i}][{k}] is a series\")\n",
    "#         elif isinstance(val_metrics[i][k], pd.core.frame.DataFrame):\n",
    "#             print(f\"val_metrics[{i}][{k}] is a dataframe\")        \n",
    "\n",
    "# s = val_metrics['task1']['classification_agg']\n",
    "# print(s)\n",
    "# print(s.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047eff66",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Load previously saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d5d47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T23:46:09.100795Z",
     "start_time": "2021-12-20T23:46:08.702295Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_separator('READ YAML')\n",
    "opt, gpu_ids, exp_ids =read_yaml_from_input(input_args)\n",
    "print(gpu_ids, exp_ids,  opt['train']['policy_iter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27360c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T23:46:09.100795Z",
     "start_time": "2021-12-20T23:46:08.702295Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "current_iter = environ.load_checkpoint('latest')\n",
    "\n",
    "print('Evaluating the snapshot saved at %d iter' % current_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4551c36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T23:46:09.100795Z",
     "start_time": "2021-12-20T23:46:08.702295Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "opt['train']['weight_iter_alternate'] = opt['train'].get('weight_iter_alternate', len(train1_loader))\n",
    "opt['train']['alpha_iter_alternate'] = opt['train'].get('alpha_iter_alternate'  , len(train2_loader))\n",
    "\n",
    "print(opt['train']['weight_iter_alternate'], opt['train']['alpha_iter_alternate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aea9c4a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Weight Training Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a561e1a9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Weight training - prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454204e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T23:40:00.014577Z",
     "start_time": "2021-12-20T23:39:59.990525Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# arch_parms = environ.networks['mtl-net'].named_parameters()\n",
    "# print(arch_parms)\n",
    "# for name, parm in arch_parms:\n",
    "#     print(name, '    ',parm.requires_grad)\n",
    "# print_underline('MTL3_Dev Policys', verbose = True)\n",
    "# for i in   environ.networks['mtl-net'].policys:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ad431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T22:57:34.590953Z",
     "start_time": "2021-12-21T22:57:34.234886Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_heading(f\"** {timestring()} - Training current iteration {current_iter}  flag: {flag} \", verbose = True)    \n",
    "\n",
    "current_iter_w = 0 \n",
    "current_iter_a = 0 \n",
    "batch_idx_a = 0 \n",
    "batch_idx_w = 0 \n",
    "\n",
    "if flag_warmup:\n",
    "    print_heading(f\"** Set optimizer and scheduler to policy_learning = True\", verbose = True)\n",
    "    environ.define_optimizer(policy_learning=True)\n",
    "    environ.define_scheduler(policy_learning=True)\n",
    "    flag_warmup = False\n",
    "\n",
    "if current_iter == opt['train']['warm_up_iters']:\n",
    "    print_heading(f\"** Switch from Warm Up training to Alternate training Weights & Policy \\n\"\n",
    "                  f\"   Take checkpoint and block gradient flow through Policy net\", verbose=True)\n",
    "    environ.save_checkpoint('warmup', current_iter)\n",
    "    environ.fix_alpha()\n",
    "    \n",
    "# batch_enumerator1 = enumerate(train1_loader,1)  \n",
    "# batch_enumerator2 = enumerate(train2_loader,1)  \n",
    "\n",
    "train_total_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c0a04",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Weight training - main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc47806",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T22:57:57.069633Z",
     "start_time": "2021-12-21T22:57:57.026843Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"opt['train']['print_freq']         {opt['train']['print_freq']}\")\n",
    "print(f\"opt['train']['hard_sampling']      {opt['train']['hard_sampling']}\")\n",
    "print(f\"opt['policy']                      {opt['policy']}\")\n",
    "print(f\"opt['tasks']                       {opt['tasks']}\")\n",
    "print(f\"weight_iter_alternate:             {opt['train']['weight_iter_alternate']}\")\n",
    "print(f\"alpha_iter_alternate :             {opt['train']['alpha_iter_alternate']}\")\n",
    "print(f\"current_iter                       {current_iter  }\")\n",
    "print(f\"current_iter_w                     {current_iter_w}\")\n",
    "print(f\"current_iter_a                     {current_iter_a}\")\n",
    "print(f\"batch_idx_w                        {batch_idx_w}\")\n",
    "print(f\"flag                               {flag          }\")\n",
    "print(f\"train_total_epochs                 {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8a69c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T22:41:10.189643Z",
     "start_time": "2021-12-21T22:41:10.164497Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c31fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T22:58:10.493069Z",
     "start_time": "2021-12-21T22:58:10.469631Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##---------------------------------------------------------------     \n",
    "## Weight / Policy Training\n",
    "##--------------------------------------------------------------- \n",
    "# stop_iter = current_iter_w +  opt['train']['weight_iter_alternate']\n",
    "# print(f\" Current Weight iteration {current_iter_w} - Run  from {current_iter_w+1} to {stop_iter+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee9029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T22:58:12.219746Z",
     "start_time": "2021-12-21T22:58:12.193318Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f076d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T22:58:13.757096Z",
     "start_time": "2021-12-21T22:58:13.731942Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with tnrange(start_iter_t , stop_iter_t  , initial = start_iter_t , total = stop_iter_t, position=0, leave= True, desc=\"master\") as t :\n",
    "# with tqdm_notebook(total=train_total_epochs) as t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d3730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T18:50:23.014384Z",
     "start_time": "2021-12-21T18:50:22.955398Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534cdee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T23:08:28.021068Z",
     "start_time": "2021-12-21T22:59:25.316087Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "curr_epoch = 0\n",
    "main_iter_ctr = 0 \n",
    "verbose = False\n",
    "t = tqdm(total=train_total_epochs, desc=f\" Alternate Weight/Policy training\")\n",
    "\n",
    "while curr_epoch < train_total_epochs:\n",
    "    curr_epoch+=1\n",
    "    t.update(1)\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # Train & Update the network weights\n",
    "    #-----------------------------------------\n",
    "    if flag == 'update_w':\n",
    "        current_iter_w  = 0 \n",
    "        stop_iter_w =   opt['train']['weight_iter_alternate']\n",
    "\n",
    "        with trange(+1, stop_iter_w+1 , initial = current_iter_w, total = stop_iter_w, \n",
    "                     position=0, leave= False, desc=f\"Epoch {curr_epoch} weight training\") as t_weights :\n",
    "            for current_iter_w in t_weights:    \n",
    "                current_iter += 1\n",
    "\n",
    "                start_time = time.time()\n",
    "                environ.train()\n",
    "                \n",
    "#                 if batch_idx_w == len(train1_loader):\n",
    "#                     print_dbg(f\"  Reenumerate train1_loader -  index_w: {batch_idx_w}   len(train1_loader) = {len(train1_loader)} \", verbose)\n",
    "#                     batch_enumerator1 = enumerate(train1_loader,1)    \n",
    "                    \n",
    "                batch = next(train1_loader)\n",
    "                environ.set_inputs(batch, train1_loader.dataset.input_size)\n",
    "\n",
    "                ##----------------------------------------------------------------------\n",
    "                ## Set number of layers to train based on cirriculum_speed \n",
    "                ## and p_epoch (number of epochs of policy training)\n",
    "                ## When curriculum_speed == 3, a num_train_layers is incremented \n",
    "                ## after completion of every 3 policy training epochs\n",
    "                ##----------------------------------------------------------------------\n",
    "                if opt['is_curriculum']:\n",
    "                    num_train_layers = p_epoch // opt['curriculum_speed'] + 1\n",
    "                else:\n",
    "                    num_train_layers = None\n",
    "\n",
    "\n",
    "#                 print_heading(f\"{timestring()} CALL ENVIRON.OPTIMIZE()    current_iter: {current_iter}     flag: {flag}\\n\"\n",
    "#                       f\"{' ':10s} current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#                       f\"{' ':10s} current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \\n\"                          \n",
    "#                       f\"{' ':10s} is_policy: {opt['policy']}     p_epoch: {p_epoch}       num_train_layers: {num_train_layers}\", verbose = False) \n",
    "\n",
    "                environ.optimize(opt['lambdas'], \n",
    "                                 is_policy=opt['policy'], \n",
    "                                 flag=flag, \n",
    "                                 num_train_layers=num_train_layers,\n",
    "                                 hard_sampling=opt['train']['hard_sampling'],\n",
    "                                 verbose = False)\n",
    "\n",
    "                t_weights.set_postfix({'iteration': current_iter, 'Loss': f\"{environ.losses['total']['total'].item():.4f}\" , \n",
    "                                       'row_ids':f\"{batch['row_id'][0]}-{batch['row_id'][-1]}\"})\n",
    "                \n",
    "                if should(current_iter, opt['train']['print_freq']):\n",
    "                    environ.print_loss(current_iter, start_time, title = \"Weight training iteration\", verbose = True)\n",
    "                    environ.resize_results()\n",
    "\n",
    "#                 print_heading(f\"{timestring()} - CONTINUE WEIGHT TRAINING   current_iter: {current_iter}\\n\"\n",
    "#                   f\" current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#                   f\" current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']}\",\n",
    "#                   verbose = False)        \n",
    "\n",
    "        #-------------------------------------------------------\n",
    "        # validation process\n",
    "        #------------------------------------------------------- \n",
    "\n",
    "#         if should(current_iter_w, opt['train']['weight_iter_alternate']): \n",
    "\n",
    "        if (current_iter_w >= stop_iter_w):\n",
    "            environ.eval()\n",
    "            print_dbg(\"++ Weight Training Validation  and then Switch to update_alpha\", verbose = False)\n",
    "\n",
    "            val_metrics = eval_dev(environ, \n",
    "                                  val_loader, \n",
    "                                  opt['tasks'], \n",
    "                                  policy=opt['policy'],\n",
    "                                  num_train_layers=num_train_layers, \n",
    "                                  hard_sampling=opt['train']['hard_sampling'],\n",
    "                                  eval_iter = -1)        \n",
    "\n",
    "            if (verbose):\n",
    "                for t_id, task in enumerate(environ.tasks):\n",
    "                    task_key = f\"task{t_id+1}\"    \n",
    "                    environ.print_metrics(current_iter, start_time, val_metrics[task_key][\"classification_agg\"], title='validation', verbose = verbose)        \n",
    "\n",
    "            environ.save_checkpoint('latest', current_iter)\n",
    "\n",
    "            #----------------------------------------------------------------------------------------------\n",
    "            # if number of iterations completed after the warm up phase is greater than the number of \n",
    "            # (weight/policy alternations) x (cirriculum speed) x (number of layers to be policy trained)\n",
    "            #\n",
    "            # check metrics for improvement, and issue a checkpoint if necessary\n",
    "            #----------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "            if current_iter - opt['train']['warm_up_iters'] >= num_blocks * opt['curriculum_speed'] * \\\n",
    "                    (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate']):\n",
    "                new_value = 0\n",
    "#                 print_heading(f\"  evaluate progress and make checkpoint if necessary.\" , verbose = True)\n",
    "#                 print(f\" current iter                                 : {current_iter} \\n\"\n",
    "#                       f\" opt['train']['warm_up_iters']                : {opt['train']['warm_up_iters']} \\n\"\n",
    "#                       f\" num_blocks                                   : {num_blocks} \\n\"\n",
    "#                       f\" opt['curriculum_speed']                      : {opt['curriculum_speed']}\\n\"\n",
    "#                       f\" opt['train']['weight_iter_alternate']        : {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#                       f\" opt['train']['alpha_iter_alternate']         : {opt['train']['alpha_iter_alternate']}\\n\"\n",
    "#                       f\" alpha_iter_alternate + weight_iter_alternate : {opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate']}\\n\"\n",
    "#                       f\" num_blks * curriculum_speed * (alpha_alternate + weight_alternate): \"\n",
    "#                       f\" {num_blocks * opt['curriculum_speed'] * (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate'])} \\n\"\n",
    "\n",
    "                print(f\"  {current_iter - opt['train']['warm_up_iters']} IS GREATER THAN \"\n",
    "                       f\" {num_blocks * opt['curriculum_speed'] * (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate'])} -- \"\n",
    "                       f\"  evaluate progress and make checkpoint if necessary.\" )            \n",
    "#               ## compare validation metrics against reference metrics.\n",
    "\n",
    "#                 for k in refer_metrics.keys():\n",
    "#                     if k in val_metrics.keys():\n",
    "#                         for kk in val_metrics[k].keys():\n",
    "#                             if not kk in refer_metrics[k].keys():\n",
    "#                                 continue\n",
    "#                             if (k == 'sn' and kk in ['Angle Mean', 'Angle Median']) or (\n",
    "#                                     k == 'depth' and not kk.startswith('sigma')) or (kk == 'err'):\n",
    "#                                 value = refer_metrics[k][kk] / val_metrics[k][kk]\n",
    "#                             else:\n",
    "#                                 value = val_metrics[k][kk] / refer_metrics[k][kk]\n",
    "#                             value = value / len(list(set(val_metrics[k].keys()) & set(refer_metrics[k].keys())))\n",
    "#                             new_value += value\n",
    "\n",
    "#                 print('Best Value %.4f  New value: %.4f' % new_value)\n",
    "\n",
    "                # if results have improved, save these results and issue a checkpoint\n",
    "\n",
    "#                 if (new_value > best_value):\n",
    "#                     print('Previous best iter: %d, best_value: %.4f' % (best_iter, best_value), best_metrics)\n",
    "#                     best_value = new_value\n",
    "#                     best_metrics = val_metrics\n",
    "#                     best_iter = current_iter\n",
    "#                     environ.save_checkpoint('best', current_iter)\n",
    "#                     print('New      best iter: %d, best_value: %.4f' % (best_iter, best_value), best_metrics)                         \n",
    "#                     print('Best Value %.4f  New value: %.4f' % new_value)\n",
    "\n",
    "                # if results have improved, save these results and issue a checkpoint   \n",
    "\n",
    "            environ.train()\n",
    "            #-------------------------------------------------------\n",
    "            # END validation process\n",
    "            #-------------------------------------------------------       \n",
    "            print_heading(f\"{timestring()} - SWITCH TO ALPHA TRAINING    current_iter: {current_iter}\\n\"\n",
    "              f\" current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "              f\" current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']}\",\n",
    "              verbose = False)       \n",
    "            flag = 'update_alpha'\n",
    "            environ.fix_w()\n",
    "            environ.free_alpha()\n",
    "        #-------------------------------------------------------\n",
    "        # end validation process\n",
    "        #-------------------------------------------------------               \n",
    "\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # Train & Update the  policy \n",
    "    #-----------------------------------------\n",
    "    if flag == 'update_alpha':\n",
    "        current_iter_a = 0\n",
    "        stop_iter_a = opt['train']['alpha_iter_alternate']\n",
    "\n",
    "        with trange( +1, stop_iter_a+1 , initial = 0, total = stop_iter_a, \n",
    "                     position=0, leave= False, desc=f\"Epoch {curr_epoch} policy training\") as t_policy :\n",
    "            for current_iter_a in t_policy:    \n",
    "                current_iter += 1\n",
    "\n",
    "#                 batch_idx_a, batch = next(batch_enumerator2)\n",
    "                batch = next(train2_loader)\n",
    "                environ.set_inputs(batch, train2_loader.dataset.input_size)\n",
    "\n",
    "#                 if batch_idx_a == len(train2_loader):\n",
    "#                     print_dbg(f\" Re-enumerate train2_loader  batch_idx_a: {batch_idx_a}   len(train2_loader) = {len(train2_loader)}\", verbose=False)                \n",
    "#                     batch_enumerator2 = enumerate(train2_loader,1)        \n",
    "\n",
    "#                 print_heading(f\"{timestring()} - ENVIRON.OPTIMIZE()    flag: {flag}    current_iter: {current_iter}   \\n\"\n",
    "#                               f\" current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#                               f\" current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \\n\"\n",
    "#                               f\" is_policy: {opt['policy']}   num_train_layers: {num_train_layers}  hard_sampling: {opt['train']['hard_sampling']}\\n\"\n",
    "#                               f\" is_curriculum: {opt['is_curriculum']}     curriculum_speed: {opt['curriculum_speed']}   p_epoch: {p_epoch}\"\n",
    "#                               , verbose = False) \n",
    "\n",
    "                if opt['is_curriculum']:\n",
    "                    num_train_layers = (p_epoch // opt['curriculum_speed']) + 1\n",
    "                else:\n",
    "                    num_train_layers = None\n",
    "\n",
    "                print_dbg(f\" num_train_layers  : {num_train_layers}\", verbose = False)\n",
    "\n",
    "\n",
    "                environ.optimize(opt['lambdas'], \n",
    "                                 is_policy=opt['policy'], \n",
    "                                 flag=flag, \n",
    "                                 num_train_layers=num_train_layers,\n",
    "                                 hard_sampling=opt['train']['hard_sampling'],\n",
    "                                 verbose = False)\n",
    "                \n",
    "                t_policy.set_postfix({'iteration': current_iter, 'Loss': f\"{environ.losses['total']['total'].item():.4f}\" , \n",
    "                                      'row_ids':f\"{batch['row_id'][0]}-{batch['row_id'][-1]}\"})\n",
    "                \n",
    "                if should(current_iter, opt['train']['print_freq']):\n",
    "                    environ.print_loss(current_iter, start_time, title = \"Policy training iteration\", verbose=True)\n",
    "                    environ.resize_results()\n",
    "                    # environ.visual_policy(current_iter)\n",
    "\n",
    "#                 print_heading(f\"{timestring()} - CONTINUE ALPHA TRAINING    current_iter: {current_iter}\\n\"\n",
    "#                               f\"{' ':15s} current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#                               f\"{' ':15s} current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \", \n",
    "#                               verbose = False )      \n",
    "\n",
    "        ## if (current_iter_a % alpha_iter_alternate) == 0 \n",
    "#         if should(current_iter_a, opt['train']['alpha_iter_alternate']):\n",
    "#         print(f\" policy loop ended - current_iter_a: {current_iter_a}   stop_iter_a: {stop_iter_a}\")\n",
    "        if( current_iter_a >= stop_iter_a):            \n",
    "#             print_heading(f\"{timestring()} - SWITCH TO WEIGHT TRAINING  urrent_iter: {current_iter}\\n\"\n",
    "#                           f\"{' ':15s} current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#                           f\"{' ':15s} current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \",\n",
    "#                           verbose = False )       \n",
    "\n",
    "            flag = 'update_w'\n",
    "            environ.fix_alpha()\n",
    "            environ.free_w(opt['fix_BN'])\n",
    "            environ.decay_temperature()\n",
    "\n",
    "            # print the distribution\n",
    "            print_dbg(np.concatenate(environ.get_policy_prob(), axis=-1), verbose = False)\n",
    "            \n",
    "            p_epoch += 1\n",
    "            print_dbg(f\"** p_epoch incremented: {p_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ae87f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T23:20:09.766802Z",
     "start_time": "2021-12-21T23:20:09.716093Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"{opt['train']['Lambda_sharing']:.5e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9f0fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T21:26:17.162189Z",
     "start_time": "2021-12-21T21:26:16.777249Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Previous best iter: %d, best_value: %.4f' % (best_iter, best_value))\n",
    "print(best_metrics)\n",
    "best_value = new_value\n",
    "best_metrics = val_metrics\n",
    "best_iter = current_iter\n",
    "environ.save_checkpoint('best', current_iter)\n",
    "print('New best iter : %d, best_value: %.4f \\n' % (best_iter, best_value))                         \n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f37b2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T21:27:15.488947Z",
     "start_time": "2021-12-21T21:27:15.382938Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.losses['tasks'] = {'total' : torch.tensor(0.0, device  = environ.device, dtype=torch.float64)}\n",
    "# environ.device\n",
    "\n",
    "# print(val_metrics)\n",
    "pp.pprint(environ.losses)\n",
    "# environ.print_loss_2(current_iter, start_time, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b334b1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Policy Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97645f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T06:36:24.639972Z",
     "start_time": "2021-12-18T06:36:24.620024Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(f\" current iter                                 : {current_iter} \\n\"\n",
    "#       f\" opt['train']['warm_up_iters']                : {opt['train']['warm_up_iters']} \\n\"\n",
    "#       f\" num_blocks                                   : {num_blocks} \\n\"\n",
    "#       f\" opt['curriculum_speed']                      : {opt['curriculum_speed']}\\n\"\n",
    "#       f\" opt['train']['weight_iter_alternate']        : {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#       f\" opt['train']['alpha_iter_alternate']         : {opt['train']['alpha_iter_alternate']}\\n\"\n",
    "#       f\" alpha_iter_alternate + weight_iter_alternate : {opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate']}\\n\"\n",
    "#       f\" num_blocks * curriculum_speed * (alpha_iter_alternate + weight_iter_alternate): \\\n",
    "#           {num_blocks * opt['curriculum_speed'] * (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate'])} \\n\"\n",
    "#       f\" IF {current_iter - opt['train']['warm_up_iters']} IS GREATER THAN  ??\"\n",
    "#       f\" {num_blocks * opt['curriculum_speed'] * (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4ff6a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T06:36:36.364353Z",
     "start_time": "2021-12-18T06:36:36.341535Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(f\" task1_logits: {environ.networks['mtl-net'].task1_logits} \\n\")\n",
    "# print(f\" task2_logits: {environ.networks['mtl-net'].task2_logits} \\n\")\n",
    "# print(f\" task3_logits: {environ.networks['mtl-net'].task3_logits} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17dcee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T02:07:18.061296Z",
     "start_time": "2021-12-20T02:07:18.038742Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(current_iter_a , opt['train']['alpha_iter_alternate'],flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e9dc0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T02:07:19.091639Z",
     "start_time": "2021-12-20T02:07:19.060936Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##---------------------------------------------------------------     \n",
    "## part one: warm up\n",
    "##--------------------------------------------------------------- \n",
    "# print(current_iter_a , opt['train']['alpha_iter_alternate'],flag)\n",
    "# stop_iter = current_iter_a +  opt['train']['alpha_iter_alternate']\n",
    "# print(f\" Run iteration {current_iter_a+1} to {stop_iter+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01179d7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T02:16:10.956462Z",
     "start_time": "2021-12-20T02:16:10.915819Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(current_iter_a, stop_iter, flag)\n",
    "# print(current_iter_a , opt['train']['alpha_iter_alternate'],flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8deabd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if flag == 'update_alpha':\n",
    "\n",
    "    stop_iter = current_iter_a +  opt['train']['alpha_iter_alternate']\n",
    "    print(f\" Current Alpha iteration {current_iter_a} - Run  from {current_iter_a+1} to {stop_iter+1}\")\n",
    "    \n",
    "    with tnrange(current_iter_a+1, stop_iter+1 , initial = current_iter_a+1, total = stop_iter+1, position=0, leave= True, desc=\"weight training\") as t :\n",
    "        for current_iter_a in t:    \n",
    "            current_iter += 1\n",
    " \n",
    "            batch_idx_a, batch = next(batch_enumerator2)\n",
    "            environ.set_inputs(batch, train2_loader.dataset.input_size)\n",
    "\n",
    "            if batch_idx_a == len(train2_loader):\n",
    "                print_dbg(f\" Re-enumerate train2_loader  batch_idx_a: {batch_idx_a}   len(train2_loader) = {len(train2_loader)}\", verbose=False)                \n",
    "                batch_enumerator2 = enumerate(train2_loader,1)        \n",
    "                  \n",
    "            print_heading(f\"{timestring()} - ENVIRON.OPTIMIZE()    flag: {flag}    current_iter: {current_iter}   \\n\"\n",
    "                          f\" current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "                          f\" current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \\n\"\n",
    "                          f\" is_policy: {opt['policy']}   num_train_layers: {num_train_layers}  hard_sampling: {opt['train']['hard_sampling']}\\n\"\n",
    "                          f\" is_curriculum: {opt['is_curriculum']}     curriculum_speed: {opt['curriculum_speed']}   p_epoch: {p_epoch}\"\n",
    "                          , verbose = False) \n",
    "    \n",
    "            if opt['is_curriculum']:\n",
    "                num_train_layers = (p_epoch // opt['curriculum_speed']) + 1\n",
    "            else:\n",
    "                num_train_layers = None\n",
    "\n",
    "            print_dbg(f\" num_train_layers  : {num_train_layers}\", verbose = False)\n",
    "\n",
    "\n",
    "            environ.optimize(opt['lambdas'], \n",
    "                             is_policy=opt['policy'], \n",
    "                             flag=flag, \n",
    "                             num_train_layers=num_train_layers,\n",
    "                             hard_sampling=opt['train']['hard_sampling'],\n",
    "                             verbose = False)\n",
    "\n",
    "            if should(current_iter, opt['train']['print_freq']):\n",
    "                environ.print_loss_2(current_iter, start_time, verbose=True)\n",
    "                environ.resize_results()\n",
    "                # environ.visual_policy(current_iter)\n",
    "\n",
    "            print_heading(f\"{timestring()} - CONTINUE ALPHA TRAINING    current_iter: {current_iter}\\n\"\n",
    "                          f\"{' ':15s} current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "                          f\"{' ':15s} current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \", \n",
    "                          verbose = False )      \n",
    "    \n",
    "    ## if (current_iter_a % alpha_iter_alternate) == 0 \n",
    "    if should(current_iter_a, opt['train']['alpha_iter_alternate']):\n",
    "        print_dbg(f\"** Switch training to update_weight\")                \n",
    "        print_heading(f\"{timestring()} - SWITCH TO WEIGHT TRAINING  urrent_iter: {current_iter}\\n\"\n",
    "                      f\"{' ':15s} current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "                      f\"{' ':15s} current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \",\n",
    "                      verbose = True )       \n",
    "        \n",
    "        flag = 'update_w'\n",
    "        environ.fix_alpha()\n",
    "        environ.free_w(opt['fix_BN'])\n",
    "        environ.decay_temperature()\n",
    "\n",
    "        # print the distribution\n",
    "        dists = environ.get_policy_prob()\n",
    "\n",
    "        print(np.concatenate(dists, axis=-1))\n",
    "        p_epoch += 1\n",
    "        print(f\"** p_epoch incremented: {p_epoch}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99efcd5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T04:06:20.995174Z",
     "start_time": "2021-12-21T04:06:20.972230Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(current_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320533e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T21:26:28.603565Z",
     "start_time": "2021-12-21T21:26:28.286326Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\" task1_logits: \\n {environ.networks['mtl-net'].task1_logits.detach().cpu().numpy()} \\n\")\n",
    "print(f\" task2_logits: \\n {environ.networks['mtl-net'].task2_logits.detach().cpu().numpy()} \\n\")\n",
    "print(f\" task3_logits: \\n {environ.networks['mtl-net'].task3_logits.detach().cpu().numpy()} \\n\")\n",
    "print(f\" task1 softmax: \\n {softmax(environ.networks['mtl-net'].task1_logits.detach().cpu().numpy(), axis = -1)} \\n\")\n",
    "print(f\" task2 softmax: \\n {softmax(environ.networks['mtl-net'].task2_logits.detach().cpu().numpy(), axis = -1)} \\n\")\n",
    "print(f\" task3 softmax: \\n {softmax(environ.networks['mtl-net'].task3_logits.detach().cpu().numpy(), axis = -1)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a32b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T00:06:36.002509Z",
     "start_time": "2021-12-17T00:06:35.981793Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for i in [1,2,3]:\n",
    "#     task_pred = f\"task{i}_pred\"\n",
    "#     task_logits = f\"task{i}_logits\"\n",
    "#     policy_attr = f\"policy{i}\"\n",
    "#     logits_attr = f\"logit{i}\"\n",
    "#     print_heading(f\"{task_pred}\")\n",
    "#     print(getattr(environ, task_pred))\n",
    "#     print(policy_attr)\n",
    "#     print(getattr(environ, policy_attr)) \n",
    "#     print(logits_attr)\n",
    "#     print(getattr(environ, logits_attr)) \n",
    "#     print(task_logits)\n",
    "#     print(getattr(environ.networks['mtl-net'], task_logits)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15c1877",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T01:06:53.675694Z",
     "start_time": "2021-12-20T01:06:53.648732Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tqdm.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fce8c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T01:12:07.284532Z",
     "start_time": "2021-12-20T01:12:07.262680Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "current_iter    = 2174\n",
    "current_iter_a  = 348\n",
    "current_iter_w  = 348"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9316b4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Softmax & Gumbel Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62dddc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Softmax, LogSoftMax, NegLogLikelihood and Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f6f68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T00:41:36.552551Z",
     "start_time": "2021-12-17T00:41:36.484747Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# print(nn.CrossEntropyLoss.__doc__)\n",
    "loss = nn.CrossEntropyLoss(reduction ='none')\n",
    "# i1 = torch.randn(3, 5, requires_grad=True)\n",
    "# t1 = torch.empty(3, dtype=torch.long).random_(5)\n",
    "\n",
    "# print(i1)\n",
    "# print(i1)\n",
    "# print(t1)\n",
    "# output = loss(i1, t1)\n",
    "# print(output, output.sum(), output.mean())\n",
    "\n",
    "# i2 = torch.randn(1, 2, requires_grad=True)\n",
    "i0 = torch.tensor([[0.0, 1.0]], dtype=torch.float)\n",
    "i1 = torch.tensor([[1.0, 0.0]], dtype=torch.float)\n",
    "i2 = torch.tensor([[0.5, 0.5]], dtype=torch.float)\n",
    "i3 = torch.tensor([[0.4656, 0.5388]], dtype=torch.float)\n",
    "sm = nn.Softmax(dim =-1)\n",
    "lsm = nn.LogSoftmax(dim = -1)\n",
    "nll = nn.NLLLoss(reduction='none')\n",
    "\n",
    "t1 = torch.tensor([1], dtype=torch.int64)\n",
    "t0 = torch.tensor([0], dtype=torch.int64)\n",
    "t2 = torch.tensor([2], dtype=torch.int64)\n",
    "print('i0     : ', i0)\n",
    "print('sm(i0) : ', sm(i0))\n",
    "print('lsm(i0): ', lsm(i0))\n",
    "print()\n",
    "print('i1     : ', i1)\n",
    "print('sm(i1) : ', sm(i1))\n",
    "print('lsm(i1): ', lsm(i1))\n",
    "print()\n",
    "print('i2     : ', i2)\n",
    "print('sm(i2) : ', sm(i2))\n",
    "print('lsm(i2): ', lsm(i2))\n",
    "print()\n",
    "\n",
    "print('t0: ',t0)\n",
    "print('t1: ',t1)\n",
    "print()\n",
    "output1 = loss(i0, t0)\n",
    "output2 = nll(lsm(i0), t0)\n",
    "print('loss [0,1] and [0] : ', output1)\n",
    "print('nll between lsm(i0): ', output2)\n",
    "print()\n",
    "output1 = loss(i0, t1)\n",
    "output2 = nll(lsm(i0), t1)\n",
    "print('loss [0,1] and [1] : ', output1)\n",
    "print('nll between lsm(i0): ', output2)\n",
    "print()\n",
    "\n",
    "output1 = loss(i1, t0)\n",
    "output2 = nll(lsm(i1), t0)\n",
    "print('loss [1,0] and [0] : ', output1)\n",
    "print('nll between lsm(i1): ', output2)\n",
    "print()\n",
    "\n",
    "output1 = loss(i1, t1)\n",
    "output2 = nll(lsm(i1), t1)\n",
    "print('loss [1,0] and [1] : ', output1)\n",
    "print('nll between lsm(i1): ', output2)\n",
    "print()\n",
    "\n",
    "output1 = loss(i2, t0)\n",
    "output2 = nll(lsm(i2), t0)\n",
    "print('loss [0.5, 0.5] and [0] : ', output1)\n",
    "print('nll between lsm(i1)   and [0] : ', output2)\n",
    "print()\n",
    "\n",
    "output1 = loss(i2, t1)\n",
    "output2 = nll(lsm(i2), t1)\n",
    "print('loss [0.5, 0.5] and [1] : ', output1)\n",
    "print('nll between lsm(i1)   and [1] : ', output2)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b2691",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Gumbel Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46139b4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T22:21:49.726731Z",
     "start_time": "2021-12-03T22:21:49.391724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([[0.5000, 0.5000],\n",
    "        [0.5000, 0.5000],\n",
    "        [0.5000, 0.5000],\n",
    "        [0.5000, 0.5000]], device='cuda:0', requires_grad=True) \n",
    "\n",
    "b = torch.tensor([0.5000, 0.5000,  0.5000, 0.5000], device='cuda:0', requires_grad=True) \n",
    "print(b.shape)\n",
    "c = torch.tensor([[0.000, 0.000,  0.000, 0.000]], device='cuda:0', requires_grad=True) \n",
    "print(c.shape)\n",
    "d = torch.tensor([[0.5000], [0.5000],  [0.5000], [0.5000]], device='cuda:0', requires_grad=True) \n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70dfbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T00:41:45.109937Z",
     "start_time": "2021-12-17T00:41:45.086013Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(i0)\n",
    "print(i1)\n",
    "print(i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cd0c2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T00:52:33.490328Z",
     "start_time": "2021-12-17T00:52:33.457768Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp  = 2.5\n",
    "print(F.gumbel_softmax( i1, temp, hard=False))\n",
    "print(F.gumbel_softmax( i1, temp, hard=False))\n",
    "print(F.gumbel_softmax( i1, temp, hard=False))\n",
    "print()\n",
    "\n",
    "print(F.gumbel_softmax( i2, temp, hard=False))\n",
    "print(F.gumbel_softmax( i2, temp, hard=False))\n",
    "print(F.gumbel_softmax( i2, temp, hard=False))\n",
    "print()\n",
    "\n",
    "print(F.gumbel_softmax( i3, temp, hard=False))\n",
    "print(F.gumbel_softmax( i3, temp, hard=False))\n",
    "print(F.gumbel_softmax( i3, temp, hard=False))\n",
    "# print(F.gumbel_softmax( d, 5, hard=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875518ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:34:54.606453Z",
     "start_time": "2021-12-01T01:34:54.586164Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logits = torch.randn(20, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0890b1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:34:57.902781Z",
     "start_time": "2021-12-01T01:34:57.880455Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(logits[:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85ce6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:44:54.225922Z",
     "start_time": "2021-12-01T01:44:54.204482Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format)\n",
    "print(tmp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac484d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:45:28.342309Z",
     "start_time": "2021-12-01T01:45:28.320145Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(tmp[0])\n",
    "tmp1 = tmp.exponential_()\n",
    "print(tmp1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b9eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:45:55.855272Z",
     "start_time": "2021-12-01T01:45:55.825274Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp2 = tmp1.log()\n",
    "print(tmp2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5db59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:43:07.405165Z",
     "start_time": "2021-12-01T01:43:07.383324Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " gumbels = (\n",
    "        -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format).exponential_().log()\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35984a4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:43:29.214582Z",
     "start_time": "2021-12-01T01:43:29.193794Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(gumbels.shape)\n",
    "print(gumbels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65270223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:35:04.984426Z",
     "start_time": "2021-12-01T01:35:04.949756Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sample soft categorical using reparametrization trick:\n",
    "gumbel_soft = F.gumbel_softmax(logits, tau=1, hard=False)\n",
    "\n",
    "# Sample hard categorical using \"Straight-through\" trick:\n",
    "gumbel_hard  = F.gumbel_softmax(logits, tau=1, hard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b89520b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:37:20.518987Z",
     "start_time": "2021-12-01T01:37:20.490071Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(logits.shape)\n",
    "print(logits[0])\n",
    "print(np.argmax(logits[0]))\n",
    "print('\\n')\n",
    "\n",
    "print(gumbel_soft.shape)\n",
    "print(gumbel_soft[0])\n",
    "print(np.argmax(gumbel_soft[0]))\n",
    "print('\\n')\n",
    "\n",
    "print(gumbel_hard.shape)\n",
    "print(gumbel_hard[0])\n",
    "print(np.argmax(gumbel_hard[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b49944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:11.889231Z",
     "start_time": "2021-12-01T01:47:11.865177Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gumbel_soft.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8b677",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:20.629635Z",
     "start_time": "2021-12-01T01:47:20.607058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tau = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2376a731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:21.278402Z",
     "start_time": "2021-12-01T01:47:21.254276Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = torch.empty_like(logits, memory_format=torch.legacy_contiguous_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb14b3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:21.920473Z",
     "start_time": "2021-12-01T01:47:21.899432Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e5688",
   "metadata": {
    "hidden": true
   },
   "source": [
    "fill tensor `a` with elements drawn from exponential distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636a394",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:32.866091Z",
     "start_time": "2021-12-01T01:47:32.838226Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a_e = a.exponential_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e5bfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:34.003871Z",
     "start_time": "2021-12-01T01:47:33.978450Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a_e[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682752d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "draw natural log `ln()` on elements of a_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8f568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:47.286259Z",
     "start_time": "2021-12-01T01:47:47.265716Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a_e_l = a_e.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a46e180",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:47.554155Z",
     "start_time": "2021-12-01T01:47:47.532995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a_e_l[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f86dab1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Neg log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841bf82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:51.788290Z",
     "start_time": "2021-12-01T01:47:51.763038Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a_el_neg = -a_e_l\n",
    "\n",
    "a_el_neg[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c991926d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:48:08.613360Z",
     "start_time": "2021-12-01T01:48:08.591331Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logits[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2849ed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:48:09.724747Z",
     "start_time": "2021-12-01T01:48:09.701886Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gumbels = (logits + a_el_neg) / tau \n",
    "\n",
    "gumbels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828b2b74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:48:14.682363Z",
     "start_time": "2021-12-01T01:48:14.660407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dim = -1\n",
    "gumbels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28f692",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:48:15.779652Z",
     "start_time": "2021-12-01T01:48:15.758743Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " y_soft = gumbels.softmax(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09316403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:48:17.797567Z",
     "start_time": "2021-12-01T01:48:17.776922Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_soft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09910a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:48:19.084522Z",
     "start_time": "2021-12-01T01:48:19.062543Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_soft[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a373cb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T21:41:56.235154Z",
     "start_time": "2021-09-22T21:41:56.228186Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "index = y_soft.max(dim, keepdim=True)\n",
    "print(index[0].T)\n",
    "print(index[1].T)\n",
    "y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index[1], 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6dc2ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T21:42:54.751798Z",
     "start_time": "2021-09-22T21:42:54.744929Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.argmax(y_hard,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3e1f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T03:43:17.720809Z",
     "start_time": "2021-09-24T03:43:17.662341Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp_d= [0,1,0]\n",
    "for i in range(10):\n",
    "    sampled = np.random.choice((2, 1, 0), p=tmp_d)\n",
    "    print(sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0baccc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Scratch Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1716e81d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T08:43:47.166466Z",
     "start_time": "2022-01-12T08:43:47.133961Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:12.104370Z",
     "iopub.status.busy": "2022-01-07T22:44:12.103595Z",
     "iopub.status.idle": "2022-01-07T22:44:12.133070Z",
     "shell.execute_reply": "2022-01-07T22:44:12.131731Z",
     "shell.execute_reply.started": "2022-01-07T22:44:12.104302Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from numba import cuda\n",
    "\n",
    "# cuda_device = 0 \n",
    "\n",
    "# def free_gpu_cache(cuda_device):\n",
    "#     print(\"Initial GPU Usage\")    \n",
    "#     gpu_usage()                             \n",
    "#     print(\"GPU Usage after emptying the cache\")\n",
    "#     gpu_usage()\n",
    "#     print(\"CUDA empty cache\")\n",
    "#     torch.cuda.empty_cache()\n",
    "#     print(\"Close and reopen device\")\n",
    "#     cuda.select_device(cuda_device)\n",
    "#     print(\"Close device\")    \n",
    "#     cuda.close()\n",
    "#     print(\"Reopen device\")    \n",
    "#     cuda.select_device(cuda_device)\n",
    "#     print(\"GPU Usage after closing and reopening\")\n",
    "#     gpu_usage()\n",
    "\n",
    "# free_gpu_cache(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81188503",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T21:45:43.118975Z",
     "start_time": "2022-01-07T21:45:43.089201Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def print_separator(text, total_len=50):\n",
    "#     print('#' * total_len)\n",
    "#     left_width = (total_len - len(text))//2\n",
    "#     right_width = total_len - len(text) - left_width\n",
    "#     print(\"#\" * left_width + text + \"#\" * right_width)\n",
    "#     print('#' * total_len)\n",
    "\n",
    "# def print_dbg(text, verbose = False):\n",
    "#     if verbose:\n",
    "#         print(text)\n",
    "\n",
    "# @debug_off\n",
    "# def print_heading(text,  verbose = False):\n",
    "#     len_ttl = max(len(text)+4, 50)\n",
    "#     if verbose:\n",
    "#         print('-' * len_ttl)\n",
    "#         print(f\" {text}\")\n",
    "#         # left_width = (total_len - len(text))//2\n",
    "#         # right_width = total_len - len(text) - left_width\n",
    "#         # print(\"#\" * left_width + text + \"#\" * right_width)\n",
    "#         print('-' * len_ttl,'\\n')\n",
    "\n",
    "# print_heading(\"hello_kevin\", verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f559c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Chembl Data feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a1002b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:06:53.545985Z",
     "start_time": "2022-01-12T17:06:53.520879Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.909003Z",
     "iopub.status.busy": "2022-01-07T22:44:13.907310Z",
     "iopub.status.idle": "2022-01-07T22:44:13.953692Z",
     "shell.execute_reply": "2022-01-07T22:44:13.952354Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.908963Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dataroot = opt['dataload']['dataroot']\n",
    "# ecfp     = load_sparse(dataroot, opt['dataload']['x'])\n",
    "\n",
    "# total_input = ecfp.shape[0]\n",
    "# ranges      = (np.cumsum([0]+opt['dataload']['x_split_ratios'])* total_input).astype(np.int32)\n",
    "\n",
    "\n",
    "# idx_train  = np.arange(ranges[0], ranges[1])\n",
    "# idx_train1 = np.arange(ranges[1], ranges[2])\n",
    "# idx_train2 = np.arange(ranges[2], ranges[3])\n",
    "# idx_val    = np.arange(ranges[3], ranges[4])\n",
    "\n",
    "# print(f\" Total input    :  {total_input}   Cummulative dataset sizes: {ranges}\")\n",
    "# print(f\" Ranges         :  {ranges}\")\n",
    "# print()\n",
    "# print(f\" X Dataset      :  {os.path.join(opt['dataload']['dataroot'], opt['dataload']['x'])}\")\n",
    "# print(f\" y Dataset      :  {os.path.join(opt['dataload']['dataroot'], opt['dataload']['y_tasks'][0])}\")\n",
    "# print(f\" Folding Dataset:  {os.path.join(opt['dataload']['dataroot'], opt['dataload']['folding'])}\")\n",
    "# print(f\" Weights_class  :  {opt['dataload']['weights_class']}\")\n",
    "# print()\n",
    "# print(f' idx_train    dataset size: {len(idx_train)  :6d}  - rows: {(idx_train)} ')\n",
    "# print(f' idx_train1   dataset size: {len(idx_train1) :6d}  - rows: {(idx_train1)} ')\n",
    "# print(f' idx_train2   dataset size: {len(idx_train2) :6d}  - rows: {(idx_train2)} ')\n",
    "# print(f' val_train    dataset size: {len(idx_val)    :6d}  - rows: {(idx_val)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6083b24",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Test dataloader output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eddc639f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T02:25:55.121332Z",
     "start_time": "2022-01-07T02:25:55.026894Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# val_batch_idx, val_batch = next(val_enumerator)\n",
    "# print(type(val_batch['row_id']),val_batch['row_id'][0], val_batch['row_id'][-1] )\n",
    "\n",
    "# ctr = 0\n",
    "# for i in range(100):\n",
    "#     val_batch_1 = next(val_loader)\n",
    "#     print(' iteration: ', ctr,' len: ', len(val_batch_1['row_id']),'start: [', val_batch_1['row_id'][0],   val_batch_1['row_id'][-1],']' )\n",
    "#     ctr += 1\n",
    "\n",
    "# ctr = 0    \n",
    "# for val_batch_1 in iter(val_loader):\n",
    "# #     val_batch_1 = next(val_loader)\n",
    "#     print(' iteration: ', ctr,' len: ', len(val_batch_1['row_id']),'start: [', val_batch_1['row_id'][0],   val_batch_1['row_id'][-1],']' )\n",
    "#     ctr += 1    \n",
    "#     if ctr == 105:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e60b2eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T02:25:55.212013Z",
     "start_time": "2022-01-07T02:25:55.124386Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# val_batch_1 = next(val_iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acf2511b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T02:25:55.240326Z",
     "start_time": "2022-01-07T02:25:55.216394Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#  batch_idx, batch = next(batch_enumerator)\n",
    "\n",
    "# print(batch.keys())\n",
    "# print(batch['x_ind'].shape)\n",
    "# print(type(batch['batch_size']))\n",
    "# for i in batch.keys():\n",
    "#     if not isinstance(batch[i], int):\n",
    "#         print(i, batch[i].shape)\n",
    "\n",
    "# task0_Y =  torch.sparse_coo_tensor(\n",
    "#         batch[\"task0_ind\"],\n",
    "#         batch[\"task0_data\"],\n",
    "#         size = [batch[\"batch_size\"], 5]).to(\"cpu\", non_blocking=True).to_dense().numpy()\n",
    "\n",
    "# print(task0_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7991589c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T02:25:55.275968Z",
     "start_time": "2022-01-07T02:25:55.244246Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(f\" train_loader: dataset input size       :  {train_loader.dataset.input_size}\")\n",
    "# print(f\" train_loader: class output size        :  {train_loader.dataset.class_output_size}\")\n",
    "# print()\n",
    "# print(f\" size of training set 0 (warm up)       :  {len(trainset)}\")\n",
    "# print(f\" size of training set 1 (network parms) :  {len(trainset1)}\")\n",
    "# print(f\" size of training set 2 (policy weights):  {len(trainset2)}\")\n",
    "# print(f\" size of validation set                 :  {len(valset)}\")\n",
    "# print(f\"                                Total   :  {len(trainset)+len(trainset1)+len(trainset2)+len(valset)}\")\n",
    "\n",
    "# print(f\" batch size       : {opt['train']['batch_size']}\")\n",
    "# print(f' len train_loader : {len(train_loader)}')\n",
    "# print(f' len train1_loader: {len(train1_loader)}')\n",
    "# print(f' len train2_loader: {len(train2_loader)}')\n",
    "# print(f' len val_loader   : {len(val_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4bc41",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d5a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T22:42:25.945090Z",
     "start_time": "2021-12-20T22:42:25.917655Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tnrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49b9f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T22:41:50.353599Z",
     "start_time": "2021-12-20T22:41:50.331414Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "curr_iter_t  = 0\n",
    "curr_iter_a  = 0\n",
    "curr_iter_w  = 0\n",
    "stop_iter_t  = 0\n",
    "stop_iter_w  = 0 \n",
    "stop_iter_a  = 0\n",
    "total_weight_epochs = 0\n",
    "total_policy_epochs = 0 \n",
    "train_total_iters = 8\n",
    "weight_iter_alternate = 17\n",
    "alpha_iter_alternate = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7018b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T22:41:50.588581Z",
     "start_time": "2021-12-20T22:41:50.555942Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(curr_iter_t, stop_iter_t, flag, train_total_iters,opt['train']['print_freq'] )\n",
    "start_iter_t = curr_iter_t\n",
    "stop_iter_t = curr_iter_t +  train_total_iters \n",
    "print(f\" Current iteration {curr_iter_t} - Run  from {start_iter_t} to {stop_iter_t}\")\n",
    "\n",
    "print(curr_iter_w, weight_iter_alternate , flag)\n",
    "stop_iter_w = curr_iter_w +  weight_iter_alternate \n",
    "print(f\" Current Weight iteration {curr_iter_w} - Run  from {curr_iter_w+1} to {stop_iter_w}\")\n",
    "\n",
    "\n",
    "print(curr_iter_a ,  alpha_iter_alternate ,flag)\n",
    "stop_iter_a = curr_iter_a +  alpha_iter_alternate \n",
    "print(f\" Current alpha iteration {curr_iter_a} - Run  from {curr_iter_a+1} to {stop_iter_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839ecee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T22:37:56.218327Z",
     "start_time": "2021-12-20T22:37:10.168700Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# del t, t_w, t_a\n",
    "main_iter_ctr = 0 \n",
    "with tnrange(start_iter_t , stop_iter_t  , initial = start_iter_t , total = stop_iter_t, position=0, leave= True, desc=\"master\") as t :\n",
    "    for curr_t in t:\n",
    "        \n",
    "        with  tnrange(0, weight_iter_alternate , initial = 0, total = weight_iter_alternate, \n",
    "                      position=1, leave= False, desc=f\"epoch {curr_t} weight training\") as t_w :\n",
    "            for curr_w in t_w:    \n",
    "                sleep(0.35)\n",
    "                main_iter_ctr += 1\n",
    "                curr_iter_w  = curr_w\n",
    "                t.set_postfix({'epoch': f\"{curr_t}/{train_total_iters}\", 'main_iter_ctr': main_iter_ctr})\n",
    "                t_w.set_postfix({'weight training epoch': curr_t, 'batch #': curr_iter_w})\n",
    "\n",
    "            print(f\"** Epoch {curr_t}/{train_total_iters} weight training complete - Loss: \"\n",
    "                  f\"curr_w:{curr_w}    curr_iter_w:{curr_iter_w}  curr_t:{curr_t}  main_iter_ctr:{main_iter_ctr}\" )\n",
    "                 \n",
    "        \n",
    "        with  tnrange(0, alpha_iter_alternate  , initial = 0, total = alpha_iter_alternate , \n",
    "                      position=2, leave= False, desc=f\"epoch {curr_t} policy training\") as t_a :\n",
    "            for curr_a in t_a:    \n",
    "                sleep(0.35)\n",
    "                main_iter_ctr += 1                \n",
    "                curr_iter_a = curr_a\n",
    "                t.set_postfix({'epoch': f\"{curr_t}/{train_total_iters}\", 'main_iter_ctr':main_iter_ctr})\n",
    "                t_a.set_postfix({'policy training epoch': curr_t, 'batch #': curr_iter_a})            \n",
    "                \n",
    "            print(f\"** Epoch {curr_t}/{train_total_iters} policy training complete - Loss: \"\n",
    "                  f\"curr_w:{curr_w}    curr_iter_w:{curr_iter_w}  curr_t:{curr_t}  main_iter_ctr:{main_iter_ctr}\" )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb2c8ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T23:04:03.776382Z",
     "start_time": "2021-12-20T23:04:03.746093Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "curr_iter_t  = 0\n",
    "curr_iter_a  = 0\n",
    "curr_iter_w  = 0\n",
    "stop_iter_t  = 0\n",
    "stop_iter_w  = 0 \n",
    "stop_iter_a  = 0\n",
    "total_weight_epochs = 0\n",
    "total_policy_epochs = 0 \n",
    "train_total_iters = 100\n",
    "train_total_epochs = 10\n",
    "weight_iter_alternate = 17\n",
    "alpha_iter_alternate = 17\n",
    "\n",
    "print(curr_iter_t, stop_iter_t, flag, train_total_iters,opt['train']['print_freq'] )\n",
    "start_iter_t = curr_iter_t\n",
    "stop_iter_t = curr_iter_t +  train_total_iters \n",
    "print(f\" Current iteration {curr_iter_t} - Run  from {start_iter_t} to {stop_iter_t}\")\n",
    "\n",
    "print(curr_iter_w, weight_iter_alternate , flag)\n",
    "stop_iter_w = curr_iter_w +  weight_iter_alternate \n",
    "print(f\" Current Weight iteration {curr_iter_w} - Run  from {curr_iter_w+1} to {stop_iter_w}\")\n",
    "\n",
    "\n",
    "print(curr_iter_a ,  alpha_iter_alternate ,flag)\n",
    "stop_iter_a = curr_iter_a +  alpha_iter_alternate \n",
    "print(f\" Current alpha iteration {curr_iter_a} - Run  from {curr_iter_a+1} to {stop_iter_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aba7fb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T23:08:57.280036Z",
     "start_time": "2021-12-20T23:08:41.214078Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# del t, t_w, t_a\n",
    "curr_epoch = 0\n",
    "main_iter_ctr = 0 \n",
    "# with tnrange(start_iter_t , stop_iter_t  , initial = start_iter_t , total = stop_iter_t, position=0, leave= True, desc=\"master\") as t :\n",
    "# with tqdm_notebook(total=train_total_epochs) as t:\n",
    "t = tqdm_notebook(total=train_total_epochs)\n",
    "\n",
    "while curr_epoch < train_total_epochs:\n",
    "    curr_epoch+=1\n",
    "    t.update(1)\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # Train & Update the network weights\n",
    "    #-----------------------------------------        \n",
    "    with  tnrange(0, weight_iter_alternate , initial = 0, total = weight_iter_alternate, \n",
    "                  position=1, leave= False, desc=f\"epoch {curr_epoch} weight training\") as t_w :\n",
    "        for curr_w in t_w:    \n",
    "            sleep(0.35)\n",
    "            main_iter_ctr += 1\n",
    "            curr_iter_w  = curr_w\n",
    "\n",
    "            t.set_postfix({'epoch': f\"{curr_epoch}/{train_total_epochs}\", 'main_iter_ctr': main_iter_ctr})\n",
    "            t_w.set_postfix({'weight training epoch': curr_epoch, 'batch #': curr_iter_w})\n",
    "\n",
    "        tqdm.write(f\"** Epoch {curr_epoch}/{train_total_epochs} weight training complete - Loss: \"\n",
    "              f\"curr_w:{curr_w}    curr_iter_w:{curr_iter_w}  curr_epoch:{curr_epoch}  main_iter_ctr:{main_iter_ctr}\" )\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # Train & Update the  policy \n",
    "    #-----------------------------------------        \n",
    "    with  tnrange(0, alpha_iter_alternate  , initial = 0, total = alpha_iter_alternate , \n",
    "                  position=2, leave= False, desc=f\"epoch {curr_epoch} policy training\") as t_a :\n",
    "        for curr_a in t_a:    \n",
    "            sleep(0.35)\n",
    "            main_iter_ctr += 1                \n",
    "            curr_iter_a = curr_a\n",
    "\n",
    "            t.set_postfix({'epoch': f\"{curr_epoch}/{train_total_epochs}\", 'main_iter_ctr':main_iter_ctr})\n",
    "            t_a.set_postfix({'policy training epoch': curr_epoch, 'batch #': curr_iter_a})            \n",
    "\n",
    "        tqdm.write(f\"** Epoch {curr_epoch}/{train_total_epochs} policy training complete - Loss: \"\n",
    "              f\"curr_w:{curr_w}    curr_iter_w:{curr_iter_w}  curr_epoch:{curr_epoch}  main_iter_ctr:{main_iter_ctr}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141aa027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T22:11:57.104094Z",
     "start_time": "2021-12-20T22:11:57.081272Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with tnrange(start_iter, stop_iter , initial = current_iter_w, total = stop_iter,  position=0, leave= True, desc=\"training\") as t:\n",
    "#     for current_iter_w in t:\n",
    "#         print(current_iter_w)\n",
    "#         current_iter_w += 1\n",
    "#         print(current_iter_w)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3dbaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T21:23:27.031154Z",
     "start_time": "2021-12-15T21:23:27.007124Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# start = current_iter\n",
    "# end = current_iter + opt['train']['warm_up_iters']\n",
    "# curr_range = range(start,end)\n",
    "# print(start, end)\n",
    "\n",
    "# for i in tqdm.notebook.tnrange(start, end, initial = start, total = end):\n",
    "#     sleep(0.25)\n",
    "#     current_iter += 1\n",
    "# #     print(i)\n",
    "#     pass\n",
    "\n",
    "# print(current_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d53f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T21:23:27.061710Z",
     "start_time": "2021-12-15T21:23:27.035963Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# start = current_iter\n",
    "# end = current_iter + opt['train']['warm_up_iters']\n",
    "# curr_range = range(start,end)\n",
    "# print(start, end)\n",
    "\n",
    "# for i in tqdm.notebook.tqdm_notebook(cur_range, initial = start, total = end, disable=False, position=0, desc = \"validation\"):\n",
    "#     current_iter += 1\n",
    "#     pass\n",
    "\n",
    "# print(current_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a0cd55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T20:40:03.819876Z",
     "start_time": "2021-12-14T20:40:03.768686Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from tqdm import trange\n",
    "# from time import sleep\n",
    "\n",
    "# for i in trange(40, desc='1st loop', position=0, leave = False):\n",
    "#     sleep(1.1)\n",
    "#     for j in trange(5, desc='2nd loop', position =1, leave = False):\n",
    "#         sleep(0.01)\n",
    "#         for k in trange(50, desc='3rd loop', position =0,leave=False):\n",
    "#             sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92f08b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T18:51:59.433086Z",
     "start_time": "2021-12-15T18:51:59.396500Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with tqdm(batch_enumerator, leave=False, disable=False) as t:\n",
    "# with tqdm(total=10, bar_format=\"{postfix[0]} {postfix[1][value]:>8.2g}\", postfix=[\"Batch\", dict(value=0)]) as t:\n",
    "# with trange(opt['train']['warm_up_iters'], bar_format=\"{postfix[0]} {postfix[1][value]:>8.2g}\", postfix=[\"Batch\", dict(value=0)]) as t:\n",
    "# with trange(opt['train']['warm_up_iters']) as t:\n",
    "\n",
    "#     for current_iter in t:\n",
    "#         batch_idx, batch = next(batch_enumerator)\n",
    "#         ran = random.randint(1, 100)\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         environ.train()\n",
    "\n",
    "#         print_heading(f\" {timestring()} - WARMUP Training iter {current_iter}/{opt['train']['warm_up_iters']}    batch_idx: {batch_idx}\"    \n",
    "#                       f\"    Warm-up iters: {opt['train']['warm_up_iters']}\"\n",
    "#                       f\"    Validation freq:  {opt['train']['val_freq']}\", verbose = False)\n",
    "\n",
    "#         if batch_idx == len(train_loader) :\n",
    "#     #         print_heading(f\" ******* {timestring()}  re-enumerate train_loader() *******\")\n",
    "#             batch_enumerator = enumerate(train_loader,1)   \n",
    "\n",
    "#         t.set_postfix({'batch_idx': batch_idx, 'num_vowels': ran})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2fee04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T18:51:59.469748Z",
     "start_time": "2021-12-15T18:51:59.436522Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import tqdm.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0868106a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:34:45.617713Z",
     "start_time": "2021-12-01T01:34:45.588274Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3,4,5,6,7,8,9,10],[11,12,13,14,15,16,17,18,19,20]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15829f38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:34:46.630947Z",
     "start_time": "2021-12-01T01:34:46.608486Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(a[:,::-1])\n",
    "print()\n",
    "print(a[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9215987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:34:53.104308Z",
     "start_time": "2021-12-01T01:34:53.081558Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = 4\n",
    "b = 4\n",
    "c = 1\n",
    "\n",
    "0 // b + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3f558",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Scipy Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1d7fdde1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T18:43:27.323846Z",
     "start_time": "2022-01-11T18:43:27.180307Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created y_class # dims: 2    shape: (15, 1)\n",
      "Created y_2 # dims: 2    shape: (15, 0)\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "row = np.array([5])\n",
    "col = np.array([0])\n",
    "data = np.array([6])\n",
    "y_class = scipy.sparse.csr_matrix((data, (row, col)), shape=(15,1))\n",
    "y_2 = scipy.sparse.csr_matrix((15,0))\n",
    "print(f\"Created y_class # dims: {y_class.ndim}    shape: {y_class.shape}\")\n",
    "print(f\"Created y_2 # dims: {y_2.ndim}    shape: {y_2.shape}\")\n",
    "\n",
    "# y_class[5]= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcabda9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T20:34:45.811804Z",
     "start_time": "2021-09-24T20:34:45.795397Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(y_class.toarray().T)\n",
    "print(y_2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c27bf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T20:33:18.869928Z",
     "start_time": "2021-09-24T20:33:18.853474Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_class[8,0]= 999\n",
    "y_class.toarray().squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1e9591",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### folding step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de820ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T17:03:43.426753Z",
     "start_time": "2021-11-03T17:03:43.366179Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_dev = copy.copy(x_file)\n",
    "print(x_dev.shape, type(x_dev))\n",
    "\n",
    "idx = x_dev.nonzero()\n",
    "print(idx[0][:82])\n",
    "print(idx[1][:82])\n",
    "print(x_dev[0].sum(), x_dev[1].sum())\n",
    "print(x_dev[0,0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3fd2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T17:03:43.639800Z",
     "start_time": "2021-11-03T17:03:43.592684Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folding_size = 30\n",
    "print(f\" fold - folding_size:{folding_size}\" )\n",
    "\n",
    "## collapse x into folding_size columns\n",
    "idx = x_dev.nonzero()\n",
    "folded = idx[1] % folding_size\n",
    "\n",
    "print(folded[:82])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc03a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T17:03:43.985453Z",
     "start_time": "2021-11-03T17:03:43.884440Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_fold = scipy.sparse.csr_matrix((x_dev.data, (idx[0], folded)), shape=(x_dev.shape[0], folding_size))\n",
    "print(x_fold.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44a0df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T17:03:44.191775Z",
     "start_time": "2021-11-03T17:03:44.177092Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_fold.sum_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d88c71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T17:03:44.485347Z",
     "start_time": "2021-11-03T17:03:44.465953Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d2f64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T17:03:44.739813Z",
     "start_time": "2021-11-03T17:03:44.721549Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(type(y_files[0]), type(y_class[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630d7163",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Torch tensor manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cc7205de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T21:49:34.676799Z",
     "start_time": "2022-01-11T21:49:34.654094Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# a = np.random.rand(4,3)\n",
    "# print(a.shape)\n",
    "# print(a)\n",
    "# rows = [1,3,2,0,2]\n",
    "# cols = [0,0,1,2,2]\n",
    "# a1 = a[rows,cols]\n",
    "# print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "44c7858d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T21:49:34.676799Z",
     "start_time": "2022-01-11T21:49:34.654094Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# a = torch.randn(64, 3, 16, 16)\n",
    "# print(a.shape, a.view(-1).shape, a.permute(0,2,3,1).shape)\n",
    "# b = torch.randint(0,2, [64,3,16,16])\n",
    "# print(b.shape, b.view(-1).shape, b.permute(0,2,3,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d3c6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T03:44:12.409875Z",
     "start_time": "2021-09-24T03:44:12.395721Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873b312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T03:44:14.996701Z",
     "start_time": "2021-09-24T03:44:14.978676Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459af2cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T03:48:01.639457Z",
     "start_time": "2021-09-24T03:48:01.623099Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input.contiguous().view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392718ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e478262b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b29ff118",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### using eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd00a86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:14:03.644641Z",
     "start_time": "2021-11-30T21:14:03.622475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(opt['dataload']['y_tasks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377aa7bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T08:07:39.604778Z",
     "start_time": "2021-10-27T08:07:39.579603Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task1 = [1,2,3]\n",
    "task2 = None\n",
    "task3 = {'4': 'Kevin', '5':'Bardool'}\n",
    "\n",
    "for i in [1,2,3]:\n",
    "    print('task{:d}'.format(i))\n",
    "    if eval('task{:d}'.format(i)) is None:\n",
    "        print('task{:d} :  has not been defined '.format(i))\n",
    "#         exec_str = 'task{:d} =  np.random.rand({:d},{:d})'.format(i,3,2)\n",
    "        exec_str = 'y_task{:d} = scipy.sparse.csr_matrix(({:d}, {:d})) '.format(i,3,2)\n",
    "        print(exec_str)\n",
    "        exec(exec_str)\n",
    "        print('task{:d} : '.format(i), eval('task{:d}'.format(i)))\n",
    "        print(eval('type(task{:d})'.format(i)))\n",
    "    else:\n",
    "        print('task{:d} : '.format(i), eval('task{:d}'.format(i)))\n",
    "        \n",
    "print(f\"Created task{i} shape        : {eval('len(task{:d})'.format(i))}\")\n",
    "print(len(task3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce01f48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T08:07:44.515337Z",
     "start_time": "2021-10-27T08:07:44.497413Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = np.random.rand(3,2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef347b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T08:07:46.338515Z",
     "start_time": "2021-10-27T08:07:46.319087Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(eval('len(task{:d})'.format(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdd594",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load datasets, perform folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd1116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T20:25:56.648521Z",
     "start_time": "2021-12-01T20:25:56.626710Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Verify presence of Y label data\n",
    "if (opt['dataload']['y_tasks'] is None) and (opt['dataload']['y_regr'] is None):\n",
    "   raise ValueError(\"No label data specified, please add --y_class and/or --y_regr.\")\n",
    "\n",
    "print(os.path.join(opt['dataload']['dataroot'], opt['dataload']['x']))  \n",
    "print(os.path.join(opt['dataload']['dataroot'], opt['dataload']['folding']))\n",
    "for fl in opt['dataload']['y_tasks']:\n",
    "    print(os.path.join(opt['dataload']['dataroot'], fl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ca3c95",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Load X data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd31c4c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T20:26:58.627148Z",
     "start_time": "2021-12-01T20:26:58.580407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Load data files \n",
    "##\n",
    "# ecfp     = sc.load_sparse(args.x)\n",
    "# y_class  = sc.load_sparse(args.y_class)\n",
    "# y_regr   = sc.load_sparse(args.y_regr)\n",
    "# y_censor = sc.load_sparse(args.y_censor)\n",
    "\n",
    "dataroot = opt['dataload']['dataroot']\n",
    "\n",
    "ecfp     = load_sparse(dataroot, opt['dataload']['x'])\n",
    "# x_file   = copy.copy(ecfp)\n",
    "\n",
    "print(f\" Input    {opt['dataload']['x']} - type : {type(ecfp)} shape : {ecfp.shape}\")\n",
    "# print(f\" Input    {opt['dataload']['x']} - type : {type(x_file)} shape : {x_file.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe1168",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Load Y label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948aed46",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4730a3ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T20:43:36.174351Z",
     "start_time": "2021-11-30T20:43:36.139816Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i,( y_task, y_type )in enumerate(zip(opt['dataload']['y_tasks'],opt['sc_tasks']),1):\n",
    "    print(full_path := os.path.join(dataroot, y_task ))\n",
    "    tmp = load_sparse(full_path)\n",
    "#     np.load(full_path, allow_pickle=True) \n",
    "#     print(type(tmp), tmp.shape)\n",
    "#     tmp_sparse = scipy.sparse.csr_matrix(tmp)\n",
    "    print(type(tmp_sparse), tmp_sparse.shape)\n",
    "    print('indicies: ', len(tmp_sparse.__dict__['indices']), tmp_sparse.__dict__['indices'])\n",
    "    print('indptr  : ', len(tmp_sparse.__dict__['indptr']) , tmp_sparse.__dict__['indptr'])\n",
    "    print('data    : ', len(tmp_sparse.__dict__['data'])   , tmp_sparse.__dict__['data'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e32cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:06:33.745342Z",
     "start_time": "2021-11-30T21:06:33.703310Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# y_class  = load_sparse(dataroot, opt['dataload']['y_tasks'][0])\n",
    "# print(f\" Input     - type : {type(y_class)} shape : {y_class.shape}\")\n",
    "\n",
    "# y_regr  = load_sparse(dataroot, opt['dataload']['y_tasks'][1])\n",
    "# print(f\" Input     - type : {type(y_regr)} shape : {y_regr.shape}\")\n",
    "\n",
    "##\n",
    "## Load Y label files \n",
    "##\n",
    "y_files=[]\n",
    "\n",
    "for i,( y_task, y_type )in enumerate(zip(opt['dataload']['y_tasks'],opt['sc_tasks']),1):\n",
    "    y_tmp = load_sparse(dataroot,  y_task)\n",
    "    print(f\" y_task:{i}  task type: {y_type:5s}  dataset: {y_task} - type : {type(y_tmp)} shape : {y_tmp.shape}\")\n",
    "    ## Get number of positive / neg and total for each classes\n",
    "    num_pos    = np.array((y_tmp == +1).sum(0)).flatten()\n",
    "    num_neg    = np.array((y_tmp == -1).sum(0)).flatten()\n",
    "    num_class  = np.array((y_tmp !=  0).sum(0)).flatten()\n",
    "    if (num_class != num_pos + num_neg).any():\n",
    "        raise ValueError(\"For classification all y values (--y_class/--y) must be 1 or -1.\")\n",
    "    else:\n",
    "        y_files.append(y_tmp)\n",
    "\n",
    "y_class = copy.copy(y_files[0])\n",
    "# y_regr = copy.copy(y_files[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31defb05",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Load folding file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d2773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:06:35.307158Z",
     "start_time": "2021-11-30T21:06:35.285431Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## load folding file\n",
    "##\n",
    "folding_file = os.path.join(dataroot,opt['dataload']['folding'])\n",
    "folding  = np.load(folding_file)\n",
    "print(f\" Folding  {folding_file} - type : {type(folding)} shape : {folding.shape}\")\n",
    "print(f\"          {folding[:20]}\")\n",
    "\n",
    "assert ecfp.shape[0] == folding.shape[0], \"x and folding must have same number of rows\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773adb77",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Load Y censor file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a00530d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T18:42:45.238543Z",
     "start_time": "2021-11-25T18:42:45.220911Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# y_censor = load_sparse(dataroot, opt['dataload']['y_censor'])\n",
    "# if y_censor is not None:\n",
    "#     print(f\" Input     - type : {type(y_censor)} shape : {y_censor.shape}\") \n",
    "\n",
    "##\n",
    "## Load Y censor file\n",
    "##\n",
    "\n",
    "# y_censor = load_sparse(dataroot, opt['dataload']['y_censor'])\n",
    "# if y_censor is None:\n",
    "#     y_censor = scipy.sparse.csr_matrix(y_regr.shape)\n",
    "#     vprint(f\" y_sensor is {opt['dataload']['y_censor']}   Created y_censor shape       : {y_censor.shape}\")\n",
    "    \n",
    "# y_censor_shape = y_censor.shape if y_censor is not None else \"n/a\"\n",
    "# print(f\" y_censor  - type : {type(y_censor)}  shape: {y_censor_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be4c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:03:53.990463Z",
     "start_time": "2021-11-30T21:03:53.968756Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if (y_regr is None) and (y_censor is not None):\n",
    "#     raise ValueError(\"y_censor provided please also provide --y_regr.\")\n",
    "\n",
    "# # if y_class is None:\n",
    "# #     y_class = scipy.sparse.csr_matrix((ecfp.shape[0], 0))\n",
    "# #     vprint(f\"Created y_class shape        : {y_class.shape}\")\n",
    "\n",
    "# if y_regr is None:\n",
    "#     y_regr  = scipy.sparse.csr_matrix((ecfp.shape[0], 0))\n",
    "#     vprint(f\"Created y_regr shape         : {y_regr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb45a56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T12:54:02.548598Z",
     "start_time": "2021-10-22T12:54:02.529641Z"
    },
    "hidden": true
   },
   "source": [
    "#### Input folding & transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c0a7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:06:39.945186Z",
     "start_time": "2021-11-30T21:06:39.922823Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"args.fold_inputs : {opt['dataload']['fold_inputs']} \\t\\t  transform: {opt['dataload']['input_transform']}\\n\")\n",
    "print(repr(ecfp))\n",
    "ecfp = fold_and_transform_inputs(ecfp, folding_size=opt['dataload']['fold_inputs'], transform=opt['dataload']['input_transform'])\n",
    "print(repr(ecfp))\n",
    "\n",
    "print(type(ecfp), ecfp.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be8f8e5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Loading weights files for tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8c6e9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:06:58.845909Z",
     "start_time": "2021-11-30T21:06:58.817727Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# num_regr   = np.bincount(y_regr.indices, minlength=y_regr.shape[1])\n",
    "print(' Classification weights: ',opt['dataload']['weights_class'])\n",
    "tasks_class = load_task_weights(opt['dataload']['weights_class'], y=y_class[0], label=\"y_class\")\n",
    "# tasks_regr  = load_task_weights(opt['dataload']['weights_regr'] , y=y_regr , label=\"y_regr\")\n",
    "\n",
    "print(tasks_class)\n",
    "print(tasks_class.training_weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0c5b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:07:06.169693Z",
     "start_time": "2021-11-30T21:07:06.149534Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7869b822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:07:08.157368Z",
     "start_time": "2021-11-30T21:07:08.129096Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(y_files[0].shape, y_files[1].shape, y_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1d75d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:09:55.522938Z",
     "start_time": "2021-11-30T21:09:55.500886Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if tasks_class.aggregation_weight is None:\n",
    "    '''\n",
    "    fold classes \n",
    "    '''\n",
    "    ## using min_samples rule\n",
    "    fold_pos, fold_neg = class_fold_counts(y_class, folding)\n",
    "    n = opt['dataload']['min_samples_class']\n",
    "    tasks_class.aggregation_weight = ((fold_pos >= n).all(0) & (fold_neg >= n)).all(0).astype(np.float64)\n",
    "    print(f\" tasks_class.aggregation_weight WAS NOT passed \")\n",
    "    print(f\" min_samples_class: opt['dataload']['min_samples_class']\")\n",
    "    print(f\" Class fold counts: \\n  fold_pos:\\n{fold_pos}  \\n\\n  fold_neg:\\n{fold_neg}\") \n",
    "else:\n",
    "    print(f\"  tasks_class.aggregation_weight passed \")\n",
    "    \n",
    "print(f\" tasks_class.aggregation_weight.shape: {tasks_class.aggregation_weight.shape} \\n {tasks_class.aggregation_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04975aac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T18:42:45.554463Z",
     "start_time": "2021-11-25T18:42:45.536741Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# if tasks_regr.aggregation_weight is None:\n",
    "#     if y_censor.nnz == 0:\n",
    "#         y_regr2 = y_regr.copy()\n",
    "#         y_regr2.data[:] = 1\n",
    "#     else:\n",
    "#         ## only counting uncensored data\n",
    "#         y_regr2      = y_censor.copy()\n",
    "#         y_regr2.data = (y_regr2.data == 0).astype(np.int32)\n",
    "  \n",
    "#     fold_regr, _ = sc.class_fold_counts(y_regr2, folding)\n",
    "#     del y_regr2\n",
    "#     tasks_regr.aggregation_weight = (fold_regr >= args.min_samples_regr).all(0).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ece76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:10:10.546093Z",
     "start_time": "2021-11-30T21:10:07.896313Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Display dataset dimensions \n",
    "##\n",
    "print(f\"Input dimension      : {ecfp.shape[1]}\")\n",
    "print(f\"#samples             : {ecfp.shape[0]}\")\n",
    "print(f\"#classification tasks: {y_class[0].shape[1]}\")\n",
    "print(f\"Using {(tasks_class.aggregation_weight > 0).sum()} classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\")\n",
    "\n",
    "# vprint(f\"#regression tasks    : {y_regr.shape[1]}\")\n",
    "# vprint(f\"Using {(tasks_regr.aggregation_weight > 0).sum()} regression tasks for calculating metrics (RMSE, Rsquared, correlation).\")\n",
    "# print(ecfp[18387,:10].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb078d30",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Compute batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9a1fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:10:25.779206Z",
     "start_time": "2021-11-30T21:10:25.742332Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\" batch_ratio        : {opt['batch_ratio']}\")\n",
    "print(f\" internal_batch_max : {opt['internal_batch_max']}\")\n",
    "\n",
    "# batch_size  = int(np.ceil(opt['batch_ratio'] * idx_tr.shape[0]))\n",
    "# num_int_batches = 1\n",
    "# print(f\" batch_ratio * # idx_tr:   {opt['batch_ratio']} * {idx_tr.shape[0]} = {opt['batch_ratio'] * idx_tr.shape[0]}\")\n",
    "\n",
    "\n",
    "# if opt['internal_batch_max'] is not None:\n",
    "#     if opt['internal_batch_max'] < batch_size:\n",
    "#         num_int_batches = int(np.ceil(batch_size / opt['internal_batch_max']))\n",
    "#         print(f\"\\n\\n internal_batch_max: {opt['internal_batch_max']}   batch_size: {batch_size}\")\n",
    "#         print(f\" batch_size / internal_batch_max: {batch_size / opt['internal_batch_max']}   num_int_batches: {num_int_batches}\")\n",
    "#         batch_size      = int(np.ceil(batch_size / num_int_batches))\n",
    "#         print(f\" batch_size / num_int_batches: {batch_size / num_int_batches}   modified batch_size: {batch_size}\")\n",
    "        \n",
    "\n",
    "batch_size = 320 \n",
    "print(f\" batch size:   {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e2645c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Separate test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0704f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:10:38.737304Z",
     "start_time": "2021-11-30T21:10:38.713730Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"opt['dataload']['fold_te'] : {opt['dataload']['fold_te'] }\")\n",
    "print(f\"opt['dataload']['fold_va'] : {opt['dataload']['fold_va'] }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde0718e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:11:17.886147Z",
     "start_time": "2021-11-30T21:11:17.861334Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if opt['dataload']['fold_te'] is not None and opt['dataload']['fold_te'] >= 0:\n",
    "    ## removing test data\n",
    "    print(f\" Remove test data\")\n",
    "    assert opt['dataload']['fold_te'] != opt['dataload']['fold_va'], \"fold_va and fold_te must not be equal.\"\n",
    "    keep    = (folding != args.fold_te)\n",
    "    ecfp    = ecfp[keep]\n",
    "    y_class = y_class[keep]\n",
    "    y_regr  = y_regr[keep]\n",
    "    y_censor= y_censor[keep]\n",
    "    folding = folding[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056298c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:11:23.295720Z",
     "start_time": "2021-11-30T21:11:23.267229Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prop = (np.cumsum([0.3, 0.3, 0.3, 0.1])* ecfp.shape[0]+1).astype(np.int32)\n",
    "print(prop, prop.astype(np.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e21f1d3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Separate train, train1, train2, and validation  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ed184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T21:12:32.402571Z",
     "start_time": "2021-11-30T21:12:32.372192Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fold_va = opt['dataload']['fold_va']\n",
    "fold_va = 0\n",
    "fold_train1 = 1\n",
    "fold_train2 = 2\n",
    "\n",
    "idx_val    = np.where(folding == fold_va)[0]\n",
    "idx_train  = np.where(folding == fold_train1)[0]\n",
    "idx_train1 = np.where(folding == fold_train2)[0]\n",
    "idx_train2 = np.where(folding >  fold_train2)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed5f106",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T20:27:23.242326Z",
     "start_time": "2021-12-01T20:27:23.206716Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataroot = opt['dataload']['dataroot']\n",
    "ecfp     = load_sparse(dataroot, opt['dataload']['x'])\n",
    "\n",
    "total_input = ecfp.shape[0]\n",
    "ranges      = (np.cumsum([0.3, 0.3, 0.1, 0.3])* total_input).astype(np.int32)\n",
    "print(total_input, '     ', ranges)\n",
    "\n",
    "idx_train  = np.arange(ranges[0])\n",
    "idx_train1 = np.arange(ranges[0], ranges[1])\n",
    "idx_train2 = np.arange(ranges[1], ranges[2])\n",
    "idx_val    = np.arange(ranges[2], ranges[-1])\n",
    "\n",
    "print( f' idx_train   len: {len(idx_train) :6d}  - {(idx_train)} ')\n",
    "print( f' idx_train1  len: {len(idx_train1):6d}  - {(idx_train1)}')\n",
    "print( f' idx_train2  len: {len(idx_train2):6d}  - {(idx_train2)}')\n",
    "print( f' idx_val     len: {len(idx_val)   :6d}  - {(idx_val)}   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4118c6a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T18:42:45.746087Z",
     "start_time": "2021-11-25T18:42:45.726692Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# y_class_tr = y_class[idx_train]\n",
    "# y_class_va = y_class[idx_va]\n",
    "\n",
    "# y_regr_tr  = y_regr[idx_tr]\n",
    "# y_regr_va  = y_regr[idx_va]\n",
    "\n",
    "# y_censor_tr = y_censor[idx_tr]\n",
    "# y_censor_va = y_censor[idx_va]\n",
    "\n",
    "# num_pos_va  = np.array((y_class_va == +1).sum(0)).flatten()\n",
    "# num_neg_va  = np.array((y_class_va == -1).sum(0)).flatten()\n",
    "# num_regr_va = np.bincount(y_regr_va.indices, minlength=y_regr.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt-gpu",
   "language": "python",
   "name": "pyt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
