{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408f1261",
   "metadata": {},
   "source": [
    "## Initialization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d574cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:01:09.922836Z",
     "start_time": "2022-02-15T18:01:05.350372Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:08.233990Z",
     "iopub.status.busy": "2022-01-07T22:44:08.233053Z",
     "iopub.status.idle": "2022-01-07T22:44:08.273284Z",
     "shell.execute_reply": "2022-01-07T22:44:08.271908Z",
     "shell.execute_reply.started": "2022-01-07T22:44:08.233943Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/kbardool/kusanagi/AdaSparseChem', '/home/kbardool/miniconda3/envs/pyt-gpu/lib/python39.zip', '/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9', '/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/lib-dynload', '', '/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages', '/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/IPython/extensions', '/home/kbardool/.ipython']\n",
      " Cuda is available  :  True\n",
      " CUDA device count  :  1\n",
      " CUDA current device:  0\n",
      " GPU Processes      :  GPU:0\n",
      "no processes are running\n",
      "\n",
      " Device : cuda:0\n",
      "   name:        NVIDIA GeForce GTX 970M\n",
      "   capability:  (5, 2)\n",
      "   properties:  _CudaDeviceProperties(name='NVIDIA GeForce GTX 970M', major=5, minor=2, total_memory=3071MB, multi_processor_count=10)\n",
      "   Allocated :  0\n",
      "   Reserved  :  0\n",
      "\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | nan% |  1% |\n"
     ]
    }
   ],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "print(sys.path)\n",
    "import time\n",
    "import argparse\n",
    "import yaml\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "# import tqdm.notebook.trange as tnrange\n",
    "import copy, pprint\n",
    "import numpy  as np\n",
    "import torch  \n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader \n",
    "import scipy.sparse\n",
    "from time import sleep\n",
    "from scipy.special import softmax\n",
    " \n",
    "from datetime import datetime\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    " # from tqdm import trange, tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "sys.path.insert(0, './src')\n",
    "from envs.sparsechem_env_dev import SparseChemEnv_Dev\n",
    "from utils.sparsechem_utils import load_sparse, load_task_weights, class_fold_counts, fold_and_transform_inputs, print_metrics_cr\n",
    "from dataloaders.chembl_dataloader_dev import ClassRegrSparseDataset_v3, ClassRegrSparseDataset, InfiniteDataLoader\n",
    "from utils.util import ( makedir, print_separator, create_path, print_yaml, print_yaml2, should, \n",
    "                         fix_random_seed, read_yaml_from_input, timestring, print_heading, print_dbg, \n",
    "                         print_underline, write_parms_report, get_command_line_args)\n",
    "\n",
    " \n",
    "\n",
    "print(' Cuda is available  : ', torch.cuda.is_available())\n",
    "print(' CUDA device count  : ', torch.cuda.device_count())\n",
    "print(' CUDA current device: ', torch.cuda.current_device())\n",
    "print(' GPU Processes      : ', torch.cuda.list_gpu_processes())\n",
    "print()\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\" Device : cuda:{i}\")\n",
    "    print('   name:       ', torch.cuda.get_device_name())\n",
    "    print('   capability: ', torch.cuda.get_device_capability())\n",
    "    print('   properties: ', torch.cuda.get_device_properties(i))\n",
    "    ## current GPU memory usage by tensors in bytes for a given device\n",
    "    print('   Allocated : ', torch.cuda.memory_allocated(i) ) \n",
    "    ## current GPU memory managed by caching allocator in bytes for a given device, in previous PyTorch versions the command was torch.cuda.memory_cached\n",
    "    print('   Reserved  : ', torch.cuda.memory_reserved(i) )   \n",
    "    print()\n",
    "\n",
    "gpu_usage()                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5255bad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:01:09.969473Z",
     "start_time": "2022-02-15T18:01:09.928363Z"
    }
   },
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=6, linewidth=132)\n",
    "# torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
    "pd.options.display.width = 132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74221eb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:01:10.009957Z",
     "start_time": "2022-02-15T18:01:09.975115Z"
    }
   },
   "outputs": [],
   "source": [
    "# sys.path.pop(0)\n",
    "# sys.path.insert(0, '/home/kbardool/kusanagi/AdaSparseChem/src')\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05032bf4",
   "metadata": {},
   "source": [
    "## Read yaml config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7bb1dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:01:10.059485Z",
     "start_time": "2022-02-15T18:01:10.019349Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " command line parms :  {'config': 'yamls/adashare/chembl_2task.yaml', 'exp_instance': None, 'exp_ids': [0], 'batch_size': 9999, 'backbone_lr': None, 'task_lr': None, 'decay_lr_rate': None, 'decay_lr_freq': None, 'gpus': [0], 'cpu': True}\n"
     ]
    }
   ],
   "source": [
    "input_args = \" --config yamls/adashare/chembl_2task.yaml --cpu --batch_size 09999\".split()\n",
    "# get command line arguments\n",
    "args = get_command_line_args(input_args)\n",
    "\n",
    "if args.exp_instance is None:\n",
    "    args.exp_instance = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "    \n",
    "# print(args.exp_instance)\n",
    "# print(args)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13447e2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:01:10.118282Z",
     "start_time": "2022-02-15T18:01:10.062791Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "####################READ YAML#####################\n",
      "##################################################\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      " experiment name       : SparseChem \n",
      " experiment instance   : 0215_1001 \n",
      " folder_name           : 50x6_0215_1001_plr0.0001_sp1e-06_sh10.0 \n",
      " experiment description: No Alternating Weight/Policy - training all done with both weights and policy\n",
      " log folder            : ../experiments/AdaSparseChem/50x6_0215_1001_plr0.0001_sp1e-06_sh10.0\n",
      " checkpoint folder     : ../experiments/AdaSparseChem/50x6_0215_1001_plr0.0001_sp1e-06_sh10.0\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_separator('READ YAML')\n",
    "\n",
    "opt, gpu_ids, _ = read_yaml_from_input(args)\n",
    "\n",
    "fix_random_seed(opt[\"seed\"][1])\n",
    "\n",
    "opt['exp_description'] = f\"No Alternating Weight/Policy - training all done with both weights and policy\"\n",
    "opt['exp_log_dir']        =  os.path.join(opt['paths']['log_dir'], opt['paths']['exp_folder'])\n",
    "opt['exp_checkpoint_dir'] =  os.path.join(opt['paths']['checkpoint_dir'], opt['paths']['exp_folder'])\n",
    "# folder_name=  f\"{opt['exp_instance']}_bs{opt['train']['batch_size']:03d}_{opt['train']['decay_lr_rate']:3.2f}_{opt['train']['decay_lr_freq']}\"\n",
    "\n",
    "print_heading(f\" experiment name       : {opt['exp_name']} \\n\"\n",
    "              f\" experiment instance   : {opt['exp_instance']} \\n\"\n",
    "              f\" folder_name           : {opt['paths']['exp_folder']} \\n\"\n",
    "              f\" experiment description: {opt['exp_description']}\\n\"\n",
    "              f\" log folder            : {opt['exp_log_dir']}\\n\"\n",
    "              f\" checkpoint folder     : {opt['exp_checkpoint_dir']}\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d33640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:01:10.189007Z",
     "start_time": "2022-02-15T18:01:10.122923Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.145647Z",
     "iopub.status.busy": "2022-01-07T22:44:13.145313Z",
     "iopub.status.idle": "2022-01-07T22:44:13.193262Z",
     "shell.execute_reply": "2022-01-07T22:44:13.192140Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.145622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Create folder ../experiments/AdaSparseChem/50x6_0215_1001_plr0.0001_sp1e-06_sh10.0\n",
      "            exp_name : SparseChem\n",
      "        exp_instance : 0215_1001\n",
      "     exp_description : No Alternating Weight/Policy - training all done with both weights and policy\n",
      "                seed : [88, 45, 50, 100, 44, 48, 2048, 2222, 9999]\n",
      "            backbone : SparseChem\n",
      "       backbone_orig : ResNet18\n",
      "          orig_tasks : ['seg', 'sn']\n",
      "               tasks : ['class', 'class', 'class']\n",
      "     tasks_num_class : [5, 5, 5]\n",
      "             lambdas : [1, 1, 1]\n",
      "        policy_model : task-specific\n",
      "             verbose : False\n",
      "     input_size_freq : None\n",
      "          input_size : 32000\n",
      "        hidden_sizes : [50, 50, 50, 50, 50, 50]\n",
      "    tail_hidden_size : 50\n",
      " first_non_linearity : relu\n",
      "middle_non_linearity : relu\n",
      "      middle_dropout : 0.2\n",
      "  last_non_linearity : relu\n",
      "        last_dropout : 0.2\n",
      "   class_output_size : None\n",
      "    regr_output_size : None\n",
      "              policy : True\n",
      "           is_sparse : True\n",
      "          is_sharing : True\n",
      "diff_sparsity_weights : False\n",
      "          skip_layer : 0\n",
      "       is_curriculum : False\n",
      "    curriculum_speed : 1\n",
      "              fix_BN : False\n",
      "     retrain_from_pl : False\n",
      "\n",
      "train\n",
      "-----\n",
      "          batch_size : 128\n",
      "             task_lr : 0.01\n",
      "         backbone_lr : 0.01\n",
      "           policy_lr : 0.0001\n",
      "       decay_lr_rate : 0.85\n",
      "       decay_lr_freq : 2000\n",
      "policy_decay_lr_rate : 0.85\n",
      "policy_decay_lr_freq : 2200\n",
      "     lambda_sparsity : 1e-06\n",
      "      lambda_sharing : 10.0\n",
      "        lambda_tasks : 1\n",
      "         init_method : random\n",
      "           init_temp : 4\n",
      "          decay_temp : 0.9\n",
      "     decay_temp_freq : 8\n",
      "     init_neg_logits : None\n",
      "       hard_sampling : False\n",
      "         total_iters : 25000\n",
      "       warm_up_iters : None\n",
      "      warm_up_epochs : 1\n",
      "    iteration_epochs : 50\n",
      "            val_freq : 500\n",
      "          print_freq : -1\n",
      "           val_iters : -1\n",
      "              resume : False\n",
      "      retrain_resume : False\n",
      "         policy_iter : best\n",
      "          which_iter : warmup\n",
      "\n",
      "paths\n",
      "-----\n",
      "      experiment_dir : ../experiments/AdaSparseChem\n",
      "             log_dir : ../experiments/AdaSparseChem\n",
      "          result_dir : ../experiments/AdaSparseChem\n",
      "      checkpoint_dir : ../experiments/AdaSparseChem\n",
      "          exp_folder : 50x6_0215_1001_plr0.0001_sp1e-06_sh10.0\n",
      "\n",
      "dataload\n",
      "--------\n",
      "             dataset : Chembl_23_mini\n",
      "            dataroot : /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic\n",
      "                   x : chembl_23mini_x.npy\n",
      "      x_split_ratios : [0.75, 0.001, 0.001, 0.248]\n",
      "             folding : chembl_23mini_folds.npy\n",
      "         fold_inputs : 32000\n",
      "     input_transform : None\n",
      "             y_tasks : ['chembl_23mini_adashare_y1_bin_sparse.npy', 'chembl_23mini_adashare_y2_bin_sparse.npy', 'chembl_23mini_adashare_y3_bin_sparse.npy']\n",
      "            y_censor : None\n",
      "       weights_class : None\n",
      "              crop_h : 321\n",
      "              crop_w : 321\n",
      "   min_samples_class : 5\n",
      "             fold_va : 0\n",
      "             fold_te : None\n",
      "\n",
      "SC\n",
      "--\n",
      "         batch_ratio : 0.02\n",
      "      normalize_loss : None\n",
      "\n",
      "test\n",
      "----\n",
      "          which_iter : best\n",
      "                 cpu : True\n",
      "         exp_log_dir : ../experiments/AdaSparseChem/50x6_0215_1001_plr0.0001_sp1e-06_sh10.0\n",
      "  exp_checkpoint_dir : ../experiments/AdaSparseChem/50x6_0215_1001_plr0.0001_sp1e-06_sh10.0\n"
     ]
    }
   ],
   "source": [
    "# for line in lines: \n",
    "create_path(opt)    \n",
    "\n",
    "# print yaml on the screen\n",
    "for line in print_yaml2(opt):\n",
    "    print(line)\n",
    "\n",
    "write_parms_report(opt)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bfa8d",
   "metadata": {},
   "source": [
    "## Chembl Dataloader V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c17b578f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:01:10.999625Z",
     "start_time": "2022-02-15T18:01:10.193087Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:16.229028Z",
     "iopub.status.busy": "2022-01-07T22:44:16.227544Z",
     "iopub.status.idle": "2022-01-07T22:44:16.659397Z",
     "shell.execute_reply": "2022-01-07T22:44:16.658348Z",
     "shell.execute_reply.started": "2022-01-07T22:44:16.228966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trainset.y_class                       :  [(13791, 5), (13791, 5), (13791, 5)]\n",
      " trainset1.y_class                      :  [(18, 5), (18, 5), (18, 5)]\n",
      " trainset2.y_class                      :  [(18, 5), (18, 5), (18, 5)]\n",
      " valset.y_class                         :  [(4561, 5), (4561, 5), (4561, 5)] \n",
      "\n",
      " size of training set 0 (warm up)       :  13791\n",
      " size of training set 1 (network parms) :  18\n",
      " size of training set 2 (policy weights):  18\n",
      " size of validation set                 :  4561\n",
      "                               Total    :  18388\n",
      "\n",
      " batch size                             :  128\n",
      "\n",
      " # batches training 0 (warm up)         :  108\n",
      " # batches training 1 (network parms)   :  1\n",
      " # batches training 2 (policy weights)  :  1\n",
      " # batches validation dataset           :  36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainset  = ClassRegrSparseDataset_v3(opt, split_ratios = opt['dataload']['x_split_ratios'], ratio_index = 0, verbose = False)\n",
    "trainset1 = ClassRegrSparseDataset_v3(opt, split_ratios = opt['dataload']['x_split_ratios'], ratio_index = 1)\n",
    "trainset2 = ClassRegrSparseDataset_v3(opt, split_ratios = opt['dataload']['x_split_ratios'], ratio_index = 2)\n",
    "valset    = ClassRegrSparseDataset_v3(opt, split_ratios = opt['dataload']['x_split_ratios'], ratio_index = 3)\n",
    "\n",
    "train_loader  = InfiniteDataLoader(trainset , batch_size=opt['train']['batch_size'], num_workers = 2, pin_memory=True, collate_fn=trainset.collate, shuffle=False)\n",
    "val_loader    = InfiniteDataLoader(valset   , batch_size=opt['train']['batch_size'], num_workers = 1, pin_memory=True, collate_fn=valset.collate  , shuffle=False)\n",
    "train1_loader = InfiniteDataLoader(trainset1, batch_size=opt['train']['batch_size'], num_workers = 2, pin_memory=True, collate_fn=trainset1.collate, shuffle=False)\n",
    "train2_loader = InfiniteDataLoader(trainset2, batch_size=opt['train']['batch_size'], num_workers = 2, pin_memory=True, collate_fn=trainset2.collate, shuffle=False)\n",
    "\n",
    "print(f\" trainset.y_class                       :  {[ i.shape  for i in trainset.y_class_list]}\")\n",
    "print(f\" trainset1.y_class                      :  {[ i.shape  for i in trainset1.y_class_list]}\")\n",
    "print(f\" trainset2.y_class                      :  {[ i.shape  for i in trainset2.y_class_list]}\")\n",
    "print(f\" valset.y_class                         :  {[ i.shape  for i in valset.y_class_list  ]} \")\n",
    "print()\n",
    "print(f' size of training set 0 (warm up)       :  {len(trainset)}')\n",
    "print(f' size of training set 1 (network parms) :  {len(trainset1)}')\n",
    "print(f' size of training set 2 (policy weights):  {len(trainset2)}')\n",
    "print(f' size of validation set                 :  {len(valset)}')\n",
    "print(f'                               Total    :  {len(trainset)+len(trainset1)+len(trainset2)+len(valset)}')\n",
    "print()\n",
    "print(f\" batch size                             :  {opt['train']['batch_size']}\")\n",
    "print()\n",
    "print(f\" # batches training 0 (warm up)         :  {len(train_loader)}\")\n",
    "print(f\" # batches training 1 (network parms)   :  {len(train1_loader)}\")\n",
    "print(f\" # batches training 2 (policy weights)  :  {len(train2_loader)}\")\n",
    "print(f\" # batches validation dataset           :  {len(val_loader)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f4f21",
   "metadata": {},
   "source": [
    "## Create Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf868bb",
   "metadata": {},
   "source": [
    "### Create model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3293d4b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:01:11.298892Z",
     "start_time": "2022-02-15T18:01:11.010436Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:21.499081Z",
     "iopub.status.busy": "2022-01-07T22:44:21.498215Z",
     "iopub.status.idle": "2022-01-07T22:44:21.604241Z",
     "shell.execute_reply": "2022-01-07T22:44:21.602711Z",
     "shell.execute_reply.started": "2022-01-07T22:44:21.499039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "* SparseChemEnv_Dev  Initializtion - verbose: False\n",
      "------------------------------------------------------- \n",
      "\n",
      "------------------------------------------------------------\n",
      "SparseChemEnv_Dev.super() init()  Start - verbose: False\n",
      "------------------------------------------------------------ \n",
      "\n",
      " log_dir        :  ../experiments/AdaSparseChem/50x6_0215_1001_plr0.0001_sp1e-06_sh10.0 \n",
      " checkpoint_dir :  ../experiments/AdaSparseChem/50x6_0215_1001_plr0.0001_sp1e-06_sh10.0 \n",
      " exp_name       :  SparseChem \n",
      " tasks_num_class:  [5, 5, 5] \n",
      " device         :  cuda:0 \n",
      " device id      :  0 \n",
      " dataset        :  Chembl_23_mini \n",
      " tasks          :  ['class', 'class', 'class'] \n",
      "\n",
      "--------------------------------------------------\n",
      "SparseChemEnv_Dev.super() init()  end\n",
      "-------------------------------------------------- \n",
      "\n",
      " is_train       :  True \n",
      " init_neg_logits:  None \n",
      " init temp      :  4 \n",
      " decay temp     :  0.9 \n",
      " input_size     :  32000 \n",
      " normalize loss :  None \n",
      " num_tasks      :  3 \n",
      " policys        :  [None, None, None]\n",
      "--------------------------------------------------------\n",
      "* SparseChemEnv_Dev environment successfully created\n",
      "-------------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MTL3_Dev(\n",
       "  (backbone): SparseChem_Backbone(\n",
       "    (Input_linear): SparseLinear(in_features=32000, out_features=50, bias=True)\n",
       "    (blocks): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): SparseChemBlock(\n",
       "          (linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (non_linear): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): SparseChemBlock(\n",
       "          (linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (non_linear): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): SparseChemBlock(\n",
       "          (linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (non_linear): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): SparseChemBlock(\n",
       "          (linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (non_linear): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): SparseChemBlock(\n",
       "          (linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (non_linear): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): SparseChemBlock(\n",
       "          (linear): Linear(in_features=50, out_features=50, bias=True)\n",
       "          (non_linear): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (task1_fc1_c0): SparseChem_Classification_Module(\n",
       "    (linear): Linear(in_features=50, out_features=5, bias=True)\n",
       "  )\n",
       "  (task2_fc1_c0): SparseChem_Classification_Module(\n",
       "    (linear): Linear(in_features=50, out_features=5, bias=True)\n",
       "  )\n",
       "  (task3_fc1_c0): SparseChem_Classification_Module(\n",
       "    (linear): Linear(in_features=50, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ = SparseChemEnv_Dev(log_dir          = opt['exp_log_dir'], \n",
    "                            checkpoint_dir   = opt['exp_checkpoint_dir'], \n",
    "                            exp_name         = opt['exp_name'],\n",
    "                            tasks_num_class  = opt['tasks_num_class'], \n",
    "                            init_neg_logits  = opt['train']['init_neg_logits'], \n",
    "                            device           = gpu_ids[0],\n",
    "                            init_temperature = opt['train']['init_temp'], \n",
    "                            temperature_decay= opt['train']['decay_temp'], \n",
    "                            is_train         = True,\n",
    "                            opt              = opt, \n",
    "                            verbose          = False)\n",
    "\n",
    "cfg = environ.print_configuration()\n",
    "write_parms_report(opt, cfg, mode = 'a')\n",
    "environ.networks['mtl-net']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07462f4d",
   "metadata": {},
   "source": [
    "## Warmup Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d738062",
   "metadata": {},
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9a2145b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:01:15.502449Z",
     "start_time": "2022-02-15T18:01:11.303146Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:27.458746Z",
     "iopub.status.busy": "2022-01-07T22:44:27.457640Z",
     "iopub.status.idle": "2022-01-07T22:44:27.491358Z",
     "shell.execute_reply": "2022-01-07T22:44:27.490019Z",
     "shell.execute_reply.started": "2022-01-07T22:44:27.458686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate Training \n",
      "cuda available [0]\n",
      "\n",
      "\n",
      " set print_freq to length of train loader: 108\n",
      " set eval_iters to length of val loader  : 36\n"
     ]
    }
   ],
   "source": [
    "environ.define_optimizer(policy_learning=False)\n",
    "environ.define_scheduler(policy_learning=False)\n",
    "# Fix Alpha - \n",
    "environ.fix_alpha()\n",
    "environ.free_weights(opt['fix_BN'])\n",
    "\n",
    "if opt['train']['resume']:\n",
    "    print('Resume training')\n",
    "    current_iter = environ.load(opt['train']['which_iter'])\n",
    "    environ.networks['mtl-net'].reset_logits()\n",
    "else:\n",
    "    print('Initiate Training ')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda available', gpu_ids)   \n",
    "    environ.cuda(gpu_ids)\n",
    "else:\n",
    "    print('cuda not available')\n",
    "    environ.cpu()\n",
    "print('\\n')\n",
    "\n",
    "flag           = 'update_w'\n",
    "current_epoch  = 0\n",
    "current_iter   = 0\n",
    "current_iter_w = 0 \n",
    "current_iter_a = 0\n",
    "best_value     = 0 \n",
    "best_iter      = 0\n",
    "p_epoch        = 0\n",
    "w_epoch        = 0\n",
    "\n",
    "best_metrics   = None\n",
    "flag_warmup    = True\n",
    "eval_iters     = -1\n",
    "num_prints     = 0\n",
    "num_blocks     = sum(environ.networks['mtl-net'].layers)\n",
    " \n",
    "warm_up_epochs     = opt['train']['warm_up_epochs']\n",
    "train_total_epochs = opt['train']['iteration_epochs']\n",
    "curriculum_speed   = opt['curriculum_speed'] \n",
    "\n",
    "stop_epoch = current_epoch + warm_up_epochs\n",
    "\n",
    "\n",
    "if opt['train']['print_freq'] == -1:\n",
    "    print(f\" set print_freq to length of train loader: {len(train_loader)}\")\n",
    "    opt['train']['print_freq']    = len(train_loader)\n",
    "\n",
    "if opt['train']['val_iters'] == -1:\n",
    "    print(f\" set eval_iters to length of val loader  : {len(val_loader)}\")\n",
    "    eval_iters    = len(val_loader)    \n",
    "else:\n",
    "    eval_iters    = opt['train']['val_iters']\n",
    "\n",
    "# opt['train']['weight_iter_alternate'] = opt['train'].get('weight_iter_alternate' , len(train1_loader))\n",
    "# opt['train']['alpha_iter_alternate']  = opt['train'].get('alpha_iter_alternate'  , len(train2_loader))\n",
    "opt['train']['weight_iter_alternate'] = len(train_loader)\n",
    "opt['train']['alpha_iter_alternate']  = len(train_loader)\n",
    "stop_iter_w = opt['train']['weight_iter_alternate']\n",
    "stop_iter_a = (opt['train']['alpha_iter_alternate'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ea212ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:01:15.654500Z",
     "start_time": "2022-02-15T18:01:15.515483Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:18.146907Z",
     "iopub.status.busy": "2022-01-07T22:44:18.145721Z",
     "iopub.status.idle": "2022-01-07T22:44:18.191126Z",
     "shell.execute_reply": "2022-01-07T22:44:18.189994Z",
     "shell.execute_reply.started": "2022-01-07T22:44:18.146867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " experiment name           : SparseChem \n",
      " experiment description    : No Alternating Weight/Policy - training all done with both weights and policy                                 \n",
      "\n",
      " Network[mtl_net].layers   : [1, 1, 1, 1, 1, 1] \n",
      " Num_blocks                : 6                                \n",
      "\n",
      " batch size                : 128 \n",
      " Total iterations          : 25000 \n",
      " Warm-up iterations        : None \n",
      " Warm-up epochs            : 1 \n",
      " train_total_epochs        : 50                                 \n",
      "\n",
      " Print Frequency           : 108 \n",
      " Validation Frequency      : 500 \n",
      " Validation Iterations     : -1 \n",
      " eval_iters                : 36 \n",
      " which_iter                : warmup \n",
      " train_resume              : False                                 \n",
      " \n",
      " Length train_loader       : 108 \n",
      " Length val_loader         : 36 \n",
      " stop_iter_w               : 108                                 \n",
      " \n",
      " fix BN parms              : False \n",
      " Backbone LR               : 0.01 \n",
      " Backbone LR               : 0.01                                 \n",
      "\n",
      " Sharing  regularization   : 10.0 \n",
      " Sparsity regularization   : 1e-06 \n",
      " Task     regularization   : 1\n",
      " Last Epoch: 0   # of warm-up epochs to do:  1 - Run epochs 1 to 1\n"
     ]
    }
   ],
   "source": [
    "print( \n",
    "    f\"\\n experiment name           : {opt['exp_name']}\",\n",
    "    f\"\\n experiment description    : {opt['exp_description']}\",\n",
    "    f\"                                \\n\"\n",
    "    f\"\\n Network[mtl_net].layers   : {environ.networks['mtl-net'].layers}\",\n",
    "    f\"\\n Num_blocks                : {sum(environ.networks['mtl-net'].layers)}\"    \n",
    "    f\"                                \\n\"\n",
    "    f\"\\n batch size                : {opt['train']['batch_size']}\",    \n",
    "    f\"\\n Total iterations          : {opt['train']['total_iters']}\",\n",
    "    f\"\\n Warm-up iterations        : {opt['train']['warm_up_iters']}\",\n",
    "    f\"\\n Warm-up epochs            : {opt['train']['warm_up_epochs']}\",\n",
    "    f\"\\n train_total_epochs        : {train_total_epochs}\",\n",
    "    f\"                                \\n\"\n",
    "    f\"\\n Print Frequency           : {opt['train']['print_freq']}\",\n",
    "    f\"\\n Validation Frequency      : {opt['train']['val_freq']}\",\n",
    "    f\"\\n Validation Iterations     : {opt['train']['val_iters']}\",\n",
    "    f\"\\n eval_iters                : {eval_iters}\",\n",
    "    f\"\\n which_iter                : {opt['train']['which_iter']}\",\n",
    "    f\"\\n train_resume              : {opt['train']['resume']}\",\n",
    "    f\"                                \\n\",                     \n",
    "    f\"\\n Length train_loader       : {len(train_loader)}\",\n",
    "    f\"\\n Length val_loader         : {len(val_loader)}\",\n",
    "    f\"\\n stop_iter_w               : {stop_iter_w}\",\n",
    "    f\"                                \\n\",\n",
    "    f\"\\n fix BN parms              : {opt['fix_BN']}\",    \n",
    "    f\"\\n Backbone LR               : {opt['train']['backbone_lr']}\",\n",
    "    f\"\\n Backbone LR               : {opt['train']['task_lr']   }\",     \n",
    "    f\"                                \\n\"\n",
    "    f\"\\n Sharing  regularization   : {opt['train']['lambda_sharing']}\",    \n",
    "    f\"\\n Sparsity regularization   : {opt['train']['lambda_sparsity']}\",  \n",
    "    f\"\\n Task     regularization   : {opt['train']['lambda_tasks']}\")\n",
    "\n",
    "print(f\" Last Epoch: {current_epoch}   # of warm-up epochs to do:  {warm_up_epochs} - Run epochs {current_epoch+1} to {stop_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61bc6107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:01:15.696942Z",
     "start_time": "2022-02-15T18:01:15.659025Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:18.146907Z",
     "iopub.status.busy": "2022-01-07T22:44:18.145721Z",
     "iopub.status.idle": "2022-01-07T22:44:18.191126Z",
     "shell.execute_reply": "2022-01-07T22:44:18.189994Z",
     "shell.execute_reply.started": "2022-01-07T22:44:18.146867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " folder: 50x6_0215_1001_plr0.0001_sp1e-06_sh10.0 \n",
      " layers: [50, 50, 50, 50, 50, 50]                                \n",
      " \n",
      " diff_sparsity_weights  : False \n",
      " skip_layer             : 0 \n",
      " is_curriculum          : False \n",
      " curriculum_speed       : 1                               \n",
      " \n",
      " decay_lr_rate          : 0.85 \n",
      " decay_lr_freq          : 2000 \n",
      " policy_decay_lr_rate   : 0.85 \n",
      " policy_decay_lr_freq   : 2200                               \n",
      " \n",
      " policy_lr              : 0.0001 \n",
      " lambda_sparsity        : 1e-06 \n",
      " lambda_sharing         : 10.0                               \n",
      " \n",
      " lambda_tasks           : 1 \n",
      " init_temp              : 4 \n",
      " decay_temp             : 0.9 \n",
      " decay_temp_freq        : 8 \n",
      " init_method            : random \n",
      " init_neg_logits        : None \n",
      " hard_sampling          : False \n",
      " Warm-up epochs         : 1 \n",
      " iteration epochs       : 50\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"\\n folder: {opt['paths']['exp_folder']}\",\n",
    "    f\"\\n layers: {opt['hidden_sizes']}\",    \n",
    "    f\"                               \\n\",\n",
    "    f\"\\n diff_sparsity_weights  : {opt['diff_sparsity_weights']}\",\n",
    "    f\"\\n skip_layer             : {opt['skip_layer']}\",\n",
    "    f\"\\n is_curriculum          : {opt['is_curriculum']}\",\n",
    "    f\"\\n curriculum_speed       : {opt['curriculum_speed']}\",\n",
    "    f\"                              \\n\",    \n",
    "    f\"\\n decay_lr_rate          : {opt['train']['decay_lr_rate']}\",      \n",
    "    f\"\\n decay_lr_freq          : {opt['train']['decay_lr_freq']}\",     \n",
    "    f\"\\n policy_decay_lr_rate   : {opt['train']['policy_decay_lr_rate']}\",      \n",
    "    f\"\\n policy_decay_lr_freq   : {opt['train']['policy_decay_lr_freq']}\", \n",
    "    f\"                              \\n\",    \n",
    "    f\"\\n policy_lr              : {opt['train']['policy_lr']}\", \n",
    "    f\"\\n lambda_sparsity        : {opt['train']['lambda_sparsity']}\",      \n",
    "    f\"\\n lambda_sharing         : {opt['train']['lambda_sharing']}\", \n",
    "    f\"                              \\n\",    \n",
    "    f\"\\n lambda_tasks           : {opt['train']['lambda_tasks']}\",  \n",
    "    f\"\\n init_temp              : {opt['train']['init_temp']}\",\n",
    "    f\"\\n decay_temp             : {opt['train']['decay_temp']}\",    \n",
    "    f\"\\n decay_temp_freq        : {opt['train']['decay_temp_freq']}\",   \n",
    "    f\"\\n init_method            : {opt['train']['init_method']}\", \n",
    "    f\"\\n init_neg_logits        : {opt['train']['init_neg_logits']}\",    \n",
    "    f\"\\n hard_sampling          : {opt['train']['hard_sampling']}\",\n",
    "    f\"\\n Warm-up epochs         : {opt['train']['warm_up_epochs']}\",\n",
    "    f\"\\n iteration epochs       : {opt['train']['iteration_epochs']}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e42d110",
   "metadata": {},
   "source": [
    "### Warm-up Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6730d0b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:01:43.799160Z",
     "start_time": "2022-02-15T18:01:15.700932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Last Epoch: 0   # of warm-up epochs to do:  1 - Run epochs 1 to 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98462037c9fb47378acc3374025537e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Warmup training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Warmup Epoch 1:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch |  trn loss     trn spar     trn shar  trn total |   logloss   bceloss    aucroc     aucpr |  val loss     val spar     val shar  val total |  time |\n",
      "1     |   10.0734   2.0795e-06   2.7106e-01    10.3445 |   0.00015   0.68333   0.62691   0.62964 |   10.2477   2.0795e-06   2.7106e-01    10.5188 |  27.9 |\n",
      "[e] Warmup epoch:1    iter:  108 -  Total Loss: 10.3091     \n",
      "Task: 10.0381   Sparsity: 2.07947e-06    Sharing: 2.71059e-01 \n",
      "\n",
      "   1 epochs  softmax        sel        softmax       sel        softmax       sel \n",
      " -----    ---------------   ---     ---------------  ---     ---------------  --- \n",
      "   1      0.4999   0.5001    0      0.5004   0.4996   1      0.4994   0.5006   0\n",
      "   2      0.4998   0.5002    0      0.5001   0.4999   1      0.5004   0.4996   1\n",
      "   3      0.5002   0.4998    1      0.5002   0.4998   1      0.4997   0.5003   0\n",
      "   4      0.5002   0.4998    1      0.5004   0.4996   1      0.4991   0.5009   0\n",
      "   5      0.4999   0.5001    0      0.5001   0.4999   1      0.4997   0.5003   0\n",
      "   6      0.5008   0.4992    1      0.4995   0.5005   0      0.5001   0.4999   1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\" Last Epoch: {current_epoch}   # of warm-up epochs to do:  {warm_up_epochs} - Run epochs {current_epoch+1} to {stop_epoch}\")\n",
    "\n",
    "# verbose = False\n",
    "line_count = 0\n",
    "t = tqdm(initial = current_epoch, total=stop_epoch, desc=f\" Warmup training\")\n",
    "\n",
    "while current_epoch < stop_epoch:\n",
    "    start_time = time.time()\n",
    "    current_epoch+=1\n",
    "    t.update(1)\n",
    "    current_iter_w  = 0     \n",
    "    #-----------------------------------------\n",
    "    # Train & Update the network weights\n",
    "    #-----------------------------------------   \n",
    "    with trange(+1, stop_iter_w+1 , initial = 0 , total = stop_iter_w, \n",
    "                     position=0, leave= False, desc=f\" Warmup Epoch {current_epoch}\") as t_warmup :\n",
    "        for current_iter_w in t_warmup:\n",
    "            current_iter += 1            \n",
    "\n",
    "            environ.train()    \n",
    "            batch = next(train_loader)            \n",
    "            environ.set_inputs(batch, train_loader.dataset.input_size)\n",
    "            environ.optimize(opt['lambdas'], \n",
    "                             is_policy=False, \n",
    "                             flag='update_w', \n",
    "                             verbose = False)\n",
    "        \n",
    "            t_warmup.set_postfix({'curr_iter':current_iter, \n",
    "                                  'Loss': f\"{environ.losses['total']['total'].item():.4f}\"})\n",
    "#                                   'row_ids':f\"{batch['row_id'][0]}-{batch['row_id'][-1]}\"})\n",
    "        ##--------------------------------------------------------------- \n",
    "        ## validation\n",
    "        ##--------------------------------------------------------------- \n",
    "#         if should(current_iter_w, stop_iter_w):\n",
    "        trn_losses = environ.losses\n",
    "        environ.print_loss(current_iter, start_time, title = f\"[e] Warmup epoch:{current_epoch}    iter:\")\n",
    "\n",
    "        val_metrics = environ.evaluate(val_loader, opt['tasks'], \n",
    "                               is_policy       = False, \n",
    "                               num_train_layers= None,\n",
    "                               eval_iters      = eval_iters, \n",
    "                               progress        = True,\n",
    "                               leave           = False,\n",
    "                               verbose         = False)\n",
    "\n",
    "        environ.print_metrics(current_iter, start_time, val_metrics, title = f\"[v] Warmup epoch:{current_epoch}    iter:\")\n",
    "    \n",
    "        print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics, line_count, out=[sys.stdout, environ.log_file]) \n",
    "        line_count += 1\n",
    "\n",
    "environ.save_checkpoint('warmup', current_iter)   \n",
    "environ.display_loss(current_iter, title = f\"[e] Warmup epoch:{current_epoch}    iter:\")\n",
    "environ.display_trained_policy(current_epoch,out=[sys.stdout, environ.log_file])\n",
    "environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49645c",
   "metadata": {},
   "source": [
    "## Weight & Policy Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aade16",
   "metadata": {},
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acf7ca48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T18:02:22.477250Z",
     "start_time": "2022-02-15T18:02:22.133482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "** 2022-02-15 10:02:22:156772 - Training iteration 108   flag: update_w \n",
      "** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\n",
      "** Switch from Warm Up training to Alternate training Weights & Policy \n",
      "** Take checkpoint and block gradient flow through Policy net\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Weight iter alternate  : 108\n",
      "Alpha  iter alternate  : 108\n",
      "stop_iter_w (Batches in weight epoch)  : 108\n",
      "stop_iter_a (Batches in policy epoch)7 : 108\n",
      "\n",
      "current_iters          : 108\n",
      "current_epoch          : 1\n",
      "train_total_epochs     : 50\n"
     ]
    }
   ],
   "source": [
    "if flag_warmup:\n",
    "    print_heading( f\"** {timestring()} - Training iteration {current_iter}   flag: {flag} \\n\"\n",
    "                   f\"** Set optimizer and scheduler to policy_learning = True (Switch weight optimizer from ADAM to SGD)\\n\"\n",
    "                   f\"** Switch from Warm Up training to Alternate training Weights & Policy \\n\"\n",
    "                   f\"** Take checkpoint and block gradient flow through Policy net\", verbose=True)\n",
    "    environ.define_optimizer(policy_learning=True)\n",
    "    environ.define_scheduler(policy_learning=True)\n",
    "    flag_warmup = False\n",
    "    environ.save_checkpoint('warmup', current_iter)\n",
    "    environ.fix_alpha()\n",
    "    flag = 'update_w'\n",
    "    \n",
    "# train_total_epochs = 100\n",
    "# train_total_epochs = 50\n",
    "print(f\"Weight iter alternate  : {opt['train']['weight_iter_alternate'] }\")\n",
    "print(f\"Alpha  iter alternate  : {opt['train']['alpha_iter_alternate'] }\")\n",
    "print(f\"stop_iter_w (Batches in weight epoch)  : {stop_iter_w}\")\n",
    "print(f\"stop_iter_a (Batches in policy epoch)7 : {stop_iter_a}\")\n",
    "print()\n",
    "print(f\"current_iters          : {current_iter}\")  \n",
    "print(f\"current_epoch          : {current_epoch}\") \n",
    "print(f\"train_total_epochs     : {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5f9f2",
   "metadata": {},
   "source": [
    "### Weight/Policy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96d311d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-15T18:02:24.488Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      " Last Epoch: 1   # of iteration epochs to do:  50 - Run epochs 2 to 50\n",
      "-------------------------------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148c8ffd939740ada0a6c15015e52f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Alternate Weight/Policy training:   2%|2         | 1/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbardool/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch |  trn loss     trn spar     trn shar  trn total |   logloss   bceloss    aucroc     aucpr |  val loss     val spar     val shar  val total |  time |\n",
      "2     |    8.8784   2.0795e-06   2.7106e-01     9.1495 |   0.00019   0.88596   0.58063   0.59147 |   13.2605   2.0795e-06   2.7106e-01    13.5316 |  36.9 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2     |    8.8821   2.0764e-06   4.3220e-03     8.8864 |   0.00019   0.88698   0.58114   0.58439 |   13.2909   2.0764e-06   2.8936e-03    13.2937 |  37.2 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3     |    8.9173   2.0764e-06   2.8936e-03     8.9202 |   0.00020   0.90199   0.62003   0.61344 |   13.5709   2.0764e-06   2.8936e-03    13.5738 |  38.7 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3     |    8.7908   2.0760e-06   2.9246e-03     8.7937 |   0.00020   0.90385   0.61371   0.61084 |   13.5403   2.0760e-06   4.1379e-03    13.5445 |  34.9 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4     |    9.0706   2.0760e-06   4.1379e-03     9.0747 |   0.00021   0.93816   0.62303   0.62069 |   14.0382   2.0760e-06   4.1379e-03    14.0423 |  40.8 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4     |    9.0187   2.0781e-06   3.5756e-03     9.0223 |   0.00022   0.98854   0.61805   0.61031 |   14.7959   2.0781e-06   2.3805e-03    14.7983 |  36.9 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5     |    8.9097   2.0781e-06   2.3805e-03     8.9121 |   0.00018   0.80614   0.65936   0.64774 |   12.0698   2.0781e-06   2.3805e-03    12.0722 |  40.0 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5     |    8.7128   2.0786e-06   5.5351e-03     8.7184 |   0.00018   0.80430   0.65627   0.64815 |   12.0436   2.0786e-06   4.7457e-03    12.0483 |  36.5 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6     |    7.7645   2.0786e-06   4.7457e-03     7.7692 |   0.00018   0.81809   0.66218   0.64818 |   12.2472   2.0786e-06   4.7457e-03    12.2519 |  41.6 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6     |    7.7081   2.0794e-06   2.6113e-03     7.7107 |   0.00017   0.77403   0.66967   0.66307 |   11.6314   2.0794e-06   2.1438e-03    11.6336 |  37.0 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7     |    8.0292   2.0794e-06   2.1438e-03     8.0314 |   0.00018   0.80936   0.67446   0.66635 |   12.1174   2.0794e-06   2.1438e-03    12.1196 |  39.4 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7     |    7.9272   2.0797e-06   2.4863e-03     7.9297 |   0.00018   0.81337   0.68314   0.66768 |   12.2220   2.0797e-06   2.1338e-03    12.2242 |  37.0 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8     |    7.6986   2.0797e-06   2.1338e-03     7.7007 |   0.00017   0.77941   0.68609   0.68107 |   11.7395   2.0797e-06   2.1338e-03    11.7417 |  41.7 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8     |    7.6939   2.0810e-06   2.6485e-03     7.6966 |   0.00018   0.81382   0.68104   0.67807 |   12.1950   2.0810e-06   2.2759e-03    12.1972 |  36.7 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9     |    7.8094   2.0810e-06   2.2759e-03     7.8117 |   0.00018   0.79595   0.70127   0.69197 |   12.0217   2.0810e-06   2.2759e-03    12.0240 |  39.8 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9     |    7.8123   2.0791e-06   1.5482e-03     7.8138 |   0.00016   0.72102   0.70842   0.70414 |   10.8260   2.0790e-06   1.7911e-03    10.8277 |  36.5 |\n",
      " decay gumbel softmax to 3.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10    |    7.4061   2.0790e-06   1.7911e-03     7.4079 |   0.00017   0.79814   0.69619   0.69049 |   11.9672   2.0790e-06   1.7911e-03    11.9690 |  38.4 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10    |    7.4247   2.0802e-06   3.2464e-03     7.4280 |   0.00018   0.80816   0.70137   0.69800 |   12.1072   2.0802e-06   2.7035e-03    12.1099 |  37.3 |\n",
      "\n",
      "  10 epochs  softmax        sel        softmax       sel        softmax       sel \n",
      " -----    ---------------   ---     ---------------  ---     ---------------  --- \n",
      "   1      0.5051   0.4949    1      0.5045   0.4955   1      0.5036   0.4964   1\n",
      "   2      0.5037   0.4963    1      0.5004   0.4996   1      0.4999   0.5001   0\n",
      "   3      0.4976   0.5024    0      0.4998   0.5002   0      0.4987   0.5013   0\n",
      "   4      0.4976   0.5024    0      0.5017   0.4983   1      0.4983   0.5017   0\n",
      "   5      0.4945   0.5055    0      0.4993   0.5007   0      0.4994   0.5006   0\n",
      "   6      0.4963   0.5037    0      0.5002   0.4998   1      0.5016   0.4984   1\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    |    6.8931   2.0802e-06   2.7035e-03     6.8958 |   0.00016   0.72433   0.70057   0.70248 |   10.8671   2.0802e-06   2.7035e-03    10.8698 |  38.4 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    |    6.8449   2.0794e-06   3.0998e-03     6.8480 |   0.00016   0.72415   0.70254   0.69257 |   10.8466   2.0794e-06   2.6657e-03    10.8492 |  36.0 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12    |    6.4495   2.0794e-06   2.6657e-03     6.4521 |   0.00016   0.74738   0.71396   0.71482 |   11.2016   2.0794e-06   2.6657e-03    11.2042 |  39.6 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12    |    6.4719   2.0788e-06   1.6365e-03     6.4735 |   0.00017   0.76462   0.70799   0.69057 |   11.5062   2.0788e-06   1.7620e-03    11.5080 |  38.2 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13    |    6.5430   2.0788e-06   1.7620e-03     6.5448 |   0.00018   0.82709   0.70592   0.69986 |   12.3807   2.0788e-06   1.7620e-03    12.3825 |  37.7 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13    |    6.4841   2.0781e-06   2.3251e-03     6.4864 |   0.00016   0.72777   0.72066   0.72111 |   10.9052   2.0781e-06   2.9766e-03    10.9081 |  36.1 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14    |    6.7512   2.0781e-06   2.9766e-03     6.7542 |   0.00018   0.80452   0.70116   0.69339 |   12.0487   2.0781e-06   2.9766e-03    12.0517 |  39.2 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch |  trn loss     trn spar     trn shar  trn total |   logloss   bceloss    aucroc     aucpr |  val loss     val spar     val shar  val total |  time |\n",
      "14    |    6.6481   2.0786e-06   1.7159e-03     6.6498 |   0.00017   0.76751   0.70939   0.69981 |   11.4953   2.0786e-06   2.0051e-03    11.4973 |  35.5 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    |    6.2432   2.0786e-06   2.0051e-03     6.2452 |   0.00016   0.72189   0.72728   0.72090 |   10.8185   2.0786e-06   2.0051e-03    10.8205 |  38.8 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    |    6.1596   2.0794e-06   1.7666e-03     6.1614 |   0.00017   0.76253   0.71801   0.71338 |   11.4303   2.0794e-06   1.7855e-03    11.4321 |  37.2 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16    |    5.8493   2.0794e-06   1.7855e-03     5.8511 |   0.00016   0.74380   0.72226   0.72101 |   11.1559   2.0794e-06   1.7855e-03    11.1577 |  38.3 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16    |    5.8755   2.0809e-06   2.7098e-03     5.8782 |   0.00016   0.74137   0.72520   0.72263 |   11.1072   2.0809e-06   2.5227e-03    11.1098 |  36.2 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17    |    6.0545   2.0809e-06   2.5227e-03     6.0570 |   0.00015   0.70239   0.73709   0.73591 |   10.5248   2.0809e-06   2.5227e-03    10.5273 |  40.7 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17    |    6.0377   2.0826e-06   2.0422e-03     6.0397 |   0.00016   0.71825   0.73549   0.73015 |   10.7589   2.0826e-06   2.3540e-03    10.7613 |  37.4 |\n",
      " decay gumbel softmax to 3.24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    |    5.6646   2.0826e-06   2.3540e-03     5.6669 |   0.00016   0.73190   0.73655   0.73578 |   10.9644   2.0826e-06   2.3540e-03    10.9668 |  38.0 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    |    5.6613   2.0839e-06   3.0918e-03     5.6644 |   0.00016   0.75193   0.73299   0.73238 |   11.2637   2.0839e-06   2.7713e-03    11.2665 |  38.0 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19    |    5.6179   2.0839e-06   2.7713e-03     5.6207 |   0.00016   0.71859   0.73564   0.73298 |   10.7631   2.0839e-06   2.7713e-03    10.7658 |  38.4 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19    |    5.4909   2.0844e-06   2.3004e-03     5.4932 |   0.00015   0.68478   0.74539   0.74652 |   10.2578   2.0844e-06   2.1444e-03    10.2599 |  37.3 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20    |    5.2259   2.0844e-06   2.1444e-03     5.2280 |   0.00015   0.68574   0.75017   0.75325 |   10.2832   2.0844e-06   2.1444e-03    10.2854 |  37.4 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20    |    5.1668   2.0835e-06   1.9062e-03     5.1687 |   0.00018   0.81430   0.72921   0.72422 |   12.1925   2.0835e-06   1.7760e-03    12.1943 |  35.2 |\n",
      "\n",
      "  20 epochs  softmax        sel        softmax       sel        softmax       sel \n",
      " -----    ---------------   ---     ---------------  ---     ---------------  --- \n",
      "   1      0.5083   0.4917    1      0.5055   0.4945   1      0.5041   0.4959   1\n",
      "   2      0.5042   0.4958    1      0.5014   0.4986   1      0.4995   0.5005   0\n",
      "   3      0.4961   0.5039    0      0.5006   0.4994   1      0.4986   0.5014   0\n",
      "   4      0.4956   0.5044    0      0.5044   0.4956   1      0.4976   0.5024   0\n",
      "   5      0.4920   0.5080    0      0.5035   0.4965   1      0.4987   0.5013   0\n",
      "   6      0.4957   0.5043    0      0.5049   0.4951   1      0.5010   0.4990   1\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21    |    4.9951   2.0835e-06   1.7760e-03     4.9969 |   0.00015   0.68422   0.75415   0.75209 |   10.2508   2.0835e-06   1.7760e-03    10.2526 |  38.1 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21    |    4.9826   2.0850e-06   3.1281e-03     4.9858 |   0.00015   0.69805   0.74981   0.74905 |   10.4620   2.0850e-06   3.4941e-03    10.4655 |  35.8 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22    |    4.9697   2.0850e-06   3.4941e-03     4.9732 |   0.00015   0.69826   0.75635   0.75676 |   10.4638   2.0850e-06   3.4941e-03    10.4673 |  40.2 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22 policy training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22    |    4.9413   2.0848e-06   2.6675e-03     4.9440 |   0.00017   0.75618   0.75532   0.75769 |   11.3252   2.0848e-06   2.4624e-03    11.3276 |  35.5 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23 weight training:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cb9dd1131c45308b0d999f8faa90c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_heading(f\" Last Epoch: {current_epoch}   # of iteration epochs to do:  {train_total_epochs} - Run epochs {current_epoch+1} to {train_total_epochs}\", verbose = True)\n",
    "leave      = False\n",
    "verbose    = False\n",
    "line_count = 0\n",
    "t = tqdm(initial = current_epoch, total=train_total_epochs, desc=f\" Alternate Weight/Policy training\")\n",
    "\n",
    "while current_epoch < train_total_epochs:\n",
    "    current_epoch+=1\n",
    "    t.update(1)\n",
    "    #-----------------------------------------------------------------------------------------------------------\n",
    "    # Set number of layers to train based on cirriculum_speed and p_epoch (number of epochs of policy training)\n",
    "    # e.g., When curriculum_speed == 3, num_train_layers is incremented  after every 3 policy training epochs\n",
    "    #-----------------------------------------------------------------------------------------------------------\n",
    "    num_train_layers = (p_epoch // opt['curriculum_speed']) + 1  if opt['is_curriculum'] else None\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # Train & Update the network weights\n",
    "    #-----------------------------------------\n",
    "    if flag == 'update_w':\n",
    "        start_time = time.time()\n",
    "\n",
    "        with trange(+1, stop_iter_w+1 , initial = 0, total = stop_iter_w, position=0,\n",
    "                     leave= leave, desc=f\"Epoch {current_epoch} weight training\") as t_weights :\n",
    "            \n",
    "            for current_iter_w in t_weights:    \n",
    "                current_iter += 1\n",
    "                environ.train()\n",
    "                batch = next(train_loader)\n",
    "\n",
    "                environ.set_inputs(batch, train1_loader.dataset.input_size)\n",
    " \n",
    "                environ.optimize(opt['lambdas'], \n",
    "                                 is_policy=opt['policy'], \n",
    "                                 flag=flag, \n",
    "                                 num_train_layers=num_train_layers,\n",
    "                                 hard_sampling=opt['train']['hard_sampling'],\n",
    "                                 verbose = False)\n",
    "\n",
    "                t_weights.set_postfix({'iter': current_iter, \n",
    "                                       'Loss': f\"{environ.losses['losses']['total'].item():.4f}\" , \n",
    "                                       'Spar': f\"{environ.losses['sparsity']['total'].item():.4e}\",  \n",
    "                                       'Shar': f\"{environ.losses['sharing']['total'].item():.4e}\"})  \n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        # validation process (here current_iter_w and stop_iter_w are equal)\n",
    "        #--------------------------------------------------------------------\n",
    "        trn_losses = environ.losses\n",
    "        environ.print_loss(current_iter, start_time, title = f\"[e] Weight training epoch:{current_epoch}    iter:\", to_display = False)\n",
    "\n",
    "        val_metrics = environ.evaluate(val_loader, opt['tasks'], is_policy=opt['policy'],\n",
    "                                       num_train_layers=num_train_layers, hard_sampling=opt['train']['hard_sampling'],\n",
    "                                       eval_iters = eval_iters, progress = True, leave = leave, verbose = False)  \n",
    "\n",
    "        environ.print_metrics(current_iter, start_time, val_metrics, title = f\"[v] Weight training epoch:{current_epoch}    iter:\", verbose = False)\n",
    "        print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics, line_count, out=[sys.stdout, environ.log_file]) \n",
    "        line_count += 1\n",
    "\n",
    "        # Take check point:     environ.save_checkpoint('latest_weights', current_iter)\n",
    "        #------------------------------------------------------------------------ \n",
    "        #  Save Best Checkpoint Code (saved below and in sparsechem_env_dev.py)\n",
    "        #----------------------------------------------------------------------- \n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # END validation process - prepare for policy training iteration\n",
    "        #-----------------------------------------------------------------------\n",
    "        flag = 'update_alpha'\n",
    "        environ.fix_weights()\n",
    "        environ.free_alpha()\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # Policy Training  \n",
    "    #-----------------------------------------\n",
    "    if flag == 'update_alpha':\n",
    "        start_time = time.time()        \n",
    "\n",
    "        with trange( +1, stop_iter_a+1 , initial = 0, total = stop_iter_a,  position=0,\n",
    "                     leave= leave, desc=f\"Epoch {current_epoch} policy training\") as t_policy :\n",
    "            for current_iter_a in t_policy:    \n",
    "                current_iter += 1\n",
    "                batch = next(train_loader)\n",
    "\n",
    "                environ.set_inputs(batch, train2_loader.dataset.input_size)\n",
    "\n",
    "                environ.optimize(opt['lambdas'], is_policy=opt['policy'], \n",
    "                                 flag=flag, num_train_layers=num_train_layers,\n",
    "                                 hard_sampling=opt['train']['hard_sampling'], verbose = False)\n",
    "                \n",
    "                t_policy.set_postfix({'iter': current_iter, \n",
    "                                      'Loss': f\"{environ.losses['losses']['total'].item():.4f}\" , \n",
    "                                      'Spar': f\"{environ.losses['sparsity']['total'].item():.4e}\" ,  \n",
    "                                      'Shar': f\"{environ.losses['sharing']['total'].item():.4e}\",\n",
    "                                      'lyrs': f\"{num_train_layers}\"})    \n",
    "#                                       'row_ids':f\"{batch['row_id'][0]}-{batch['row_id'][-1]}\"})\n",
    "        #---------------------------------------------------------------------\n",
    "        # print loss results (here current_iter_w and stop_iter_w are equal)\n",
    "        #---------------------------------------------------------------------\n",
    "        trn_losses = environ.losses\n",
    "        environ.print_loss(current_iter, start_time, title = f\"[e] Policy training epoch:{current_epoch}    iter:\")\n",
    "\n",
    "        val_metrics = environ.evaluate(val_loader, opt['tasks'], is_policy=opt['policy'],\n",
    "                                       num_train_layers=num_train_layers, hard_sampling=opt['train']['hard_sampling'],\n",
    "                                       eval_iters = eval_iters, progress = True, leave = False, verbose = False)  \n",
    "\n",
    "        environ.print_metrics(current_iter, start_time, val_metrics, title = f\"[v] Policy training epoch:{current_epoch}    iter:\", verbose = False)\n",
    "        print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics, line_count, out=[sys.stdout, environ.log_file])      \n",
    "        line_count += 1\n",
    "        \n",
    "        p_epoch += 1        \n",
    "        if should(p_epoch, opt['train']['decay_temp_freq']):\n",
    "            environ.decay_temperature()\n",
    "            print(f\" decay gumbel softmax to {environ.temp}\")\n",
    "        \n",
    "        flag = 'update_w'\n",
    "        environ.fix_alpha()\n",
    "        environ.free_weights(opt['fix_BN'])\n",
    "\n",
    "    if should(current_epoch, 10):\n",
    "        environ.log_file.flush()\n",
    "        environ.save_checkpoint('latest_weights_policy', current_iter)        \n",
    "        environ.display_trained_policy(current_epoch,out=[sys.stdout, environ.log_file])\n",
    "\n",
    "environ.save_checkpoint('final_weights_policy', current_iter)   \n",
    "environ.display_loss(current_iter, title = f\"[e] Policy training epoch:{current_epoch}    iter:\", to_display = True)\n",
    "environ.display_trained_policy(current_epoch,out=[sys.stdout, environ.log_file])\n",
    "environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aabea7b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-15T17:41:23.205Z"
    }
   },
   "outputs": [],
   "source": [
    "print( f\"\\n Sparsity regularization   : {opt['train']['lambda_sparsity']}\",\n",
    "       f\"\\n Sharing  regularization   : {opt['train']['lambda_sharing']}\",\n",
    "       f\"\\n current_epochs               : {current_epoch}\") # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f1fb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9695bcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e71f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f771fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d498519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f017cda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T17:41:59.110283Z",
     "start_time": "2022-02-14T17:41:59.042649Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ.print_loss(current_iter, start_time, title = f\"[e]Policy training epoch:{current_epoch}   iteration:\", verbose=True)\n",
    "# environ.display_trained_policy(current_epoch, out = [None, environ.log_file])\n",
    "# environ.log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3cab68f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T18:13:59.234029Z",
     "start_time": "2022-02-14T18:13:59.156444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_iters         : 540\n",
      "curr_epochs           : 3\n",
      "train_total_epochs    : 6\n"
     ]
    }
   ],
   "source": [
    "train_total_epochs += 3\n",
    "     \n",
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1ab1dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T18:11:08.395760Z",
     "start_time": "2022-02-14T18:11:08.195848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'losses': {   'task1': tensor(3.384938, device='cuda:0', dtype=torch.float64),\n",
      "                  'task2': tensor(3.544476, device='cuda:0', dtype=torch.float64),\n",
      "                  'task3': tensor(4.924039, device='cuda:0', dtype=torch.float64),\n",
      "                  'total': tensor(11.853453, device='cuda:0', dtype=torch.float64)},\n",
      "    'losses_mean': {   'task1': tensor(0.676988, device='cuda:0', dtype=torch.float64),\n",
      "                       'task2': tensor(0.708895, device='cuda:0', dtype=torch.float64),\n",
      "                       'task3': tensor(0.984808, device='cuda:0', dtype=torch.float64),\n",
      "                       'total': tensor(2.370691, device='cuda:0', dtype=torch.float64)},\n",
      "    'parms': {   'gumbel_temp': 4,\n",
      "                 'lr_0': 0.01,\n",
      "                 'lr_1': 0.01,\n",
      "                 'policy_lr': 0.0001,\n",
      "                 'train_layers': 0},\n",
      "    'sharing': {'total': tensor(0.000328, device='cuda:0')},\n",
      "    'sparsity': {   'task1_logits': tensor(6.913636e-08, device='cuda:0'),\n",
      "                    'task2_logits': tensor(6.942656e-08, device='cuda:0'),\n",
      "                    'task3_logits': tensor(6.903436e-08, device='cuda:0'),\n",
      "                    'total': tensor(2.075973e-07, device='cuda:0')},\n",
      "    'task1': {   'cls_loss': tensor(3.384938, device='cuda:0', dtype=torch.float64),\n",
      "                 'cls_loss_mean': tensor(0.676988, device='cuda:0', dtype=torch.float64)},\n",
      "    'task2': {   'cls_loss': tensor(3.544476, device='cuda:0', dtype=torch.float64),\n",
      "                 'cls_loss_mean': tensor(0.708895, device='cuda:0', dtype=torch.float64)},\n",
      "    'task3': {   'cls_loss': tensor(4.924039, device='cuda:0', dtype=torch.float64),\n",
      "                 'cls_loss_mean': tensor(0.984808, device='cuda:0', dtype=torch.float64)},\n",
      "    'total': {   'total': tensor(11.853781, device='cuda:0', dtype=torch.float64),\n",
      "                 'total_mean': tensor(2.371019, device='cuda:0', dtype=torch.float64)},\n",
      "    'total_mean': {}}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60ed5d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Post Training Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82a453",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Post Warm-up Training stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bb74c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:45:43.999959Z",
     "start_time": "2022-02-01T12:45:43.862475Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'aggregated': {   'auc_pr': 0.5683542231355692,\n",
      "                      'avg_prec_score': 0.5686955149511226,\n",
      "                      'bceloss': 0.6940069357554117,\n",
      "                      'f1_max': 0.6753742658177068,\n",
      "                      'kappa': 0.08318090860174578,\n",
      "                      'kappa_max': 0.11385237142207795,\n",
      "                      'logloss': tensor(0.0002, device='cuda:0', dtype=torch.float64),\n",
      "                      'p_f1_max': 0.29707588851451877,\n",
      "                      'p_kappa_max': 0.48534467220306404,\n",
      "                      'roc_auc_score': 0.5679242272843051,\n",
      "                      'sc_loss': tensor(0.2891, device='cuda:0', dtype=torch.float64)},\n",
      "    'epoch': 1,\n",
      "    'loss': {   'task1': 3.5098743182605396,\n",
      "                'task2': 3.4508372449718867,\n",
      "                'task3': 3.4480013587242775,\n",
      "                'total': 10.408712921956704},\n",
      "    'loss_mean': {   'task1': 0.701974863652108,\n",
      "                     'task2': 0.6901674489943774,\n",
      "                     'task3': 0.6896002717448555,\n",
      "                     'total': 2.081742584391341},\n",
      "    'sharing': {'total': 0.0},\n",
      "    'sparsity': {   'task1': 0.006931469672256046,\n",
      "                    'task2': 0.006931469672256046,\n",
      "                    'task3': 0.006931469672256046,\n",
      "                    'total': 0.02079441025853157},\n",
      "    'task1': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.481316  0.429663        0.430056  0.621828  0.471980  0.007806   0.011740     0.501525  0.711726\n",
      "1          0.614529  0.563585        0.563966  0.592718  0.274593  0.163883   0.197754     0.467472  0.666188\n",
      "2          0.522325  0.502621        0.502973  0.674570  0.496948  0.023925   0.051563     0.584286  0.737475\n",
      "3          0.604399  0.573962        0.574392  0.654175  0.170357  0.120525   0.155403     0.545623  0.686908\n",
      "4          0.547591  0.537607        0.537968  0.682173  0.107585  0.035985   0.094520     0.418316  0.706954,\n",
      "                 'classification_agg': {   'auc_pr': 0.5214877235862244,\n",
      "                                           'avg_prec_score': 0.5218710163685921,\n",
      "                                           'bceloss': 0.701850187778473,\n",
      "                                           'f1_max': 0.6450929564660765,\n",
      "                                           'kappa': 0.07042502365080995,\n",
      "                                           'kappa_max': 0.10219606455150174,\n",
      "                                           'logloss': 0.005540691754324903,\n",
      "                                           'p_f1_max': 0.30429269671440123,\n",
      "                                           'p_kappa_max': 0.5034442186355592,\n",
      "                                           'roc_auc_score': 0.55403197977543,\n",
      "                                           'sc_loss': 3.5098743182605396}},\n",
      "    'task2': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.534265  0.559859        0.560165  0.693035  0.218099  0.060112   0.080040     0.485316  0.695036\n",
      "1          0.530896  0.552645        0.553118  0.693306  0.425663  0.026862   0.048743     0.510863  0.689872\n",
      "2          0.576279  0.542077        0.542489  0.661162  0.428496  0.099542   0.110405     0.489080  0.690190\n",
      "3          0.570442  0.599299        0.599621  0.687941  0.390608  0.066299   0.108004     0.535856  0.683957\n",
      "4          0.573253  0.563653        0.563954  0.670703  0.355411  0.064108   0.122336     0.415524  0.693014,\n",
      "                 'classification_agg': {   'auc_pr': 0.5635064814369257,\n",
      "                                           'avg_prec_score': 0.5638693726843218,\n",
      "                                           'bceloss': 0.6904138207435608,\n",
      "                                           'f1_max': 0.68122964433069,\n",
      "                                           'kappa': 0.06338457615584966,\n",
      "                                           'kappa_max': 0.09390563833389994,\n",
      "                                           'logloss': 0.005447495760534441,\n",
      "                                           'p_f1_max': 0.36365539729595187,\n",
      "                                           'p_kappa_max': 0.48732774853706357,\n",
      "                                           'roc_auc_score': 0.5570268805789104,\n",
      "                                           'sc_loss': 3.4508372449718867}},\n",
      "    'task3': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.614326  0.669207        0.669500  0.741408  0.294902  0.156246   0.192341     0.449188  0.678097\n",
      "1          0.622672  0.643428        0.643670  0.700539  0.259311  0.175533   0.185877     0.495724  0.678892\n",
      "2          0.599966  0.585534        0.585907  0.656115  0.252795  0.146259   0.153308     0.452810  0.678784\n",
      "3          0.565999  0.629145        0.629346  0.716296  0.062077  0.041028   0.092855     0.403423  0.724491\n",
      "4          0.560606  0.573028        0.573308  0.684643  0.247313  0.059600   0.102897     0.525165  0.688519,\n",
      "                 'classification_agg': {   'auc_pr': 0.6200684643835576,\n",
      "                                           'avg_prec_score': 0.6203461558004543,\n",
      "                                           'bceloss': 0.6897567987442017,\n",
      "                                           'f1_max': 0.699800196656354,\n",
      "                                           'kappa': 0.11573312599857777,\n",
      "                                           'kappa_max': 0.1454554113808322,\n",
      "                                           'logloss': 0.005443019027146415,\n",
      "                                           'p_f1_max': 0.22327957153320316,\n",
      "                                           'p_kappa_max': 0.4652620494365692,\n",
      "                                           'roc_auc_score': 0.5927138214985748,\n",
      "                                           'sc_loss': 3.4480013587242775}},\n",
      "    'train_time': 17.335111618041992}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "912b47da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:36.700361Z",
     "start_time": "2022-02-01T12:46:36.367037Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.5000, 0.5000],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5000, 0.5000]], device='cuda:0'),\n",
       " Parameter containing:\n",
       " tensor([[0.5000, 0.5000],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5000, 0.5000]], device='cuda:0'),\n",
       " Parameter containing:\n",
       " tensor([[0.5000, 0.5000],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5000, 0.5000]], device='cuda:0')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.networks['mtl-net'].arch_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "922f0235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:37:10.158440Z",
     "start_time": "2022-01-28T16:37:09.742327Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]], device='cuda:0'), tensor([[0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1]], device='cuda:0'), tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1]], device='cuda:0')], [array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32), array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32), array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32)])\n",
      "[array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32), array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32), array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32)]\n",
      "[array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32), array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32), array([[0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5],\n",
      "       [0.5, 0.5]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "p = environ.get_sample_policy(hard_sampling = False)\n",
    "print(p)\n",
    "p = environ.get_policy_prob()\n",
    "print(p)\n",
    "p = environ.get_policy_logits()\n",
    "print(p)\n",
    "\n",
    "# p = environ.get_current_policy()\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6bddd44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:40:37.799917Z",
     "start_time": "2022-01-28T16:40:37.773177Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26894142 0.73105858]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "a = softmax([0.0, 1])\n",
    "print(a)\n",
    "sampled = np.random.choice((1, 0), p=a)\n",
    "print(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5e8f376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:13:16.205889Z",
     "start_time": "2022-01-28T16:13:16.179303Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.5, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    weight_decay: 0.0001\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.5, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "[0.01, 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(environ.optimizers['weights'])\n",
    "print(environ.schedulers['weights'].get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dddf9c47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:46:50.411465Z",
     "start_time": "2022-02-01T12:46:50.020540Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses.keys      :  dict_keys(['parms', 'losses', 'losses_mean', 'sparsity', 'sharing', 'total', 'total_mean', 'task1', 'task2', 'task3'])\n",
      "losses[task]keys :  dict_keys(['cls_loss', 'cls_loss_mean'])\n",
      "{   'losses': {   'task1': tensor(3.5704, device='cuda:0', dtype=torch.float64),\n",
      "                  'task2': tensor(3.3313, device='cuda:0', dtype=torch.float64),\n",
      "                  'task3': tensor(3.3721, device='cuda:0', dtype=torch.float64),\n",
      "                  'total': tensor(10.2737, device='cuda:0', dtype=torch.float64)},\n",
      "    'losses_mean': {   'task1': tensor(0.7141, device='cuda:0', dtype=torch.float64),\n",
      "                       'task2': tensor(0.6663, device='cuda:0', dtype=torch.float64),\n",
      "                       'task3': tensor(0.6744, device='cuda:0', dtype=torch.float64),\n",
      "                       'total': tensor(2.0547, device='cuda:0', dtype=torch.float64)},\n",
      "    'parms': {'gumbel_temp': 5, 'lr_0': 0.01, 'lr_1': 0.01, 'train_layers': 0},\n",
      "    'sharing': {'total': tensor(0., device='cuda:0')},\n",
      "    'sparsity': {   'task1_logits': tensor(0.0069, device='cuda:0'),\n",
      "                    'task2_logits': tensor(0.0069, device='cuda:0'),\n",
      "                    'task3_logits': tensor(0.0069, device='cuda:0'),\n",
      "                    'total': tensor(0.0208, device='cuda:0')},\n",
      "    'task1': {   'cls_loss': tensor(3.5704, device='cuda:0', dtype=torch.float64),\n",
      "                 'cls_loss_mean': tensor(0.7141, device='cuda:0', dtype=torch.float64)},\n",
      "    'task2': {   'cls_loss': tensor(3.3313, device='cuda:0', dtype=torch.float64),\n",
      "                 'cls_loss_mean': tensor(0.6663, device='cuda:0', dtype=torch.float64)},\n",
      "    'task3': {   'cls_loss': tensor(3.3721, device='cuda:0', dtype=torch.float64),\n",
      "                 'cls_loss_mean': tensor(0.6744, device='cuda:0', dtype=torch.float64)},\n",
      "    'total': {},\n",
      "    'total_mean': {}}\n"
     ]
    }
   ],
   "source": [
    "print('losses.keys      : ', environ.losses.keys())\n",
    "print('losses[task]keys : ', environ.losses['task1'].keys())\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20950069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T22:57:02.151169Z",
     "start_time": "2022-01-15T22:57:02.056562Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'loss_mean', 'task1', 'task2', 'task3', 'aggregated', 'train_time', 'epoch'])\n",
      "<class 'dict'>\n",
      "\n",
      "<class 'dict'>\n",
      "\n",
      "{   'aggregated': {   'auc_pr': 0.8163426647572675,\n",
      "                      'avg_prec_score': 0.8164138615123665,\n",
      "                      'bceloss': 0.7729340473810831,\n",
      "                      'f1_max': 0.7574111413660235,\n",
      "                      'kappa': 0.4593877004350045,\n",
      "                      'kappa_max': 0.4722816344851592,\n",
      "                      'logloss': tensor(0.0002, device='cuda:0', dtype=torch.float64),\n",
      "                      'p_f1_max': 0.1918067594369252,\n",
      "                      'p_kappa_max': 0.545021508137385,\n",
      "                      'roc_auc_score': 0.8101998985724014,\n",
      "                      'sc_loss': tensor(0.3217, device='cuda:0', dtype=torch.float64)},\n",
      "    'epoch': 4000,\n",
      "    'loss': {   'task1': 3.990690022259455,\n",
      "                'task2': 3.7726694706664947,\n",
      "                'task3': 3.817710672775008,\n",
      "                'total': 11.581070165700957},\n",
      "    'loss_mean': {   'task1': 0.7981380044518911,\n",
      "                     'task2': 0.7545338941332989,\n",
      "                     'task3': 0.7635421345550015,\n",
      "                     'total': 2.316214033140191},\n",
      "    'task1': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.840926  0.819320        0.819383  0.744605  0.188466  0.505203   \n",
      "1          0.817256  0.785624        0.785697  0.706325  0.234966  0.461667   \n",
      "2          0.821726  0.819394        0.819462  0.768309  0.103616  0.482997   \n",
      "3          0.772370  0.766114        0.766202  0.713072  0.197119  0.414875   \n",
      "4          0.785095  0.803825        0.803897  0.735945  0.241081  0.416901   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.524762     0.693089  0.702767  \n",
      "1      0.474705     0.729373  0.757761  \n",
      "2      0.496770     0.312012  0.779951  \n",
      "3      0.423936     0.581922  0.935489  \n",
      "4      0.427422     0.811243  0.819495  ,\n",
      "                 'classification_agg': {   'auc_pr': 0.798855508429197,\n",
      "                                           'avg_prec_score': 0.7989281568935325,\n",
      "                                           'bceloss': 0.799092447757721,\n",
      "                                           'f1_max': 0.7336512000971758,\n",
      "                                           'kappa': 0.4563288316147501,\n",
      "                                           'kappa_max': 0.46951913050242283,\n",
      "                                           'logloss': 0.006299707993919771,\n",
      "                                           'p_f1_max': 0.19304971992969516,\n",
      "                                           'p_kappa_max': 0.6255278527736664,\n",
      "                                           'roc_auc_score': 0.807474721566956,\n",
      "                                           'sc_loss': 3.990690022259455}},\n",
      "    'task2': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.833828  0.843551        0.843636  0.786776  0.286642  0.512757   \n",
      "1          0.784282  0.798552        0.798620  0.756201  0.065474  0.405454   \n",
      "2          0.794011  0.798233        0.798299  0.733455  0.167343  0.431454   \n",
      "3          0.839064  0.860586        0.860625  0.781065  0.199097  0.508344   \n",
      "4          0.841909  0.844915        0.844966  0.774130  0.124443  0.519265   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.518114     0.426390  0.753670  \n",
      "1      0.422608     0.354472  0.840536  \n",
      "2      0.436441     0.481076  0.776165  \n",
      "3      0.518856     0.430450  0.718333  \n",
      "4      0.526225     0.478729  0.695051  ,\n",
      "                 'classification_agg': {   'auc_pr': 0.8291675538480338,\n",
      "                                           'avg_prec_score': 0.8292292868467086,\n",
      "                                           'bceloss': 0.7567508101463318,\n",
      "                                           'f1_max': 0.7663254180716083,\n",
      "                                           'kappa': 0.4754547147763093,\n",
      "                                           'kappa_max': 0.48444883865167504,\n",
      "                                           'logloss': 0.005955540493049498,\n",
      "                                           'p_f1_max': 0.16859976947307587,\n",
      "                                           'p_kappa_max': 0.4342232346534729,\n",
      "                                           'roc_auc_score': 0.8186188467896192,\n",
      "                                           'sc_loss': 3.7726694706664947}},\n",
      "    'task3': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.789143  0.818832        0.818915  0.795256  0.131201  0.430588   \n",
      "1          0.773360  0.795295        0.795367  0.746918  0.344915  0.380806   \n",
      "2          0.863028  0.864169        0.864209  0.780428  0.294887  0.545351   \n",
      "3          0.807607  0.821005        0.821136  0.791405  0.165901  0.457213   \n",
      "4          0.789393  0.805724        0.805793  0.747277  0.131950  0.417939   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  \n",
      "task                                    \n",
      "0      0.437650     0.549203  0.781711  \n",
      "1      0.414754     0.814326  0.928911  \n",
      "2      0.565829     0.637907  0.605613  \n",
      "3      0.469116     0.303002  0.703193  \n",
      "4      0.427037     0.572130  0.795366  ,\n",
      "                 'classification_agg': {   'auc_pr': 0.8210049319945718,\n",
      "                                           'avg_prec_score': 0.8210841407968588,\n",
      "                                           'bceloss': 0.7629588842391969,\n",
      "                                           'f1_max': 0.7722568059292869,\n",
      "                                           'kappa': 0.4463795549139541,\n",
      "                                           'kappa_max': 0.46287693430137955,\n",
      "                                           'logloss': 0.006026642588024569,\n",
      "                                           'p_f1_max': 0.21377078890800477,\n",
      "                                           'p_kappa_max': 0.5753134369850159,\n",
      "                                           'roc_auc_score': 0.8045061273606293,\n",
      "                                           'sc_loss': 3.817710672775008}},\n",
      "    'train_time': 47.46593999862671}\n"
     ]
    }
   ],
   "source": [
    "print( environ.val_metrics.keys())\n",
    "# pp.pprint(val_metrics)\n",
    "print(type(environ.val_metrics['aggregated']))\n",
    "print()\n",
    "print(type(environ.val_metrics['task1']['classification_agg']))\n",
    "print()\n",
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eed6e311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.266303Z",
     "start_time": "2022-01-14T18:57:26.166878Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"val_metrics.pkl\", mode= 'wb') as f:\n",
    "#         pickle.dump(val_metrics, f)\n",
    "    \n",
    "# with open('val_metrics.pkl', 'rb') as f:    \n",
    "#     tst_val_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b00a8aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.297444Z",
     "start_time": "2022-01-14T18:57:26.269323Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(environ.input.shape) \n",
    "# a = getattr(environ, 'task1_pred')\n",
    "# yc_data = environ.batch['task1_data']\n",
    "# print(yc_data.shape)\n",
    "# yc_ind = environ.batch['task1_ind']\n",
    "# print(yc_ind.shape)\n",
    "# yc_hat_all = getattr(environ, 'task1_pred')\n",
    "# print(yc_hat_all.shape)\n",
    "# yc_hat  = yc_hat_all[yc_ind[0], yc_ind[1]]\n",
    "# print(yc_hat_all.shape, yc_hat.shape)\n",
    "\n",
    "# \n",
    "# environ.losses\n",
    "# loss = {}\n",
    "# for key in environ.losses.keys():\n",
    "#     loss[key] = {}\n",
    "#     for subkey, v in environ.losses[key].items():\n",
    "#         print(f\" key:  {key}   subkey: {subkey} \")\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             loss[key][subkey] = v.data\n",
    "#             print(f\" Tensor  -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "#         else:\n",
    "#             loss[key][subkey] = v\n",
    "#             print(f\" integer -  key:  {key}   subkey: {subkey}           value type: {type(v)}  value: {v:.4f}\")\n",
    "# pp.pprint(tst_val_metrics)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5987f89f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.340792Z",
     "start_time": "2022-01-14T18:57:26.302528Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:49:07.606120Z",
     "iopub.status.busy": "2022-01-07T22:49:07.604909Z",
     "iopub.status.idle": "2022-01-07T22:49:08.025886Z",
     "shell.execute_reply": "2022-01-07T22:49:08.024798Z",
     "shell.execute_reply.started": "2022-01-07T22:49:07.606065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print('metrics.keys: ', environ.metrics.keys())\n",
    "# print('metrics[task].keys: ', environ.metrics['task1'].keys())\n",
    "# pp.pprint(environ.metrics['task1'])\n",
    "# pp.pprint(environ.losses['task1']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "864ae417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T18:57:26.373399Z",
     "start_time": "2022-01-14T18:57:26.345065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# title='Iteration'\n",
    "# for t_id, _ in enumerate(environ.tasks):\n",
    "#     task_key = f\"task{t_id+1}\"\n",
    "# #     print_heading(f\"{title}  {current_iter}  {task_key} : {val_metrics[task_key]['classification_agg']}\", verbose = True)\n",
    "\n",
    "#     for key, _  in val_metrics[task_key]['classification_agg'].items():\n",
    "#         print('%s/%-20s'%(task_key, key), val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print(f\"{task_key:s}/{key:20s}\", val_metrics[task_key]['classification_agg'][key], current_iter)\n",
    "#         print()\n",
    "#             # print_current_errors(os.path.join(self.log_dir, 'loss.txt'), current_iter,key, loss[key], time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0b73b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:48.162261Z",
     "start_time": "2022-01-07T22:52:48.140423Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.print_loss(current_iter, start_time, metrics = val_metrics['loss'], verbose=True)\n",
    "# print(opt['lambdas'])\n",
    "# p = (opt['lambdas'][0] * environ.losses['tasks']['task1'])\n",
    "# print(p)\n",
    "\n",
    "# environ.print_metrics(current_iter, start_time, val_metrics , title='validation', verbose=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "850378b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T22:52:47.661019Z",
     "start_time": "2022-01-07T22:52:47.639094Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(current_iter)\n",
    "# print_metrics_cr(current_iter, t1 - t0, None, val_metrics , True)\n",
    "# environ.print_metrics(current_iter, start_time, val_metrics, title='validation', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "266a80b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T23:14:58.034384Z",
     "start_time": "2022-01-07T23:14:58.004850Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17988/3181484359.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" val_metric keys               : {val_metrics.keys()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" loss keys                     : {val_metrics['loss'].keys()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" task1 keys                    : {val_metrics['task1'].keys()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" task1 classification keys     : {val_metrics['task1']['classification'].keys()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" task1 classification_agg keys : {val_metrics['task1']['classification_agg'].keys()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "print(f\" val_metric keys               : {val_metrics.keys()}\")\n",
    "print(f\" loss keys                     : {val_metrics['loss'].keys()}\")\n",
    "print(f\" task1 keys                    : {val_metrics['task1'].keys()}\")\n",
    "print(f\" task1 classification keys     : {val_metrics['task1']['classification'].keys()}\")\n",
    "print(f\" task1 classification_agg keys : {val_metrics['task1']['classification_agg'].keys()}\")\n",
    "print()\n",
    "print(f\" task1                       : {val_metrics['task1']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task2                       : {val_metrics['task2']['classification_agg']['loss']:5f}\")\n",
    "print(f\" task3                       : {val_metrics['task3']['classification_agg']['loss']:5f}\")\n",
    "print(f\" loss                        : {val_metrics['loss']['total']:5f}\")\n",
    "print(f\" train_time                  : {val_metrics['train_time']:2f}\")\n",
    "print(f\" epoch                       : {val_metrics['epoch']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc43a6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Post Weight + Policy Training Stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "65640cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:22:20.634818Z",
     "start_time": "2022-01-27T00:22:20.444566Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.networks['mtl-net'].backbone.layer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4374287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:30:31.940280Z",
     "start_time": "2022-01-26T19:30:31.910058Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0])\n",
      "tensor([0.1667, 0.3333, 0.5000, 0.6667, 0.8333, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "num_blocks = 6\n",
    "num_policy_layers = 6\n",
    "gt =  torch.ones((num_blocks)).long()\n",
    "gt0 =  torch.zeros((num_blocks)).long()\n",
    "print(gt)\n",
    "print(gt0)\n",
    "\n",
    "loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "print(loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8651bc43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T19:42:31.300891Z",
     "start_time": "2022-01-26T19:42:31.257774Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond 2\n",
      "Compute CrossEntropyLoss between \n",
      " Logits   : \n",
      "tensor([[0.3306, 0.4518],\n",
      "        [0.3532, 0.5529],\n",
      "        [0.3888, 0.6125],\n",
      "        [0.4204, 0.7685],\n",
      "        [0.4520, 0.7994],\n",
      "        [0.4840, 0.8021]]) \n",
      " and gt: \n",
      "tensor([1, 1, 1, 1, 1, 1]) \n",
      "\n",
      "task1_logits sparsity error:  0.5725929141044617\n",
      "\n",
      " cond 2\n",
      "Compute CrossEntropyLoss between Logits      : tensor([[0.4840, 0.8021]])  and gt: 1 \n",
      "task1_logits sparsity error:  0.5467103123664856 \n",
      "\n",
      "Compute CrossEntropyLoss between Logits      : tensor([[0.4840, 0.8021]])  and gt: 0 \n",
      "task1_logits sparsity error:  0.864768385887146 \n",
      "\n",
      "\n",
      " cond 3\n",
      "Compute CrossEntropyLoss between Logits   : tensor([[0.3306, 0.4518]])  and gt: tensor([1]) \n",
      "task1_logits sparsity error:  0.634384036064148 \n",
      "\n",
      "Compute CrossEntropyLoss between Logits   : tensor([[0.3306, 0.4518]])  and gt: tensor([0]) \n",
      "task1_logits sparsity error:  0.7555801868438721 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if environ.opt['diff_sparsity_weights'] and not environ.opt['is_sharing']:\n",
    "    print(' cond 1')\n",
    "    ## Assign higher weights to higher layers \n",
    "    loss_weights = ((torch.arange(0, num_policy_layers, 1) + 1).float() / num_policy_layers)\n",
    "    print(f\"{task_key} sparsity error:  {2 * (loss_weights[-num_blocks:] * environ.cross_entropy2(logits[-num_blocks:], gt)).mean()})\")\n",
    "    print_dbg(f\" loss_weights :  {loss_weights}\", verbose = True)\n",
    "    print_dbg(f\" cross_entropy:  {environ.cross_entropy2(logits[-num_blocks:], gt)}  \", verbose = True)\n",
    "    print_dbg(f\" loss[sparsity][{task_key}]: {self.losses['sparsity'][task_key] } \", verbose = True)\n",
    "\n",
    "else:\n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between \\n Logits   : \\n{logits[-num_blocks:]} \\n and gt: \\n{gt} \\n\", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-num_blocks:], gt)}\")\n",
    "    \n",
    "    print('\\n cond 2')\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt[-1:])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits      : {logits[-1:]}  and gt: {gt0[-1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[-1:], gt0[-1:])} \\n\")\n",
    "    \n",
    "    print('\\n cond 3')    \n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt[0:1])} \\n\")\n",
    "    print_dbg(f\"Compute CrossEntropyLoss between Logits   : {logits[0:1]}  and gt: {gt0[0:1]} \", verbose = True)\n",
    "    print(f\"{task_key} sparsity error:  {environ.cross_entropy_sparsity(logits[0:1], gt0[0:1])} \\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686cd05",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c83ee1b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:30.155045Z",
     "start_time": "2022-01-26T00:14:30.107095Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# flag = 'update_w'\n",
    "# environ.fix_alpha\n",
    "# environ.free_w(opt['fix_BN'])\n",
    "\n",
    "flag = 'update_alpha'\n",
    "environ.fix_weights()\n",
    "environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e7996b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:31.184285Z",
     "start_time": "2022-01-25T23:43:31.159229Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.networks['mtl-net'].num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f436ee6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T00:14:34.993711Z",
     "start_time": "2022-01-26T00:14:34.968623Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_iters         : 6580\n",
      "curr_epochs           : 60\n",
      "train_total_epochs    : 60\n"
     ]
    }
   ],
   "source": [
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") \n",
    "\n",
    "train_total_epochs += 5\n",
    "\n",
    "print(f\"current_iters         : {current_iter}\")  \n",
    "print(f\"current_epochs           : {current_epoch}\") \n",
    "print(f\"train_total_epochs    : {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5334a0b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T17:15:02.216665Z",
     "start_time": "2022-01-25T17:15:01.848081Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | logloss bceloss  aucroc   aucpr  f1_max| t1 loss t2 loss t3 lossttl loss|tr_time|\n",
      "1     | 0.00020 0.89942 0.81016 0.81627 0.75738|  4.6591  4.3649  4.4500 13.4740| 333.4|"
     ]
    }
   ],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - t0, None, environ.val_metrics , num_prints)      \n",
    "\n",
    "# num_prints += 1\n",
    "# t0 = time.time()\n",
    "\n",
    "# # Take check point\n",
    "# environ.save_checkpoint('latest', current_iter)\n",
    "# environ.train()\n",
    "# #-------------------------------------------------------\n",
    "# # END validation process\n",
    "# #-------------------------------------------------------       \n",
    "# flag = 'update_alpha'\n",
    "# environ.fix_w()\n",
    "# environ.free_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d8c4f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:08:57.366231Z",
     "start_time": "2022-01-08T01:08:57.295445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dilation = 2\n",
    "# kernel_size = np.asarray((3, 3))\n",
    "# upsampled_kernel_size = (kernel_size - 1) * (dilation - 1) + kernel_size\n",
    "# print(upsampled_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9500c390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:39.763599Z",
     "start_time": "2022-01-25T23:43:39.728402Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.optimizers['weights'].param_groups[0]\n",
    "# for param_group in optimizer.param_groups:\n",
    "#     return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fb71bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T23:43:41.628847Z",
     "start_time": "2022-01-25T23:43:41.602238Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-05, 1e-05]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environ.schedulers['weights'].get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d7934862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:36:17.129535Z",
     "start_time": "2022-01-08T01:36:16.006144Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state dict for weights = SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.0001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      "\n",
      "Parameter Group 1\n",
      "    dampening: 0\n",
      "    lr: 0.0001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "state dict for alphas = Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "{   'alphas': {   'param_groups': [   {   'amsgrad': False,\n",
      "                                          'betas': (0.9, 0.999),\n",
      "                                          'eps': 1e-08,\n",
      "                                          'lr': 0.0001,\n",
      "                                          'params': [0, 1, 2],\n",
      "                                          'weight_decay': 0.0005}],\n",
      "                  'state': {   0: {   'exp_avg': tensor([[ 0.0607, -0.0007],\n",
      "        [-0.0428, -0.0069],\n",
      "        [-0.1218,  0.0138],\n",
      "        [ 0.0086,  0.0238]], device='cuda:0'),\n",
      "                                      'exp_avg_sq': tensor([[0.0523, 0.0112],\n",
      "        [0.1734, 0.0073],\n",
      "        [0.3830, 0.0086],\n",
      "        [0.6783, 0.0108]], device='cuda:0'),\n",
      "                                      'step': 8613},\n",
      "                               1: {   'exp_avg': tensor([[ 0.0535, -0.0901],\n",
      "        [-0.0352, -0.0387],\n",
      "        [ 0.1020, -0.0073],\n",
      "        [-0.0796, -0.0576]], device='cuda:0'),\n",
      "                                      'exp_avg_sq': tensor([[0.0549, 0.0120],\n",
      "        [0.1729, 0.0070],\n",
      "        [0.3925, 0.0042],\n",
      "        [0.6830, 0.0098]], device='cuda:0'),\n",
      "                                      'step': 8613},\n",
      "                               2: {   'exp_avg': tensor([[-0.0127, -0.0090],\n",
      "        [ 0.1781, -0.0526],\n",
      "        [ 0.0248, -0.0095],\n",
      "        [ 0.1182, -0.0113]], device='cuda:0'),\n",
      "                                      'exp_avg_sq': tensor([[0.0501, 0.0096],\n",
      "        [0.1758, 0.0075],\n",
      "        [0.3727, 0.0086],\n",
      "        [0.6747, 0.0059]], device='cuda:0'),\n",
      "                                      'step': 8613}}},\n",
      "    'weights': {   'param_groups': [   {   'dampening': 0,\n",
      "                                           'lr': 0.0001,\n",
      "                                           'momentum': 0.9,\n",
      "                                           'nesterov': False,\n",
      "                                           'params': [0, 1, 2, 3, 4, 5],\n",
      "                                           'weight_decay': 0.0001},\n",
      "                                       {   'dampening': 0,\n",
      "                                           'lr': 0.0001,\n",
      "                                           'momentum': 0.9,\n",
      "                                           'nesterov': False,\n",
      "                                           'params': [   6,\n",
      "                                                         7,\n",
      "                                                         8,\n",
      "                                                         9,\n",
      "                                                         10,\n",
      "                                                         11,\n",
      "                                                         12,\n",
      "                                                         13,\n",
      "                                                         14,\n",
      "                                                         15],\n",
      "                                           'weight_decay': 0.0001}],\n",
      "                   'state': {   0: {   'momentum_buffer': tensor([[-5.4482e-01, -2.7512e-01,  4.6711e-02, -4.5902e-01, -2.5247e-01, -2.1980e-01,  9.4069e-02, -1.7776e-01, -2.0681e-01,\n",
      "         -1.0892e-01, -2.7464e-01,  9.3985e-03, -3.7082e-01, -2.7459e-01,  3.1315e-01, -2.4067e-01, -2.3865e-01, -2.0458e-01,\n",
      "         -3.9198e-01, -1.3971e-01, -2.2085e-01,  2.9561e-01, -3.2675e-01, -4.4961e-01, -2.5565e-01, -1.9292e-01,  2.3961e-02,\n",
      "         -1.4747e-01, -2.0461e-01, -2.9271e-01, -1.2636e-01, -3.2118e-01, -1.3085e-02, -3.2467e-01,  7.6504e-02, -3.8073e-01,\n",
      "         -3.4652e-01, -4.8136e-01, -1.0855e-01, -4.6362e-01],\n",
      "        [ 7.5279e-02,  5.0053e-01, -6.5901e-02,  4.2624e-01, -1.1979e-01,  1.3010e-01, -5.5052e-03,  6.0068e-02,  1.6456e-01,\n",
      "          6.9727e-02,  5.5028e-01,  7.4976e-02,  2.0544e-01, -1.8356e-01,  5.8646e-03,  3.8858e-01,  5.8229e-01, -6.4714e-02,\n",
      "         -9.7311e-02,  1.5540e-02,  2.6569e-01,  1.2685e-01,  3.5929e-01,  6.1809e-02,  6.5516e-02,  1.7281e-01,  2.4054e-01,\n",
      "          2.5444e-01,  8.1368e-02,  1.7834e-01,  6.4536e-01,  2.9524e-01,  5.1240e-02,  1.0327e-01,  5.0252e-01, -1.2009e-01,\n",
      "          5.2004e-01,  3.6589e-01,  2.5036e-02,  1.1756e-01],\n",
      "        [-2.6041e-02,  3.7978e-01, -2.9577e-02,  1.2583e-01, -1.9533e-01,  1.3204e-01, -2.4134e-01, -2.2500e-01,  1.1932e-01,\n",
      "         -2.8338e-02, -1.2620e-01,  4.1562e-02, -1.4164e-01,  1.0466e-02, -7.2124e-03, -1.7311e-01, -1.0594e-02, -1.1018e-01,\n",
      "         -4.0215e-01,  2.2231e-01, -3.5036e-01, -1.2274e-01, -2.5909e-01, -4.9505e-01,  2.7185e-01, -6.1372e-02, -3.2376e-01,\n",
      "         -4.9975e-01,  4.8624e-01, -2.4463e-03, -5.9059e-02, -2.9173e-02, -8.6035e-02,  2.1797e-02, -3.9157e-02, -1.6863e-01,\n",
      "          5.4898e-01,  1.9727e-01, -1.3099e-01,  2.3543e-01],\n",
      "        [ 2.3553e-01,  3.4450e-01, -7.3627e-02,  4.6605e-01,  4.3280e-02, -6.7811e-02,  7.9972e-02,  5.1132e-01, -2.0549e-02,\n",
      "          3.1941e-01,  7.4393e-01,  8.0956e-01,  5.7910e-02, -5.3678e-02,  2.2120e-01,  8.8379e-01,  8.9871e-01, -1.4795e-01,\n",
      "         -2.7687e-02,  3.6311e-01,  4.9540e-01,  3.6264e-01,  3.9721e-01,  3.3454e-01,  5.2051e-01,  1.9513e-01,  3.0391e-01,\n",
      "          1.0195e-01, -1.7816e-01,  5.9080e-01,  1.0638e+00, -2.2466e-01,  1.3106e-01,  2.6890e-01,  4.8539e-01, -1.6549e-01,\n",
      "          1.6727e-01,  1.9687e-01, -5.7773e-02,  6.5643e-04],\n",
      "        [-1.4043e+00, -4.7333e-01, -2.1537e-01, -6.8192e-01, -4.0019e-01, -3.0406e-01, -3.6066e-01, -8.0768e-01, -3.2529e-02,\n",
      "         -6.8346e-01, -1.1644e+00, -8.0557e-01, -7.2629e-01, -6.1576e-02, -2.6680e-01, -1.1771e+00, -9.3424e-01, -3.5853e-01,\n",
      "         -5.4122e-01, -5.1141e-01, -6.5359e-01, -5.1459e-01, -8.0336e-01, -8.5221e-01, -5.7714e-01, -4.6222e-01, -6.1317e-01,\n",
      "         -8.5647e-01,  1.8005e-02, -1.0541e+00, -1.6143e+00, -3.8753e-01, -6.1965e-01, -6.0904e-01, -6.1653e-01, -3.2613e-01,\n",
      "         -4.6098e-01, -5.1365e-01, -5.4302e-01, -6.4716e-01]], device='cuda:0')},\n",
      "                                1: {   'momentum_buffer': tensor([-0.0579,  0.2361, -0.0467,  0.4477, -0.6013], device='cuda:0')},\n",
      "                                2: {   'momentum_buffer': tensor([[-0.2612, -0.1668, -0.0060, -0.4843,  0.0824,  0.2120, -0.0110, -0.2463,  0.0614, -0.1931, -0.0739, -0.3940, -0.1723,\n",
      "         -0.0844, -0.0420, -0.3581, -0.3555,  0.1027,  0.3321, -0.2004,  0.0719, -0.1718, -0.1382, -0.2087, -0.4006,  0.1659,\n",
      "         -0.0612,  0.2602, -0.3789, -0.5442, -0.6798, -0.0991,  0.1144,  0.0608, -0.3799,  0.1046, -0.5230, -0.1794,  0.2387,\n",
      "         -0.3948],\n",
      "        [-0.7644, -0.4455,  0.1079, -0.6770, -0.0285, -0.0317, -0.0798, -0.5369, -0.1481, -0.5042, -0.6391, -0.6097, -0.4634,\n",
      "         -0.3808, -0.4200, -0.5469, -0.9528, -0.0851,  0.2172, -0.3774, -0.0737, -0.6040, -0.4646, -0.6076, -0.3767,  0.0727,\n",
      "         -0.1834,  0.3338, -0.3549, -0.7231, -1.1620,  0.0138, -0.1620, -0.3471, -0.4770,  0.0757, -0.6643, -0.6895,  0.0787,\n",
      "         -0.4058],\n",
      "        [ 0.2805, -0.0582,  0.1003,  0.0825,  0.2279, -0.3497,  0.1211,  0.5327,  0.0040,  0.5895,  0.3208,  0.3248,  0.1391,\n",
      "          0.3223,  0.3612,  0.3953, -0.0528,  0.2579,  0.6889,  0.3003,  0.2949,  0.3943,  0.3399,  0.3902,  0.2274,  0.1454,\n",
      "          0.2639,  0.4317,  0.0282,  0.2718,  0.7873,  0.1240, -0.0545, -0.0371, -0.2902,  0.1248,  0.0531,  0.4477,  0.1740,\n",
      "          0.3522],\n",
      "        [-0.1528, -0.1209,  0.0156, -0.2532, -0.0495, -0.1200,  0.2843, -0.2697,  0.0212, -0.3180, -0.1699,  0.0696, -0.0441,\n",
      "         -0.2312,  0.0227,  0.0530,  0.4047, -0.4066,  0.1157, -0.0749,  0.0571, -0.2684,  0.0121,  0.2005, -0.0978,  0.0283,\n",
      "          0.1963, -0.2490, -0.3016, -0.0356,  0.0103,  0.0743,  0.2626,  0.0507, -0.0169, -0.3918, -0.1736,  0.0629, -0.0922,\n",
      "         -0.0151],\n",
      "        [-0.1752,  0.0017, -0.0910, -0.4192, -0.1514,  0.1885, -0.0909, -0.2453,  0.0872, -0.2964, -0.3132, -0.5285, -0.0679,\n",
      "         -0.0362, -0.2413, -0.5825, -0.5508,  0.1931, -0.0183, -0.3240, -0.0980, -0.0574, -0.3542, -0.1842, -0.1074,  0.2090,\n",
      "         -0.1148,  0.0744, -0.1232, -0.2965, -0.8092,  0.1216,  0.0491,  0.0700,  0.0853,  0.0258,  0.0286, -0.4716,  0.1206,\n",
      "         -0.0628]], device='cuda:0')},\n",
      "                                3: {   'momentum_buffer': tensor([-0.1741, -0.3002,  0.2925,  0.2971, -0.3722], device='cuda:0')},\n",
      "                                4: {   'momentum_buffer': tensor([[-0.0849, -0.1597,  0.2053, -0.1966, -0.0118, -0.2330, -0.0241, -0.6122, -0.2113, -0.3294, -0.2063, -0.3181,  0.0481,\n",
      "         -0.4093, -0.4637, -0.7161, -0.4272, -0.1147,  0.2656, -0.4111,  0.0617, -0.3495, -0.3421, -0.1997,  0.0105,  0.0609,\n",
      "         -0.0572,  0.1777, -0.0505, -0.6948, -0.4959,  0.2197,  0.1054, -0.3540, -0.4853,  0.2524, -0.3534, -0.1041,  0.0436,\n",
      "         -0.0729],\n",
      "        [-0.2884, -0.0777, -0.1561, -0.0193, -0.2145,  0.1506,  0.0461, -0.1056,  0.1115,  0.0735,  0.0143, -0.1489, -0.1132,\n",
      "         -0.1654, -0.0719, -0.0780,  0.0905, -0.1635,  0.0411,  0.0230, -0.1094,  0.2141,  0.2209,  0.2538, -0.2747, -0.0911,\n",
      "          0.2328, -0.0246, -0.2137,  0.0164,  0.4605,  0.0623,  0.1916,  0.0445,  0.2819,  0.0821, -0.2006,  0.0480, -0.2465,\n",
      "         -0.0939],\n",
      "        [-0.3999, -0.1251, -0.2381, -0.1985, -0.1385, -0.0977, -0.1711, -0.1430, -0.2113, -0.3605, -0.0474, -0.3035,  0.0633,\n",
      "         -0.0959, -0.1873, -0.3301, -0.1024, -0.2385, -0.4791, -0.1046, -0.2390, -0.2179, -0.3163, -0.2241, -0.5092,  0.1025,\n",
      "         -0.1386, -0.4020, -0.2547, -0.1484, -0.6128, -0.2314, -0.0788,  0.2300, -0.0069, -0.2817, -0.1210, -0.0113, -0.4520,\n",
      "         -0.2268],\n",
      "        [ 0.2257,  0.3765,  0.1650, -0.1478,  0.0906,  0.1179,  0.1602, -0.1910,  0.4880, -0.0549, -0.0863,  0.1077,  0.3084,\n",
      "          0.1151, -0.0719, -0.2795,  0.0179,  0.6149,  0.4591, -0.0565, -0.0812,  0.2760, -0.0342,  0.0169,  0.0639, -0.0015,\n",
      "          0.0713,  0.1656,  0.2635,  0.0067, -0.1705,  0.2555,  0.2492, -0.0994,  0.1673,  0.3523,  0.3903,  0.0610,  0.2200,\n",
      "          0.0149],\n",
      "        [ 0.4827,  0.3845,  0.2594,  0.7605,  0.4389,  0.4478,  0.4341,  0.6531,  0.1451,  0.5494,  0.8218,  0.7176,  0.2111,\n",
      "          0.1574,  0.5871,  1.1305,  0.7570,  0.1728,  0.4147,  0.5044,  0.3479,  0.4095,  0.6468,  0.4890,  0.3662,  0.0461,\n",
      "          0.3462,  0.2534,  0.3233,  0.7041,  1.0300,  0.2806,  0.3191,  0.6002,  0.5828,  0.2223,  0.5332,  0.5004,  0.1183,\n",
      "          0.3750]], device='cuda:0')},\n",
      "                                5: {   'momentum_buffer': tensor([-0.3636,  0.1302, -0.1584, -0.0355,  0.4779], device='cuda:0')},\n",
      "                                6: {   'momentum_buffer': tensor([[ 1.5304e-01, -5.9271e-03,  4.8917e-01,  ..., -2.2712e-01, -1.2944e-01, -1.5610e-01],\n",
      "        [ 2.3775e-02, -9.0718e-03,  2.1647e-02,  ...,  3.9088e-02,  2.5611e-02, -2.9572e-02],\n",
      "        [ 1.6747e-02, -1.2741e-02,  1.7129e-02,  ...,  1.8492e-02, -8.0235e-03, -2.1392e-02],\n",
      "        ...,\n",
      "        [-3.1285e-06, -2.0295e-06,  7.8620e-06,  ...,  1.1699e-06,  3.7180e-07,  5.9421e-07],\n",
      "        [ 7.3640e-06, -1.7594e-05,  7.4498e-05,  ..., -2.5983e-05,  1.2307e-05,  3.2505e-05],\n",
      "        [-9.6068e-06, -8.5949e-06,  1.0171e-05,  ..., -6.1072e-06, -8.3978e-07, -6.7925e-06]], device='cuda:0')},\n",
      "                                7: {   'momentum_buffer': tensor([ 0.3887, -0.0579,  0.3107,  0.1551,  0.8331, -0.1376, -0.3844, -0.0353,  0.4420, -0.5766,  0.0788, -0.0751, -0.1867,\n",
      "         0.1001, -0.3312, -0.2118, -0.3287, -0.0677,  0.3000, -0.2234,  0.1245, -0.1919, -0.2328,  0.3670,  0.0290, -0.1925,\n",
      "         0.4300, -0.1144, -0.4987, -0.1107, -0.3611,  0.4313, -0.4842,  0.6604,  0.0137,  0.0144,  0.2782, -0.2992, -0.2614,\n",
      "        -0.2438], device='cuda:0')},\n",
      "                                8: {   'momentum_buffer': tensor([[ 1.5098e-01,  6.8066e-02, -1.1790e-01,  ...,  9.2484e-02, -4.3672e-02,  6.0582e-02],\n",
      "        [-2.7928e-02, -3.8709e-02,  1.1351e-02,  ...,  1.4022e-02,  1.4181e-02, -2.3581e-02],\n",
      "        [ 1.2368e-05,  1.6269e-04, -2.8662e-04,  ..., -4.4968e-05, -1.8164e-04, -3.3822e-04],\n",
      "        ...,\n",
      "        [-4.0677e-02,  2.7337e-02,  1.5571e-02,  ..., -4.8724e-02, -3.2856e-02, -1.0650e-02],\n",
      "        [ 1.6598e-01,  9.5019e-02, -4.6000e-02,  ...,  6.4921e-02,  3.7100e-02,  8.7817e-02],\n",
      "        [-8.4905e-03,  2.2479e-02, -2.5620e-03,  ..., -7.5068e-03, -5.1343e-03, -1.6064e-02]], device='cuda:0')},\n",
      "                                9: {   'momentum_buffer': tensor([ 3.4776e-01, -3.5319e-02,  1.0072e-04,  3.8190e-03,  4.6922e-01, -1.4719e-02, -1.9333e-01, -1.0430e-01, -4.9097e-02,\n",
      "        -3.4282e-01, -1.2632e-01,  1.1640e-01,  1.4245e-01,  3.9221e-01, -1.5241e-01,  1.0361e-01,  2.8693e-01, -3.8438e-02,\n",
      "         5.4297e-01,  2.2322e-02,  2.2954e-01, -2.4616e-01,  8.4137e-02,  2.5481e-01, -9.6045e-02,  4.1123e-02,  1.7366e-01,\n",
      "        -3.3607e-02, -7.8799e-02, -8.1003e-02, -1.5968e-01,  1.4050e-01,  7.0586e-02,  2.4685e-01,  8.4280e-02,  1.2348e-01,\n",
      "        -1.0331e-01, -9.8404e-02,  2.8721e-01, -3.6698e-02], device='cuda:0')},\n",
      "                                10: {   'momentum_buffer': tensor([[ 0.0122, -0.0239, -0.0222,  ...,  0.0248,  0.0130, -0.0082],\n",
      "        [ 0.0409, -0.0863, -0.0585,  ...,  0.0649, -0.0058,  0.0468],\n",
      "        [ 0.0525,  0.0079, -0.0112,  ...,  0.0785,  0.0505,  0.0502],\n",
      "        ...,\n",
      "        [ 0.2707,  0.1044, -0.0254,  ...,  0.1337,  0.0744,  0.0592],\n",
      "        [ 0.0154,  0.0331,  0.0019,  ...,  0.0142, -0.0596, -0.0396],\n",
      "        [-0.0857,  0.0114, -0.0162,  ..., -0.0332, -0.1018, -0.0657]], device='cuda:0')},\n",
      "                                11: {   'momentum_buffer': tensor([ 0.0760, -0.0063,  0.1234, -0.0805,  0.1407, -0.0494,  0.0783,  0.1751, -0.0619, -0.1029,  0.0626, -0.1621,  0.0215,\n",
      "         0.0589,  0.0777, -0.0114,  0.0356,  0.0869,  0.1138,  0.0837,  0.0116, -0.0266,  0.1767,  0.2595,  0.0828, -0.0264,\n",
      "         0.1041,  0.0221,  0.0534, -0.0933,  0.0266, -0.0506, -0.0109, -0.0572, -0.0290,  0.0525, -0.0016,  0.2201, -0.0559,\n",
      "        -0.0764], device='cuda:0')},\n",
      "                                12: {   'momentum_buffer': tensor([[ 0.0542,  0.0008, -0.0059,  ...,  0.0547,  0.0933,  0.0654],\n",
      "        [-0.0124, -0.0217, -0.0174,  ...,  0.0780, -0.0404,  0.0119],\n",
      "        [-0.0024, -0.0011, -0.0005,  ...,  0.0003, -0.0004, -0.0003],\n",
      "        ...,\n",
      "        [ 0.0027,  0.0664,  0.0873,  ...,  0.0592,  0.0687,  0.0510],\n",
      "        [ 0.0913,  0.0534, -0.0025,  ...,  0.0306, -0.0440,  0.0299],\n",
      "        [-0.0215,  0.0202, -0.0636,  ..., -0.0170, -0.0338, -0.0677]], device='cuda:0')},\n",
      "                                13: {   'momentum_buffer': tensor([ 0.1389, -0.0492, -0.0026, -0.1231, -0.0199,  0.0288,  0.0002,  0.0369,  0.0689,  0.0349, -0.0123, -0.0443, -0.0297,\n",
      "         0.0026,  0.0345,  0.0489,  0.0253,  0.0764,  0.0739,  0.0602, -0.0033,  0.0222, -0.0743,  0.0255,  0.0509,  0.1373,\n",
      "         0.0104,  0.0234, -0.0108,  0.0034, -0.0159,  0.0054,  0.0429,  0.0476, -0.0150, -0.0057, -0.0413,  0.0307,  0.0383,\n",
      "        -0.0091], device='cuda:0')},\n",
      "                                14: {   'momentum_buffer': tensor([[ 0.1029,  0.0980,  0.0202,  ...,  0.1078,  0.0647,  0.0686],\n",
      "        [ 0.1083,  0.0676,  0.0507,  ...,  0.1634,  0.0056,  0.0213],\n",
      "        [ 0.0021, -0.0008, -0.0076,  ...,  0.0037, -0.0008, -0.0021],\n",
      "        ...,\n",
      "        [ 0.0117,  0.0903,  0.0301,  ..., -0.0045,  0.0020,  0.0292],\n",
      "        [ 0.0616,  0.0727, -0.0032,  ...,  0.0555,  0.0145,  0.0146],\n",
      "        [-0.0441, -0.0322, -0.0147,  ...,  0.0057, -0.0240, -0.0302]], device='cuda:0')},\n",
      "                                15: {   'momentum_buffer': tensor([ 0.0819,  0.0197, -0.0006, -0.0349,  0.0058,  0.0291, -0.0123, -0.0388, -0.0164, -0.0855,  0.0779,  0.0347, -0.0715,\n",
      "        -0.0225,  0.0360,  0.0105, -0.0919,  0.2164,  0.0061,  0.0852,  0.1488, -0.1035,  0.0128, -0.0246,  0.1463,  0.0421,\n",
      "         0.0069, -0.0251,  0.0041, -0.0824, -0.1332, -0.0114, -0.0141,  0.0515,  0.0716,  0.0047, -0.0701, -0.0178,  0.0446,\n",
      "        -0.0167], device='cuda:0')}}}}\n"
     ]
    }
   ],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.optimizers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    current_state[k] = v.state_dict()\n",
    "pp.pprint(current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d5faf7f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:40:22.032247Z",
     "start_time": "2022-01-08T01:40:22.006953Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state dict for weights = <torch.optim.lr_scheduler.StepLR object at 0x7f90c01c0ca0>\n",
      "{'step_size': 4000, 'gamma': 0.5, 'base_lrs': [0.0001, 0.0001], 'last_epoch': 9100, '_step_count': 9101, 'verbose': False, '_get_lr_called_within_step': False, '_last_lr': [2.5e-05, 2.5e-05]}\n"
     ]
    }
   ],
   "source": [
    "current_state = {}\n",
    "for k, v in environ.schedulers.items():\n",
    "    print(f'state dict for {k} = {v}')\n",
    "    print(v.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd497e72",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Losses and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66169a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T16:34:44.555617Z",
     "start_time": "2022-02-09T16:34:44.507417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_losses = environ.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60cb8234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:35:11.758429Z",
     "start_time": "2022-02-10T03:35:11.278211Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch |  trn loss     trn spar     trn shar    trn total |   logloss   bceloss    aucroc     aucpr |  val loss     val spar     val shar    val total |tr_time |\n",
      "12    |    7.3148   1.0717e+00   2.6055e-03       8.3891 |   0.00021   0.97756   0.68488   0.68055 |   14.6682   1.0160e+00   2.1285e-03      15.6863 |  227.5 |"
     ]
    }
   ],
   "source": [
    "print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ce0301f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:21:49.107793Z",
     "start_time": "2022-02-10T03:21:49.084484Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print_metrics_cr(current_epoch, time.time() - start_time, trn_losses, environ.val_metrics , num_prints)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a498b6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:20:32.866010Z",
     "start_time": "2022-02-10T03:20:32.442919Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'losses': {   'task1': tensor(2.450312, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                  'task2': tensor(2.467013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                  'task3': tensor(2.687793, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                  'total': tensor(7.605118, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)},\n",
      "    'losses_mean': {   'task1': tensor(0.490062, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>),\n",
      "                       'task2': tensor(0.493403, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>),\n",
      "                       'task3': tensor(0.537559, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>),\n",
      "                       'total': tensor(1.521024, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)},\n",
      "    'parms': {   'gumbel_temp': 2.6244000000000005,\n",
      "                 'lr_0': 0.01,\n",
      "                 'lr_1': 0.01,\n",
      "                 'policy_lr': 0.001,\n",
      "                 'train_layers': 0},\n",
      "    'sharing': {'total': tensor(0.002794, device='cuda:0')},\n",
      "    'sparsity': {   'task1_logits': tensor(0.384502, device='cuda:0'),\n",
      "                    'task2_logits': tensor(0.372063, device='cuda:0'),\n",
      "                    'task3_logits': tensor(0.395169, device='cuda:0'),\n",
      "                    'total': tensor(1.151734, device='cuda:0')},\n",
      "    'task1': {   'cls_loss': tensor(2.450312, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                 'cls_loss_mean': tensor(0.490062, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)},\n",
      "    'task2': {   'cls_loss': tensor(2.467013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                 'cls_loss_mean': tensor(0.493403, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)},\n",
      "    'task3': {   'cls_loss': tensor(2.687793, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                 'cls_loss_mean': tensor(0.537559, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)},\n",
      "    'total': {   'total': tensor(8.759646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>),\n",
      "                 'total_mean': tensor(2.675551, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)},\n",
      "    'total_mean': {}}\n"
     ]
    }
   ],
   "source": [
    "# pp.pprint(environ.losses)\n",
    "pp.pprint(trn_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fe30724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-10T03:34:21.945701Z",
     "start_time": "2022-02-10T03:34:21.411234Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'aggregated': {   'auc_pr': 0.6805474562906618,\n",
      "                      'avg_prec_score': 0.6807816533341606,\n",
      "                      'bceloss': 0.9775612473487854,\n",
      "                      'f1_max': 0.6969378498338702,\n",
      "                      'kappa': 0.2500278499434187,\n",
      "                      'kappa_max': 0.29669160426755137,\n",
      "                      'logloss': tensor(0.000214, device='cuda:0', dtype=torch.float64),\n",
      "                      'p_f1_max': 0.2160851760388027,\n",
      "                      'p_kappa_max': 0.5119348396857579,\n",
      "                      'roc_auc_score': 0.6848840436108541,\n",
      "                      'sc_loss': tensor(0.407449, device='cuda:0', dtype=torch.float64)},\n",
      "    'epoch': 12,\n",
      "    'loss': {   'task1': 3.91353933321791,\n",
      "                'task2': 4.751992322450581,\n",
      "                'task3': 6.002632442335283,\n",
      "                'total': 14.668164098003771},\n",
      "    'loss_mean': {   'task1': 0.782707866643582,\n",
      "                     'task2': 0.9503984644901166,\n",
      "                     'task3': 1.200526488467057,\n",
      "                     'total': 2.9336328196007546},\n",
      "    'sharing': {'total': 0.002128511667251587},\n",
      "    'sparsity': {   'task1': 0.33643248346116805,\n",
      "                    'task2': 0.329370207256741,\n",
      "                    'task3': 0.35019368595547146,\n",
      "                    'total': 1.0159963369369507},\n",
      "    'task1': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                         \n",
      "0          0.714776  0.644673        0.644931  0.669210  0.592656  0.195617   0.334438     0.886543  1.125510\n",
      "1          0.724395  0.639299        0.639681  0.649219  0.298842  0.333314   0.348251     0.537890  0.686129\n",
      "2          0.791108  0.793189        0.793272  0.739347  0.575144  0.363001   0.439977     0.780065  0.664167\n",
      "3          0.710935  0.681036        0.681353  0.682753  0.227855  0.288870   0.332234     0.415195  0.693247\n",
      "4          0.674741  0.689493        0.689699  0.687405  0.105984  0.263917   0.274597     0.578992  0.748321,\n",
      "                 'classification_agg': {   'auc_pr': 0.6895379290374435,\n",
      "                                           'avg_prec_score': 0.689787325959293,\n",
      "                                           'bceloss': 0.7834747195243836,\n",
      "                                           'f1_max': 0.6855868567358512,\n",
      "                                           'kappa': 0.2889437468845333,\n",
      "                                           'kappa_max': 0.345899677809135,\n",
      "                                           'logloss': 0.006177917824856161,\n",
      "                                           'p_f1_max': 0.36009601652622225,\n",
      "                                           'p_kappa_max': 0.6397369682788849,\n",
      "                                           'roc_auc_score': 0.7231909220316995,\n",
      "                                           'sc_loss': 3.91353933321791}},\n",
      "    'task2': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max      p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                             \n",
      "0          0.767504  0.762136        0.762553  0.746565  5.256325e-01  0.360623   0.403085     0.720969  0.734849\n",
      "1          0.644054  0.630326        0.630543  0.698768  1.764253e-01  0.244581   0.250126     0.579957  1.024544\n",
      "2          0.593119  0.585249        0.585570  0.658917  4.445018e-07  0.162276   0.188429     0.287746  1.359396\n",
      "3          0.713297  0.719673        0.719820  0.715348  1.955647e-01  0.317520   0.326780     0.454685  0.761726\n",
      "4          0.710767  0.719084        0.719242  0.681888  7.153978e-03  0.296313   0.338648     0.307402  0.893089,\n",
      "                 'classification_agg': {   'auc_pr': 0.6832936547689177,\n",
      "                                           'avg_prec_score': 0.6835457357223023,\n",
      "                                           'bceloss': 0.9547208666801454,\n",
      "                                           'f1_max': 0.7002974317752696,\n",
      "                                           'kappa': 0.2762625964892511,\n",
      "                                           'kappa_max': 0.30141371981469617,\n",
      "                                           'logloss': 0.007501500706346018,\n",
      "                                           'p_f1_max': 0.18095537466558653,\n",
      "                                           'p_kappa_max': 0.4701518118381501,\n",
      "                                           'roc_auc_score': 0.6857480762869699,\n",
      "                                           'sc_loss': 4.751992322450581}},\n",
      "    'task3': {   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max      p_f1_max     kappa  kappa_max  p_kappa_max   bceloss\n",
      "task                                                                                                             \n",
      "0          0.619825  0.685091        0.685240  0.741770  5.004321e-05  0.194901   0.207721     0.537464  1.137648\n",
      "1          0.597932  0.605720        0.605949  0.702000  1.436832e-01  0.132104   0.180635     0.713469  1.592534\n",
      "2          0.700095  0.668253        0.668544  0.679696  3.922369e-01  0.333498   0.340205     0.463163  0.841955\n",
      "3          0.654756  0.716051        0.716197  0.716439  5.050880e-05  0.159188   0.234104     0.270025  1.131815\n",
      "4          0.655957  0.668939        0.669129  0.684742  3.418194e-08  0.104695   0.251143     0.145458  1.268490,\n",
      "                 'classification_agg': {   'auc_pr': 0.6688107850656247,\n",
      "                                           'avg_prec_score': 0.6690118983208868,\n",
      "                                           'bceloss': 1.1944881558418274,\n",
      "                                           'f1_max': 0.7049292609904902,\n",
      "                                           'kappa': 0.1848772064564717,\n",
      "                                           'kappa_max': 0.24276141517882294,\n",
      "                                           'logloss': 0.009475762680292488,\n",
      "                                           'p_f1_max': 0.10720413692459943,\n",
      "                                           'p_kappa_max': 0.425915738940239,\n",
      "                                           'roc_auc_score': 0.6457131325138926,\n",
      "                                           'sc_loss': 6.002632442335283}},\n",
      "    'total': {'total': 15.686288946607974, 'total_mean': 3.951757668204957},\n",
      "    'train_time': 145.85945844650269}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(environ.val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a1d81167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:49.364883Z",
     "start_time": "2022-01-27T00:58:49.342931Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.opt['train']['Lambda_sharing'] = 0.5\n",
    "# opt['train']['Lambda_sharing'] = 0.5\n",
    "\n",
    "# environ.opt['train']['policy_lr'] = 0.001\n",
    "# opt['train']['policy_lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a73aa06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T01:00:41.996410Z",
     "start_time": "2022-01-26T01:00:41.559006Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'losses': {   'task1': tensor(2.3789, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                  'task2': tensor(2.1948, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                  'task3': tensor(2.3476, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                  'total': tensor(6.9212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)},\n",
      "    'losses_mean': {   'task1': tensor(0.4758, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>),\n",
      "                       'task2': tensor(0.4390, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>),\n",
      "                       'task3': tensor(0.4695, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>),\n",
      "                       'total': tensor(1.3842, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)},\n",
      "    'parms': {'gumbel_temp': 2.6330653896376153, 'lr_0': 0.005, 'lr_1': 0.005},\n",
      "    'sharing': {   'total': tensor(2.1338e-06, device='cuda:0', grad_fn=<MulBackward0>)},\n",
      "    'sparsity': {   'task1_logits': tensor(0.5853, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
      "                    'task2_logits': tensor(0.5846, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
      "                    'task3_logits': tensor(0.5848, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
      "                    'total': tensor(0.0877, device='cuda:0', grad_fn=<MulBackward0>)},\n",
      "    'task1': {   'cls_loss': tensor(2.3789, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                 'cls_loss_mean': tensor(0.4758, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)},\n",
      "    'task2': {   'cls_loss': tensor(2.1948, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                 'cls_loss_mean': tensor(0.4390, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)},\n",
      "    'task3': {   'cls_loss': tensor(2.3476, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
      "                 'cls_loss_mean': tensor(0.4695, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)},\n",
      "    'total': {   'total': tensor(7.0090, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>),\n",
      "                 'total_mean': tensor(1.4720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)},\n",
      "    'total_mean': {}}\n"
     ]
    }
   ],
   "source": [
    "environ.losses.keys()\n",
    "pp.pprint(environ.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e06ece74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-08T01:19:43.683550Z",
     "start_time": "2022-01-08T01:19:43.571450Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['task1', 'task2', 'task3', 'tasks', 'total', 'sharing', 'sparsity'])\n",
      "{   'sharing': {'total': tensor(0.0002, device='cuda:0')},\n",
      "    'sparsity': {   'task1_logits': tensor(0.5147, device='cuda:0'),\n",
      "                    'task2_logits': tensor(0.5195, device='cuda:0'),\n",
      "                    'task3_logits': tensor(0.4978, device='cuda:0'),\n",
      "                    'total': tensor(0.0766, device='cuda:0')},\n",
      "    'task1': {'total': tensor(3.3657, device='cuda:0', dtype=torch.float64)},\n",
      "    'task2': {'total': tensor(3.5906, device='cuda:0', dtype=torch.float64)},\n",
      "    'task3': {'total': tensor(3.2182, device='cuda:0', dtype=torch.float64)},\n",
      "    'tasks': {   'task1': tensor(3.3657, device='cuda:0', dtype=torch.float64),\n",
      "                 'task2': tensor(3.5906, device='cuda:0', dtype=torch.float64),\n",
      "                 'task3': tensor(3.2182, device='cuda:0', dtype=torch.float64),\n",
      "                 'total': tensor(10.1745, device='cuda:0', dtype=torch.float64)},\n",
      "    'total': {'total': tensor(10.2513, device='cuda:0', dtype=torch.float64)}}\n"
     ]
    }
   ],
   "source": [
    "tmp = environ.get_loss_dict()\n",
    "print(tmp.keys())\n",
    "pp.pprint(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "00ac0256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T00:58:50.458223Z",
     "start_time": "2022-01-27T00:58:50.430889Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "0.5\n",
      "0.5\n",
      "0.05\n",
      "0.05\n",
      "0.001\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print(opt['diff_sparsity_weights'])\n",
    "print(opt['is_sharing'])\n",
    "print(opt['diff_sparsity_weights'] and not opt['is_sharing'])\n",
    "print(environ.opt['train']['Lambda_sharing'])\n",
    "print(opt['train']['Lambda_sharing'])\n",
    "print(environ.opt['train']['Lambda_sparsity'])\n",
    "print(opt['train']['Lambda_sparsity'])\n",
    "print(environ.opt['train']['policy_lr'])\n",
    "print(opt['train']['policy_lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2d510",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Policy / Logit stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb628497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:35:14.041577Z",
     "start_time": "2022-02-08T20:35:14.018303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.special          import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79eed454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:30.103364Z",
     "start_time": "2022-02-08T20:00:30.068021Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03b5cc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_task_logits(n)` Get logits for task group n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2aed8b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:56:35.652087Z",
     "start_time": "2022-02-08T20:56:35.327406Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.00035114, -0.06397165],\n",
      "        [ 0.00056738, -0.03663344],\n",
      "        [ 0.00056098, -0.02617791],\n",
      "        [-0.00044851, -0.07137010],\n",
      "        [ 0.00013184, -0.05879313],\n",
      "        [ 0.00079021, -0.05743587]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "task_logits = environ.get_task_logits(1)\n",
    "print(task_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66fa5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_arch_parameters()`: Get last used logits from network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a85521e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:00:31.101960Z",
     "start_time": "2022-02-08T20:00:30.757064Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.00035120, -0.06617914],\n",
      "        [ 0.00056736, -0.04341661],\n",
      "        [ 0.00056091, -0.01096974],\n",
      "        [-0.00044879, -0.01083876],\n",
      "        [ 0.00013163,  0.00874004],\n",
      "        [ 0.00079006, -0.00861552]], device='cuda:0'), Parameter containing:\n",
      "tensor([[-0.00035114, -0.06397165],\n",
      "        [ 0.00056738, -0.03663344],\n",
      "        [ 0.00056098, -0.02617791],\n",
      "        [-0.00044851, -0.07137010],\n",
      "        [ 0.00013184, -0.05879313],\n",
      "        [ 0.00079021, -0.05743587]], device='cuda:0'), Parameter containing:\n",
      "tensor([[-0.00035016, -0.06321616],\n",
      "        [ 0.00056696, -0.03072025],\n",
      "        [ 0.00056129, -0.01022454],\n",
      "        [-0.00044983, -0.00021709],\n",
      "        [ 0.00013071,  0.00484093],\n",
      "        [ 0.00078938, -0.02230957]], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "489b0bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:06.054699Z",
     "start_time": "2022-02-09T15:43:05.689327Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 1.873275e-03, -5.276022e-01],\n",
      "        [ 2.345233e-03, -2.740704e-01],\n",
      "        [ 2.614364e-03,  1.604760e-02],\n",
      "        [ 2.143114e-04,  2.198091e-02],\n",
      "        [ 4.191113e-04,  5.969038e-02],\n",
      "        [ 2.007700e-03,  3.544179e-02]], device='cuda:0'), Parameter containing:\n",
      "tensor([[ 1.873281e-03, -4.892288e-01],\n",
      "        [ 2.345207e-03, -2.255457e-01],\n",
      "        [ 2.614349e-03, -2.191145e-01],\n",
      "        [ 2.143144e-04, -3.354620e-01],\n",
      "        [ 4.190930e-04, -3.310193e-01],\n",
      "        [ 2.007697e-03, -2.532191e-01]], device='cuda:0'), Parameter containing:\n",
      "tensor([[ 1.873283e-03, -6.248206e-01],\n",
      "        [ 2.345208e-03, -2.149665e-01],\n",
      "        [ 2.614360e-03, -1.423603e-01],\n",
      "        [ 2.143196e-04, -1.089546e-01],\n",
      "        [ 4.191188e-04, -7.532501e-02],\n",
      "        [ 2.007698e-03, -1.407905e-01]], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "arch_parameters      = environ.get_arch_parameters()\n",
    "print(arch_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea1743",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_logits()`:  Get Policy Logits - returns same as `get_arch_parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdbb40c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:24.972390Z",
     "start_time": "2022-02-09T15:43:24.636629Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.8732749e-03 -5.2760220e-01]\n",
      " [ 2.3452332e-03 -2.7407044e-01]\n",
      " [ 2.6143640e-03  1.6047601e-02]\n",
      " [ 2.1431143e-04  2.1980910e-02]\n",
      " [ 4.1911125e-04  5.9690382e-02]\n",
      " [ 2.0077003e-03  3.5441790e-02]] \n",
      "\n",
      "[[ 1.8732806e-03 -4.8922884e-01]\n",
      " [ 2.3452067e-03 -2.2554573e-01]\n",
      " [ 2.6143489e-03 -2.1911447e-01]\n",
      " [ 2.1431442e-04 -3.3546203e-01]\n",
      " [ 4.1909298e-04 -3.3101928e-01]\n",
      " [ 2.0076970e-03 -2.5321913e-01]] \n",
      "\n",
      "[[ 1.8732828e-03 -6.2482059e-01]\n",
      " [ 2.3452076e-03 -2.1496648e-01]\n",
      " [ 2.6143598e-03 -1.4236034e-01]\n",
      " [ 2.1431963e-04 -1.0895463e-01]\n",
      " [ 4.1911882e-04 -7.5325012e-02]\n",
      " [ 2.0076977e-03 -1.4079048e-01]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs = environ.get_policy_logits()\n",
    "for i in logs:\n",
    "    print(i, '\\n')\n",
    "# probs = softmax(logs, axis= -1)\n",
    "# for i in probs:\n",
    "#     print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080a364",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `get_policy_prob()` : Gets the softmax of the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b59c75af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T15:43:29.733732Z",
     "start_time": "2022-02-09T15:43:29.699600Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6293608  0.37063923]\n",
      " [0.5686673  0.43133274]\n",
      " [0.49664173 0.5033582 ]\n",
      " [0.4945586  0.5054415 ]\n",
      " [0.48518652 0.5148135 ]\n",
      " [0.49164233 0.50835776]] \n",
      "\n",
      "[[0.62036604 0.379634  ]\n",
      " [0.55672747 0.44327256]\n",
      " [0.5552062  0.44479376]\n",
      " [0.58313996 0.4168601 ]\n",
      " [0.58210933 0.41789067]\n",
      " [0.5634626  0.4365374 ]] \n",
      "\n",
      "[[0.6517394  0.34826055]\n",
      " [0.5541151  0.44588488]\n",
      " [0.5361803  0.46381968]\n",
      " [0.5272652  0.47273484]\n",
      " [0.518927   0.48107296]\n",
      " [0.535639   0.464361  ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "for i in policy_softmaxs:\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3160d9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = False)` : Calls test_sample_policy of network with random choices based on softmax of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "3f411444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:21:15.636722Z",
     "start_time": "2022-02-08T22:21:15.165456Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00035120 -0.06617914] \t [0 1] \t [0.51645106 0.48354897]\n",
      "[ 0.00056736 -0.04341661] \t [0 1] \t [0.51099426 0.48900577]\n",
      "[ 0.00056091 -0.01096974] \t [1 0] \t [0.50288266 0.49711737]\n",
      "[-0.00044879 -0.01083876] \t [0 1] \t [0.50259751 0.49740252]\n",
      "[0.00013163 0.00874004] \t [0 1] \t [0.49784794 0.50215214]\n",
      "[ 0.00079006 -0.00861552] \t [0 1] \t [0.50235140 0.49764863]\n",
      "\n",
      "\n",
      "[-0.00035114 -0.06397165] \t [0 1] \t [0.51589972 0.48410025]\n",
      "[ 0.00056738 -0.03663344] \t [1 0] \t [0.50929916 0.49070087]\n",
      "[ 0.00056098 -0.02617791] \t [1 0] \t [0.5066843 0.4933157]\n",
      "[-0.00044851 -0.07137010] \t [0 1] \t [0.51772296 0.48227707]\n",
      "[ 0.00013184 -0.05879313] \t [0 1] \t [0.514727 0.485273]\n",
      "[ 0.00079021 -0.05743587] \t [0 1] \t [0.51455247 0.48544762]\n",
      "\n",
      "\n",
      "[-0.00035016 -0.06321616] \t [0 1] \t [0.51571137 0.48428872]\n",
      "[ 0.00056696 -0.03072025] \t [1 0] \t [0.50782120 0.49217883]\n",
      "[ 0.00056129 -0.01022454] \t [1 0] \t [0.50269639 0.49730355]\n",
      "[-0.00044983 -0.00021709] \t [0 1] \t [0.4999418 0.5000582]\n",
      "[0.00013071 0.00484093] \t [1 0] \t [0.49882248 0.50117755]\n",
      "[ 0.00078938 -0.02230957] \t [0 1] \t [0.50577444 0.49422547]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "policies,logits = environ.get_sample_policy(hard_sampling = False)\n",
    "\n",
    "for l, p, s in zip(logits, policies, policy_softmaxs) :\n",
    "    for  l_row, p_row, s_row in zip(l, p, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802664ec",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_sample_policy( hard_sampling = True)` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dea65bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:59:40.790899Z",
     "start_time": "2022-02-08T20:59:40.726657Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0003512  -0.06617914] \t [1 0] \t [0.51645106 0.48354897]\n",
      "[ 0.00056736 -0.04341661] \t [1 0] \t [0.51099426 0.48900577]\n",
      "[ 0.00056091 -0.01096974] \t [1 0] \t [0.50288266 0.49711737]\n",
      "[-0.00044879 -0.01083876] \t [1 0] \t [0.5025975  0.49740252]\n",
      "[0.00013163 0.00874004] \t [0 1] \t [0.49784794 0.50215214]\n",
      "[ 0.00079006 -0.00861552] \t [1 0] \t [0.5023514  0.49764863]\n",
      "\n",
      "\n",
      "[-0.00035114 -0.06397165] \t [1 0] \t [0.5158997  0.48410025]\n",
      "[ 0.00056738 -0.03663344] \t [1 0] \t [0.50929916 0.49070087]\n",
      "[ 0.00056098 -0.02617791] \t [1 0] \t [0.5066843 0.4933157]\n",
      "[-0.00044851 -0.0713701 ] \t [1 0] \t [0.51772296 0.48227707]\n",
      "[ 0.00013184 -0.05879313] \t [1 0] \t [0.514727 0.485273]\n",
      "[ 0.00079021 -0.05743587] \t [1 0] \t [0.5145525  0.48544762]\n",
      "\n",
      "\n",
      "[-0.00035016 -0.06321616] \t [1 0] \t [0.51571137 0.48428872]\n",
      "[ 0.00056696 -0.03072025] \t [1 0] \t [0.5078212  0.49217883]\n",
      "[ 0.00056129 -0.01022454] \t [1 0] \t [0.5026964  0.49730355]\n",
      "[-0.00044983 -0.00021709] \t [0 1] \t [0.4999418 0.5000582]\n",
      "[0.00013071 0.00484093] \t [0 1] \t [0.49882248 0.50117755]\n",
      "[ 0.00078938 -0.02230957] \t [1 0] \t [0.50577444 0.49422547]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_softmaxs = environ.get_policy_prob()\n",
    "hard_policies, logits = environ.get_sample_policy(hard_sampling = True)\n",
    "\n",
    "for p,l,s in zip(hard_policies, logits, policy_softmaxs) :\n",
    "    for  p_row, l_row, s_row in zip(p, l, s):\n",
    "        print( l_row,'\\t', p_row, '\\t', s_row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c39cf",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4c0fe096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:00:47.452220Z",
     "start_time": "2022-02-08T21:00:47.422902Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer    task 1      task 2      task 3\n",
      " -----    ------      ------      ------\n",
      "   1      [1 0]       [1 0]       [1 0]\n",
      "   2      [1 0]       [1 0]       [1 0]\n",
      "   3      [1 0]       [1 0]       [1 0]\n",
      "   4      [1 0]       [1 0]       [0 1]\n",
      "   5      [0 1]       [1 0]       [0 1]\n",
      "   6      [1 0]       [1 0]       [1 0]\n",
      "\n",
      "\n",
      " where [p1  p2]:  p1: layer is selected    p2: layer is not selected\n"
     ]
    }
   ],
   "source": [
    "print(f\" Layer    task 1      task 2      task 3\")\n",
    "print(f\" -----    ------      ------      ------\")\n",
    "for idx, (l1, l2, l3) in enumerate(zip(hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1}       {l2}       {l3}\")\n",
    "    \n",
    "\n",
    "    print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "7ade0ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:39:39.936555Z",
     "start_time": "2022-02-08T22:39:39.911591Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_trained_policy(iter):\n",
    "\n",
    "    policy_softmaxs = environ.get_policy_prob()\n",
    "    policy_argmaxs = 1-np.argmax(policy_softmaxs, axis = -1)\n",
    "    print(f\"  Trained polcies at iteration: {iter} \")\n",
    "    print(f\"                   task 1                           task 2                         task 3        \")\n",
    "    print(f\" Layer       softmax        select          softmax        select          softmax        select   \")\n",
    "    print(f\" -----    ---------------   ------       ---------------   ------       ---------------   ------   \")\n",
    "    for idx, (l1,l2,l3,  p1,p2,p3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2], policy_argmaxs[0], policy_argmaxs[1], policy_argmaxs[2]),1):\n",
    "        print(f\"   {idx}      {l1[0]:.4f}   {l1[1]:.4f}   {p1:4d}    {l2[0]:11.4f}   {l2[1]:.4f}   {p2:4d}    {l3[0]:11.4f}   {l3[1]:.4f}   {p3:4d}\")\n",
    "\n",
    "    print()\n",
    "# print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "ec208dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:42:12.650813Z",
     "start_time": "2022-02-08T22:42:12.330169Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trained polcies at iteration: 5 \n",
      "                   task 1                           task 2                         task 3        \n",
      " Layer       softmax        select          softmax        select          softmax        select   \n",
      " -----    ---------------   ------       ---------------   ------       ---------------   ------   \n",
      "   1      0.5165   0.4835      1         0.5159   0.4841      1         0.5157   0.4843      1\n",
      "   2      0.5110   0.4890      1         0.5093   0.4907      1         0.5078   0.4922      1\n",
      "   3      0.5029   0.4971      1         0.5067   0.4933      1         0.5027   0.4973      1\n",
      "   4      0.5026   0.4974      1         0.5177   0.4823      1         0.4999   0.5001      0\n",
      "   5      0.4978   0.5022      0         0.5147   0.4853      1         0.4988   0.5012      0\n",
      "   6      0.5024   0.4976      1         0.5146   0.4854      1         0.5058   0.4942      1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_trained_policy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "eec517e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:07:30.836214Z",
     "start_time": "2022-02-08T22:07:30.804575Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        POLICIES (SOFTMAX)                                       task 3          \n",
      " Layer    task1              task2            task3 softmax         softmax         argmax         softmax         argmax   \n",
      " -----    -------------     -------------     -------------   ------   \n",
      "   1      0.5165 0.4835     0.5159 0.4841     0.5157 0.4843    [1 0]\n",
      "   2      0.5110 0.4890     0.5093 0.4907     0.5078 0.4922    [1 0]\n",
      "   3      0.5029 0.4971     0.5067 0.4933     0.5027 0.4973    [1 0]\n",
      "   4      0.5026 0.4974     0.5177 0.4823     0.4999 0.5001    [0 1]\n",
      "   5      0.4978 0.5022     0.5147 0.4853     0.4988 0.5012    [0 1]\n",
      "   6      0.5024 0.4976     0.5146 0.4854     0.5058 0.4942    [1 0]\n",
      "\n",
      "\n",
      " where [p1  p2]:  p1: layer is selected    p2: layer is not selected\n"
     ]
    }
   ],
   "source": [
    "print(f\"                        POLICIES (SOFTMAX)                                       task 3          \")\n",
    "print(f\" Layer    task1              task2            task3 softmax         softmax         argmax         softmax         argmax   \")\n",
    "print(f\" -----    -------------     -------------     -------------   ------   \")\n",
    "for idx, (l1,l2,l3, h1,h2,h3) in enumerate(zip(policy_softmaxs[0], policy_softmaxs[1], policy_softmaxs[2],hard_policies[0], hard_policies[1], hard_policies[2]),1):\n",
    "    print(f\"   {idx}      {l1[0]:.4f} {l1[1]:.4f}     {l2[0]:.4f} {l2[1]:.4f}     {l3[0]:.4f} {l3[1]:.4f}    {h3}\")\n",
    "    \n",
    "print(f\"\\n\\n where [p1  p2]:  p1: layer is selected    p2: layer is not selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "8bbeacb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T22:04:50.757406Z",
     "start_time": "2022-02-08T22:04:50.731736Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.51645106, 0.48354897],\n",
      "       [0.51099426, 0.48900577],\n",
      "       [0.50288266, 0.49711737],\n",
      "       [0.50259751, 0.49740252],\n",
      "       [0.49784794, 0.50215214],\n",
      "       [0.50235140, 0.49764863]], dtype=float32), array([[0.51589972, 0.48410025],\n",
      "       [0.50929916, 0.49070087],\n",
      "       [0.50668430, 0.49331570],\n",
      "       [0.51772296, 0.48227707],\n",
      "       [0.51472700, 0.48527300],\n",
      "       [0.51455247, 0.48544762]], dtype=float32), array([[0.51571137, 0.48428872],\n",
      "       [0.50782120, 0.49217883],\n",
      "       [0.50269639, 0.49730355],\n",
      "       [0.49994180, 0.50005817],\n",
      "       [0.49882248, 0.50117755],\n",
      "       [0.50577444, 0.49422547]], dtype=float32)] [[0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# print(policy_softmaxs[2], np.argmax(1-policy_softmaxs[2], axis = -1))\n",
    "print(policy_softmaxs, np.argmax(policy_softmaxs, axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be0240",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_logits()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cfdb7240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:19:06.155425Z",
     "start_time": "2022-02-08T21:19:06.118640Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0003512  -0.06617914]\n",
      " [ 0.00056736 -0.04341661]\n",
      " [ 0.00056091 -0.01096974]\n",
      " [-0.00044879 -0.01083876]\n",
      " [ 0.00013163  0.00874004]\n",
      " [ 0.00079006 -0.00861552]] \n",
      "\n",
      "[[-0.00035114 -0.06397165]\n",
      " [ 0.00056738 -0.03663344]\n",
      " [ 0.00056098 -0.02617791]\n",
      " [-0.00044851 -0.0713701 ]\n",
      " [ 0.00013184 -0.05879313]\n",
      " [ 0.00079021 -0.05743587]] \n",
      "\n",
      "[[-0.00035016 -0.06321616]\n",
      " [ 0.00056696 -0.03072025]\n",
      " [ 0.00056129 -0.01022454]\n",
      " [-0.00044983 -0.00021709]\n",
      " [ 0.00013071  0.00484093]\n",
      " [ 0.00078938 -0.02230957]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "logits  = (environ.get_current_logits())\n",
    "for i in logits:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e84662",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `get_current_policy()` : Calls test_sample_policy of network using ARGMAX of logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "548cfa24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T20:40:06.543376Z",
     "start_time": "2022-02-08T20:40:06.230711Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] \n",
      "\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]] \n",
      "\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pols  = (environ.get_current_policy())\n",
    "\n",
    "for i in pols:\n",
    "    print(i ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f556a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T18:27:33.593255Z",
     "start_time": "2022-01-27T18:27:33.553141Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792710e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### `gumbel_softmax()`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7265490e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:28:17.107529Z",
     "start_time": "2022-02-08T21:28:17.084910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8,edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', floatmode = 'maxprec_equal')\n",
    "torch.set_printoptions(precision=8,linewidth=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "3dcb0087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:35:11.617269Z",
     "start_time": "2022-02-08T21:35:11.569599Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001180506617226113\n",
      "   [-0.00035016 -0.06321616]   \t [0.17155227 0.82844770]            \t [1. 0.]\n",
      "   [ 0.00056696 -0.03072025]   \t [0.04782803 0.95217192]            \t [1. 0.]\n",
      "   [ 0.00056129 -0.01022454]   \t [0.52678031 0.47321963]            \t [0. 1.]\n",
      "   [-0.00044983 -0.00021709]   \t [0.74226642 0.25773358]            \t [0. 1.]\n",
      "   [0.00013071 0.00484093]   \t [0.81233245 0.18766758]            \t [1. 0.]\n",
      "   [ 0.00078938 -0.02230957]   \t [0.76270294 0.23729712]            \t [1. 0.]\n",
      "\n",
      "   [-0.00035016 -0.06321616]   \t [0.01975500 0.98024493]            \t [0. 1.]\n",
      "   [ 0.00056696 -0.03072025]   \t [0.33801472 0.66198522]            \t [1. 0.]\n",
      "   [ 0.00056129 -0.01022454]   \t [0.2644645 0.7355355]            \t [0. 1.]\n",
      "   [-0.00044983 -0.00021709]   \t [0.08984101 0.91015899]            \t [1. 0.]\n",
      "   [0.00013071 0.00484093]   \t [0.17066659 0.82933342]            \t [1. 0.]\n",
      "   [ 0.00078938 -0.02230957]   \t [0.74648136 0.25351864]            \t [0. 1.]\n",
      "\n",
      "   [-0.00035016 -0.06321616]   \t [0.5077298 0.4922701]            \t [0. 1.]\n",
      "   [ 0.00056696 -0.03072025]   \t [0.97178763 0.02821237]            \t [0. 1.]\n",
      "   [ 0.00056129 -0.01022454]   \t [0.15721972 0.84278023]            \t [1. 0.]\n",
      "   [-0.00044983 -0.00021709]   \t [0.13137119 0.86862880]            \t [1. 0.]\n",
      "   [0.00013071 0.00484093]   \t [0.89678597 0.10321394]            \t [1. 0.]\n",
      "   [ 0.00078938 -0.02230957]   \t [0.36205515 0.63794482]            \t [1. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(environ.temp)\n",
    "# tau = environ.temp\n",
    "tau = 1\n",
    "for i in range(3): \n",
    "    logits_tensor = torch.tensor(logits[0])\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=tau, hard=False).cpu().numpy() \n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=tau, hard=True).cpu().numpy()\n",
    "    \n",
    "    for l, gs, gh in zip(lgts, gumbel_soft, gumbel_hard):\n",
    "        print(f\"   {l}   \\t {gs}            \\t {gh}\")\n",
    "#     print(lgts)\n",
    "#     print(gumbel_soft)\n",
    "#     print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5ef7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4b0e0e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:21:35.524957Z",
     "start_time": "2022-02-08T21:21:35.488812Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0003512  -0.06617914]\n",
      " [ 0.00056736 -0.04341661]\n",
      " [ 0.00056091 -0.01096974]\n",
      " [-0.00044879 -0.01083876]\n",
      " [ 0.00013163  0.00874004]\n",
      " [ 0.00079006 -0.00861552]]\n",
      "tensor([[0.22969657, 0.77030343],\n",
      "        [0.47433791, 0.52566212],\n",
      "        [0.60556847, 0.39443150],\n",
      "        [0.00808809, 0.99191189],\n",
      "        [0.99667323, 0.00332679],\n",
      "        [0.56034184, 0.43965816]])\n",
      "tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "\n",
      "[[-0.00035114 -0.06397165]\n",
      " [ 0.00056738 -0.03663344]\n",
      " [ 0.00056098 -0.02617791]\n",
      " [-0.00044851 -0.0713701 ]\n",
      " [ 0.00013184 -0.05879313]\n",
      " [ 0.00079021 -0.05743587]]\n",
      "tensor([[0.29727638, 0.70272362],\n",
      "        [0.65075004, 0.34924990],\n",
      "        [0.83831531, 0.16168469],\n",
      "        [0.72130281, 0.27869719],\n",
      "        [0.87410325, 0.12589674],\n",
      "        [0.53555954, 0.46444049]])\n",
      "tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "\n",
      "[[-0.00035016 -0.06321616]\n",
      " [ 0.00056696 -0.03072025]\n",
      " [ 0.00056129 -0.01022454]\n",
      " [-0.00044983 -0.00021709]\n",
      " [ 0.00013071  0.00484093]\n",
      " [ 0.00078938 -0.02230957]]\n",
      "tensor([[0.00141716, 0.99858284],\n",
      "        [0.96934801, 0.03065197],\n",
      "        [0.70224190, 0.29775816],\n",
      "        [0.26444790, 0.73555207],\n",
      "        [0.63976562, 0.36023444],\n",
      "        [0.73902303, 0.26097697]])\n",
      "tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lgts in logits:\n",
    "    logits_tensor = torch.tensor(lgts)\n",
    "    print(lgts)\n",
    "    # Sample soft categorical using reparametrization trick:\n",
    "    gumbel_soft = F.gumbel_softmax(logits_tensor, tau=1, hard=False)\n",
    "    print(gumbel_soft)\n",
    "\n",
    "    # Sample hard categorical using \"Straight-through\" trick:\n",
    "    gumbel_hard  = F.gumbel_softmax(logits_tensor, tau=1, hard=True)\n",
    "    print(gumbel_hard)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe34a06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T20:49:37.643349Z",
     "start_time": "2022-02-03T20:49:37.580786Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2)\n",
      "[[0.47754285 0.52245715]\n",
      " [0.45825934 0.54174066]\n",
      " [0.45530966 0.54469034]\n",
      " [0.43196854 0.56803146]\n",
      " [0.43017322 0.56982678]\n",
      " [0.43333559 0.56666441]]\n",
      "[0.47754285 0.52245715]\n",
      "0.9999999999999998\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "smax = scipy.special.softmax(logs, axis =1)\n",
    "# smax = np.array( \n",
    "# [[0.46973792, 0.530262  ],\n",
    "#  [0.45025694, 0.549743  ],\n",
    "#  [0.4443086 , 0.5556915 ],\n",
    "#  [0.4138397 , 0.58616036],\n",
    "#  [0.4140113 , 0.5859887 ],\n",
    "#  [0.42114905, 0.57885087]])\n",
    "\n",
    "print(smax.shape)\n",
    "print(smax)\n",
    "print(smax[0])\n",
    "print(smax[0].sum())\n",
    "print(np.random.choice((1,0), p =smax[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7e7de25c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:15:19.893888Z",
     "start_time": "2022-02-08T21:15:19.870899Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logs = np.array(\n",
    "[[0.33064184, 0.42053092],\n",
    " [0.3532089 , 0.52056104],\n",
    " [0.3888512 , 0.5680909 ],\n",
    " [0.42039296, 0.694217  ],\n",
    " [0.4519742 , 0.73311865],\n",
    " [0.48401102, 0.7522658 ]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e101600",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load previously saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b1db09e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T20:30:30.175802Z",
     "start_time": "2022-01-19T20:30:30.149533Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " command line parms :  {'config': 'yamls/adashare/chembl_2task.yml', 'exp_instance': None, 'exp_ids': [0], 'batch_size': 9999, 'backbone_lr': None, 'task_lr': None, 'decay_lr_rate': None, 'decay_lr_freq': None, 'gpus': [0], 'cpu': True}\n",
      "Namespace(config='yamls/adashare/chembl_2task.yml', exp_instance=None, exp_ids=[0], batch_size=9999, backbone_lr=None, task_lr=None, decay_lr_rate=None, decay_lr_freq=None, gpus=[0], cpu=True)\n",
      "\n",
      "0119_1230 yamls/adashare/chembl_2task.yml\n"
     ]
    }
   ],
   "source": [
    "input_args = \" --config yamls/adashare/chembl_2task.yml --cpu --batch_size 09999\".split()\n",
    "# get command line arguments\n",
    "args = get_command_line_args(input_args)\n",
    "print(args)\n",
    "\n",
    "print()\n",
    "\n",
    "if args.exp_instance is None:\n",
    "    args.exp_instance = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "    \n",
    "print(args.exp_instance, args.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b88b29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T20:31:01.630624Z",
     "start_time": "2022-01-19T20:31:01.595882Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "####################READ YAML#####################\n",
      "##################################################\n",
      "[0] [0] best\n"
     ]
    }
   ],
   "source": [
    "print_separator('READ YAML')\n",
    "opt, gpu_ids, exp_ids =read_yaml_from_input(args)\n",
    "print(gpu_ids, exp_ids,  opt['train']['policy_iter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3afa36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T23:46:09.100795Z",
     "start_time": "2021-12-20T23:46:08.702295Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "current_iter = environ.load_checkpoint('latest')\n",
    "\n",
    "print('Evaluating the snapshot saved at %d iter' % current_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc853a0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T23:46:09.100795Z",
     "start_time": "2021-12-20T23:46:08.702295Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "opt['train']['weight_iter_alternate'] = opt['train'].get('weight_iter_alternate', len(train1_loader))\n",
    "opt['train']['alpha_iter_alternate'] = opt['train'].get('alpha_iter_alternate'  , len(train2_loader))\n",
    "\n",
    "print(opt['train']['weight_iter_alternate'], opt['train']['alpha_iter_alternate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9316b4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Softmax & Gumbel Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62dddc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Softmax, LogSoftMax, NegLogLikelihood and Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0f6f68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T17:48:49.526350Z",
     "start_time": "2022-01-28T17:48:49.417750Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i0     :  tensor([[0., 1.]])\n",
      "sm(i0) :  tensor([[0.2689, 0.7311]])\n",
      "lsm(i0):  tensor([[-1.3133, -0.3133]])\n",
      "\n",
      "i1     :  tensor([[1., 0.]])\n",
      "sm(i1) :  tensor([[0.7311, 0.2689]])\n",
      "lsm(i1):  tensor([[-0.3133, -1.3133]])\n",
      "\n",
      "i2     :  tensor([[0.5000, 0.5000]])\n",
      "sm(i2) :  tensor([[0.5000, 0.5000]])\n",
      "lsm(i2):  tensor([[-0.6931, -0.6931]])\n",
      "\n",
      "t0:  tensor([0])\n",
      "t1:  tensor([1])\n",
      "\n",
      "loss [0,1] and [0] :  tensor([1.3133])\n",
      "nll between lsm(i0):  tensor([1.3133])\n",
      "\n",
      "loss [0,1] and [1] :  tensor([0.3133])\n",
      "nll between lsm(i0):  tensor([0.3133])\n",
      "\n",
      "loss [1,0] and [0] :  tensor([0.3133])\n",
      "nll between lsm(i1):  tensor([0.3133])\n",
      "\n",
      "loss [1,0] and [1] :  tensor([1.3133])\n",
      "nll between lsm(i1):  tensor([1.3133])\n",
      "\n",
      "loss [0.5, 0.5] and [0] :  tensor([0.6931])\n",
      "nll between lsm(i1)   and [0] :  tensor([0.6931])\n",
      "\n",
      "loss [0.5, 0.5] and [1] :  tensor([0.6931])\n",
      "nll between lsm(i1)   and [1] :  tensor([0.6931])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "# print(nn.CrossEntropyLoss.__doc__)\n",
    "loss = nn.CrossEntropyLoss(reduction ='none')\n",
    "sm = nn.Softmax(dim =-1)\n",
    "lsm = nn.LogSoftmax(dim = -1)\n",
    "nll = nn.NLLLoss(reduction='none')\n",
    "\n",
    "# i1 = torch.randn(3, 5, requires_grad=True)\n",
    "# t1 = torch.empty(3, dtype=torch.long).random_(5)\n",
    "\n",
    "# print(i1)\n",
    "# print(i1)\n",
    "# print(t1)\n",
    "# output = loss(i1, t1)\n",
    "# print(output, output.sum(), output.mean())\n",
    "\n",
    "# i2 = torch.randn(1, 2, requires_grad=True)\n",
    "i0 = torch.tensor([[0.0, 1.0]], dtype=torch.float)\n",
    "i1 = torch.tensor([[1.0, 0.0]], dtype=torch.float)\n",
    "i2 = torch.tensor([[0.5, 0.5]], dtype=torch.float)\n",
    "i3 = torch.tensor([[0.4656, 0.5388]], dtype=torch.float)\n",
    "\n",
    "\n",
    "t1 = torch.tensor([1], dtype=torch.int64)\n",
    "t0 = torch.tensor([0], dtype=torch.int64)\n",
    "t2 = torch.tensor([2], dtype=torch.int64)\n",
    "print('i0     : ', i0)\n",
    "print('sm(i0) : ', sm(i0))\n",
    "print('lsm(i0): ', lsm(i0))\n",
    "print()\n",
    "print('i1     : ', i1)\n",
    "print('sm(i1) : ', sm(i1))\n",
    "print('lsm(i1): ', lsm(i1))\n",
    "print()\n",
    "print('i2     : ', i2)\n",
    "print('sm(i2) : ', sm(i2))\n",
    "print('lsm(i2): ', lsm(i2))\n",
    "print()\n",
    "\n",
    "print('t0: ',t0)\n",
    "print('t1: ',t1)\n",
    "print()\n",
    "output1 = loss(i0, t0)\n",
    "output2 = nll(lsm(i0), t0)\n",
    "print('loss [0,1] and [0] : ', output1)\n",
    "print('nll between lsm(i0): ', output2)\n",
    "print()\n",
    "output1 = loss(i0, t1)\n",
    "output2 = nll(lsm(i0), t1)\n",
    "print('loss [0,1] and [1] : ', output1)\n",
    "print('nll between lsm(i0): ', output2)\n",
    "print()\n",
    "\n",
    "output1 = loss(i1, t0)\n",
    "output2 = nll(lsm(i1), t0)\n",
    "print('loss [1,0] and [0] : ', output1)\n",
    "print('nll between lsm(i1): ', output2)\n",
    "print()\n",
    "\n",
    "output1 = loss(i1, t1)\n",
    "output2 = nll(lsm(i1), t1)\n",
    "print('loss [1,0] and [1] : ', output1)\n",
    "print('nll between lsm(i1): ', output2)\n",
    "print()\n",
    "\n",
    "output1 = loss(i2, t0)\n",
    "output2 = nll(lsm(i2), t0)\n",
    "print('loss [0.5, 0.5] and [0] : ', output1)\n",
    "print('nll between lsm(i1)   and [0] : ', output2)\n",
    "print()\n",
    "\n",
    "output1 = loss(i2, t1)\n",
    "output2 = nll(lsm(i2), t1)\n",
    "print('loss [0.5, 0.5] and [1] : ', output1)\n",
    "print('nll between lsm(i1)   and [1] : ', output2)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b2691",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Gumbel Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "46139b4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:14:05.002610Z",
     "start_time": "2022-02-08T21:14:04.668735Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(\n",
    "       [[0.5000, 0.5000],\n",
    "        [0.5000, 0.5000],\n",
    "        [0.5000, 0.5000],\n",
    "        [0.5000, 0.5000]], device='cuda:0', requires_grad=True) \n",
    "\n",
    "b = torch.tensor([0.5000, 0.5000,  0.5000, 0.5000], device='cuda:0', requires_grad=True) \n",
    "print(b.shape)\n",
    "c = torch.tensor([[0.000, 0.000,  0.000, 0.000]], device='cuda:0', requires_grad=True) \n",
    "print(c.shape)\n",
    "d = torch.tensor([[0.5000], [0.5000],  [0.5000], [0.5000]], device='cuda:0', requires_grad=True) \n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5c2dcfab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:14:10.258238Z",
     "start_time": "2022-02-08T21:14:10.220508Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.50000000, 0.50000000]])\n",
      "tensor([[0.46560001, 0.53880000]])\n"
     ]
    }
   ],
   "source": [
    "i0 = torch.tensor([[0.0, 1.0]], dtype=torch.float)\n",
    "i1 = torch.tensor([[1.0, 0.0]], dtype=torch.float)\n",
    "i2 = torch.tensor([[0.5, 0.5]], dtype=torch.float)\n",
    "i3 = torch.tensor([[0.4656, 0.5388]], dtype=torch.float)\n",
    "\n",
    "\n",
    "print(i0)\n",
    "print(i1)\n",
    "print(i2)\n",
    "print(i3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b6cd0c2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:14:16.323624Z",
     "start_time": "2022-02-08T21:14:16.273436Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "-------------------------\n",
      "tensor([[0.35299182, 0.64700818]])\n",
      "tensor([[0.44149891, 0.55850112]])\n",
      "tensor([[0.20112066, 0.79887938]])\n",
      "\n",
      "tensor([[1., 0.]])\n",
      "-------------------------\n",
      "tensor([[0.66644371, 0.33355635]])\n",
      "tensor([[0.49296239, 0.50703758]])\n",
      "tensor([[0.63502610, 0.36497390]])\n",
      "\n",
      "tensor([[0.50000000, 0.50000000]])\n",
      "-------------------------\n",
      "tensor([[0.45357519, 0.54642475]])\n",
      "tensor([[0.53368020, 0.46631980]])\n",
      "tensor([[0.53128326, 0.46871671]])\n",
      "\n",
      "tensor([[0.46560001, 0.53880000]])\n",
      "-------------------------\n",
      "tensor([[0.75833476, 0.24166526]])\n",
      "tensor([[0.47358128, 0.52641875]])\n",
      "tensor([[0.47027132, 0.52972871]])\n"
     ]
    }
   ],
   "source": [
    "temp  = 2.5\n",
    "print(i0)\n",
    "print('-'*25)\n",
    "print(F.gumbel_softmax( i0, temp, hard=False))\n",
    "print(F.gumbel_softmax( i0, temp, hard=False))\n",
    "print(F.gumbel_softmax( i0, temp, hard=False))\n",
    "print()\n",
    "\n",
    "print(i1)\n",
    "print('-'*25)\n",
    "print(F.gumbel_softmax( i1, temp, hard=False))\n",
    "print(F.gumbel_softmax( i1, temp, hard=False))\n",
    "print(F.gumbel_softmax( i1, temp, hard=False))\n",
    "print()\n",
    "\n",
    "print(i2)\n",
    "print('-'*25)\n",
    "print(F.gumbel_softmax( i2, temp, hard=False))\n",
    "print(F.gumbel_softmax( i2, temp, hard=False))\n",
    "print(F.gumbel_softmax( i2, temp, hard=False))\n",
    "print()\n",
    "\n",
    "\n",
    "print(i3)\n",
    "print('-'*25)\n",
    "print(F.gumbel_softmax( i3, temp, hard=False))\n",
    "print(F.gumbel_softmax( i3, temp, hard=False))\n",
    "print(F.gumbel_softmax( i3, temp, hard=False))\n",
    "# print(F.gumbel_softmax( d, 5, hard=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875518ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:34:54.606453Z",
     "start_time": "2021-12-01T01:34:54.586164Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logits = torch.randn(20, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0890b1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:34:57.902781Z",
     "start_time": "2021-12-01T01:34:57.880455Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(logits[:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85ce6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:44:54.225922Z",
     "start_time": "2021-12-01T01:44:54.204482Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format)\n",
    "print(tmp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac484d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:45:28.342309Z",
     "start_time": "2021-12-01T01:45:28.320145Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(tmp[0])\n",
    "tmp1 = tmp.exponential_()\n",
    "print(tmp1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b9eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:45:55.855272Z",
     "start_time": "2021-12-01T01:45:55.825274Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp2 = tmp1.log()\n",
    "print(tmp2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5db59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:43:07.405165Z",
     "start_time": "2021-12-01T01:43:07.383324Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " gumbels = (\n",
    "        -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format).exponential_().log()\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35984a4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:43:29.214582Z",
     "start_time": "2021-12-01T01:43:29.193794Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(gumbels.shape)\n",
    "print(gumbels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "65270223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T21:14:38.375624Z",
     "start_time": "2022-02-08T21:14:38.335331Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty_like(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18219/4270493771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Sample soft categorical using reparametrization trick:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgumbel_soft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgumbel_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Sample hard categorical using \"Straight-through\" trick:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgumbel_hard\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgumbel_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgumbel_softmax\u001b[0;34m(logits, tau, hard, eps, dim)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m     gumbels = (\n\u001b[0;32m-> 1732\u001b[0;31m         \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_contiguous_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexponential_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1733\u001b[0m     )  # ~Gumbel(0,1)\n\u001b[1;32m   1734\u001b[0m     \u001b[0mgumbels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgumbels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtau\u001b[0m  \u001b[0;31m# ~Gumbel(logits,tau)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: empty_like(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "# Sample soft categorical using reparametrization trick:\n",
    "gumbel_soft = F.gumbel_softmax(logits, tau=1, hard=False)\n",
    "\n",
    "# Sample hard categorical using \"Straight-through\" trick:\n",
    "gumbel_hard  = F.gumbel_softmax(logits, tau=1, hard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b89520b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:37:20.518987Z",
     "start_time": "2021-12-01T01:37:20.490071Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(logits.shape)\n",
    "print(logits[0])\n",
    "print(np.argmax(logits[0]))\n",
    "print('\\n')\n",
    "\n",
    "print(gumbel_soft.shape)\n",
    "print(gumbel_soft[0])\n",
    "print(np.argmax(gumbel_soft[0]))\n",
    "print('\\n')\n",
    "\n",
    "print(gumbel_hard.shape)\n",
    "print(gumbel_hard[0])\n",
    "print(np.argmax(gumbel_hard[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b49944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:11.889231Z",
     "start_time": "2021-12-01T01:47:11.865177Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gumbel_soft.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8b677",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:20.629635Z",
     "start_time": "2021-12-01T01:47:20.607058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tau = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2376a731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:21.278402Z",
     "start_time": "2021-12-01T01:47:21.254276Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = torch.empty_like(logits, memory_format=torch.legacy_contiguous_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb14b3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:21.920473Z",
     "start_time": "2021-12-01T01:47:21.899432Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e5688",
   "metadata": {
    "hidden": true
   },
   "source": [
    "fill tensor `a` with elements drawn from exponential distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636a394",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:32.866091Z",
     "start_time": "2021-12-01T01:47:32.838226Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a_e = a.exponential_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e5bfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:34.003871Z",
     "start_time": "2021-12-01T01:47:33.978450Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a_e[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682752d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "draw natural log `ln()` on elements of a_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8f568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:47.286259Z",
     "start_time": "2021-12-01T01:47:47.265716Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a_e_l = a_e.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a46e180",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:47.554155Z",
     "start_time": "2021-12-01T01:47:47.532995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a_e_l[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f86dab1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Neg log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841bf82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:47:51.788290Z",
     "start_time": "2021-12-01T01:47:51.763038Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a_el_neg = -a_e_l\n",
    "\n",
    "a_el_neg[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c991926d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:48:08.613360Z",
     "start_time": "2021-12-01T01:48:08.591331Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logits[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2849ed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:48:09.724747Z",
     "start_time": "2021-12-01T01:48:09.701886Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gumbels = (logits + a_el_neg) / tau \n",
    "\n",
    "gumbels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828b2b74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:48:14.682363Z",
     "start_time": "2021-12-01T01:48:14.660407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dim = -1\n",
    "gumbels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28f692",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:48:15.779652Z",
     "start_time": "2021-12-01T01:48:15.758743Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    " y_soft = gumbels.softmax(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09316403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:48:17.797567Z",
     "start_time": "2021-12-01T01:48:17.776922Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_soft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09910a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T01:48:19.084522Z",
     "start_time": "2021-12-01T01:48:19.062543Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_soft[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a373cb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T21:41:56.235154Z",
     "start_time": "2021-09-22T21:41:56.228186Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "index = y_soft.max(dim, keepdim=True)\n",
    "print(index[0].T)\n",
    "print(index[1].T)\n",
    "y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index[1], 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6dc2ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T21:42:54.751798Z",
     "start_time": "2021-09-22T21:42:54.744929Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.argmax(y_hard,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3e1f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T03:43:17.720809Z",
     "start_time": "2021-09-24T03:43:17.662341Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp_d= [0,1,0]\n",
    "for i in range(10):\n",
    "    sampled = np.random.choice((2, 1, 0), p=tmp_d)\n",
    "    print(sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0baccc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Scratch Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1716e81d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T08:43:47.166466Z",
     "start_time": "2022-01-12T08:43:47.133961Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:12.104370Z",
     "iopub.status.busy": "2022-01-07T22:44:12.103595Z",
     "iopub.status.idle": "2022-01-07T22:44:12.133070Z",
     "shell.execute_reply": "2022-01-07T22:44:12.131731Z",
     "shell.execute_reply.started": "2022-01-07T22:44:12.104302Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from numba import cuda\n",
    "\n",
    "# cuda_device = 0 \n",
    "\n",
    "# def free_gpu_cache(cuda_device):\n",
    "#     print(\"Initial GPU Usage\")    \n",
    "#     gpu_usage()                             \n",
    "#     print(\"GPU Usage after emptying the cache\")\n",
    "#     gpu_usage()\n",
    "#     print(\"CUDA empty cache\")\n",
    "#     torch.cuda.empty_cache()\n",
    "#     print(\"Close and reopen device\")\n",
    "#     cuda.select_device(cuda_device)\n",
    "#     print(\"Close device\")    \n",
    "#     cuda.close()\n",
    "#     print(\"Reopen device\")    \n",
    "#     cuda.select_device(cuda_device)\n",
    "#     print(\"GPU Usage after closing and reopening\")\n",
    "#     gpu_usage()\n",
    "\n",
    "# free_gpu_cache(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81188503",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T21:45:43.118975Z",
     "start_time": "2022-01-07T21:45:43.089201Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def print_separator(text, total_len=50):\n",
    "#     print('#' * total_len)\n",
    "#     left_width = (total_len - len(text))//2\n",
    "#     right_width = total_len - len(text) - left_width\n",
    "#     print(\"#\" * left_width + text + \"#\" * right_width)\n",
    "#     print('#' * total_len)\n",
    "\n",
    "# def print_dbg(text, verbose = False):\n",
    "#     if verbose:\n",
    "#         print(text)\n",
    "\n",
    "# @debug_off\n",
    "# def print_heading(text,  verbose = False):\n",
    "#     len_ttl = max(len(text)+4, 50)\n",
    "#     if verbose:\n",
    "#         print('-' * len_ttl)\n",
    "#         print(f\" {text}\")\n",
    "#         # left_width = (total_len - len(text))//2\n",
    "#         # right_width = total_len - len(text) - left_width\n",
    "#         # print(\"#\" * left_width + text + \"#\" * right_width)\n",
    "#         print('-' * len_ttl,'\\n')\n",
    "\n",
    "# print_heading(\"hello_kevin\", verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f559c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Chembl Data feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a1002b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:06:53.545985Z",
     "start_time": "2022-01-12T17:06:53.520879Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:13.909003Z",
     "iopub.status.busy": "2022-01-07T22:44:13.907310Z",
     "iopub.status.idle": "2022-01-07T22:44:13.953692Z",
     "shell.execute_reply": "2022-01-07T22:44:13.952354Z",
     "shell.execute_reply.started": "2022-01-07T22:44:13.908963Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dataroot = opt['dataload']['dataroot']\n",
    "# ecfp     = load_sparse(dataroot, opt['dataload']['x'])\n",
    "\n",
    "# total_input = ecfp.shape[0]\n",
    "# ranges      = (np.cumsum([0]+opt['dataload']['x_split_ratios'])* total_input).astype(np.int32)\n",
    "\n",
    "\n",
    "# idx_train  = np.arange(ranges[0], ranges[1])\n",
    "# idx_train1 = np.arange(ranges[1], ranges[2])\n",
    "# idx_train2 = np.arange(ranges[2], ranges[3])\n",
    "# idx_val    = np.arange(ranges[3], ranges[4])\n",
    "\n",
    "# print(f\" Total input    :  {total_input}   Cummulative dataset sizes: {ranges}\")\n",
    "# print(f\" Ranges         :  {ranges}\")\n",
    "# print()\n",
    "# print(f\" X Dataset      :  {os.path.join(opt['dataload']['dataroot'], opt['dataload']['x'])}\")\n",
    "# print(f\" y Dataset      :  {os.path.join(opt['dataload']['dataroot'], opt['dataload']['y_tasks'][0])}\")\n",
    "# print(f\" Folding Dataset:  {os.path.join(opt['dataload']['dataroot'], opt['dataload']['folding'])}\")\n",
    "# print(f\" Weights_class  :  {opt['dataload']['weights_class']}\")\n",
    "# print()\n",
    "# print(f' idx_train    dataset size: {len(idx_train)  :6d}  - rows: {(idx_train)} ')\n",
    "# print(f' idx_train1   dataset size: {len(idx_train1) :6d}  - rows: {(idx_train1)} ')\n",
    "# print(f' idx_train2   dataset size: {len(idx_train2) :6d}  - rows: {(idx_train2)} ')\n",
    "# print(f' val_train    dataset size: {len(idx_val)    :6d}  - rows: {(idx_val)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4bc41",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d5a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T22:42:25.945090Z",
     "start_time": "2021-12-20T22:42:25.917655Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tnrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49b9f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T22:41:50.353599Z",
     "start_time": "2021-12-20T22:41:50.331414Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "curr_iter_t  = 0\n",
    "curr_iter_a  = 0\n",
    "curr_iter_w  = 0\n",
    "stop_iter_t  = 0\n",
    "stop_iter_w  = 0 \n",
    "stop_iter_a  = 0\n",
    "total_weight_epochs = 0\n",
    "total_policy_epochs = 0 \n",
    "train_total_iters = 8\n",
    "weight_iter_alternate = 17\n",
    "alpha_iter_alternate = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7018b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T22:41:50.588581Z",
     "start_time": "2021-12-20T22:41:50.555942Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(curr_iter_t, stop_iter_t, flag, train_total_iters,opt['train']['print_freq'] )\n",
    "start_iter_t = curr_iter_t\n",
    "stop_iter_t = curr_iter_t +  train_total_iters \n",
    "print(f\" Current iteration {curr_iter_t} - Run  from {start_iter_t} to {stop_iter_t}\")\n",
    "\n",
    "print(curr_iter_w, weight_iter_alternate , flag)\n",
    "stop_iter_w = curr_iter_w +  weight_iter_alternate \n",
    "print(f\" Current Weight iteration {curr_iter_w} - Run  from {curr_iter_w+1} to {stop_iter_w}\")\n",
    "\n",
    "\n",
    "print(curr_iter_a ,  alpha_iter_alternate ,flag)\n",
    "stop_iter_a = curr_iter_a +  alpha_iter_alternate \n",
    "print(f\" Current alpha iteration {curr_iter_a} - Run  from {curr_iter_a+1} to {stop_iter_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839ecee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T22:37:56.218327Z",
     "start_time": "2021-12-20T22:37:10.168700Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# del t, t_w, t_a\n",
    "main_iter_ctr = 0 \n",
    "with tnrange(start_iter_t , stop_iter_t  , initial = start_iter_t , total = stop_iter_t, position=0, leave= True, desc=\"master\") as t :\n",
    "    for curr_t in t:\n",
    "        \n",
    "        with  tnrange(0, weight_iter_alternate , initial = 0, total = weight_iter_alternate, \n",
    "                      position=1, leave= False, desc=f\"epoch {curr_t} weight training\") as t_w :\n",
    "            for curr_w in t_w:    \n",
    "                sleep(0.35)\n",
    "                main_iter_ctr += 1\n",
    "                curr_iter_w  = curr_w\n",
    "                t.set_postfix({'epoch': f\"{curr_t}/{train_total_iters}\", 'main_iter_ctr': main_iter_ctr})\n",
    "                t_w.set_postfix({'weight training epoch': curr_t, 'batch #': curr_iter_w})\n",
    "\n",
    "            print(f\"** Epoch {curr_t}/{train_total_iters} weight training complete - Loss: \"\n",
    "                  f\"curr_w:{curr_w}    curr_iter_w:{curr_iter_w}  curr_t:{curr_t}  main_iter_ctr:{main_iter_ctr}\" )\n",
    "                 \n",
    "        \n",
    "        with  tnrange(0, alpha_iter_alternate  , initial = 0, total = alpha_iter_alternate , \n",
    "                      position=2, leave= False, desc=f\"epoch {curr_t} policy training\") as t_a :\n",
    "            for curr_a in t_a:    \n",
    "                sleep(0.35)\n",
    "                main_iter_ctr += 1                \n",
    "                curr_iter_a = curr_a\n",
    "                t.set_postfix({'epoch': f\"{curr_t}/{train_total_iters}\", 'main_iter_ctr':main_iter_ctr})\n",
    "                t_a.set_postfix({'policy training epoch': curr_t, 'batch #': curr_iter_a})            \n",
    "                \n",
    "            print(f\"** Epoch {curr_t}/{train_total_iters} policy training complete - Loss: \"\n",
    "                  f\"curr_w:{curr_w}    curr_iter_w:{curr_iter_w}  curr_t:{curr_t}  main_iter_ctr:{main_iter_ctr}\" )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb2c8ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T23:04:03.776382Z",
     "start_time": "2021-12-20T23:04:03.746093Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "curr_iter_t  = 0\n",
    "curr_iter_a  = 0\n",
    "curr_iter_w  = 0\n",
    "stop_iter_t  = 0\n",
    "stop_iter_w  = 0 \n",
    "stop_iter_a  = 0\n",
    "total_weight_epochs = 0\n",
    "total_policy_epochs = 0 \n",
    "train_total_iters = 100\n",
    "train_total_epochs = 10\n",
    "weight_iter_alternate = 17\n",
    "alpha_iter_alternate = 17\n",
    "\n",
    "print(curr_iter_t, stop_iter_t, flag, train_total_iters,opt['train']['print_freq'] )\n",
    "start_iter_t = curr_iter_t\n",
    "stop_iter_t = curr_iter_t +  train_total_iters \n",
    "print(f\" Current iteration {curr_iter_t} - Run  from {start_iter_t} to {stop_iter_t}\")\n",
    "\n",
    "print(curr_iter_w, weight_iter_alternate , flag)\n",
    "stop_iter_w = curr_iter_w +  weight_iter_alternate \n",
    "print(f\" Current Weight iteration {curr_iter_w} - Run  from {curr_iter_w+1} to {stop_iter_w}\")\n",
    "\n",
    "\n",
    "print(curr_iter_a ,  alpha_iter_alternate ,flag)\n",
    "stop_iter_a = curr_iter_a +  alpha_iter_alternate \n",
    "print(f\" Current alpha iteration {curr_iter_a} - Run  from {curr_iter_a+1} to {stop_iter_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aba7fb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T23:08:57.280036Z",
     "start_time": "2021-12-20T23:08:41.214078Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# del t, t_w, t_a\n",
    "current_epoch = 0\n",
    "main_iter_ctr = 0 \n",
    "# with tnrange(start_iter_t , stop_iter_t  , initial = start_iter_t , total = stop_iter_t, position=0, leave= True, desc=\"master\") as t :\n",
    "# with tqdm_notebook(total=train_total_epochs) as t:\n",
    "t = tqdm_notebook(total=train_total_epochs)\n",
    "\n",
    "while current_epoch < train_total_epochs:\n",
    "    current_epoch+=1\n",
    "    t.update(1)\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # Train & Update the network weights\n",
    "    #-----------------------------------------        \n",
    "    with  tnrange(0, weight_iter_alternate , initial = 0, total = weight_iter_alternate, \n",
    "                  position=1, leave= False, desc=f\"epoch {current_epoch} weight training\") as t_w :\n",
    "        for curr_w in t_w:    \n",
    "            sleep(0.35)\n",
    "            main_iter_ctr += 1\n",
    "            curr_iter_w  = curr_w\n",
    "\n",
    "            t.set_postfix({'epoch': f\"{current_epoch}/{train_total_epochs}\", 'main_iter_ctr': main_iter_ctr})\n",
    "            t_w.set_postfix({'weight training epoch': current_epoch, 'batch #': curr_iter_w})\n",
    "\n",
    "        tqdm.write(f\"** Epoch {current_epoch}/{train_total_epochs} weight training complete - Loss: \"\n",
    "              f\"curr_w:{curr_w}    curr_iter_w:{curr_iter_w}  current_epoch:{current_epoch}  main_iter_ctr:{main_iter_ctr}\" )\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # Train & Update the  policy \n",
    "    #-----------------------------------------        \n",
    "    with  tnrange(0, alpha_iter_alternate  , initial = 0, total = alpha_iter_alternate , \n",
    "                  position=2, leave= False, desc=f\"epoch {current_epoch} policy training\") as t_a :\n",
    "        for curr_a in t_a:    \n",
    "            sleep(0.35)\n",
    "            main_iter_ctr += 1                \n",
    "            curr_iter_a = curr_a\n",
    "\n",
    "            t.set_postfix({'epoch': f\"{current_epoch}/{train_total_epochs}\", 'main_iter_ctr':main_iter_ctr})\n",
    "            t_a.set_postfix({'policy training epoch': current_epoch, 'batch #': curr_iter_a})            \n",
    "\n",
    "        tqdm.write(f\"** Epoch {current_epoch}/{train_total_epochs} policy training complete - Loss: \"\n",
    "              f\"curr_w:{curr_w}    curr_iter_w:{curr_iter_w}  current_epoch:{current_epoch}  main_iter_ctr:{main_iter_ctr}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141aa027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T22:11:57.104094Z",
     "start_time": "2021-12-20T22:11:57.081272Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with tnrange(start_iter, stop_iter , initial = current_iter_w, total = stop_iter,  position=0, leave= True, desc=\"training\") as t:\n",
    "#     for current_iter_w in t:\n",
    "#         print(current_iter_w)\n",
    "#         current_iter_w += 1\n",
    "#         print(current_iter_w)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3dbaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T21:23:27.031154Z",
     "start_time": "2021-12-15T21:23:27.007124Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# start = current_iter\n",
    "# end = current_iter + opt['train']['warm_up_iters']\n",
    "# curr_range = range(start,end)\n",
    "# print(start, end)\n",
    "\n",
    "# for i in tqdm.notebook.tnrange(start, end, initial = start, total = end):\n",
    "#     sleep(0.25)\n",
    "#     current_iter += 1\n",
    "# #     print(i)\n",
    "#     pass\n",
    "\n",
    "# print(current_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d53f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T21:23:27.061710Z",
     "start_time": "2021-12-15T21:23:27.035963Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# start = current_iter\n",
    "# end = current_iter + opt['train']['warm_up_iters']\n",
    "# curr_range = range(start,end)\n",
    "# print(start, end)\n",
    "\n",
    "# for i in tqdm.notebook.tqdm_notebook(cur_range, initial = start, total = end, disable=False, position=0, desc = \"validation\"):\n",
    "#     current_iter += 1\n",
    "#     pass\n",
    "\n",
    "# print(current_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a0cd55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T20:40:03.819876Z",
     "start_time": "2021-12-14T20:40:03.768686Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from tqdm import trange\n",
    "# from time import sleep\n",
    "\n",
    "# for i in trange(40, desc='1st loop', position=0, leave = False):\n",
    "#     sleep(1.1)\n",
    "#     for j in trange(5, desc='2nd loop', position =1, leave = False):\n",
    "#         sleep(0.01)\n",
    "#         for k in trange(50, desc='3rd loop', position =0,leave=False):\n",
    "#             sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92f08b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T18:51:59.433086Z",
     "start_time": "2021-12-15T18:51:59.396500Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with tqdm(batch_enumerator, leave=False, disable=False) as t:\n",
    "# with tqdm(total=10, bar_format=\"{postfix[0]} {postfix[1][value]:>8.2g}\", postfix=[\"Batch\", dict(value=0)]) as t:\n",
    "# with trange(opt['train']['warm_up_iters'], bar_format=\"{postfix[0]} {postfix[1][value]:>8.2g}\", postfix=[\"Batch\", dict(value=0)]) as t:\n",
    "# with trange(opt['train']['warm_up_iters']) as t:\n",
    "\n",
    "#     for current_iter in t:\n",
    "#         batch_idx, batch = next(batch_enumerator)\n",
    "#         ran = random.randint(1, 100)\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         environ.train()\n",
    "\n",
    "#         print_heading(f\" {timestring()} - WARMUP Training iter {current_iter}/{opt['train']['warm_up_iters']}    batch_idx: {batch_idx}\"    \n",
    "#                       f\"    Warm-up iters: {opt['train']['warm_up_iters']}\"\n",
    "#                       f\"    Validation freq:  {opt['train']['val_freq']}\", verbose = False)\n",
    "\n",
    "#         if batch_idx == len(train_loader) :\n",
    "#     #         print_heading(f\" ******* {timestring()}  re-enumerate train_loader() *******\")\n",
    "#             batch_enumerator = enumerate(train_loader,1)   \n",
    "\n",
    "#         t.set_postfix({'batch_idx': batch_idx, 'num_vowels': ran})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2fee04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T18:51:59.469748Z",
     "start_time": "2021-12-15T18:51:59.436522Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import tqdm.notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ff118",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### using eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377aa7bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T08:07:39.604778Z",
     "start_time": "2021-10-27T08:07:39.579603Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task1 = [1,2,3]\n",
    "task2 = None\n",
    "task3 = {'4': 'Kevin', '5':'Bardool'}\n",
    "\n",
    "for i in [1,2,3]:\n",
    "    print('task{:d}'.format(i))\n",
    "    if eval('task{:d}'.format(i)) is None:\n",
    "        print('task{:d} :  has not been defined '.format(i))\n",
    "#         exec_str = 'task{:d} =  np.random.rand({:d},{:d})'.format(i,3,2)\n",
    "        exec_str = 'y_task{:d} = scipy.sparse.csr_matrix(({:d}, {:d})) '.format(i,3,2)\n",
    "        print(exec_str)\n",
    "        exec(exec_str)\n",
    "        print('task{:d} : '.format(i), eval('task{:d}'.format(i)))\n",
    "        print(eval('type(task{:d})'.format(i)))\n",
    "    else:\n",
    "        print('task{:d} : '.format(i), eval('task{:d}'.format(i)))\n",
    "        \n",
    "print(f\"Created task{i} shape        : {eval('len(task{:d})'.format(i))}\")\n",
    "print(len(task3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce01f48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T08:07:44.515337Z",
     "start_time": "2021-10-27T08:07:44.497413Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = np.random.rand(3,2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef347b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T08:07:46.338515Z",
     "start_time": "2021-10-27T08:07:46.319087Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(eval('len(task{:d})'.format(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f8147",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dev code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0579637",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Warm-up:  validation - Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9ead6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:41:10.772791Z",
     "start_time": "2021-12-15T20:41:05.690320Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# validation\n",
    "if should(current_iter, opt['train']['val_freq']):\n",
    "    print(f\"**  {timestring()}  START VALIDATION iteration: {current_iter} \")    \n",
    "\n",
    "    environ.eval()     # set to evaluation mode (train = False)\n",
    "    num_seg_class = opt['tasks_num_class'][opt['tasks'].index('seg')] if 'seg' in opt['tasks'] else -1\n",
    "    val_metrics = eval_dev(environ, \n",
    "                          val_loader, \n",
    "                          opt['tasks'], \n",
    "                          policy=False, \n",
    "                          num_train_layers=None, \n",
    "                          eval_iter = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4195f56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:41:11.489480Z",
     "start_time": "2021-12-15T20:41:11.461278Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_metrics.keys()\n",
    "val_metrics['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5371cde4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:41:55.074366Z",
     "start_time": "2021-12-15T20:41:55.029329Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in val_metrics:\n",
    "    print(f'\\n {i} \\n -----------------')\n",
    "    print(val_metrics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a599fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:37:44.423495Z",
     "start_time": "2021-12-15T20:37:44.400109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    for t_id, task in enumerate(environ.tasks):\n",
    "        task_key = f\"task{t_id+1}\"    \n",
    "        environ.print_loss(current_iter, start_time, val_metrics[task_key][\"classification_agg\"], title='validation')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2e308",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:36:43.503203Z",
     "start_time": "2021-12-15T20:36:43.371900Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    environ.save_checkpoint('latest', current_iter)\n",
    "\n",
    "    print(f\"** {timestring()} - END VALIDATION iteration:  {current_iter} \")                \n",
    "    environ.train()    # set to training mode (train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7a5e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T22:26:36.573475Z",
     "start_time": "2021-12-12T22:26:36.455074Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for i in val_metrics.keys():\n",
    "#     print(i, type(val_metrics[i]))\n",
    "#     for k in val_metrics[i].keys():\n",
    "#         print(i,k, type(val_metrics[i][k]))\n",
    "#         if isinstance(val_metrics[i][k], pd.core.series.Series):\n",
    "#             print(f\"val_metrics[{i}][{k}] is a series\")\n",
    "#         elif isinstance(val_metrics[i][k], pd.core.frame.DataFrame):\n",
    "#             print(f\"val_metrics[{i}][{k}] is a dataframe\")        \n",
    "\n",
    "# s = val_metrics['task1']['classification_agg']\n",
    "# print(s)\n",
    "# print(s.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d702c397",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T18:19:18.285289Z",
     "start_time": "2022-01-27T18:19:18.236934Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:38.657578Z",
     "iopub.status.busy": "2022-01-07T22:44:38.657285Z",
     "iopub.status.idle": "2022-01-07T22:45:02.893150Z",
     "shell.execute_reply": "2022-01-07T22:45:02.891381Z",
     "shell.execute_reply.started": "2022-01-07T22:44:38.657539Z"
    },
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "##\n",
    "##  Iteration based method\n",
    "##\n",
    "# ##---------------------------------------------------------------     \n",
    "# ## part one: warm up\n",
    "# ##---------------------------------------------------------------\n",
    "# num_prints = 0\n",
    "# print(f\" Last iteration: {current_iter}  # of warm-up iterations to do:{opt['train']['warm_up_iters']} - Run  from {current_iter+1} to {stop_iter}\")\n",
    "# t0 = time.time()\n",
    "\n",
    "# with trange(current_iter+1, stop_iter+1 , initial = current_iter, total = stop_iter, position=0, leave= True, desc=\"training\") as t_warmup :\n",
    "    \n",
    "#     for current_iter in t_warmup:\n",
    "#         start_time = time.time()\n",
    "#         environ.train()\n",
    "#         batch = next(train_loader)    \n",
    "    \n",
    "# #         print_heading(f\" {timestring()} - WARMUP Training iter {current_iter}/{opt['train']['warm_up_iters']} \", verbose = False)\n",
    "\n",
    "#         environ.set_inputs(batch, train_loader.dataset.input_size)\n",
    "\n",
    "#         environ.optimize(opt['lambdas'], \n",
    "#                          is_policy=False, \n",
    "#                          flag='update_w', \n",
    "#                          verbose = False)\n",
    "        \n",
    "#         t_warmup.set_postfix({'curr_iter':current_iter, \n",
    "#                               'Loss': f\"{environ.losses['total']['total'].item():.4f}\" , \n",
    "#                               'row_ids':f\"{batch['row_id'][0]}-{batch['row_id'][-1]}\"})\n",
    "        \n",
    "# ## Using this causes displaying a zig zag pattern in the training losses \n",
    "# #         if should(current_iter, opt['train']['print_freq']):\n",
    "# #             environ.print_loss(current_iter, start_time, title = f\"[c]Warmup training : iteration: {current_iter}\", verbose = True)\n",
    "    \n",
    "#         ##--------------------------------------------------------------- \n",
    "#         # validation\n",
    "#         ##--------------------------------------------------------------- \n",
    "#         if should(current_iter, opt['train']['val_freq']):\n",
    "#             environ.print_loss(current_iter, start_time, title = f\"[e]Weight training epoch: iteration: {current_iter}\", verbose = True)\n",
    "\n",
    "#             val_metrics = environ.evaluate(\n",
    "#                                    val_loader, \n",
    "#                                    opt['tasks'], \n",
    "#                                    is_policy=False, \n",
    "#                                    num_train_layers=None,\n",
    "#                                    eval_iters = eval_iters, \n",
    "#                                    progress=True,\n",
    "#                                    leave = False,\n",
    "#                                    verbose = False)\n",
    "\n",
    "#             environ.print_metrics(current_iter, start_time, title='validation')\n",
    "#             environ.save_checkpoint('warmup', current_iter)\n",
    "            \n",
    "#             print_metrics_cr(current_iter, time.time() - t0, None, environ.val_metrics, num_prints)\n",
    "#             num_prints += 1            \n",
    "#             t0 = time.time()\n",
    "#             print()     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a966a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Save Best Checkpoint Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24d68b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "            #-----------------------------------------------------------------------------------------------------------------------\n",
    "            #  Save Best Checkpoint Code\n",
    "            #-----------------------------------------------------------------------------------------------------------------------\n",
    "            #\n",
    "            #            #----------------------------------------------------------------------------------------------\n",
    "            #            # if number of iterations completed after the warm up phase is greater than the number of \n",
    "            #            # (weight/policy alternations) x (cirriculum speed) x (number of layers to be policy trained)\n",
    "            #            #\n",
    "            #            # check metrics for improvement, and issue a checkpoint if necessary\n",
    "            #            #----------------------------------------------------------------------------------------------\n",
    "            # \n",
    "            #             if current_iter - opt['train']['warm_up_iters'] >= num_blocks * opt['curriculum_speed'] * \\\n",
    "            #                     (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate']):\n",
    "            #                 new_value = 0\n",
    "            #                 print(f\"  {current_iter - opt['train']['warm_up_iters']} IS GREATER THAN \"\n",
    "            #                        f\" {num_blocks * opt['curriculum_speed'] * (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate'])} -- \"\n",
    "            #                        f\"  evaluate progress and make checkpoint if necessary.\" )            \n",
    "            # \n",
    "            #                 ## compare validation metrics against reference metrics.\n",
    "            #                 \n",
    "            #                 for k in refer_metrics.keys():\n",
    "            #                     if k in val_metrics.keys():\n",
    "            #                         for kk in val_metrics[k].keys():\n",
    "            #                             if not kk in refer_metrics[k].keys():\n",
    "            #                                 continue\n",
    "            #                             if (k == 'sn' and kk in ['Angle Mean', 'Angle Median']) or (\n",
    "            #                                     k == 'depth' and not kk.startswith('sigma')) or (kk == 'err'):\n",
    "            #                                 value = refer_metrics[k][kk] / val_metrics[k][kk]\n",
    "            #                             else:\n",
    "            #                                 value = val_metrics[k][kk] / refer_metrics[k][kk]\n",
    "            #                             value = value / len(list(set(val_metrics[k].keys()) & set(refer_metrics[k].keys())))\n",
    "            #                             new_value += value\n",
    "            # \n",
    "            #                 print('Best Value %.4f  New value: %.4f' % new_value)\n",
    "            # \n",
    "            #                 ## if results have improved, save these results and issue a checkpoint\n",
    "            # \n",
    "            #                 if (new_value > best_value):\n",
    "            #                     print('Previous best iter: %d, best_value: %.4f' % (best_iter, best_value), best_metrics)\n",
    "            #                     best_value = new_value\n",
    "            #                     best_metrics = val_metrics\n",
    "            #                     best_iter = current_iter\n",
    "            #                     environ.save_checkpoint('best', current_iter)\n",
    "            #                     print('New      best iter: %d, best_value: %.4f' % (best_iter, best_value), best_metrics)                         \n",
    "            #                     print('Best Value %.4f  New value: %.4f' % new_value)\n",
    "            #\n",
    "            #-----------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598255f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Warm-up:  validation - Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc7996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:41:10.772791Z",
     "start_time": "2021-12-15T20:41:05.690320Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# validation\n",
    "if should(current_iter, opt['train']['val_freq']):\n",
    "    print(f\"**  {timestring()}  START VALIDATION iteration: {current_iter} \")    \n",
    "\n",
    "    environ.eval()     # set to evaluation mode (train = False)\n",
    "    num_seg_class = opt['tasks_num_class'][opt['tasks'].index('seg')] if 'seg' in opt['tasks'] else -1\n",
    "    val_metrics = eval_dev(environ, \n",
    "                          val_loader, \n",
    "                          opt['tasks'], \n",
    "                          policy=False, \n",
    "                          num_train_layers=None, \n",
    "                          eval_iter = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8575d382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:37:44.423495Z",
     "start_time": "2021-12-15T20:37:44.400109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    for t_id, task in enumerate(environ.tasks):\n",
    "        task_key = f\"task{t_id+1}\"    \n",
    "        environ.print_loss(current_iter, start_time, val_metrics[task_key][\"classification_agg\"], title='validation')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932780d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:36:43.503203Z",
     "start_time": "2021-12-15T20:36:43.371900Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    environ.save_checkpoint('latest', current_iter)\n",
    "\n",
    "    print(f\"** {timestring()} - END VALIDATION iteration:  {current_iter} \")                \n",
    "    environ.train()    # set to training mode (train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81288543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:41:11.489480Z",
     "start_time": "2021-12-15T20:41:11.461278Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_metrics.keys()\n",
    "val_metrics['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebbdb4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T20:41:55.074366Z",
     "start_time": "2021-12-15T20:41:55.029329Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in val_metrics:\n",
    "    print(f'\\n {i} \\n -----------------')\n",
    "    print(val_metrics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04deb4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T22:26:36.573475Z",
     "start_time": "2021-12-12T22:26:36.455074Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for i in val_metrics.keys():\n",
    "#     print(i, type(val_metrics[i]))\n",
    "#     for k in val_metrics[i].keys():\n",
    "#         print(i,k, type(val_metrics[i][k]))\n",
    "#         if isinstance(val_metrics[i][k], pd.core.series.Series):\n",
    "#             print(f\"val_metrics[{i}][{k}] is a series\")\n",
    "#         elif isinstance(val_metrics[i][k], pd.core.frame.DataFrame):\n",
    "#             print(f\"val_metrics[{i}][{k}] is a dataframe\")        \n",
    "\n",
    "# s = val_metrics['task1']['classification_agg']\n",
    "# print(s)\n",
    "# print(s.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "176c979f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T18:19:18.285289Z",
     "start_time": "2022-01-27T18:19:18.236934Z"
    },
    "execution": {
     "iopub.execute_input": "2022-01-07T22:44:38.657578Z",
     "iopub.status.busy": "2022-01-07T22:44:38.657285Z",
     "iopub.status.idle": "2022-01-07T22:45:02.893150Z",
     "shell.execute_reply": "2022-01-07T22:45:02.891381Z",
     "shell.execute_reply.started": "2022-01-07T22:44:38.657539Z"
    },
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "##\n",
    "##  Iteration based method\n",
    "##\n",
    "# ##---------------------------------------------------------------     \n",
    "# ## part one: warm up\n",
    "# ##---------------------------------------------------------------\n",
    "# num_prints = 0\n",
    "# print(f\" Last iteration: {current_iter}  # of warm-up iterations to do:{opt['train']['warm_up_iters']} - Run  from {current_iter+1} to {stop_iter}\")\n",
    "# t0 = time.time()\n",
    "\n",
    "# with trange(current_iter+1, stop_iter+1 , initial = current_iter, total = stop_iter, position=0, leave= True, desc=\"training\") as t_warmup :\n",
    "    \n",
    "#     for current_iter in t_warmup:\n",
    "#         start_time = time.time()\n",
    "#         environ.train()\n",
    "#         batch = next(train_loader)    \n",
    "    \n",
    "# #         print_heading(f\" {timestring()} - WARMUP Training iter {current_iter}/{opt['train']['warm_up_iters']} \", verbose = False)\n",
    "\n",
    "#         environ.set_inputs(batch, train_loader.dataset.input_size)\n",
    "\n",
    "#         environ.optimize(opt['lambdas'], \n",
    "#                          is_policy=False, \n",
    "#                          flag='update_w', \n",
    "#                          verbose = False)\n",
    "        \n",
    "#         t_warmup.set_postfix({'curr_iter':current_iter, \n",
    "#                               'Loss': f\"{environ.losses['total']['total'].item():.4f}\" , \n",
    "#                               'row_ids':f\"{batch['row_id'][0]}-{batch['row_id'][-1]}\"})\n",
    "        \n",
    "# ## Using this causes displaying a zig zag pattern in the training losses \n",
    "# #         if should(current_iter, opt['train']['print_freq']):\n",
    "# #             environ.print_loss(current_iter, start_time, title = f\"[c]Warmup training : iteration: {current_iter}\", verbose = True)\n",
    "    \n",
    "#         ##--------------------------------------------------------------- \n",
    "#         # validation\n",
    "#         ##--------------------------------------------------------------- \n",
    "#         if should(current_iter, opt['train']['val_freq']):\n",
    "#             environ.print_loss(current_iter, start_time, title = f\"[e]Weight training epoch: iteration: {current_iter}\", verbose = True)\n",
    "\n",
    "#             val_metrics = environ.evaluate(\n",
    "#                                    val_loader, \n",
    "#                                    opt['tasks'], \n",
    "#                                    is_policy=False, \n",
    "#                                    num_train_layers=None,\n",
    "#                                    eval_iters = eval_iters, \n",
    "#                                    progress=True,\n",
    "#                                    leave = False,\n",
    "#                                    verbose = False)\n",
    "\n",
    "#             environ.print_metrics(current_iter, start_time, title='validation')\n",
    "#             environ.save_checkpoint('warmup', current_iter)\n",
    "            \n",
    "#             print_metrics_cr(current_iter, time.time() - t0, None, environ.val_metrics, num_prints)\n",
    "#             num_prints += 1            \n",
    "#             t0 = time.time()\n",
    "#             print()     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573a1c4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Save Best Checkpoint Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4725f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "            #-----------------------------------------------------------------------------------------------------------------------\n",
    "            #  Save Best Checkpoint Code\n",
    "            #-----------------------------------------------------------------------------------------------------------------------\n",
    "            #\n",
    "            #            #----------------------------------------------------------------------------------------------\n",
    "            #            # if number of iterations completed after the warm up phase is greater than the number of \n",
    "            #            # (weight/policy alternations) x (cirriculum speed) x (number of layers to be policy trained)\n",
    "            #            #\n",
    "            #            # check metrics for improvement, and issue a checkpoint if necessary\n",
    "            #            #----------------------------------------------------------------------------------------------\n",
    "            # \n",
    "            #             if current_iter - opt['train']['warm_up_iters'] >= num_blocks * opt['curriculum_speed'] * \\\n",
    "            #                     (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate']):\n",
    "            #                 new_value = 0\n",
    "            #                 print(f\"  {current_iter - opt['train']['warm_up_iters']} IS GREATER THAN \"\n",
    "            #                        f\" {num_blocks * opt['curriculum_speed'] * (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate'])} -- \"\n",
    "            #                        f\"  evaluate progress and make checkpoint if necessary.\" )            \n",
    "            # \n",
    "            #                 ## compare validation metrics against reference metrics.\n",
    "            #                 \n",
    "            #                 for k in refer_metrics.keys():\n",
    "            #                     if k in val_metrics.keys():\n",
    "            #                         for kk in val_metrics[k].keys():\n",
    "            #                             if not kk in refer_metrics[k].keys():\n",
    "            #                                 continue\n",
    "            #                             if (k == 'sn' and kk in ['Angle Mean', 'Angle Median']) or (\n",
    "            #                                     k == 'depth' and not kk.startswith('sigma')) or (kk == 'err'):\n",
    "            #                                 value = refer_metrics[k][kk] / val_metrics[k][kk]\n",
    "            #                             else:\n",
    "            #                                 value = val_metrics[k][kk] / refer_metrics[k][kk]\n",
    "            #                             value = value / len(list(set(val_metrics[k].keys()) & set(refer_metrics[k].keys())))\n",
    "            #                             new_value += value\n",
    "            # \n",
    "            #                 print('Best Value %.4f  New value: %.4f' % new_value)\n",
    "            # \n",
    "            #                 ## if results have improved, save these results and issue a checkpoint\n",
    "            # \n",
    "            #                 if (new_value > best_value):\n",
    "            #                     print('Previous best iter: %d, best_value: %.4f' % (best_iter, best_value), best_metrics)\n",
    "            #                     best_value = new_value\n",
    "            #                     best_metrics = val_metrics\n",
    "            #                     best_iter = current_iter\n",
    "            #                     environ.save_checkpoint('best', current_iter)\n",
    "            #                     print('New      best iter: %d, best_value: %.4f' % (best_iter, best_value), best_metrics)                         \n",
    "            #                     print('Best Value %.4f  New value: %.4f' % new_value)\n",
    "            #\n",
    "            #-----------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a88ce58",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Policy Training Dev Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d7e33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T06:36:24.639972Z",
     "start_time": "2021-12-18T06:36:24.620024Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(f\" current iter                                 : {current_iter} \\n\"\n",
    "#       f\" opt['train']['warm_up_iters']                : {opt['train']['warm_up_iters']} \\n\"\n",
    "#       f\" num_blocks                                   : {num_blocks} \\n\"\n",
    "#       f\" opt['curriculum_speed']                      : {opt['curriculum_speed']}\\n\"\n",
    "#       f\" opt['train']['weight_iter_alternate']        : {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#       f\" opt['train']['alpha_iter_alternate']         : {opt['train']['alpha_iter_alternate']}\\n\"\n",
    "#       f\" alpha_iter_alternate + weight_iter_alternate : {opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate']}\\n\"\n",
    "#       f\" num_blocks * curriculum_speed * (alpha_iter_alternate + weight_iter_alternate): \\\n",
    "#           {num_blocks * opt['curriculum_speed'] * (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate'])} \\n\"\n",
    "#       f\" IF {current_iter - opt['train']['warm_up_iters']} IS GREATER THAN  ??\"\n",
    "#       f\" {num_blocks * opt['curriculum_speed'] * (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b42a1c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T06:36:36.364353Z",
     "start_time": "2021-12-18T06:36:36.341535Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(f\" task1_logits: {environ.networks['mtl-net'].task1_logits} \\n\")\n",
    "# print(f\" task2_logits: {environ.networks['mtl-net'].task2_logits} \\n\")\n",
    "# print(f\" task3_logits: {environ.networks['mtl-net'].task3_logits} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc47c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T02:07:18.061296Z",
     "start_time": "2021-12-20T02:07:18.038742Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(current_iter_a , opt['train']['alpha_iter_alternate'],flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f3be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T02:07:19.091639Z",
     "start_time": "2021-12-20T02:07:19.060936Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##---------------------------------------------------------------     \n",
    "## part one: warm up\n",
    "##--------------------------------------------------------------- \n",
    "# print(current_iter_a , opt['train']['alpha_iter_alternate'],flag)\n",
    "# stop_iter = current_iter_a +  opt['train']['alpha_iter_alternate']\n",
    "# print(f\" Run iteration {current_iter_a+1} to {stop_iter+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd16c4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T02:16:10.956462Z",
     "start_time": "2021-12-20T02:16:10.915819Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(current_iter_a, stop_iter, flag)\n",
    "# print(current_iter_a , opt['train']['alpha_iter_alternate'],flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe17e6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if flag == 'update_alpha':\n",
    "\n",
    "    stop_iter = current_iter_a +  opt['train']['alpha_iter_alternate']\n",
    "    print(f\" Current Alpha iteration {current_iter_a} - Run  from {current_iter_a+1} to {stop_iter+1}\")\n",
    "    \n",
    "    with tnrange(current_iter_a+1, stop_iter+1 , initial = current_iter_a+1, total = stop_iter+1, position=0, leave= True, desc=\"weight training\") as t :\n",
    "        for current_iter_a in t:    \n",
    "            current_iter += 1\n",
    " \n",
    "            batch_idx_a, batch = next(batch_enumerator2)\n",
    "            environ.set_inputs(batch, train2_loader.dataset.input_size)\n",
    "\n",
    "            if batch_idx_a == len(train2_loader):\n",
    "                print_dbg(f\" Re-enumerate train2_loader  batch_idx_a: {batch_idx_a}   len(train2_loader) = {len(train2_loader)}\", verbose=False)                \n",
    "                batch_enumerator2 = enumerate(train2_loader,1)        \n",
    "                  \n",
    "            print_heading(f\"{timestring()} - ENVIRON.OPTIMIZE()    flag: {flag}    current_iter: {current_iter}   \\n\"\n",
    "                          f\" current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "                          f\" current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \\n\"\n",
    "                          f\" is_policy: {opt['policy']}   num_train_layers: {num_train_layers}  hard_sampling: {opt['train']['hard_sampling']}\\n\"\n",
    "                          f\" is_curriculum: {opt['is_curriculum']}     curriculum_speed: {opt['curriculum_speed']}   p_epoch: {p_epoch}\"\n",
    "                          , verbose = False) \n",
    "    \n",
    "            if opt['is_curriculum']:\n",
    "                num_train_layers = (p_epoch // opt['curriculum_speed']) + 1\n",
    "            else:\n",
    "                num_train_layers = None\n",
    "\n",
    "            print_dbg(f\" num_train_layers  : {num_train_layers}\", verbose = False)\n",
    "\n",
    "\n",
    "            environ.optimize(opt['lambdas'], \n",
    "                             is_policy=opt['policy'], \n",
    "                             flag=flag, \n",
    "                             num_train_layers=num_train_layers,\n",
    "                             hard_sampling=opt['train']['hard_sampling'],\n",
    "                             verbose = False)\n",
    "\n",
    "            if should(current_iter, opt['train']['print_freq']):\n",
    "                environ.print_loss_2(current_iter, start_time, verbose=True)\n",
    "                environ.resize_results()\n",
    "                # environ.visual_policy(current_iter)\n",
    "\n",
    "            print_heading(f\"{timestring()} - CONTINUE ALPHA TRAINING    current_iter: {current_iter}\\n\"\n",
    "                          f\"{' ':15s} current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "                          f\"{' ':15s} current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \", \n",
    "                          verbose = False )      \n",
    "    \n",
    "    ## if (current_iter_a % alpha_iter_alternate) == 0 \n",
    "    if should(current_iter_a, opt['train']['alpha_iter_alternate']):\n",
    "        print_dbg(f\"** Switch training to update_weight\")                \n",
    "        print_heading(f\"{timestring()} - SWITCH TO WEIGHT TRAINING  urrent_iter: {current_iter}\\n\"\n",
    "                      f\"{' ':15s} current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "                      f\"{' ':15s} current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \",\n",
    "                      verbose = True )       \n",
    "        \n",
    "        flag = 'update_w'\n",
    "        environ.fix_alpha()\n",
    "        environ.free_w(opt['fix_BN'])\n",
    "        environ.decay_temperature()\n",
    "\n",
    "        # print the distribution\n",
    "        dists = environ.get_policy_prob()\n",
    "\n",
    "        print(np.concatenate(dists, axis=-1))\n",
    "        p_epoch += 1\n",
    "        print(f\"** p_epoch incremented: {p_epoch}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f9426d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T04:06:20.995174Z",
     "start_time": "2021-12-21T04:06:20.972230Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(current_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cfac1c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-31T12:59:06.764Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(f\" task1_logits: \\n {environ.networks['mtl-net'].task1_logits.detach().cpu().numpy()} \\n\")\n",
    "# print(f\" task2_logits: \\n {environ.networks['mtl-net'].task2_logits.detach().cpu().numpy()} \\n\")\n",
    "# print(f\" task3_logits: \\n {environ.networks['mtl-net'].task3_logits.detach().cpu().numpy()} \\n\")\n",
    "# print(f\" task1 softmax: \\n {softmax(environ.networks['mtl-net'].task1_logits.detach().cpu().numpy(), axis = -1)} \\n\")\n",
    "# print(f\" task2 softmax: \\n {softmax(environ.networks['mtl-net'].task2_logits.detach().cpu().numpy(), axis = -1)} \\n\")\n",
    "# print(f\" task3 softmax: \\n {softmax(environ.networks['mtl-net'].task3_logits.detach().cpu().numpy(), axis = -1)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995815db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T00:06:36.002509Z",
     "start_time": "2021-12-17T00:06:35.981793Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for i in [1,2,3]:\n",
    "#     task_pred = f\"task{i}_pred\"\n",
    "#     task_logits = f\"task{i}_logits\"\n",
    "#     policy_attr = f\"policy{i}\"\n",
    "#     logits_attr = f\"logit{i}\"\n",
    "#     print_heading(f\"{task_pred}\")\n",
    "#     print(getattr(environ, task_pred))\n",
    "#     print(policy_attr)\n",
    "#     print(getattr(environ, policy_attr)) \n",
    "#     print(logits_attr)\n",
    "#     print(getattr(environ, logits_attr)) \n",
    "#     print(task_logits)\n",
    "#     print(getattr(environ.networks['mtl-net'], task_logits)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8bdfb5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Weight Training Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ac5304",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Weight training - prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b0346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T23:40:00.014577Z",
     "start_time": "2021-12-20T23:39:59.990525Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# arch_parms = environ.networks['mtl-net'].named_parameters()\n",
    "# print(arch_parms)\n",
    "# for name, parm in arch_parms:\n",
    "#     print(name, '    ',parm.requires_grad)\n",
    "# print_underline('MTL3_Dev Policys', verbose = True)\n",
    "# for i in   environ.networks['mtl-net'].policys:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d09a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T22:57:34.590953Z",
     "start_time": "2021-12-21T22:57:34.234886Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_heading(f\"** {timestring()} - Training current iteration {current_iter}  flag: {flag} \", verbose = True)    \n",
    "\n",
    "current_iter_w = 0 \n",
    "current_iter_a = 0 \n",
    "batch_idx_a = 0 \n",
    "batch_idx_w = 0 \n",
    "\n",
    "if flag_warmup:\n",
    "    print_heading(f\"** Set optimizer and scheduler to policy_learning = True\", verbose = True)\n",
    "    environ.define_optimizer(policy_learning=True)\n",
    "    environ.define_scheduler(policy_learning=True)\n",
    "    flag_warmup = False\n",
    "\n",
    "if current_iter == opt['train']['warm_up_iters']:\n",
    "    print_heading(f\"** Switch from Warm Up training to Alternate training Weights & Policy \\n\"\n",
    "                  f\"   Take checkpoint and block gradient flow through Policy net\", verbose=True)\n",
    "    environ.save_checkpoint('warmup', current_iter)\n",
    "    environ.fix_alpha()\n",
    "    \n",
    "# batch_enumerator1 = enumerate(train1_loader,1)  \n",
    "# batch_enumerator2 = enumerate(train2_loader,1)  \n",
    "\n",
    "train_total_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40214d23",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Weight training - main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a34bb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T22:57:57.069633Z",
     "start_time": "2021-12-21T22:57:57.026843Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"opt['train']['print_freq']         {opt['train']['print_freq']}\")\n",
    "print(f\"opt['train']['hard_sampling']      {opt['train']['hard_sampling']}\")\n",
    "print(f\"opt['policy']                      {opt['policy']}\")\n",
    "print(f\"opt['tasks']                       {opt['tasks']}\")\n",
    "print(f\"weight_iter_alternate:             {opt['train']['weight_iter_alternate']}\")\n",
    "print(f\"alpha_iter_alternate :             {opt['train']['alpha_iter_alternate']}\")\n",
    "print(f\"current_iter                       {current_iter  }\")\n",
    "print(f\"current_iter_w                     {current_iter_w}\")\n",
    "print(f\"current_iter_a                     {current_iter_a}\")\n",
    "print(f\"batch_idx_w                        {batch_idx_w}\")\n",
    "print(f\"flag                               {flag          }\")\n",
    "print(f\"train_total_epochs                 {train_total_epochs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ecd56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T22:58:10.493069Z",
     "start_time": "2021-12-21T22:58:10.469631Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##---------------------------------------------------------------     \n",
    "## Weight / Policy Training\n",
    "##--------------------------------------------------------------- \n",
    "# stop_iter = current_iter_w +  opt['train']['weight_iter_alternate']\n",
    "# print(f\" Current Weight iteration {current_iter_w} - Run  from {current_iter_w+1} to {stop_iter+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4127b354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T22:58:12.219746Z",
     "start_time": "2021-12-21T22:58:12.193318Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca1d55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T22:58:13.757096Z",
     "start_time": "2021-12-21T22:58:13.731942Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with tnrange(start_iter_t , stop_iter_t  , initial = start_iter_t , total = stop_iter_t, position=0, leave= True, desc=\"master\") as t :\n",
    "# with tqdm_notebook(total=train_total_epochs) as t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e57d06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T18:50:23.014384Z",
     "start_time": "2021-12-21T18:50:22.955398Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8965abac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T23:08:28.021068Z",
     "start_time": "2021-12-21T22:59:25.316087Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "current_epoch = 0\n",
    "main_iter_ctr = 0 \n",
    "verbose = False\n",
    "t = tqdm(total=train_total_epochs, desc=f\" Alternate Weight/Policy training\")\n",
    "\n",
    "while current_epoch < train_total_epochs:\n",
    "    current_epoch+=1\n",
    "    t.update(1)\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # Train & Update the network weights\n",
    "    #-----------------------------------------\n",
    "    if flag == 'update_w':\n",
    "        current_iter_w  = 0 \n",
    "        stop_iter_w =   opt['train']['weight_iter_alternate']\n",
    "\n",
    "        with trange(+1, stop_iter_w+1 , initial = current_iter_w, total = stop_iter_w, \n",
    "                     position=0, leave= False, desc=f\"Epoch {current_epoch} weight training\") as t_weights :\n",
    "            for current_iter_w in t_weights:    \n",
    "                current_iter += 1\n",
    "\n",
    "                start_time = time.time()\n",
    "                environ.train()\n",
    "                \n",
    "#                 if batch_idx_w == len(train1_loader):\n",
    "#                     print_dbg(f\"  Reenumerate train1_loader -  index_w: {batch_idx_w}   len(train1_loader) = {len(train1_loader)} \", verbose)\n",
    "#                     batch_enumerator1 = enumerate(train1_loader,1)    \n",
    "                    \n",
    "                batch = next(train1_loader)\n",
    "                environ.set_inputs(batch, train1_loader.dataset.input_size)\n",
    "\n",
    "                ##----------------------------------------------------------------------\n",
    "                ## Set number of layers to train based on cirriculum_speed \n",
    "                ## and p_epoch (number of epochs of policy training)\n",
    "                ## When curriculum_speed == 3, a num_train_layers is incremented \n",
    "                ## after completion of every 3 policy training epochs\n",
    "                ##----------------------------------------------------------------------\n",
    "                if opt['is_curriculum']:\n",
    "                    num_train_layers = p_epoch // opt['curriculum_speed'] + 1\n",
    "                else:\n",
    "                    num_train_layers = None\n",
    "\n",
    "\n",
    "#                 print_heading(f\"{timestring()} CALL ENVIRON.OPTIMIZE()    current_iter: {current_iter}     flag: {flag}\\n\"\n",
    "#                       f\"{' ':10s} current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#                       f\"{' ':10s} current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \\n\"                          \n",
    "#                       f\"{' ':10s} is_policy: {opt['policy']}     p_epoch: {p_epoch}       num_train_layers: {num_train_layers}\", verbose = False) \n",
    "\n",
    "                environ.optimize(opt['lambdas'], \n",
    "                                 is_policy=opt['policy'], \n",
    "                                 flag=flag, \n",
    "                                 num_train_layers=num_train_layers,\n",
    "                                 hard_sampling=opt['train']['hard_sampling'],\n",
    "                                 verbose = False)\n",
    "\n",
    "                t_weights.set_postfix({'iteration': current_iter, 'Loss': f\"{environ.losses['total']['total'].item():.4f}\" , \n",
    "                                       'row_ids':f\"{batch['row_id'][0]}-{batch['row_id'][-1]}\"})\n",
    "                \n",
    "                if should(current_iter, opt['train']['print_freq']):\n",
    "                    environ.print_loss(current_iter, start_time, title = \"Weight training iteration\", verbose = True)\n",
    "                    environ.resize_results()\n",
    "\n",
    "#                 print_heading(f\"{timestring()} - CONTINUE WEIGHT TRAINING   current_iter: {current_iter}\\n\"\n",
    "#                   f\" current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#                   f\" current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']}\",\n",
    "#                   verbose = False)        \n",
    "\n",
    "        #-------------------------------------------------------\n",
    "        # validation process\n",
    "        #------------------------------------------------------- \n",
    "\n",
    "#         if should(current_iter_w, opt['train']['weight_iter_alternate']): \n",
    "\n",
    "        if (current_iter_w >= stop_iter_w):\n",
    "            environ.eval()\n",
    "            print_dbg(\"++ Weight Training Validation  and then Switch to update_alpha\", verbose = False)\n",
    "\n",
    "            val_metrics = eval_dev(environ, \n",
    "                                  val_loader, \n",
    "                                  opt['tasks'], \n",
    "                                  policy=opt['policy'],\n",
    "                                  num_train_layers=num_train_layers, \n",
    "                                  hard_sampling=opt['train']['hard_sampling'],\n",
    "                                  eval_iter = -1)        \n",
    "\n",
    "            if (verbose):\n",
    "                for t_id, task in enumerate(environ.tasks):\n",
    "                    task_key = f\"task{t_id+1}\"    \n",
    "                    environ.print_metrics(current_iter, start_time, val_metrics[task_key][\"classification_agg\"], title='validation', verbose = verbose)        \n",
    "\n",
    "            environ.save_checkpoint('latest', current_iter)\n",
    "\n",
    "            #----------------------------------------------------------------------------------------------\n",
    "            # if number of iterations completed after the warm up phase is greater than the number of \n",
    "            # (weight/policy alternations) x (cirriculum speed) x (number of layers to be policy trained)\n",
    "            #\n",
    "            # check metrics for improvement, and issue a checkpoint if necessary\n",
    "            #----------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "            if current_iter - opt['train']['warm_up_iters'] >= num_blocks * opt['curriculum_speed'] * \\\n",
    "                    (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate']):\n",
    "                new_value = 0\n",
    "#                 print_heading(f\"  evaluate progress and make checkpoint if necessary.\" , verbose = True)\n",
    "#                 print(f\" current iter                                 : {current_iter} \\n\"\n",
    "#                       f\" opt['train']['warm_up_iters']                : {opt['train']['warm_up_iters']} \\n\"\n",
    "#                       f\" num_blocks                                   : {num_blocks} \\n\"\n",
    "#                       f\" opt['curriculum_speed']                      : {opt['curriculum_speed']}\\n\"\n",
    "#                       f\" opt['train']['weight_iter_alternate']        : {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#                       f\" opt['train']['alpha_iter_alternate']         : {opt['train']['alpha_iter_alternate']}\\n\"\n",
    "#                       f\" alpha_iter_alternate + weight_iter_alternate : {opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate']}\\n\"\n",
    "#                       f\" num_blks * curriculum_speed * (alpha_alternate + weight_alternate): \"\n",
    "#                       f\" {num_blocks * opt['curriculum_speed'] * (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate'])} \\n\"\n",
    "\n",
    "                print(f\"  {current_iter - opt['train']['warm_up_iters']} IS GREATER THAN \"\n",
    "                       f\" {num_blocks * opt['curriculum_speed'] * (opt['train']['weight_iter_alternate'] + opt['train']['alpha_iter_alternate'])} -- \"\n",
    "                       f\"  evaluate progress and make checkpoint if necessary.\" )            \n",
    "#               ## compare validation metrics against reference metrics.\n",
    "\n",
    "#                 for k in refer_metrics.keys():\n",
    "#                     if k in val_metrics.keys():\n",
    "#                         for kk in val_metrics[k].keys():\n",
    "#                             if not kk in refer_metrics[k].keys():\n",
    "#                                 continue\n",
    "#                             if (k == 'sn' and kk in ['Angle Mean', 'Angle Median']) or (\n",
    "#                                     k == 'depth' and not kk.startswith('sigma')) or (kk == 'err'):\n",
    "#                                 value = refer_metrics[k][kk] / val_metrics[k][kk]\n",
    "#                             else:\n",
    "#                                 value = val_metrics[k][kk] / refer_metrics[k][kk]\n",
    "#                             value = value / len(list(set(val_metrics[k].keys()) & set(refer_metrics[k].keys())))\n",
    "#                             new_value += value\n",
    "\n",
    "#                 print('Best Value %.4f  New value: %.4f' % new_value)\n",
    "\n",
    "                # if results have improved, save these results and issue a checkpoint\n",
    "\n",
    "#                 if (new_value > best_value):\n",
    "#                     print('Previous best iter: %d, best_value: %.4f' % (best_iter, best_value), best_metrics)\n",
    "#                     best_value = new_value\n",
    "#                     best_metrics = val_metrics\n",
    "#                     best_iter = current_iter\n",
    "#                     environ.save_checkpoint('best', current_iter)\n",
    "#                     print('New      best iter: %d, best_value: %.4f' % (best_iter, best_value), best_metrics)                         \n",
    "#                     print('Best Value %.4f  New value: %.4f' % new_value)\n",
    "\n",
    "                # if results have improved, save these results and issue a checkpoint   \n",
    "\n",
    "            environ.train()\n",
    "            #-------------------------------------------------------\n",
    "            # END validation process\n",
    "            #-------------------------------------------------------       \n",
    "            print_heading(f\"{timestring()} - SWITCH TO ALPHA TRAINING    current_iter: {current_iter}\\n\"\n",
    "              f\" current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "              f\" current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']}\",\n",
    "              verbose = False)       \n",
    "            flag = 'update_alpha'\n",
    "            environ.fix_w()\n",
    "            environ.free_alpha()\n",
    "        #-------------------------------------------------------\n",
    "        # end validation process\n",
    "        #-------------------------------------------------------               \n",
    "\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # Train & Update the  policy \n",
    "    #-----------------------------------------\n",
    "    if flag == 'update_alpha':\n",
    "        current_iter_a = 0\n",
    "        stop_iter_a = opt['train']['alpha_iter_alternate']\n",
    "\n",
    "        with trange( +1, stop_iter_a+1 , initial = 0, total = stop_iter_a, \n",
    "                     position=0, leave= False, desc=f\"Epoch {current_epoch} policy training\") as t_policy :\n",
    "            for current_iter_a in t_policy:    \n",
    "                current_iter += 1\n",
    "\n",
    "#                 batch_idx_a, batch = next(batch_enumerator2)\n",
    "                batch = next(train2_loader)\n",
    "                environ.set_inputs(batch, train2_loader.dataset.input_size)\n",
    "\n",
    "#                 if batch_idx_a == len(train2_loader):\n",
    "#                     print_dbg(f\" Re-enumerate train2_loader  batch_idx_a: {batch_idx_a}   len(train2_loader) = {len(train2_loader)}\", verbose=False)                \n",
    "#                     batch_enumerator2 = enumerate(train2_loader,1)        \n",
    "\n",
    "#                 print_heading(f\"{timestring()} - ENVIRON.OPTIMIZE()    flag: {flag}    current_iter: {current_iter}   \\n\"\n",
    "#                               f\" current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#                               f\" current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \\n\"\n",
    "#                               f\" is_policy: {opt['policy']}   num_train_layers: {num_train_layers}  hard_sampling: {opt['train']['hard_sampling']}\\n\"\n",
    "#                               f\" is_curriculum: {opt['is_curriculum']}     curriculum_speed: {opt['curriculum_speed']}   p_epoch: {p_epoch}\"\n",
    "#                               , verbose = False) \n",
    "\n",
    "                if opt['is_curriculum']:\n",
    "                    num_train_layers = (p_epoch // opt['curriculum_speed']) + 1\n",
    "                else:\n",
    "                    num_train_layers = None\n",
    "\n",
    "                print_dbg(f\" num_train_layers  : {num_train_layers}\", verbose = False)\n",
    "\n",
    "\n",
    "                environ.optimize(opt['lambdas'], \n",
    "                                 is_policy=opt['policy'], \n",
    "                                 flag=flag, \n",
    "                                 num_train_layers=num_train_layers,\n",
    "                                 hard_sampling=opt['train']['hard_sampling'],\n",
    "                                 verbose = False)\n",
    "                \n",
    "                t_policy.set_postfix({'iteration': current_iter, 'Loss': f\"{environ.losses['total']['total'].item():.4f}\" , \n",
    "                                      'row_ids':f\"{batch['row_id'][0]}-{batch['row_id'][-1]}\"})\n",
    "                \n",
    "                if should(current_iter, opt['train']['print_freq']):\n",
    "                    environ.print_loss(current_iter, start_time, title = \"Policy training iteration\", verbose=True)\n",
    "                    environ.resize_results()\n",
    "                    # environ.visual_policy(current_iter)\n",
    "\n",
    "#                 print_heading(f\"{timestring()} - CONTINUE ALPHA TRAINING    current_iter: {current_iter}\\n\"\n",
    "#                               f\"{' ':15s} current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#                               f\"{' ':15s} current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \", \n",
    "#                               verbose = False )      \n",
    "\n",
    "        ## if (current_iter_a % alpha_iter_alternate) == 0 \n",
    "#         if should(current_iter_a, opt['train']['alpha_iter_alternate']):\n",
    "#         print(f\" policy loop ended - current_iter_a: {current_iter_a}   stop_iter_a: {stop_iter_a}\")\n",
    "        if( current_iter_a >= stop_iter_a):            \n",
    "#             print_heading(f\"{timestring()} - SWITCH TO WEIGHT TRAINING  urrent_iter: {current_iter}\\n\"\n",
    "#                           f\"{' ':15s} current_iter_w: {current_iter_w}  batch_idx_w:{batch_idx_w}   weight_iter_alternate: {opt['train']['weight_iter_alternate']}\\n\"\n",
    "#                           f\"{' ':15s} current_iter_a: {current_iter_a}  batch_idx_a:{batch_idx_a}   alpha_iter_alternate : {opt['train']['alpha_iter_alternate']} \",\n",
    "#                           verbose = False )       \n",
    "\n",
    "            flag = 'update_w'\n",
    "            environ.fix_alpha()\n",
    "            environ.free_w(opt['fix_BN'])\n",
    "            environ.decay_temperature()\n",
    "\n",
    "            # print the distribution\n",
    "            print_dbg(np.concatenate(environ.get_policy_prob(), axis=-1), verbose = False)\n",
    "            \n",
    "            p_epoch += 1\n",
    "            print_dbg(f\"** p_epoch incremented: {p_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39455ec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T23:20:09.766802Z",
     "start_time": "2021-12-21T23:20:09.716093Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"{opt['train']['Lambda_sharing']:.5e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80f91a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T21:26:17.162189Z",
     "start_time": "2021-12-21T21:26:16.777249Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Previous best iter: %d, best_value: %.4f' % (best_iter, best_value))\n",
    "print(best_metrics)\n",
    "best_value = new_value\n",
    "best_metrics = val_metrics\n",
    "best_iter = current_iter\n",
    "environ.save_checkpoint('best', current_iter)\n",
    "print('New best iter : %d, best_value: %.4f \\n' % (best_iter, best_value))                         \n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb17fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T21:27:15.488947Z",
     "start_time": "2021-12-21T21:27:15.382938Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# environ.losses['tasks'] = {'total' : torch.tensor(0.0, device  = environ.device, dtype=torch.float64)}\n",
    "# environ.device\n",
    "\n",
    "# print(val_metrics)\n",
    "pp.pprint(environ.losses)\n",
    "# environ.print_loss_2(current_iter, start_time, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt-gpu",
   "language": "python",
   "name": "pyt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "399px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
